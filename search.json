[{"title":"Python3 json序列化","url":"/posts/2018/08/05/64067/","content":"json.dumps() 序列化‌JSON序列化‌是指将对象转化为字节序列的过程。序列化后的数据可以用于在网络上传输或保存到硬盘上。JSON是一种轻量级的数据交换格式，它使用人类可读的文本来表示数据，通常用于数据交换和存储。\njson.dumps(): python数据类型转化为json字符串比如: 将字符串，字典，列表类型的数据转换成json字符串类型的数据\nimport jsondata_dict = &#123;&quot;name&quot;: &quot;jack Ma&quot;, &quot;QQ&quot;: [&quot;12345&quot;, &quot;abcd&quot;]&#125;data_json = json.dumps(data_dict)print(type(data_json), data_dict)# &lt;class &#x27;str&#x27;&gt; &#123;&#x27;name&#x27;: &#x27;jack Ma&#x27;, &#x27;QQ&#x27;: [&#x27;12345&#x27;, &#x27;abcd&#x27;]&#125;data_list = [1, 2, 3, 4]data_json = json.dumps(data_list)print(type(data_json), data_json)# &lt;class &#x27;str&#x27;&gt; [1, 2, 3, 4]\n\njson.loads() 反序列化json.loads(): json字符串转化为python数据类型比如:将json字符串类型的数据转换成列表，字典，字符串类型数据\nimport jsondata_json_str = &#x27;&#123;&quot;name&quot;:&quot;jack ma&quot;, &quot;QQ&quot;:[&quot;12345&quot;,&quot;abcde&quot;]&#125;&#x27;data_dict = json.loads(data_json_str)print(type(data_dict), data_dict)# &lt;class &#x27;dict&#x27;&gt; &#123;&#x27;name&#x27;: &#x27;jack ma&#x27;, &#x27;QQ&#x27;: [&#x27;12345&#x27;, &#x27;abcde&#x27;]&#125;data_json_str = &#x27;[1,2,3,4]&#x27;data_list = json.loads(data_json_str)print(type(data_list), data_list)# &lt;class &#x27;list&#x27;&gt; [1, 2, 3, 4]\n\njson.load() 和 json.dump()json.load() : 包含json的类文件对象转化为python数据类型；json.dump(): python数据类型转化为包含json的类文件对象；\n举例1\nimport jsonfile_json = &quot;data_list.json&quot;data_list = [&#123;&quot;city&quot;: &quot;nanjing&quot;&#125;, &#123;&quot;name&quot;: &quot;zhu&quot;&#125;]# 写入json文件with open(file_json, &quot;w&quot;) as fw:    json.dump(data_list, fw, ensure_ascii=False)# 从json文件读出with open(file_json) as f:    get_data_list = json.load(f)    print(type(get_data_list), get_data_list)# &lt;class &#x27;list&#x27;&gt; [&#123;&#x27;city&#x27;: &#x27;nanjing&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;zhu&#x27;&#125;]\n\n\n举例2\nimport jsonfile_json = &quot;data_list.json&quot;data_dict = &#123;&quot;city&quot;: &quot;nanjing&quot;, &quot;name&quot;: &quot;ma&quot;&#125;with open(file_json, &quot;w&quot;) as fw:    json.dump(data_dict, fw, ensure_ascii=False)with open(file_json) as f:    get_data_dict = json.load(f)    print(type(get_data_dict), get_data_dict)# &lt;class &#x27;dict&#x27;&gt; &#123;&#x27;city&#x27;: &#x27;nanjing&#x27;, &#x27;name&#x27;: &#x27;ma&#x27;&#125;\n\n注: json文件为防出现中文乱码：ensure_ascii&#x3D;False\n什么是类文件对象？\n具有read()或者write()方法的对象就是类文件对象，file = open(&quot;listStr.json&quot;, &quot;w&quot;) 中  file 就是类文件对象\n\n应用：将txt文件转为json文件demo1：将txt文本读取到，然后转为json形式，再写入json格式文件。\nimport jsonfile_txt = &#x27;test.txt&#x27;file_json = &#x27;test.json&#x27;with open(file_txt, &#x27;rb&#x27;) as fr:    content = fr.read().decode(&#x27;utf8&#x27;)    print(content)  # strwith open(file_json, &#x27;w&#x27;) as fw:    content_json = json.dumps(content)    fw.write(content_json)    \ndemo2：如果是将一个json文件的内容写到另一个json文件，先将json文本读取，再直接写入另一个json格式文本。\nimport jsonfile = &#x27;test.json&#x27;# file = &#x27;test.txt&#x27;newfile = &#x27;newtest.json&#x27;with open(file, &#x27;rb&#x27;) as fr:    if file.endswith(&#x27;json&#x27;):        content = json.load(fr)    elif file.endswith(&#x27;txt&#x27;):        content = fr.read().decode(&#x27;utf8&#x27;)    print(type(content), content)  # strwith open(newfile, &#x27;w&#x27;) as fw:    json.dump(content, fw)\n","categories":["技术","Python"],"tags":["Python","json"]},{"title":"python词云安装报错解决","url":"/posts/2018/07/16/19729/","content":"环境：windows10\n直接用pip install wordcloud 可能会报错，会有文件required的问题:\nerror: Microsoft Visual C++ 14.0 is required. Get it with “Microsoft Visual C++ Build Tools”: http://landinghub.visualstudio.com/visual-cpp-build-tools\n解决办法是从报错信息入手 , 分析报错中的每一句话 , 根据响应的语句，找对应的解决方案。\n方法一\n下载安装 Visual Studio Installer\n方法二\ngithub 上下载：Releases · amueller&#x2F;word_cloud (github.com)\n","categories":["技术"],"tags":["Python","FixBug"]},{"title":"Python3 range()","url":"/posts/2018/08/15/54133/","content":"在 Python3.6 中，range() 函数返回一个可迭代的范围对象，范围类型表示不可变的数字序列，一般用在 for 循环中。\nrange() 的返回值不是列表，是需要通过转换类型才能变成列表。\nPython 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; range(4)range(0, 4)&gt;&gt;&gt; a = range(4)&gt;&gt;&gt; type(a)&lt;class &#x27;range&#x27;&gt;&gt;&gt;&gt; b = list(range(4))&gt;&gt;&gt; b[0, 1, 2, 3]&gt;&gt;&gt; type(b)&lt;class &#x27;list&#x27;&gt;\n\n使用方式: range(start, stop[, step]) ：\n\nstart: 计数从 start 开始。默认是从 0 开始。range(4) 相当于 range(0,4) \nstop: 计数到 stop 结束，不包括 stop。range(0,4) 转成 list 后表示 [0, 1, 2, 3]\nstep：步长，默认为1。range(0,3)  相当于 range(0, 3, 1)\n\nrange函数逆序有两种实现方式:\n1 . 先创建一个可迭代对象，后对其中的元素进行逆序操作。\na = range(6)  # list(a): [0, 1, 2, 3, 4, 5]new = []for i in reversed(a):    new.append(i)print(new)  # [5, 4, 3, 2, 1, 0]\n\n2 . 利用range()函数特点来进行逆序。\nnew =[]for i in range(5, -1, -1):    new.append(i)print(new)  # [5, 4, 3, 2, 1, 0]\nrange(a,b)，函数”包前不包后”，只包含a，不包含b，默认步长为1。\n\n来看一个比较难的问题:删除某个list里面的重复元素,用sort进行排序,要求从列表list的最后一个元素开始判断a&#x3D;[1,2,4,2,4,5,7,10,5,5,7,8,9,0,3]\na=[1,2,4,2,4,5,7,10,5,5,7,8,9,0,3]a.sort()last=a[-1]for i in range(len(a)-2,-1,-1):    if last==a[i]:        del a[i]    else:        last=a[i]print(a)            # [0, 1, 2, 3, 4, 5, 7, 8, 9, 10]\n解释:\na = [1, 2, 4, 2, 4, 5, 7, 10, 5, 5, 7, 8, 9, 0, 3]  # length : 15a.sort()print(a)       # [0, 1, 2, 2, 3, 4, 4, 5, 5, 5, 7, 7, 8, 9, 10]last = a[-1]print(last)    # 最后一个元素是last,最开始时为10# 从index=13(倒数第2个)(包含)开始,倒着数,到 index=-1 (不含)# 或者说:从下标index=13(含),到index=-1(不含)相当于到index=0(含)for i in range(len(a)-2, -1, -1):    if last == a[i]:    #  将最后一个元素 分别与 其他元素比较大小        del a[i]      # 相同就删掉    else:        last = a[i]     # 不同就把当前元素赋值传给lastprint(a)\n","categories":["技术","Python"],"tags":["Python","range"]},{"title":"Redis报错 (error) NOAUTH Authentication required.","url":"/posts/2018/08/03/28726/","content":"这个错误是因为没有用密码登陆认证 , 先输入密码试试 .\n127.0.0.1:6379&gt; auth &quot;yourpassword&quot;\n例如密码是‘root’,当出现认证问题时候，输入“auth ‘root’”就可以了.\n127.0.0.1:6379&gt; set name &quot;hello&quot;(error) NOAUTH Authentication required.127.0.0.1:6379&gt; (error) NOAUTH Authentication required.(error) ERR unknown command &#x27;(error)&#x27;127.0.0.1:6379&gt; auth &quot;root&quot;\n如果输入密码后出现以下提示:\n(error) ERR invalid password\n那么就是你的密码输入错误 , 如果你忘记密码了, 那么这样做来查看自己的密码 :\n\n进入redis的安装目录（是安装目录的），查看redis.config文件\n\n用记事本打开,找到 “requirepass foobared”,就能找到你的密码了.  比如我的密码是这样的: requirepass 123456  也就是123456  \n\n接着cmd 重新进入redis的安装目录 :(1) redis-server.exe  redis.windows.conf 打开服务器(2) 在另一个窗口重新进入该目录,  输入 redis-cli.exe 打开客户端.(3) 在客户端 中 输入 auth “123456”  就可以进去了(你输入的是你查到的密码) .比如(3), 我的是这样的:\nC:\\Program Files\\redis64-2.8.2101&gt;redis-cli.exe127.0.0.1:6379&gt; auth &quot;123456&quot;OK\n\n\n补充:报错MISCONF Redis is configured to save RDB snapshots具体如下:\n(error) MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.127.0.0.1:6379&gt; config set stop-writes-on-bgsave-error no\n翻译:（错误）misconf redis被配置以保存数据库快照，但misconf redis目前不能在硬盘上持久化。用来修改数据集合的命令不能用，请使用日志的错误详细信息。\n解决办法:运行　config set stop-writes-on-bgsave-error no命令关闭配置项stop-writes-on-bgsave-error解决该问题。如下:\n127.0.0.1:6379&gt; config set stop-writes-on-bgsave-error noOK127.0.0.1:6379&gt; set a 110OK127.0.0.1:6379&gt; get a&quot;110&quot;\n","categories":["技术","数据库","Redis"],"tags":["FixBug","Redis"]},{"title":"工作小结之一2018.11.18","url":"/posts/2018/11/18/19993/","content":"代码规范写代码要规范,变量名的设定和文件日志名的取法都是有讲究的,养成规范后不用考虑怎么命名不用混淆一些变量和其他名字;还有代码的整理版本控制,如果有一个项目,一些通用的脚本或者经常要使用的工具文件,一般会分开放,调用的时候很快知道文件在哪里. 通常一些要用到的文件,只要不是代码文件, 一般不要上传到代码库中取.\n学会封装经常使用的代码选择封装起来,以后方便调用,封装的代码越来越多的时候,考虑将他们放到一个单独的模块中去. 顺便手说一句,封装代码,要记得写注释,这样不仅提醒自己也可以让后来的人很快直接封装这段代码的用途.\n使用main函数可以更好的方便调用, 多使用def 函数,调试用起来可以很方便,当然写main中也方便调试.\n调试可以利用python shell 或者其他,比如adb shell ,都是不错的选择. 遇到不懂的代码,尝试打印出来看. 遇到不懂的命令, 最好的了解方法就是将他用起来,看输出什么.\n学会百度goodle来查找解决办法. 有的问题想想有没有那种折中或者曲线救国的方法,寻找等效方法也是很重要的.\n定位问题问题很难的时候,首先需要将bug定位出来,然后确定这是属于哪方面的问题, 光看和空想是不能解决问题的,要动手去查资料,或者请教其他人.\n工作不比平时自己写代码, 在工作中要严谨,凡是要多加考虑. 写代码要考虑后果,考虑以后的改动性大不大,代码越灵活越好,很多地方用变量代替不能写死才行, 不然以后要改的话就很麻烦了. 特别是考虑到很多用到的三方库,最好下载到项目代码库中,不能自己电脑里安装库就行,万一项目在其他人电脑中运行呢,也就是环境很重要,要开发先准备好环境.\n加班还是要加的,不能因为下班就走人,任务没有完成的话还是要写代码的, 任务完成了的话再多想一点,多做一点,每天多做一点多学一点,厚积薄发,以后请求别人的事情就少一点.\n","categories":["技术","工作小结"],"tags":["总结"]},{"title":"requests的response.text与response.content","url":"/posts/2018/08/10/16084/","content":"response的属性:\nimport requestsresponse=requests.get(&quot;http://www.baidu.com/&quot;)print(response)            #  &lt;Response [200]&gt;print(type(response))   # &lt;class &#x27;requests.models.Response&#x27;&gt;\n\n\n\n1. response.status_codehttp请求的返回状态，2XX 表示连接成功，3XX 表示跳转 , 4XX 客户端错误 , 500 服务器错误\n2. response.texthttp响应内容的 字符串(str) 形式，请求url对应的页面内容 \nresponse=requests.get(&quot;http://www.baidu.com/&quot;)print(response.text)\n打印出的内容含有乱码:\n# &lt;title&gt;ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é&lt;/title&gt;\n修改如下, 改变下载得到的页面的编码,就可以正常打印出”友好的”文本了:\nresponse.encoding=&quot;utf-8&quot;print(response.text)  # 打印文本中没有乱码\n小结 : 更改编码使用：response.encoding&#x3D;”utf-8” 或者 response.encoding&#x3D;”gbk”具体要看你请求的网页是用什么方式编码的,针对不同情况用对应的编码方式.\n比如下面这个例子, 不用编码也可以打印正常文本 ,如果你还是用response.encoding&#x3D;”utf-8”  ,反而会出现乱码\n# 没有乱码:response =requests.get(&quot;http://www.qq.com/&quot;)print(response.text)   response =requests.get(&quot;http://www.qq.com/&quot;)response.encoding=&quot;gbk&quot;  print(response.text)    # 有乱码:response =requests.get(&quot;http://www.qq.com/&quot;)response.encoding=&quot;utf-8&quot;  print(response.text)    \n\n\n\n3. response.contentHTTP响应内容的 二进制(bytes) 形式\nresponse =requests.get(&quot;http://www.baidu.com/&quot;)# print(response.content)     #打印出的是二进制形式print(response.content.decode(&quot;utf-8&quot;))\nresponse =requests.get(&quot;http://www.qq.com/&quot;)# print(response.content)     #打印出的是二进制形式 print(response.content.decode(&quot;gbk&quot;))\n小结:更改编码使用 response.content.deocde(“utf8”)更推荐使用response.content.deocde()的方式获取响应的html页面.\n4. response.encoding从HTTP header中猜测的响应内容编码方式\n5. response.apparent_encoding从内容分析出的响应内容的编码方式（备选编码方式）\n6. response.headershttp响应内容的头部内容\n","categories":["技术","Python"],"tags":["Python","requests"]},{"title":"对称子串的最大长度","url":"/posts/2018/08/27/14461/","content":"举例: \n\n输入cool 则输出2  \n输入nan 则输出\n输入google 则输出4\n\n代码:\ndef count_sym(inputS):    if inputS is None:        return &quot;输入值不能为None&quot;    length = len(inputS)    if length == 0:        return 0    list_s = []    for i in range(length-1):        if inputS[i] == inputS[i+1]:            count = 2            key = 2*i +1            while i-1 &gt;=0 and key -i+1 &lt;=length-1:                i = i -1                if inputS[i] != inputS[key-i]:                    break                count += 2            list_s.append(count)        try:            if inputS[i] == inputS[i+2]:                count = 3                key = 2*i + 2                while i -1 &gt;= 0 and key-i+1 &lt;=length-1:                    i = i-1                    if inputS[i] != inputS[key-i]:                        break                    count += 2                list_s.append(count)        except IndexError:            continue    return max(list_s)print(count_sym(&#x27;happy&#x27;))\n","categories":["技术","面试题"],"tags":["Python","code"]},{"title":"本地远程连接云服务器的Mysql","url":"/posts/2018/08/18/8674/","content":"1、先设置云服务器上的mysql允许远程访问\n编辑文件 /etc/mysql/mysql.conf.d/mysqld.cnf：\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf\n注释掉bind-address &#x3D; 127.0.0.1：修改为: bind-address&#x3D;0.0.0.0\n2、再在你的云服务器中连接:\nmysql -u root -p \n进入后选择你想要连接的database\nmysql&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || mysql              || performance_schema || sys                |+--------------------+4 rows in set (0.00 sec)\n\n\n3、然后使用“use mysql”命令，选择要使用的数据库(我这里用的是其中的mysql)，修改远程连接的基本信息，保存在mysql数据库中，因此使用mysql数据库。\n 对新用户(如:本地电脑windows,非云服务器本地用户)设置访问权限\nGRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27; WITH GRANT OPTION;\n其中的’root’是登录用户名(建议不要改), ‘123456’ 是密码 (你可以自己改)\nmysql&gt; use mysqlDatabase changedmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27; WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; select host,user from user;+-----------+------------------+| host      | user             |+-----------+------------------+| %         | root             || localhost | debian-sys-maint || localhost | mysql.session    || localhost | mysql.sys        || localhost | root             |+-----------+------------------+5 rows in set (0.00 sec)\n重启mysql:\nsudo /etc/init.d/mysql stop  \nsudo /etc/init.d/mysql start\n\n\n4、如果在windows上还是不能连接云服务器,检查一下的云服务器的安全组,看是否开放了端口3306\n","categories":["技术","数据库","MySQL"],"tags":["FixBug","MySQL"]},{"title":"数组降维","url":"/posts/2018/08/27/11747/","content":"Given an array that may contain nested arrays, produce a single resultant array.方法一:\ndef flattenArray(inputArray, outArray=None):    if outArray is None:        outArray = []    for ele in inputArray:        if isinstance(ele, Iterable):            flattenArray(ele, outArray)        else:            outArray.append(ele)    return outArray     if __name__ == &quot;__main__&quot;:    print(flattenArray([1, 2, [3, 4], [5, [6, [7, 8]]], 9]))\n\n方法二: \n# returns iterator def flatten_iter(iterable):    #  使得该函数变成一个生成器    &quot;&quot;&quot;    Takes as input multi dimensional iterable and    --&gt; Takes multi dimensional iterable as input and    returns generator which produces one dimensional output.    &quot;&quot;&quot;    for element in iterable:        if isinstance(element, Iterable):            yield from flatten_iter(element)            else:            yield element if __name__ == &quot;__main__&quot;:    flatten_iter([1,2,3,[4,5,6],[7,[8,9]]])\n","categories":["技术","面试题"],"tags":["Python","code"]},{"title":"Git 常见操作","url":"/posts/2019/12/01/48729/","content":"在多人一起开发写代码时，平时常用的git协作流程是比较固定的：\n现在使用的是GitLab，发现这个工具真的是很好用啊，开始习惯了这个版本代码管理工具。不过GitLab在版本控制代码方面也是基于git的，平时我们是这样来工作的：\n\n遇到新的任务时，先新建一个议题Issue，它会自动创建一个分支，暂且记为branch1\n在该议题下面创建一个Request，即将的编码都是提交到这个Request\n将本地的分支切换为branch1，然后在该分支上编码\n经过代码Review，修改代码通过审核后，将Request通过，并且将branch1合入主线\n如果发现还有遗漏没有做完的内容，可以Reopen开始时创建的Issue，接着重复前几步操作\n\n现在我们都是在pycharm上进行分支的checkout和代码的commit &amp; push，不得不说pycharm结合代码的版本控制，真的是完美，极大提高了工作效率。想想第一份工作时每次编码完成后都是在最原始的git bash界面来提交代码，太耗时且容易出错。\n虽然主要用pycharm界面化来commit &amp; push:\n\ncommit 提交内容\n查看、检查即将要提交的内容\npush\n\n但有时也会使用其他git语句在git bash界面来管理，用的多了就更熟练一些，而有的命令一直也没有机会使用。常见命令：\ngit statusgit pullgit fetch origingit branchgit branch -a git branch  xxx-branchgit branch -d xxx-branchgit checkout  xx-branchgit stashgit stash popgit checkout xxx-file  xxx-directiorygit reset xxx-file \n\n\n一、新建代码库\n# 在当前目录新建一个Git代码库$ git init # 新建一个目录，将其初始化为Git代码库$ git init [project-name] # 下载一个项目和它的整个代码历史$ git clone [url]\n\n二、配置\n# 显示当前的Git配置$ git config --list # 编辑Git配置文件$ git config -e [--global] # 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot;\n\n三、增加&#x2F;删除文件\n# 添加指定文件到暂存区$ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录$ git add [dir] # 添加当前目录的所有文件到暂存区$ git add . # 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p # 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed]\n\n四、代码提交\n# 提交暂存区到仓库区$ git commit -m [message] # 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a # 提交时显示所有diff信息$ git commit -v # 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ...\n\n五、分支\n# 列出所有本地分支$ git branch # 列出所有远程remote分支$ git branch -r # 列出所有本地local分支和远程remote分支$ git branch -a # 新建一个分支，但依然停留在当前分支$ git branch [branch-name] # 新建一个分支，并切换到该分支$ git checkout -b [branch] # 新建一个分支，指向指定commit$ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区（已有该分支的情况下，所以不用加 -b ）$ git checkout [branch-name] # 切换到上一个分支$ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支$ git merge [branch] # 选择一个commit，合并进当前分支$ git cherry-pick [commit] # 删除分支$ git branch -d [branch-name] # 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]\n\n六、标签\n# 列出所有tag$ git tag # 新建一个tag在当前commit$ git tag [tag] # 新建一个tag在指定commit$ git tag [tag] [commit] # 删除本地tag$ git tag -d [tag] # 删除远程tag$ git push origin :refs/tags/[tagName] # 查看tag信息$ git show [tag] # 提交指定tag$ git push [remote] [tag] # 提交所有tag$ git push [remote] --tags # 新建一个分支，指向某个tag$ git checkout -b [branch] [tag]\n\n七、查看信息\n# 显示有变更的文件$ git status # 显示当前分支的版本历史$ git log # 显示commit历史，以及每次commit发生变更的文件$ git log --stat # 搜索提交历史，根据关键词$ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file] # 显示指定文件相关的每一次diff$ git log -p [file] # 显示过去5次提交$ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序$ git shortlog -sn # 显示指定文件是什么人在什么时间修改过$ git blame [file] # 显示暂存区和工作区的差异$ git diff # 显示暂存区和上一个commit的差异$ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异$ git diff HEAD # 显示两次提交之间的差异$ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot; # 显示某次提交的元数据和内容变化$ git show [commit] # 显示某次提交发生变化的文件$ git show --name-only [commit] # 显示某次提交时，某个文件的内容$ git show [commit]:[filename] # 显示当前分支的最近几次提交$ git reflog\n\n八、远程同步\n# 下载远程仓库的所有变动$ git fetch [remote] # 显示所有远程仓库$ git remote -v # 显示某个远程仓库的信息$ git remote show [remote] # 增加一个新的远程仓库，并命名$ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch] # 上传本地指定分支到远程仓库$ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force # 推送所有分支到远程仓库$ git push [remote] --all\n\n九、撤销\n# 恢复暂存区的指定文件到工作区$ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区$ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit] # 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit] # 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop\n","categories":["技术","Git"],"tags":["Git"]},{"title":"Python TCPServer 多线程多客户端通信","url":"/posts/2019/12/29/48640/","content":"最简单、原始的TCP通信demo服务端Http请求：\nimport socket# 创建一个servicesockeserviceSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 给服务器绑定地址(ip地址,端口号)serviceSocket.bind((&quot;192.168.171.1&quot;, 80))print(&quot;等待客户端接入&quot;)# sock 是客户端的socket信息# addr 是客户端的地址(ip,端口)sock, addr = serviceSocket.accept()print(f&quot;sock from client:&#123;sock&#125;&quot;)print(f&quot;addr of client:&#123;addr&#125;&quot;)while True:    # 接收客户端的请求    recvData = sock.recv(1024)    print(&quot;客户端说:%s&quot; % (recvData.decode(&quot;utf-8&quot;)))    sendData = input(&quot;服务器说:&quot;)    # 发送(回复)数据给客户端    sock.send(sendData.encode(&quot;utf-8&quot;))\n\n客户端Http请求：\nimport socket# 创建客户端socketclientSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 连接服务器clientSocket.connect((&quot;192.168.171.1&quot;, 80))while True:    # 发送消息给服务器    sendData = input(&quot;客户端说:&quot;)    if sendData == &quot;bye&quot;:        clientSocket.send(sendData.encode(&quot;utf-8&quot;))  # 编码:将数据装换成二进制形式        break    clientSocket.send(sendData.encode(&quot;utf-8&quot;))    recvData = clientSocket.recv(1024)    print(&quot;服务器说:%s&quot; % (recvData.decode(&quot;utf-8&quot;)))  # 解码:将二进制转换成字符\n\n\n\n1、在TCP中，客户端的实现流程：\n\n创建客户端的socket对象  \n建立与服务器之间的联系 \n发送请求 \n接收数据 \n关闭连接\n\n2、服务端的实现流程：\n\n创建服务端的socket对象 \n绑定服务端的地址 \n设置监听器 \n等待客户端的连接 \n接收客户端的请求 \n返回处理的结果到客户端\n\n\nThreadingTCPServer 多线程多客户端通信自动重连demo\n\nTCPServer# from socketserver import TCPServer, BaseRequestHandler, ThreadingTCPServerfrom socketserver import TCPServer, StreamRequestHandler, ThreadingMixInimport traceback# class MyBaseRequestHandler(BaseRequestHandler):class MyBaseRequestHandler(StreamRequestHandler):    def handle(self):        self.addr = self.request.getpeername()        self.server.users[self.addr[1]] = self.request        message = &quot;IP &quot; + self.addr[0] + &quot;:&quot; + str(self.addr[1]) + &quot; Connected...&quot;        print(message)        while True:            try:                data = self.request.recv(1024).decode(&#x27;UTF-8&#x27;, &#x27;ignore&#x27;).strip()                print(f&#x27;receive from &#123;self.client_address&#125;:&#123;data&#125;&#x27;)                back_data = (f&quot;response\\&quot;&quot; + data + &quot;\\&quot;:\\n&quot;).encode(&quot;utf8&quot;)                self.request.sendall(back_data)            except:                traceback.print_exc()                break# 源码：class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass# 从ThreadingMixIn和TCPServer继承，实现多线程class MyThreadingTCPServer(ThreadingMixIn, TCPServer):    def __init__(self, server_address, RequestHandlerClass):        TCPServer.__init__(self, server_address, RequestHandlerClass)        self.users = &#123;&#125;class MyTCPserver():    def __init__(self, server_addr=&#x27;192.168.1.109&#x27;, server_port=23):        self.server_address = server_addr        self.server_port = server_port        self.server_tuple = (self.server_address, self.server_port)    def run(self):        # server = TCPServer(self.server_tuple, MyBaseRequestHandler)        server = MyThreadingTCPServer(self.server_tuple, MyBaseRequestHandler)        server.serve_forever()if __name__ == &#x27;__main__&#x27;:    myserver = MyTCPserver()    myserver.run()\n\n在telnet 下开启开启两个客户端，本电脑的IP为192.168.1.109，开两个客户端后，TCPServer的终端出现同一个IP但是不同端口的连接：\n\nTCPClientimport socketimport timeclass MyClient:    host = &#x27;192.168.1.109&#x27;    port = 23    bufsiz = 1024    addr = None    skt = None    def __init__(self, host=None, port=None):        if host != None:            self.host = host        if port != None:            self.port = port        if self.addr == None:            self.addr = (self.host, self.port)        self.doConnection()    def doConnection(self):        try:            self.skt = socket.socket(socket.AF_INET, socket.SOCK_STREAM)            self.skt.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)            print(self.addr)            self.skt.connect(self.addr)        except:            pass    def run(self):        while True:            try:                _time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())                self.skt.sendall(f&#x27;&#123;_time&#125;:i am clent1 &#x27;.encode(&#x27;utf-8&#x27;))                data = self.skt.recv(self.bufsiz)                print(data.decode(&#x27;utf-8&#x27;, &#x27;ignore&#x27;))                if not data:                    break                print(data.strip())                time.sleep(5)            except socket.error:                print(&#x27;socket error, reconnection&#x27;)  # 自动重连                time.sleep(3)                self.doConnection()            except:                print(&#x27;other error&#x27;)        self.skt.close()myclient = MyClient()myclient.run()\n\n上面用的是telnet工具来作为客户端，这里是用代码实现模拟的客户端。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python TypeError can't create a consistent method resolution","url":"/posts/2019/08/11/31143/","content":"今天在学习使用Ctrl+H、Ctrl+Shift+H的用处时，随便写了几个类的继承举例来测试，结果运行一下出现报错了TypeError: Cannot create a consistent method resolution无法创建一致的方法解析\n修正后代码截图如下：定位到报错的位置，改了一些继承类A、B的顺序就好了。究其原因：类C想要继承A和B，由于B已经继承A了，写成class C(A, B)错误形式时，python无法确定先查找哪些类的方法，于是无法覆盖定义在A中定义的方法。其实没有必要再继承一下A，因为既然B已经继承A了，那只要继承一下B就行了。\n另外，在查找实例属性&#x2F;方法时，python需要决定按哪个顺序搜索（直接和间接）基类。它通过线性化继承图来实现这一点，也就是通过使用一种叫做c3或mro的算法将基类图转换成序列。MRO算法是一种独特的算法，可实现以下几个理想特性：\n\n每个祖先类只出现一次\n类总是出现在其祖先之前（“单调性”）。\n同一类的直接父类应按照类定义中列出的顺序显示（“一致的本地优先顺序”）。\n如果A类的子类总是出现在B类的子类之前，则A应出现在B类之前（“一致的扩展优先顺序”）。\n\n这里的话，第二个特性要求B首先出现，而自己的代码错误写成要求A首先出现，由于无法满足所有特性，报错提示。\n  class A(object):    def __init__(self, name):        self.name = name    def get(self):        return self.nameclass B(A):    def get(self):        super(B, self).get()class C(B, A):   # class C(A, B): 错误写法    def get(self):        super(C, self).get()c = C(&quot;Name&quot;)\n\n参考：python - TypeError: Cannot create a consistent method resolution order (MRO) - Stack Overflow\n","categories":["技术","Python"],"tags":["Python","FixBug"]},{"title":"Python中的几种拷贝方式","url":"/posts/2019/08/03/8011/","content":"提到拷贝，主要使用赋值、copy模块、列表切片、字典copy() 来实现拷贝。\n赋值赋值产生的拷贝是浅拷贝，共享地址。\n改变任意一个对象中元素的值，会同时影响拷贝对象，当前对象怎么变，拷贝的对象就跟着怎么变。\nlist1 = [1,2,3,4,5]list2 = list1list2[0] = 100print(list1,id(list1))  # [100, 2, 3, 4, 5]  2166018012616print(list2,id(list2))  # [100, 2, 3, 4, 5]  2166018012616list1 = [[1,2,3],2,3,4,5]list2 = list1list2[0][0] = 100print(list1,id(list1))  # [[100, 2, 3], 2, 3, 4, 5] 1932839048904print(list2,id(list2))  # [[100, 2, 3], 2, 3, 4, 5] 1932839048904\n\nCopy浅拷贝 copy.copy()\n对于不可变类型：数字、字符串、元组, 浅拷贝仅仅是地址，即就是使用相同的地址，引用相同的地址id，不会开辟新空间。\nimport copyiNum = 1iNewNum = copy.copy(iNum)print(iNum,id(iNum))       # 1 1969923168print(iNewNum,id(iNewNum)) # 1 1969923168# 对于可变类型：列表、字典、集合，浅拷贝会开辟新的空间地址# (仅仅是最外层开辟了新的空间，里层的元素地址还是相同的)lstchild = [&#x27;a&#x27;,&#x27;b&#x27;]lst = [lstchild, 1, 2, 3]lstCopy = copy.copy(lst)print(lst,id(lst))          # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3] 2419428511048print(lstCopy,id(lstCopy))  # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3] 2419428455688print(id(lst[0]))           # 1539324376328print(id(lstCopy[0]))       # 1539324376328# 可以看出浅拷贝前后两个列表的地址是不同的，但是子元素列表的地址是相同的。\n\n# 由上面可知，浅拷贝后，改变任意一个对象中不可变类型的元素的值，只有当前对象受影响，不影响拷贝的对象；# 改变任意一个对象中为可变类型的元素的值，会同时影响拷贝对象的。lst[0][0] = &#x27;aa&#x27;lst[1] = 11print(lst)        # [[&#x27;aa&#x27;, &#x27;b&#x27;], 11, 2, 3]print(lstCopy)    # [[&#x27;aa&#x27;, &#x27;b&#x27;], 1, 2, 3]# 改变lstCopy同理# 注意：若改变任意一个对象中一个可变类型（整个，不是其中的某个元素），也只会影响当前对象。lst[0] = &quot;ab&quot;print(lst)         # [&#x27;ab&#x27;, 11, 2, 3]print(lstCopy)     # [[&#x27;aa&#x27;, &#x27;b&#x27;], 1, 2, 3]\n\n\n\n深拷贝 copy.deepcopy()\ncopy.deepcopy() 除了外层拷贝，还对子元素也进行了拷贝（本质上递归浅拷贝）\n# 原对象和拷贝对象地址不同，所有的元素地址也不同import copylstchild = [&#x27;a&#x27;,&#x27;b&#x27;]lst = [lstchild, 1, 2, 3]lstCopy = copy.deepcopy(lst)print(lst,id(lst))          # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3] 2096824546824print(lstCopy,id(lstCopy))  # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3] 2096824601928print(id(lst[0]))           # 2096824547592print(id(lstCopy[0]))       # 2096824546696# 深拷贝后，改变任意一个对象中元素的值，只有当前对象受影响lst[0][0] = &#x27;aa&#x27;lst[1] = 11print(lst)        # [[&#x27;aa&#x27;, &#x27;b&#x27;], 11, 2, 3]print(lstCopy)    # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3]\n\n\n\n列表切片常使用的列表切片，也是浅拷贝，效果和 copy.copy() 相同\nlstchild = [&#x27;a&#x27;,&#x27;b&#x27;]lst = [lstchild, 1, 2, 3]lstCopy = lst[:]print(lst,id(lst))          # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3] 2096824546824print(lstCopy,id(lstCopy))  # [[&#x27;a&#x27;, &#x27;b&#x27;], 1, 2, 3] 2096824601928print(id(lst[0]))           # 2685187220808print(id(lstCopy[0]))       # 2685187220808lst[0][0] = &#x27;aa&#x27;lst[1] = 11print(lst)        # [[&#x27;aa&#x27;, &#x27;b&#x27;], 11, 2, 3]print(lstCopy)    # [[&#x27;aa&#x27;, &#x27;b&#x27;], 1, 2, 3]\n\n\n\n字典拷贝字典自带有 copy() 函数，这种拷贝为浅拷贝\noriginal_dict = &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: [2, 3], &#x27;c&#x27;: &#123;&#x27;d&#x27;: 4&#125;&#125;copied_dict = original_dict.copy()# 修改原字典中的不可变对象（如整数）不会影响拷贝original_dict[&#x27;a&#x27;] = 10  # 这不会影响 copied_dict# 修改原字典中的可变对象（如列表或字典）会同时影响拷贝original_dict[&#x27;b&#x27;].append(4)  # 这会影响 copied_dictoriginal_dict[&#x27;c&#x27;][&#x27;d&#x27;] = 5  # 这也会影响 copied_dictprint(original_dict)  # &#123;&#x27;a&#x27;: 10, &#x27;b&#x27;: [2, 3, 4], &#x27;c&#x27;: &#123;&#x27;d&#x27;: 5&#125;&#125;print(copied_dict)  # &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: [2, 3, 4], &#x27;c&#x27;: &#123;&#x27;d&#x27;: 5&#125;&#125;\n\n要想深拷贝，还得用 copy.deepcopy()\nimport copyoriginal_dict = &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: [2, 3], &#x27;c&#x27;: &#123;&#x27;d&#x27;: 4&#125;&#125;deep_copied_dict = copy.deepcopy(original_dict)# 现在修改原字典的任何嵌套对象都不会影响 deep_copied_dictoriginal_dict[&#x27;b&#x27;].append(4)original_dict[&#x27;c&#x27;][&#x27;d&#x27;] = 5print(original_dict)  # &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: [2, 3, 4], &#x27;c&#x27;: &#123;&#x27;d&#x27;: 5&#125;&#125;print(deep_copied_dict)  # &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: [2, 3], &#x27;c&#x27;: &#123;&#x27;d&#x27;: 4&#125;&#125;\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python中的类属性、类方法","url":"/posts/2019/08/18/12323/","content":"Python中的类属性类是模板，而实例则是根据类创建的对象。\n绑定在一个实例上的属性不会影响其他实例，但是，类本身也是一个对象，如果在类上绑定一个属性，则所有实例都可以访问类的属性，并且，所有实例访问的类属性都是同一个！也就是说，实例属性每个实例各自拥有，互相独立，而类属性有且只有一份。\n定义类属性可以直接在 class 中定义：\nclass Person(object):    address = &#x27;Earth&#x27;    def __init__(self, name):        self.name = name\n\n因为类属性是直接绑定在类上的，所以，访问类属性不需要创建实例，就可以直接访问：\nprint(Person.address)# =&gt; Earth\n\n对一个实例调用类的属性也是可以访问的，所有实例都可以访问到它所属的类的属性：\np1 = Person(&#x27;Bob&#x27;)p2 = Person(&#x27;Alice&#x27;)print(p1.address)# =&gt; Earthprint(p2.address)# =&gt; Earth\n\n由于Python是动态语言，类属性也是可以动态添加和修改的：\nPerson.address = &#x27;China&#x27;  # 修改 类属性print p1.address# =&gt; &#x27;China&#x27;print p2.address# =&gt; &#x27;China&#x27;\n\n因为类属性只有一份，所以，当Person类的address改变时，所有实例访问到的类属性都改变了。\n例子：\n# 给 Person 类添加一个类属性 count，每创建一个实例，count 属性就加 1，这样就可以统计出一共创建了多少个 Person 的实例。class Person(object):  countAttribut = 0  def __init__(self, name):    self.name = name    Person.countAttribut = Person.countAttribut + 1p1 = Person(name=&quot;z&quot;)p2 = Person(name=&quot;y&quot;)print(p1.countAttribut)  # 2print(p2.countAttribut)  # 2\n\n\n类属性和实例属性名字冲突怎么办修改类属性会导致所有实例访问到的类属性全部都受影响，但是，如果在实例变量上修改类属性会发生什么问题呢？\nclass Person(object):    address = &#x27;Earth&#x27;    def __init__(self, name):        self.name = namep1 = Person(&#x27;Bob&#x27;)p2 = Person(&#x27;Alice&#x27;)print(&#x27;Person.address:&#x27;, Person.address)  # Person.address: Earthp1.address = &#x27;China&#x27;print(&#x27;p1.address:&#x27;, p1.address)  # p1.address: Chinaprint(&#x27;Person.address:&#x27;, Person.address)  # Person.address: Earthprint(&#x27;p2.address:&#x27;, p2.address)  # p2.address: Earth\n\n在设置了 p1.address &#x3D; ‘China’ 后，p1访问 address 变成了 ‘China’，但是，Person.address和p2.address仍然是’Earch’。\n原因是 p1.address &#x3D; ‘China’并没有改变 Person 的 address，而是给 p1这个实例绑定了实例属性address ，对p1来说，它有一个实例属性address（值是’China’），而它所属的类Person也有一个类属性address，所以:\n访问 p1.address 时，优先查找实例属性，返回’China’。\n访问 p2.address 时，p2没有实例属性address，但是有类属性address，因此返回’Earth’。\n可见，当实例属性和类属性重名时，实例属性优先级高，它将屏蔽掉对类属性的访问。\n当我们把 p1 的 address 实例属性删除后，访问 p1.address 就又返回类属性的值 ‘Earth’了：\ndel p1.addressprint(p1.address)# =&gt; Earth\n\n可见，千万不要在实例上修改类属性，它实际上并没有修改类属性，而是给实例绑定了一个实例属性。\n\nPython中方法也是属性我们在 class 中定义的实例方法其实也是属性，它实际上是一个函数对象：\nclass Person(object):    def __init__(self, name, score):        self.name = name        self.score = score    def get_grade(self):        return &#x27;A&#x27;p1 = Person(&#x27;Bob&#x27;, 90)print p1.get_grade# =&gt; &lt;bound method Person.get_grade of &lt;__main__.Person object at 0x109e58510&gt;&gt;print p1.get_grade()# =&gt; A\n\n也就是说，p1.get_grade 返回的是一个函数对象，但这个函数是一个绑定到实例的函数，p1.get_grade() 才是方法调用。\n因为方法也是一个属性，所以，它也可以动态地添加到实例上，只是需要用 types.MethodType() 把一个函数变为一个方法：\nimport typesdef fun_getGrade(self):    if self.score &gt;= 90:        return &#x27;A&#x27;    if self.score &gt;= 60:        return &#x27;B&#x27;    return &#x27;C&#x27;class Person(object):    address = &#x27;Earth&#x27;    def __init__(self, name, score):        self.name = name        self.score = scorep1 = Person(&#x27;Bob&#x27;, 90)p1.get_grade = types.MethodType(fun_getGrade, p1)print(p1.get_grade())  # Ap2 = Person(&#x27;Alice&#x27;,80)print(p2.get_grade())# AttributeError: &#x27;Person&#x27; object has no attribute &#x27;get_grade&#x27;# 因为p2实例并没有绑定get_grade\n\n给一个实例动态添加方法并不常见，直接在class中定义要更直观。\n由于属性可以是普通的值对象，如 str，int 等，也可以是方法，还可以是函数，以下代码 p1.get_grade 为什么是函数而不是方法：\nclass Person(object):    def __init__(self, name, score):        self.name = name        self.score = score        self.get_grade = lambda: &#x27;A&#x27;p1 = Person(&#x27;Bob&#x27;, 90)print(p1.get_grade)  # &lt;function Person.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x00000123C4E33E18&gt;print(p1.get_grade())  # A \n\n原因：直接把 lambda 函数赋值给 self.get_grade 和绑定方法有所不同，函数调用不需要传入 self，但是方法调用需要传入 self。\n\nPython中定义类方法和属性类似，方法也分为 类方法 和 实例方法。\n在class中定义的全部是实例方法，实例方法第一个参数 self 是实例本身。\n在class中如何定义 类方法：\nclass Person(object):    count = 0    def __init__(self, name):        self.name = name        Person.count = Person.count +1    @classmethod    def num(cls):        return cls.countprint(Person.num())  # 0p1 = Person(&#x27;ZYP&#x27;)  p2 = Person(&#x27;ZYP2&#x27;)print(Person.num())  # 2\n\n通过装饰器 @classmethod，该方法将绑定到 Person 类上，而非类的实例。\n类方法的第一个参数将传入类本身，通常将参数名命名为 cls，上面的 cls.count 实际上相当于 Person.count。\n因为是在类上调用，而非实例上调用，因此类方法无法获得任何实例变量，只能获得类的引用。\n例子：\n# 将类属性 count 改为私有属性__count，则外部无法读取__score，但可以通过一个类方法获取。class Person(object):    __count = 0    def __init__(self, name):        self.name = name        Person.__count = Person.__count +1    @classmethod    def num(cls):        return cls.__countprint(Person.num())  # 0p1 = Person(&#x27;ZYP&#x27;)p2 = Person(&#x27;ZYP2&#x27;)print(Person.num())  # 2\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python偏函数结合类装饰器","url":"/posts/2019/08/18/33393/","content":"案例\nimport timeimport functoolsclass DelayFunc:    def __init__(self, duration, func):        self.duration = duration        self.func = func    def __call__(self, *args, **kwargs):        print(f&#x27;Wait for &#123;self.duration&#125; seconds...&#x27;)        time.sleep(self.duration)        return self.func(*args, **kwargs)    def eager_call(self, *args, **kwargs):        print(&#x27;Call without delay&#x27;)        return self.func(*args, **kwargs)def delay(duration):    &quot;&quot;&quot;    装饰器：推迟某个函数的执行。    同时提供 .eager_call 方法立即执行    &quot;&quot;&quot;    # 此处为了避免定义额外函数，    # 直接使用 functools.partial 帮助构造 DelayFunc 实例    return functools.partial(DelayFunc, duration)@delay(duration=2)def add(a, b):    return a + bprint(add)  # add 变成了类DelayFunc的实例# &lt;__main__.DelayFunc object at 0x000001EED91FA3C8&gt;print(add(3, 5))  # 直接调用实例，进入 __call__# Wait for 2 seconds...# 8print(add.eager_call(1, 2))  # 实现实例方法# Call without delay# 3\n\n\n\n提问：为啥这个 add 函数名会给自动传给 DelayFunc 的 init 函数中的 func 而不是 duration？duration 和 add 传过去时，python 是怎么区分的？\n分析\n\n首先，@delay(duration=2) 这个装饰器表达式会被首先执行：\n# 等价于执行delay(duration=2)  # 返回 functools.partial(DelayFunc, duration=2)\n\ndelay(duration=2) 返回了一个偏函数：\n# 等价于functools.partial(DelayFunc, 2)  # 这个偏函数已经固定了第一个参数 duration=2\n\n然后这个偏函数会作为装饰器作用在 add 函数上：\n# 等价于add = functools.partial(DelayFunc, 2)(add)# 进一步等价于add = DelayFunc(2, add)\n\n所以完整的执行顺序是：\n# 1. 首先执行装饰器函数delayed_func = delay(duration=2)  # 返回 partial(DelayFunc, 2)# 2. 用返回的偏函数作为装饰器装饰 add 函数add = delayed_func(add)  # 等价于 DelayFunc(2, add)\n\n\n\n用一个更直观的例子来说明：\nimport functoolsimport timedef debug_decorator():    print(&quot;1. 装饰器函数被调用&quot;)        class Wrapper:        def __init__(self, func):            print(&quot;3. Wrapper.__init__被调用，参数是:&quot;, func.__name__)            self.func = func                def __call__(self, *args, **kwargs):            print(&quot;4. 调用被装饰的函数&quot;)            return self.func(*args, **kwargs)        print(&quot;2. 返回Wrapper类&quot;)    return Wrapper@debug_decorator()def hello():    print(&quot;Hello!&quot;)print(&quot;5. 开始调用hello()&quot;)hello()\n\n输出将是：\n1. 装饰器函数被调用2. 返回Wrapper类3. Wrapper.__init__被调用，参数是: hello5. 开始调用hello()4. 调用被装饰的函数Hello!\n\n回到开始的例子，我们可以加入调试信息：\nimport timeimport functoolsclass DelayFunc:    def __init__(self, duration, func):        print(f&quot;DelayFunc.__init__被调用：duration=&#123;duration&#125;, func=&#123;func.__name__&#125;&quot;)        self.duration = duration        self.func = func        def __call__(self, *args, **kwargs):        print(f&#x27;Wait for &#123;self.duration&#125; seconds...&#x27;)        time.sleep(self.duration)        return self.func(*args, **kwargs)def delay(duration):    print(f&quot;delay()被调用，参数duration=&#123;duration&#125;&quot;)    partial_delay = functools.partial(DelayFunc, duration)    print(&quot;返回偏函数partial_delay&quot;)    return partial_delay@delay(duration=2)def add(a, b):    return a + bprint(&quot;开始调用add(1, 2)&quot;)result = add(1, 2)print(f&quot;结果：&#123;result&#125;&quot;)\n\n执行这段代码，输出会类似：\ndelay()被调用，参数duration=2返回偏函数partial_delayDelayFunc.__init__被调用：duration=2, func=add开始调用add(1, 2)Wait for 2 seconds...结果：3\n\n这就清晰地展示了整个过程：\n\ndelay(duration=2) 被调用，返回一个偏函数\n这个偏函数被用来装饰 add，此时创建了 DelayFunc 实例\n当我们调用 add(1, 2) 时，实际上是在调用 DelayFunc 实例的 __call__ 方法\n\nPython 之所以能正确区分参数，是因为：\n\ndelay(duration=2) 创建了一个偏函数，这个偏函数已经固定了 DelayFunc 的第一个参数为 2\n当这个偏函数被用作装饰器时，被装饰的函数 add 自动作为第二个参数传入\nDelayFunc 的 __init__ 方法接收这两个参数，完成初始化\n\n这就是为什么尽管看起来有点混乱，但参数还是能被正确地传递和识别。\n\n偏函数在这里的应用：DelayFunc 类的初始化，需要两个参数，可以用偏函数来暂时固定一个。\nimport functools# 1. 假设我们有一个需要两个参数的类class Person:    def __init__(self, age, name):        self.age = age        self.name = name        print(f&quot;创建了一个&#123;age&#125;岁的&#123;name&#125;&quot;)# 2. 我们可以用偏函数固定第一个参数CreateChild = functools.partial(Person, 3)  # 固定年龄为3岁# 3. 现在使用这个偏函数，只需要提供name参数child1 = CreateChild(&quot;小明&quot;)  # 输出：创建了一个3岁的小明child2 = CreateChild(&quot;小红&quot;)  # 输出：创建了一个3岁的小红# 等价于：# child1 = Person(3, &quot;小明&quot;)# child2 = Person(3, &quot;小红&quot;)\n\n回到 DelayFunc 例子：\nimport timeimport functoolsclass DelayFunc:    def __init__(self, duration, func):        self.duration = duration        self.func = func        print(f&quot;初始化DelayFunc: duration=&#123;duration&#125;, func=&#123;func.__name__&#125;&quot;)    def print_some(self):        print(&quot;print_some&quot;)# 1. 完整调用方式normal_delayed = DelayFunc(2, print)  # 需要两个参数# 2. 使用偏函数固定第一个参数Delay2Seconds = functools.partial(DelayFunc, 2)  # 固定duration为2秒delayed_print = Delay2Seconds(print)  # 只需要提供func参数# 让我们做一个更清晰的演示：print(&quot;演示1: 创建等待3秒的偏函数&quot;)Delay3Seconds = functools.partial(DelayFunc, 3)print(&quot;Delay3Seconds是：&quot;, Delay3Seconds)print(&quot;\\n演示2: 使用这个偏函数创建实例&quot;)def greet():    print(&quot;Hello!&quot;)delayed_greet = Delay3Seconds(greet)print(&quot;delayed_greet是：&quot;, delayed_greet)print(&quot;isinstance(delayed_greet, DelayFunc)：&quot;, isinstance(delayed_greet, DelayFunc))delayed_print.print_some()\n\n输出会类似：\n演示1: 创建等待3秒的偏函数Delay3Seconds是： functools.partial(&lt;class &#x27;__main__.DelayFunc&#x27;&gt;, 3)演示2: 使用这个偏函数创建实例初始化DelayFunc: duration=3, func=greetdelayed_greet是： &lt;__main__.DelayFunc object at 0x...&gt;isinstance(delayed_greet, DelayFunc)： Trueprint_some\n\n可以再深入一点，看看偏函数是如何工作的：\nimport functoolsdef demo_func(a, b, c):    print(f&quot;a=&#123;a&#125;, b=&#123;b&#125;, c=&#123;c&#125;&quot;)# 创建偏函数，固定第一个参数partial_demo = functools.partial(demo_func, 1)# 查看偏函数的属性print(&quot;偏函数的属性:&quot;)print(f&quot;- func: &#123;partial_demo.func&#125;&quot;)print(f&quot;- args: &#123;partial_demo.args&#125;&quot;)print(f&quot;- keywords: &#123;partial_demo.keywords&#125;&quot;)# 不同的调用方式print(&quot;\\n不同的调用方式:&quot;)partial_demo(2, 3)                  # 位置参数: a=1, b=2, c=3partial_demo(b=2, c=3)             # 关键字参数: a=1, b=2, c=3partial_demo(c=3, b=2)             # 关键字参数顺序不重要: a=1, b=2, c=3# 创建一个固定关键字参数的偏函数partial_demo_kw = functools.partial(demo_func, c=3)print(&quot;\\n固定关键字参数:&quot;)partial_demo_kw(1, 2)              # a=1, b=2, c=3\n\n这样设计的好处是：\n\n参数复用\n可以创建一个固定某些参数的模板\n减少重复代码\n\n\n代码清晰\n通过固定某些参数，使函数调用更简洁\n代码意图更明确\n\n\n灵活性\n可以固定任意位置的参数\n可以固定位置参数或关键字参数\n\n\n工厂模式\n可以用来创建特定配置的函数或类实例\n很适合用在装饰器模式中\n\n\n\n在你的装饰器例子中，partial(DelayFunc, 2) 创建了一个新的可调用对象，它：\n\n已经固定了 DelayFunc 的第一个参数 (duration) 为 2\n等待接收第二个参数 (func)\n当装饰器应用到函数上时，这个函数就自动成为第二个参数\n\n这就是为什么装饰器模式和偏函数配合得如此好的原因！\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python函数式编程之高阶函数","url":"/posts/2019/08/17/16273/","content":"变量可以指向函数&gt;&gt;&gt; abs(-10)10&gt;&gt;&gt; abs&lt;built-in function abs&gt;&gt;&gt;&gt; func = abs&gt;&gt;&gt; func(-2)2\n\n\n\n指向函数的变量函数名其实是指向函数的变量\n&gt;&gt;&gt; abs = len&gt;&gt;&gt; abs(1)Traceback (most recent call last):  File &quot;&lt;pyshell#23&gt;&quot;, line 1, in &lt;module&gt;    abs(1)TypeError: object of type &#x27;int&#x27; has no len()&gt;&gt;&gt; abs([1,2,3])3\n\n\n\n高阶函数高阶函数：能接受函数作为参数的函数\n\n变量可以指向函数\n函数的参数可以接受变量\n一个函数可以接受另一个函数作为参数\n能接受函数作为参数的函数就是高阶函数\n\ndemo：\n# 定义一个函数，接受x，y，z三个参数，x和y是数值，z是函数名def absAdd(x,y,z):  return z(x)+z(y)absAdd(-1,-2,abs)  # 3# demo2:import mathdef add(x, y, f):    return f(x) + f(y)print(add(25, 9, math.sqrt))  # 8.0\n\n\n\nmap函数map()是 python 内置的高阶函数，它接收一个函数 f 和一个 list，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 并返回。\n例如，对于list [1, 2, 3, 4, 5, 6, 7, 8, 9]\n如果希望把list的每个元素都作平方，就可以用map()函数：\n只需要传入函数f(x)&#x3D;x*x，就可以利用map()函数完成这个计算：\ndef f(x):    return x*xprint map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])# [1, 4, 9, 10, 25, 36, 49, 64, 81]\n\n注意：map()函数不改变原有的 list，而是返回一个新的 list。\n利用map()函数，可以把一个 list 转换为另一个 list，只需要传入转换函数。\n由于list包含的元素可以是任何类型，因此，map() 不仅仅可以处理只包含数值的 list，事实上它可以处理包含任意类型的 list，只要传入的函数f可以处理这种数据类型。\ndemo:\n# 利用map()函数，把一个list（包含若干不规范的英文名字）变成一个包含规范英文名字的list：def format_name(s):    return s[0].upper() + s[1:].lower()print map(format_name, [&#x27;adam&#x27;, &#x27;LISA&#x27;, &#x27;barT&#x27;])\n\n\n\nreduce函数reduce()函数也是Python内置的一个高阶函数。reduce()函数接收的参数和 map()类似，一个函数 f，一个list，但行为和 map()不同，reduce()传入的函数 f 必须接收两个参数，reduce()对list的每个元素反复调用函数f，并返回最终结果值。\n例如:\n# f函数，接收x和y，返回x和y的和from functools import reducedef f(x, y):    return x + yres = reduce(f,[1,2,3,4,5])print(res)  # 15# reduce()还可以接收第3个可选参数，作为计算的初始值。res = reduce(f, [1,2,3,4,5], 100)print(res)  # 115\n\n\n\nfilter()函数filter()函数是 Python 内置的另一个有用的高阶函数，filter()函数接收一个函数 f 和一个list，这个函数 f 的作用是对每个元素进行判断，返回 True或 False，filter()根据判断结果自动过滤掉不符合条件的元素，返回由符合条件元素组成的新list。\n例如:\n# 从[1,2,3,4,5,6,7]中删除偶数，保留奇数：def is_odd(x):    return x % 2 == 1res = filter(is_odd,[1,2,3,4,5,6,7])print(list(res))\n\n# 删除 None 或者空字符串def is_not_empty(string):    return string and len(string.strip()) &gt; 0res = filter(is_not_empty,[&#x27;test&#x27;, None, [], &#123;&#125;,&#x27; &#x27;])print(list(res))   # [&#x27;test&#x27;]# 利用filter()过滤出1~100中平方根是整数的数import mathdef is_sqr(x):    return math.sqrt(x) % 1 == 0print(list(filter(is_sqr, range(1, 101))))\n\n\n\n排序函数内置的 sorted() 函数可对list进行排序：\n&gt;&gt;&gt; sorted([110,12,1,98])[1, 12, 98, 110]&gt;&gt;&gt; sorted([&#x27;bob&#x27;, &#x27;about&#x27;, &#x27;Zoo&#x27;, &#x27;Credit&#x27;])[&#x27;Credit&#x27;, &#x27;Zoo&#x27;, &#x27;about&#x27;, &#x27;bob&#x27;]\n\n\n\n闭包在函数内部定义的函数和外部定义的函数是一样的，只是他们无法被外部访问：\ndef g():    print &#x27;g()...&#x27;def f():    print &#x27;f()...&#x27;    return g    # 将 g 的定义移入函数 f 内部，防止其他代码调用 g：def f():    print &#x27;f()...&#x27;    def g():        print &#x27;g()...&#x27;    return g\n\n# 像这种内层函数引用了外层函数的变量（参数也算变量），然后返回内层函数的情况，称为闭包（Closure）。def calc_sum(lst):    def lazy_sum():        return sum(lst)    return lazy_sum\n\n闭包的特点是返回的函数还引用了外层函数的局部变量，所以，要正确使用闭包，就要确保引用的局部变量在函数返回后不能变。举例如下：\n# 希望一次返回3个函数，分别计算1x1,2x2,3x3:def count():    fs = []    for i in range(1, 4):        def f():            return i*i        fs.append(f)    return fsf1, f2, f3 = count()print(f1(), f2(), f3())  \n\n可能认为调用f1()，f2()和f3()结果应该是1，4，9，但实际结果全部都是 9.\n原因就是当count()函数返回了3个函数时，这3个函数所引用的变量 i 的值已经变成了3。由于f1、f2、f3并没有被调用，所以，此时他们并未计算 i*i，当 f1 被调用时, f1()变成9， 因为此时才计算 i * i，现在的 i 值已经变为3。\n# 将f改为在函数体内执行，在函数内时就被调用，fs变为[1,4,9]def count():    fs = []    for i in range(1, 4):        def f():             return i*i        fs.append(f())    return fsf1, f2, f3 = count()print(f1, f2, f3)   # 1 4 9 \n\n# 下面函数正确返回一个闭包g，g所引用的变量j不是循环变量，因此将正常执行。def f(j):    def g():        return j*j    return g  def test():    lst = []    for i in range(4):        def closefunc(para):            def inner():                return para ** 2            return inner        lst.append(closefunc(i))    return lstfor func in test():    print(func())\n\n\n\n匿名函数高阶函数可以接收函数做参数，有些时候，我们不需要显式地定义函数，直接传入匿名函数更方便。\n在Python中，对匿名函数提供了有限支持。还是以map()函数为例，计算 f(x)&#x3D;x平方时，除了定义一个f(x)的函数外，还可以直接传入匿名函数：\n&gt;&gt;&gt; list(map(lambda x: x ** 2, range(3)))[0, 1, 4]# 关键字lambda 表示匿名函数，冒号前面的 x 表示函数参数。\n\n使用匿名函数，可以不必定义函数名，直接创建一个函数对象，很多时候可以简化代码：\nfunc = lambda x:-x if x&lt;0 else xprint(func(-22))print(func(22))\n\ndef is_not_empty(s):    return s and len(s.strip()) &gt; 0filter(is_not_empty, [&#x27;test&#x27;, None, &#x27;&#x27;, &#x27;str&#x27;, &#x27;  &#x27;, &#x27;END&#x27;])# 使用lambda简化：&gt;&gt;&gt; list(filter(lambda s:s and len(s.strip()) &gt;0, [&#x27;test&#x27;, None, &#x27;&#x27;, &#x27;str&#x27;, &#x27;  &#x27;, &#x27;END&#x27;]))[&#x27;test&#x27;, &#x27;str&#x27;, &#x27;END&#x27;]\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python的特殊方法","url":"/posts/2019/08/22/41419/","content":"__str__ 和 __repr__如果要把一个类的实例变成  __str__，就需要实现特殊方法 __str__：\nclass Person(object):    def __init__(self, name, gender):        self.name = name        self.gender = gender    def __str__(self):        return &#x27;(Person: %s, %s)&#x27; % (self.name, self.gender)\n\n在交互式命令行下用 print ：\n&gt;&gt;&gt; p = Person(&#x27;Bob&#x27;, &#x27;male&#x27;)&gt;&gt;&gt; print p(Person: Bob, male)\n\n但是，如果直接敲变量 p：\n&gt;&gt;&gt; p&lt;main.Person object at 0x10c941890&gt;\n\n因为 Python 定义了str()和repr()两种方法，__str__用于显示给用户，而__repr__用于显示给开发人员。\n有一个偷懒的定义__repr__的方法：\nclass Person(object):    def __init__(self, name, gender):        self.name = name        self.gender = gender    def __str__(self):        return &#x27;(Person: %s, %s)&#x27; % (self.name, self.gender)    __repr__ = __str__&gt;&gt;&gt; p = Person(&quot;a&quot;,&quot;b&quot;)&gt;&gt;&gt; p(Person: a, b)\n\n__cmp__python2下使用，python3无__cmp__\n对 int、str 等内置数据类型排序时，Python的 sorted() 按照默认的比较函数 cmp 排序，但是，如果对一组 Student 类的实例排序时，就必须提供我们自己的特殊方法 __cmp__()：\nclass Student(object):    def __init__(self, name, score):        self.name = name        self.score = score    def __str__(self):        return &#x27;(%s: %s)&#x27; % (self.name, self.score)    __repr__ = __str__    def __cmp__(self, s):        if self.name &lt; s.name:            return -1        elif self.name &gt; s.name:            return 1        else:            return 0\n\n上述 Student 类实现了__cmp__()方法，__cmp__用实例自身self和传入的实例 s 进行比较，如果 self 应该排在前面，就返回 -1，如果 s 应该排在前面，就返回1，如果两者相当，返回 0。\nStudent类实现了按name进行排序：\n&gt;&gt;&gt; L = [Student(&#x27;Tim&#x27;, 99), Student(&#x27;Bob&#x27;, 88), Student(&#x27;Alice&#x27;, 77)]&gt;&gt;&gt; print(sorted(L))[(Alice: 77), (Bob: 88), (Tim: 99)]\n\n注意: 如果list不仅仅包含 Student 类，则 cmp 可能会报错：\nL = [Student(&#x27;Tim&#x27;, 99), Student(&#x27;Bob&#x27;, 88), 100, &#x27;Hello&#x27;]print(sorted(L))\n\n__len__如果一个类表现得像一个list，要获取有多少个元素，就得用 len() 函数。\n要让 len() 函数工作正常，类必须提供一个特殊方法__len__()，它返回元素的个数。\nclass Students(object):    def __init__(self, *args):        self.names = args    def __len__(self):        return len(self.names)ss = Students(&#x27;Bob&#x27;, &#x27;Alice&#x27;, &#x27;Tim&#x27;)print(len(ss))  # 3\n\n运算Python 提供的基本数据类型 int、float 可以做整数和浮点的四则运算以及乘方等运算。\n但是，四则运算不局限于int和float，还可以是有理数、矩阵等。\n要表示有理数，可以用一个Rational类来表示：\nclass Rational(object):    def __init__(self, p, q):        self.p = p        self.q = q\n\np、q 都是整数，表示有理数 p&#x2F;q。\n如果要让Rational进行+运算，需要正确实现__add__：\nclass Rational(object):    def __init__(self, p, q):        self.p = p        self.q = q    def __add__(self, r):        return Rational(self.p * r.q + self.q * r.p, self.q * r.q)    def __str__(self):        return &#x27;%s/%s&#x27; % (self.p, self.q)    __repr__ = __str__r1 = Rational(1, 3)r2 = Rational(1, 2)print(r1 + r2)  # 5/6\n\n四则运算：\n# 寻找a和b的最小公约数def gcd(a, b):      if b == 0:        return a    return gcd(b, a % b)class Rational(object):    def __init__(self, p, q):        self.p = p        self.q = q    def __add__(self, r):        return Rational(self.p * r.q + self.q * r.p, self.q * r.q)    def __sub__(self, r):        return Rational(self.p * r.q - self.q * r.p, self.q * r.q)    def __mul__(self, r):        return Rational(self.p * r.p, self.q * r.q)    def __truediv__(self, r):        return Rational(self.p * r.q, self.q * r.p)    def __str__(self):        g = gcd(self.p, self.q)      \treturn f&#x27;&#123;self.p / g&#125;/&#123;self.q / g&#125;&#x27;   # 约分    __repr__ = __str__    r1 = Rational(1, 2)r2 = Rational(1, 4)print(r1 + r2)   # 3.0/4.0print(r1 - r2)   # 1.0/4.0print(r1 * r2)   # 1.0/8.0print(r1 / r2)   # 2.0/1.0\n\n类型转换Rational类实现了有理数运算，但是，如果要把结果转为 int 或 float 怎么办？\n考察整数和浮点数的转换：\n&gt;&gt;&gt; int(12.34)12&gt;&gt;&gt; float(12)12.0\n\n如果要把 Rational 转为 int，应该使用：\nr = Rational(12, 5)n = int(r)# TypeError: int() argument must be a string, a bytes-like object or a number, not &#x27;Rational&#x27;\n\n要让 int() 函数正常工作，只需要实现特殊方法__int__(),  同理要让 float() 函数正常工作，只需要实现特殊方法__float__()\ndef gcd(a, b):    if b == 0:        return a    return gcd(b, a % b)class Rational(object):    def __init__(self, p, q):        self.p = p        self.q = q    def __str__(self):        g = gcd(self.p, self.q)        return f&#x27;&#123;self.p / g&#125;/&#123;self.q / g&#125;&#x27;   \tdef __float__(self):        return float(self.p) / self.q    def __int__(self):        return self.p // self.q    __repr__ = __str__print(Rational(6,8))      # 3.0/4.0print(int(Rational(6,8)))  # 0print(float(Rational(6,8)))  # 0.75print(Rational(8,6))      # 4.0/3.0print(int(Rational(8,6)))  # 1print(float(Rational(8,6)))  # 1.3333333333333333\n\n@property举例 Student 类：\nclass Student(object):    def __init__(self, name, score):        self.name = name        self.score = score\n\n当我们想要修改一个 Student 的 score 属性时，可以这么写：\ns = Student(&#x27;Bob&#x27;, 59)s.score = 60# 但是也可以这么写：s.score = 1000\n\n但是也可以这么写：\n显然，直接给属性赋值无法检查分数的有效性。\n如果利用两个方法：\nclass Student(object):    def __init__(self, name, score):        self.name = name        self.__score = score    def get_score(self):        return self.__score    def set_score(self, score):        if score &lt; 0 or score &gt; 100:            raise ValueError(&#x27;invalid score&#x27;)        self.__score = score\n\n这样 s.set_score(1000) 就会报错, 达到检查数据的目的。\n这种使用 get&#x2F;set 方法来封装对一个属性的访问在许多面向对象编程的语言中都很常见。\n但是写 s.get_score() 和 s.set_score() 没有直接写 s.score 来得直接。\n有一个两全其美的方法：\n因为Python支持高阶函数，在函数式编程中有装饰器函数，可以用装饰器函数把 get&#x2F;set 方法“装饰”成属性调用：\nclass Student(object):    def __init__(self, name, score):        self.name = name        self.__score = score    @property    def score(self):        return self.__score    @score.setter    def score(self, score):        if score &lt; 0 or score &gt; 100:            raise ValueError(&#x27;invalid score&#x27;)        self.__score = score\n\n注意: 第一个score(self)是get方法，用@property装饰，第二个score(self, score)是set方法，用@score.setter装饰，@score.setter是前一个@property装饰后的副产品。\n现在，就可以像使用属性一样设置score了：\n&gt;&gt;&gt; s = Student(&#x27;Bob&#x27;, 59)&gt;&gt;&gt; s.score = 60&gt;&gt;&gt; print(s.score)60&gt;&gt;&gt; s.score = 1000Traceback (most recent call last):  ...ValueError: invalid score# 说明对 score 赋值实际调用的是 set方法。\n\n__slot__由于Python是动态语言，任何实例在运行期都可以动态地添加属性。\n如果要限制添加的属性，例如，Student类只允许添加 name、gender和score 这3个属性，就可以利用Python的一个特殊的__slots__来实现。\n__slots__是指一个类允许的属性列表：\nclass Student(object):    __slots__ = (&#x27;name&#x27;, &#x27;gender&#x27;, &#x27;score&#x27;)    def __init__(self, name, gender, score):        self.name = name        self.gender = gender        self.score = score\n\n对实例进行操作：\n&gt;&gt;&gt; s = Student(&#x27;Bob&#x27;, &#x27;male&#x27;, 59)&gt;&gt;&gt; s.name = &#x27;Tim&#x27;   # OK&gt;&gt;&gt; s.score = 99     # OK&gt;&gt;&gt; s.grade = &#x27;A&#x27;Traceback (most recent call last):  ...AttributeError: &#x27;Student&#x27; object has no attribute &#x27;grade&#x27;\n\n__slots__的目的是限制当前类所能拥有的属性，如果不需要添加任意动态的属性，使用__slots__也能节省内存。\n举例：假设Person类通过slots定义了name和gender，在派生类Student中通过slots继续添加score的定义，使Student类可以实现name、gender和score 3个属性\nclass Person(object):    __slots__ = (&#x27;name&#x27;, &#x27;gender&#x27;)    def __init__(self, name, gender):        self.name = name        self.gender = genderclass Student(Person):    __slots__ = (&#x27;score&#x27;)    def __init__(self, name, gender, score):        super(Student, self).__init__(name, gender)        self.score = scores = Student(&#x27;Bob&#x27;, &#x27;male&#x27;, 59)s.name = &#x27;Tim&#x27;s.score = 99print(s.score)\n\n__call__函数也是对象，也可以被调用，所有的函数都是可调用对象。\n一个类实例也可以变成一个可调用对象，只需要实现一个特殊方法__call__()。\n我们把 Person 类变成一个可调用对象：\nclass Person(object):    def __init__(self, name, gender):        self.name = name        self.gender = gender    def __call__(self, friend):        print(f&#x27;name is &#123;self.name&#125;&#x27;)        print(f&#x27;friend is &#123;friend&#125;&#x27;)# 现在可以对 Person 实例直接调用：p1 = Person(&quot;zzz&quot;,&#x27;male&#x27;)p1(&#x27;friend_uuu&#x27;)# name is zzz# friend is friend_uuu\n\n单看p1(‘friend_uuu’)无法确定 p1 是一个函数还是一个类实例，所以，在Python中，函数也是对象，对象和函数的区别并不显著。\nclass Fib(object):    def __call__(self, num):        a, b, retlist = 0, 1, []        for i in range(num):            retlist.append(a)            a, b = b, a+b        return retlistf = Fib()print(f(10))  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n\n\nBest Practices\n始终实现 __repr__ 以进行调试\n使特殊方法与内置类型一致\n尽可能使用 @property 而不是 get&#x2F;set 方法\n适当时使用 @total_ordering 实现比较方法\n需要时使用 __slots__ 进行内存优化\n保持特殊方法简单且有针对性\n彻底记录特殊方法\n\nCommon Pitfalls\n忘记在算术运算中返回新对象\n未处理比较方法中的极端情况\n实现 __str__ 而不使用 __repr__\n在 __init__ 中使用可变默认参数\n未考虑特殊方法中的类型检查\n\n请记住，特殊方法是功能强大的工具，应谨慎使用。它们允许您使对象的行为像内置类型一样并与 Python 的语法无缝集成，但只有当它们使您的代码更具可读性和可维护性时才应实现它们。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python中的继承","url":"/posts/2019/08/18/47992/","content":"继承class Person(object):    def __init__(self, name, gender):        self.name = name        self.age = genderclass Student(Person):    def __init__(self, name, gender, score):        super(Student, self).__init__(name, gender)        self.score = score\n\nsuper(Student, self).__init__(name, gender) 初始化父类，继承自 Person 的 Student  才会有 name 和 gender属性，函数 super(Student, self)  将返回当前类继承的父类，即 Person ，然后调用其 __init__()方法\n可以使用isinstance()来判断继承关系：\np1 = Person(&quot;p_name&quot;, &#x27;f&#x27;)s1 = Student(&quot;s_name&quot;, &#x27;m&#x27;, 90)print(isinstance(p1, Person))print(isinstance(p1, Student))print(isinstance(s1, Person))\n\n\n\n多态class Person(object):    def __init__(self, name, gender):        self.name = name        self.age = gender    def whoAmI(self):        return &quot;class Person:&quot;, self.name        class Student(Person):    def __init__(self, name, gender, score):        super(Student, self).__init__(name, gender)        self.score = score        def whoAmI(self):        return &quot;class Student:&quot;, self.name    class Teacher(Person):    def __init__(self, name, gender, course):        super(Teacher, self).__init__(name, gender)        self.score = course        def whoAmI(self):        return &quot;class Teacher:&quot;, self.name    def testpolymorphism(obj):    return obj.whoAmI()p1 = Person(&quot;p_name&quot;, &#x27;f&#x27;)s1 = Student(&quot;s_name&quot;, &#x27;m&#x27;, 90)t1 = Teacher(&quot;t_name&quot;, &#x27;f&#x27;, &#x27;english&#x27;)print(testpolymorphism(p1))  # (&#x27;class Person:&#x27;, &#x27;p_name&#x27;)print(testpolymorphism(s1))  # (&#x27;class Student:&#x27;, &#x27;s_name&#x27;)print(testpolymorphism(t1))  # (&#x27;class Teacher:&#x27;, &#x27;t_name&#x27;)\n\ns1 是Student类型，它实际上拥有自己的 whoAmI() 方法以及从 Person继承的 whoAmI 方法，但调用 s1.whoAmI() 总是先查找它自身的定义，如果没有定义，则顺着继承链向上查找，直到在某个父类中找到为止。\n由于Python是动态语言，所以，传递给函数 testpolymorphism(obj) 的参数 obj 不一定是 Person 或 Person 的子类型。任何数据类型的实例都可以，只要它有一个whoAmI()的方法即可：\nclass Book(object):    def whoAmI(self):        return &#x27;I am a book&#x27;\n\n这是动态语言和静态语言（例如Java）最大的差别之一。动态语言调用实例方法，不检查类型，只要方法存在，参数正确，就可以调用。\n举例：\nPython提供了 open() 函数来打开一个磁盘文件，并返回 File 对象。File对象有一个 read() 方法可以读取文件内容：\n例如，从文件读取内容并解析为JSON结果：\nimport jsonf = open(&#x27;/path/to/file.json&#x27;, &#x27;r&#x27;)print json.load(f)\n\n由于Python的动态特性，json.load() 并不一定要从一个File对象读取内容。任何对象，只要有 read() 方法，就称为File-like Object，都可以传给 json.load() 。\n尝试编写一个File-like Object，把一个字符串 r’[“Tim”, “Bob”, “Alice”]’包装成 File-like Object 并由 json.load() 解析。\nimport jsonclass TestRead(object):    def read(self):        return  r&#x27;[&quot;Tim&quot;, &quot;Bob&quot;, &quot;Alice&quot;]&#x27;t = TestRead()print(json.load(t)) # [&#x27;Tim&#x27;, &#x27;Bob&#x27;, &#x27;Alice&#x27;]print(type(json.load(t)))  # &lt;class &#x27;list&#x27;&gt;\n\n\n多继承从多个父类继承，称为多重继承。多重继承的继承链就不是一棵树了，像这样：\nclass A(object):    def __init__(self, a):        print &#x27;init A...&#x27;        self.a = aclass B(A):    def __init__(self, a):        super(B, self).__init__(a)        print &#x27;init B...&#x27;class C(A):    def __init__(self, a):        super(C, self).__init__(a)        print &#x27;init C...&#x27;class D(B, C):    def __init__(self, a):        super(D, self).__init__(a)        print &#x27;init D...&#x27;\n\n像这样，D 同时继承自 B 和 C ，也就是 D 拥有了 A、B、C 的全部功能。多重继承通过 super()调用__init__()方法时，A 虽然被继承了两次，但__init__()只调用一次：\n&gt;&gt;&gt; d = D(&#x27;d&#x27;)init A...init C...init B...init D...\n\n多重继承的目的是从两种继承树中分别选择并继承出子类，以便组合功能使用。\n举个例子，Python的网络服务器有TCPServer、UDPServer、UnixStreamServer、UnixDatagramServer，而服务器运行模式有 多进程ForkingMixin 和 多线程ThreadingMixin两种。\n要创建多进程模式的 TCPServer：\nclass MyTCPServer(TCPServer, ForkingMixin)    pass\n\n要创建多线程模式的 UDPServer：\nclass MyUDPServer(UDPServer, ThreadingMixin):    pass\n\n如果没有多重继承，要实现上述所有可能的组合需要 4x2&#x3D;8 个子类。\n\n获取对象信息除了用 isinstance() 判断它是否是某种类型的实例外，还有别的方法获取到更多的信息。\n例如，已有定义：\nclass Person(object):    def __init__(self, name, gender):        self.name = name        self.gender = genderclass Student(Person):    def __init__(self, name, gender, score):        super(Student, self).__init__(name, gender)        self.score = score    def whoAmI(self):        return &#x27;I am a Student, my name is %s&#x27; % self.name\n\n首先可以用 type() 函数获取变量的类型，它返回一个 Type 对象：\n&gt;&gt;&gt; type(123)&lt;type &#x27;int&#x27;&gt;&gt;&gt;&gt; s = Student(&#x27;Bob&#x27;, &#x27;Male&#x27;, 88)&gt;&gt;&gt; type(s)&lt;class &#x27;__main__.Student&#x27;&gt;\n\n其次，可以用 dir() 函数获取变量的所有属性：\n&gt;&gt;&gt; dir(123)   # 整数也有很多属性...[&#x27;__abs__&#x27;, &#x27;__add__&#x27;, &#x27;__and__&#x27;, &#x27;__class__&#x27;, &#x27;__cmp__&#x27;, ...]&gt;&gt;&gt; dir(s)[&#x27;__class__&#x27;, &#x27;__delattr__&#x27;, &#x27;__dict__&#x27;, &#x27;__doc__&#x27;, &#x27;__format__&#x27;, &#x27;__getattribute__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__module__&#x27;, &#x27;__new__&#x27;, &#x27;__reduce__&#x27;, &#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;, &#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;, &#x27;__subclasshook__&#x27;, &#x27;__weakref__&#x27;, &#x27;gender&#x27;, &#x27;name&#x27;, &#x27;score&#x27;, &#x27;whoAmI&#x27;]\n\n对于实例变量，dir() 返回所有实例属性，包括 __class__ 这类有特殊意义的属性。注意到方法 whoAmI 也是 s 的一个属性。\n如何去掉 __xxx__ 这类的特殊属性，只保留我们自己定义的属性？使用 filter() 函数的用法。\ndir() 返回的属性是字符串列表，如果已知一个属性名称，要获取或者设置对象的属性，就需要用  getattr()  和  setattr() 函数了：\n&gt;&gt;&gt; getattr(s, &#x27;name&#x27;)  # 获取name属性&#x27;Bob&#x27;&gt;&gt;&gt; setattr(s, &#x27;name&#x27;, &#x27;Adam&#x27;)  # 设置新的name属性&gt;&gt;&gt; s.name&#x27;Adam&#x27;&gt;&gt;&gt; getattr(s, &#x27;age&#x27;)  # 获取age属性，但是属性不存在，报错：Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AttributeError: &#x27;Student&#x27; object has no attribute &#x27;age&#x27;&gt;&gt;&gt; getattr(s, &#x27;age&#x27;, 20)  # 获取age属性，如果属性不存在，就返回默认值20：20\n\n拓展举例：使用 setattr\n对于Person类的定义：\nclass Person(object):    def __init__(self, name, gender):        self.name = name        self.gender = gender\n\n希望除了 name和gender 外，可以提供任意额外的关键字参数，并绑定到实例，请修改 Person 的 __init__()定 义，完成该功能。\nclass Person(object):    def __init__(self, name, gender, **kwargs):        self.name = name        self.gender = gender        for k, v in kwargs.items():            # dict_items([(&#x27;age&#x27;, 25), (&#x27;love&#x27;, &#x27;reading&#x27;)])            setattr(self, k, v)p1 = Person(&quot;zyp&quot;, &#x27;male&#x27;, age=25, love=&quot;reading&quot;)# print(dir(p1))print(p1.age)  # 25print(p1.love)  # reading\n","categories":["技术","Python"],"tags":["Python"]},{"title":"RuntimeError dictionary changed size during iteration 遍历字典时报错","url":"/posts/2019/11/27/7873/","content":"RuntimeError: dictionary changed size during iteration\n在字典遍历过程中修改字典长度时会报错；这里是遍历时修改了字典长度，导致了字典中有字典，一直在查找，直到RuntimError。\n\n我是在用 globals 函数时，发现的问题：\ng_dict = globals()for key in (g_dict.keys()):    print(f&#x27;&#123;key&#125;:&#123;g_dict[key]&#125;&#x27;)\n\n应该使用 list 将 dict 变为列表，才能遍历。\nfor key in list(g_dict.keys()):      print(f&#x27;&#123;key&#125;:&#123;g_dict[key]&#125;&#x27;)\n\n仔细一想，我在遍历时好像没有改变字典元素呀，原因在哪里？看了打印结果才感觉发现是 globals() 这个函数的原因：\n打印结果：\n__name__:__main____doc__:None__package__:None__loader__:&lt;_frozen_importlib_external.SourceFileLoader object at 0x000001ED473AC240&gt;__spec__:None__annotations__:&#123;&#125;__builtins__:&lt;module &#x27;builtins&#x27; (built-in)&gt;__file__:D:/keeplearning/myLearning/python/book2/test.py__cached__:Nonetest1:&lt;function test1 at 0x000001ED472A3E18&gt;Test2:&lt;class &#x27;__main__.Test2&#x27;&gt;g_dict:&#123;&#x27;__name__&#x27;: &#x27;__main__&#x27;, &#x27;__doc__&#x27;: None, &#x27;__package__&#x27;: None, &#x27;__loader__&#x27;: &lt;_frozen_importlib_external.SourceFileLoader object at 0x000001ED473AC240&gt;, &#x27;__spec__&#x27;: None, &#x27;__annotations__&#x27;: &#123;&#125;, &#x27;__builtins__&#x27;: &lt;module &#x27;builtins&#x27; (built-in)&gt;, &#x27;__file__&#x27;: &#x27;D:/keeplearning/myLearning/python/book2/test.py&#x27;, &#x27;__cached__&#x27;: None, &#x27;test1&#x27;: &lt;function test1 at 0x000001ED472A3E18&gt;, &#x27;Test2&#x27;: &lt;class &#x27;__main__.Test2&#x27;&gt;, &#x27;g_dict&#x27;: &#123;...&#125;, &#x27;key&#x27;: &#x27;g_dict&#x27;&#125;\n\n发现g_dict键的值中有递归了，g_dict的值中出现了’g_dict’: {…} 。\n修改如下：\nfor key in list(g_dict.keys()):    if not isinstance(g_dict[key],dict):        print(f&quot;&#123;key&#125;:&#123;g_dict[key]&#125;&quot;)\n\n结果：\n__name__:__main____doc__:None__package__:None__loader__:&lt;_frozen_importlib_external.SourceFileLoader object at 0x00000217DCB3C240&gt;__spec__:None__builtins__:&lt;module &#x27;builtins&#x27; (built-in)&gt;__file__:D:/keeplearning/myLearning/python/book2/test.py__cached__:Nonetest1:&lt;function test1 at 0x00000217DCA33E18&gt;Test2:&lt;class &#x27;__main__.Test2&#x27;&gt;\n\nglobals() 返回一个字典，表示当前的全局符号表。这个符号表始终针对当前模块（对函数或方法来说，是指定义它们的模块，而不是调用它们的模块）。\n","categories":["技术","Python"],"tags":["Python","FixBug"]},{"title":"Python装饰器的理解和应用","url":"/posts/2019/08/17/20652/","content":"装饰器的作用\n打印日志:  @log\n检测性能：@performance\n数据库事务： @transaction\nURL路由：@post(‘&#x2F;register’)\n\n装饰器的目的：\n\n使代码可读性更高，感觉高大上；\n代码结构更加清晰，代码冗余度更低；\n\n无参数decoratorPython的 decorator 本质上就是一个高阶函数，它接收一个函数作为参数，然后，返回一个新函数。\n使用 decorator 用Python提供的 @ 语法，这样可以避免手动编写f &#x3D; decorate(f) 这样的代码。\n考察一个@log的定义：\ndef testlog(func):    def inner(arg):        print(&quot;print log:&quot; + func.__name__)        func(arg)    return inner# 不使用@def test(x):    print(&quot;this is test function:&quot;,x)test = testlog(test)test(&quot;11&quot;)# 使用@@testlogdef test(x):    print(&quot;this is test function:&quot;,x)test(&quot;11&quot;)# print log:test# this is test function：11\n\n例子：阶乘\nfrom functools import reducedef testlog(func):    def inner(*args,**kwargs):        # 要让 @testlog 自适应任何参数定义的函数，可以利用Python的 *args 和 **kw，保证任意个数的参数总是能正常调用        print(&quot;print log:&quot; + func.__name__)        func(*args,**kwargs)    return inner@testlogdef factorial(x, y):    print(&quot;this is factorial function:&quot;)    res = reduce(lambda x, y: x * y, range(x, y))    print(res)    return resfactorial(1, 11)# print log:factorial# this is factorial function:# 3628800\n\n例子：写一个@performance，作为一个函数计时器。\nimport timedef performance(func):    def inner(*args, **kwargs):        time1 = time.time()        res = func(*args, **kwargs)        time2 = time.time()        print(f&quot;call %s%s%s in %fs&quot; % (func.__name__, args,kwargs, time2 - time1))        return res    return inner@performancedef factorial(x, y):    return reduce(lambda x, y: x * y, range(x, y))print(factorial(1, 11))# call factorial(1, 11)&#123;&#125; in 0.000999s# 3628800\n\n\n\n有参数decorator在之前没有带参数的装饰器上添加参数：\nfrom functools import reduceimport timedef performance(unit):    def decorator_(func):        def wrap(*args, **kwargs):            time1 = time.time()            res = func(*args, **kwargs)            time.sleep(1)            time2 = time.time()            t = 1000 * (time2 - time1) if unit == &#x27;ms&#x27; else (time2 - time1)            print(f&quot;call %s in %s %s&quot;%(func.__name__, t, unit))            return res        return wrap    return decorator_@performance(&#x27;ms&#x27;)def factorial_(n):    return reduce(lambda x,y: x*y, range(1, n+1))print(factorial_(6))# call factorial_ in 1000.087261199951 ms# 720\n\n\n\n装饰器的优化@decorator 可以动态实现函数功能的增加，但是，经过@decorator“改造”后的函数，和原函数相比，除了功能多一点外，还有其它不同的地方。\n在没有decorator的情况下，打印函数名：\ndef f1(x):    passprint(f1.__name__)  # f1\n\n有decorator的情况下，再打印函数名：\ndef log(func):    def wrapper(*args, **kw):        return func(*args, **kw)    return wrapper@logdef f2(x):    passprint(f2.__name__)  # wrapper\n\n由于decorator返回的新函数函数名已经不是’f2’，而是@log内部定义的’wrapper’。这对于那些依赖函数名的代码就会失效。decorator还改变了函数的 __doc__ 等其它属性。如果要让调用者看不出一个函数经过了@decorator的“改造”，就需要把原函数的一些属性复制到新函数中：\ndef log(func):    def wrapper(*args, **kw):        return func(*args, **kw)    wrapper.__name__ = func.__name__    wrapper.__doc__ = func.__doc__    return wrapper@logdef f2(x):    passprint(f2.__name__)  # f2\n\n这样写decorator很不方便，也很难把原函数的所有必要属性都一个一个复制到新函数上，所以Python内置的 functools 可以用来自动化完成这个“复制”的任务：\nimport functoolsdef log(func):    @functools.wraps(func)    def wrapper(*args, **kw):        return func(*args, **kw)    return wrapper@logdef f2(x):    passprint(f2.__name__)  # f2\n\n# 带参数的装饰器# 注意@functools.wraps应该作用在返回的新函数上。def performance(prefix):    def log(func):        @functools.wraps(func)        def wrapper(*args, **kw):            return func(*args, **kw)        return wrapper    return log@performance(&quot;debug&quot;)def f2(x):    passprint(f2.__name__)  # f2\n\n\n\n类装饰器（不带参数）基于类装饰器的实现，必须实现 __call__ 和 __init__两个内置函数。__init__ ：接收被装饰函数__call__ ：实现装饰逻辑。\nclass logger(object):    def __init__(self, func):        self.func = func    def __call__(self, *args, **kwargs):        print(f&quot;logger:&#123;self.func.__name__&#125; in decorator&quot;)        return self.func(*args, **kwargs)@loggerdef test(para):    print(f&quot;test func(&#123;para&#125;)&quot;)test(&quot;123&quot;)# logger:test in decorator# test func(123)\n\n\n\n类装饰器（带参数）若还需要打印DEBUG WARNING等级别的日志。这就需要给类装饰器传入参数，给这个函数指定级别了。\n带参数和不带参数的类装饰器有很大的不同。\n__init__ ：不再接收被装饰函数，而是接收传入参数。__call__ ：接收被装饰函数，实现装饰逻辑。\nclass logger(object):    def __init__(self, level=&#x27;info&#x27;):        self.level = level            def __call__(self, func):        def wrapper(*args, **kwargs):            print(f&quot;logger[&#123;self.level&#125;]:&#123;func.__name__&#125; in decorator&quot;)            func(*args, **kwargs)        return wrapper@logger(level=&#x27;warning&#x27;)def test_funct(para):    print(f&#x27;test test_funct(&#123;para&#125;)&#x27;)test_funct(&quot;321&quot;)# logger[warning]:test_funct in decorator# test test_funct(321)\n\n\n\n偏函数当一个函数有很多参数时，调用者就需要提供多个参数。如果减少参数个数，就可以简化写代码的负担。\n比如，int()函数可以把字符串转换为整数，当仅传入字符串时，int()函数默认按十进制转换：\n&gt;&gt;&gt; int(&#x27;12345&#x27;)12345\n\n但int()函数还提供额外的base参数，默认值为10。如果传入base参数，就可以做 N 进制的转换：\n&gt;&gt;&gt; int(&#x27;12345&#x27;, base=8)5349&gt;&gt;&gt; int(&#x27;12345&#x27;, 16)74565\n\n假设要转换大量的二进制字符串，每次都传入int(x, base&#x3D;2)非常麻烦，于是，我们想到，可以定义一个int2()的函数，默认把base&#x3D;2传进去：\ndef int2(x, base=2):    return int(x, base)\n\n这样，我们转换二进制就非常方便了：\n&gt;&gt;&gt; int2(&#x27;1000000&#x27;)64&gt;&gt;&gt; int2(&#x27;1010101&#x27;)85\n\nfunctools.partial 就是帮助我们创建一个偏函数的，不需要我们自己定义int2()，可以直接使用下面的代码创建一个新的函数int2：\n&gt;&gt;&gt; import functools&gt;&gt;&gt; int2 = functools.partial(int, base=2)&gt;&gt;&gt; int2(&#x27;1000000&#x27;)64&gt;&gt;&gt; int2(&quot;11&quot;,base=2)  # 临时需要可以更改3\n\n所以，functools.partial 可以把一个多参数的函数变成一个参数少的新函数，少的参数需要在创建时指定默认值，这样，新函数调用的难度就降低了。\nfrom functools import partial# 示例 1: 文件处理中的应用# 基础函数def read_file(filename, mode=&#x27;r&#x27;, encoding=&#x27;utf-8&#x27;, errors=&#x27;strict&#x27;):    with open(filename, mode=mode, encoding=encoding, errors=errors) as f:        return f.read()# 创建一个专门用于处理日志文件的偏函数，固定编码和错误处理方式read_log = partial(read_file, encoding=&#x27;utf-8&#x27;, errors=&#x27;ignore&#x27;)# 使用示例# log_content = read_log(&#x27;app.log&#x27;)  # 只需要提供文件名即可# 示例 2: 数值处理中的应用def round_number(number, ndigits=0, base=10):    &quot;&quot;&quot;按指定进位基数四舍五入&quot;&quot;&quot;    return round(number / base) * base# 创建一个专门用于处理十位数四舍五入的偏函数round_to_tens = partial(round_number, base=10)round_to_hundreds = partial(round_number, base=100)# 使用示例print(round_to_tens(126))      # 输出: 130print(round_to_hundreds(126))  # 输出: 100\n\n\n\n偏函数与类实现装饰器大多数装饰器都是基于函数和闭包实现的，但这并非构造装饰器的唯一方式。\nPython 对某个对象是否能通过装饰器（ @decorator）形式使用只有一个要求：decorator 必须是一个可被调用（callable）的对象。\n对于callable 对象，最熟悉的就是函数了；\n除函数之外，类也可以是 callable 对象，只要实现了__call__ 函数（上面几个例子）。\n还有容易被人忽略的偏函数其实也是 callable 对象。\nimport timeimport functoolsclass DelayFunc:    def __init__(self, duration, func):        self.duration = duration        self.func = func    def __call__(self, *args, **kwargs):        print(f&#x27;Wait for &#123;self.duration&#125; seconds...&#x27;)        time.sleep(self.duration)        return self.func(*args, **kwargs)    def eager_call(self, *args, **kwargs):        print(&#x27;Call without delay&#x27;)        return self.func(*args, **kwargs)def delay(duration):    &quot;&quot;&quot;    装饰器：推迟某个函数的执行。    同时提供 .eager_call 方法立即执行    &quot;&quot;&quot;    # 此处为了避免定义额外函数，    # 直接使用 functools.partial 帮助构造 DelayFunc 实例    return functools.partial(DelayFunc, duration) @delay(duration=2)def add(a, b):    return a+b  print(add)    # add 变成了类DelayFunc的实例# &lt;__main__.DelayFunc object at 0x000001EED91FA3C8&gt;print(add(3, 5))  #  直接调用实例，进入 __call__# Wait for 2 seconds...# 8print(add.eager_call(1,2))  # 实现实例方法# Call without delay# 3\n\n\n\n装饰类的装饰器用 Python 写单例模式的时候，常用的有三种写法。其中一种，是用装饰器来实现的。\ninstances = &#123;&#125;def singleton(cls):    def get_instance(*args, **kwargs):        cls_name = cls.__name__        print(&quot;cls_name:&quot;,cls_name)        if not cls_name in instances:            print(f&quot;cle_name[&#123;cls_name&#125;] not in instances&quot;)            instance = cls(*args, **kwargs)            instances[cls_name] = instance        return instances[cls_name]    return get_instance@singletonclass User:    _instance = None    def __init__(self, name):        self.name = name        print(&quot;name=&quot;,self.name)u1 =User(&quot;usr1&quot;)print(u1,u1.name)u2 =User(&quot;usr2&quot;)print(u2,u2.name)print(u1 == u2)# cls_name: User# cle_name[User] not in instances# name= usr1# &lt;__main__.User object at 0x000001B2D33BB2B0&gt; usr1# cls_name: User# &lt;__main__.User object at 0x000001B2D33BB2B0&gt; usr1# True\n\n\n\nwraps再理解了解完偏函数后再回看 functools.wraps() 的作用\nwraps 其实是一个偏函数对象（partial），源码如下：\ndef wraps(wrapped,          assigned = WRAPPER_ASSIGNMENTS,          updated = WRAPPER_UPDATES):    return partial(update_wrapper, wrapped=wrapped,                   assigned=assigned, updated=updated)\n\nwraps其实就是调用了一个函数update_wrapper，知道原理后，我们改写上面的代码，在不使用 wraps的情况下，也可以让wrapped.__name__ 打印出 wrapped，代码如下：\nfrom functools import update_wrapperWRAPPER_ASSIGNMENTS = (&#x27;__module__&#x27;, &#x27;__name__&#x27;, &#x27;__qualname__&#x27;, &#x27;__doc__&#x27;,                       &#x27;__annotations__&#x27;)def decorator(func):    def inner():        pass    update_wrapper(inner, func, assigned=WRAPPER_ASSIGNMENTS)    return inner@decoratordef testfunc():    passprint(testfunc.__name__)  # testfunc\n\n一般最常使用的就是：\nfrom functools import wrapsdef decorator(func):    @wraps(func)    def inner():        pass    return inner@decoratordef testfunc():    passprint(testfunc.__name__)  # testfunc\n\n\n\npython内置装饰器：propertyproperty通常存在于类中，可以将一个函数定义成一个属性，属性的值就是该函数return的内容。\n初学Python时这样给实例绑定属性：\nclass Person(object):     def __init__(self, name, age= None):        self.name = name        self.age = age# instantiatep1 = Person(&quot;person1&quot;)# add attributep1.age = 25# query attrbuteprint(p1.name)# delete attributedel p1.age\n\n但是这样存在问题：直接把属性暴露出去，虽然写起来很简单，但是并不能对属性的值做合法性限制。合理的写法如下：\nclass Person(object):    def __init__(self, name, age= None):        self.name = name        self.__age = age    def set_age(self, age):        if not isinstance(age, int):            raise ValueError(&#x27;input illegal: age must be int.&#x27;)        if not 0 &lt; age &lt; 100:            raise ValueError(&#x27;input illegal: age must between 0 and 150.&#x27;)        self.__age = age    def get_age(self):        return self.__age    def del_age(self):        self.__age = None# instantiatep1 = Person(&quot;tiny&quot;)# add attributep1.set_age(25)# query attrbuteprint(p1.get_age())# delete attributep1.del_age()\n\n上面的代码设计虽然可以变量的定义，但是可以发现不管是获取还是赋值（通过函数）都和我们平时想要的的不同。我们想要的是这样形式的：赋值p1.age = 25, 获取p1.age。\n使用@property : \nclass Person(object):    def __init__(self, name, age=None):        self.name = name        self.__age = age    @property    def age(self):        return self.__age    @age.setter    def age(self, value):        if not isinstance(value, int):            raise ValueError(&#x27;age must be int.&#x27;)        if not 0 &lt; value &lt; 150:            raise ValueError(&#x27;age must between 1 and 150.&#x27;)        self.__age = value    @age.deleter    def age(self):        del self.__age# instantiatep1 = Person(&quot;tiny&quot;)# modify attributep1.age = 25# query attrbuteprint(p1.age)# delete attributedel p1.age\n\n用@property装饰过的函数，会将一个函数定义成一个属性，属性的值就是该函数return的内容。同时，会将这个函数变成另外一个装饰器。就像@age.setter和@age.deleter。\n@age.setter 使得我们可以使用p1.age = 25这样的方式直接赋值;@age.deleter 使得我们可以使用del p1.age这样的方式来删除属性。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"pytest01 easy start","url":"/posts/2019/06/09/50554/","content":"easy start直接运行pytest\n# content of test_sample.pydef inc(x):    return x + 1def test_answer():    assert inc(3) == 5\n\n$ pytest========== test session starts ========platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 1 itemtest_sample.py F                                                     [100%]============= FAILURES =============___________ test_answer _____________    def test_answer():&gt;       assert inc(3) == 5E       assert 4 == 5E        +  where 4 = inc(3)test_sample.py:6: AssertionError========== 1 failed in 0.12 seconds ==========\n\n\n\n运行多个文件\n在没有定制的默认情况下的缺省规则\n\npytest会找当前以及递查找子文件夹下面所有的test_*.py或*_test.py的文件，把其当作测试文件\n在这些文件里，pytest会收集下面的一些函数或方法，当作测试用例\n不在类定义中的以test_开头的函数或方法\n在以Test开头的类中(不能包含__init__方法)，以test_开头的方法\n\n\npytest也支持unittest模式的用例定义\n\nAssertAssert就是断言，每个测试用例都需要断言。\n与unittest不同，pytest使用的是python自带的assert关键字来进行断言，大大降低了学习成本。\nassert关键字后面可以接一个表达式，只要表达式的最终结果为True，那么断言通过，用例执行成功，否则用例执行失败。\nFixture可以把Fixture理解为准备测试数据和初始化测试对象的阶段。\n一般我们对测试数据和测试对象的管理有这样的一些场景\n\n所有用例开始之前初始化测试数据或对象\n所有用例结束之后销毁测试数据或对象\n每个用例开始之前初始化测试数据或对象\n每个用例结束之后销毁测试数据或对象\n在每个／所有module的用例开始之前初始化数据或对象\n在每个／所有module的用例开始之后销毁数据或对象\n……\n\n举例1\n# content of ./test_smtpsimple.pyimport pytest@pytest.fixturedef smtp_connection():    import smtplib    return smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587, timeout=5)def test_ehlo(smtp_connection):    response, msg = smtp_connection.ehlo()    assert response == 250    assert 0 # for demo purposes\n\n这里test_ehlo需要smtp_connection 的fixture值，pytest将会发现并且调用@pytest.fixture 标志着smtp_connection fixture函数。\n$ pytest test_smtpsimple.py============ test session starts ===============platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 1 itemtest_smtpsimple.py F                                                 [100%]=========== FAILURES =================___________ test_ehlo ________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_ehlo(smtp_connection):        response, msg = smtp_connection.ehlo()        assert response == 250&gt;       assert 0 # for demo purposesE       assert 0test_smtpsimple.py:11: AssertionError======== 1 failed in 0.12 seconds ========\n\n举例2\n考虑一场景，需要判断用户的密码中包含简单密码，密码必须至少6位，满足6位后判断用户的密码不是password123或者password之类的弱密码。\n我们将用户的信息导出成名为users.dev.json的文件，该文件如下所示\n[  &#123;&quot;name&quot;:&quot;jack&quot;,&quot;password&quot;:&quot;Iloverose&quot;&#125;,  &#123;&quot;name&quot;:&quot;rose&quot;,&quot;password&quot;:&quot;Ilovejack&quot;&#125;,  &#123;&quot;name&quot;:&quot;tom&quot;,&quot;password&quot;:&quot;password123&quot;&#125;,]\n\n# test_user_password.pyimport pytestimport jsonclass TestUserPassword(object):    @pytest.fixture    def users(self):        return json.loads(open(&#x27;./users.dev.json&#x27;, &#x27;r&#x27;).read()) # 读取当前路径下的users.dev.json文件，返回的结果一个列表，其中是一个个dict# [&#123;&#x27;name&#x27;: &#x27;jack&#x27;, &#x27;password&#x27;: &#x27;Iloverose&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;rose&#x27;, &#x27;password&#x27;: &#x27;Ilovejack&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;tom&#x27;, &#x27;password&#x27;: &#x27;password123&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;mike&#x27;, &#x27;password&#x27;: &#x27;password&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;james&#x27;, &#x27;password&#x27;: &#x27;AGoodPasswordWordShouldBeLongEnough&#x27;&#125;]# &lt;class &#x27;list&#x27;&gt;    def test_user_password(self, users):        # 遍历每条user数据        for user in users:            passwd = user[&#x27;password&#x27;]            assert len(passwd) &gt;= 6            msg = &quot;user %s has a weak password&quot; %(user[&#x27;name&#x27;])            assert passwd != &#x27;password&#x27;, msg            assert passwd != &#x27;password123&#x27;, msg\n\n运行\npytest可以通过指定文件名的方式运行单个用例文件，这里我们只运行test_user_password.py文件\npytest test_user_password.py\n\n运行结果\n$ pytest test_user_password.py============= test session starts ================platform darwin -- Python 2.7.12, pytest-3.2.3, py-1.4.34, pluggy-0.4.0rootdir: /Users/easonhan/code/testclass.net/src/pytest, inifile:collected 1 itemtest_user_password.py F================ FAILURES ================________________ TestUserPassword.test_user_password __________self = &lt;test_user_password.TestUserPassword object at 0x1046e3290&gt;users = [&#123;&#x27;name&#x27;: &#x27;jack&#x27;, &#x27;password&#x27;: &#x27;Iloverose&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;rose&#x27;, &#x27;password&#x27;: &#x27;Ilovejack&#x27;&#125;, &#123;&#x27;name&#x27;: &#x27;tom&#x27;, &#x27;password&#x27;: &#x27;password123&#x27;&#125;]    def test_user_password(self, users):        for user in users:            passwd = user[&#x27;password&#x27;]            assert len(passwd) &gt;= 6            msg = &quot;user %s has a weak password&quot; %(user[&#x27;name&#x27;])            assert passwd != &#x27;password&#x27;, msg&gt;           assert passwd != &#x27;password123&#x27;, msgE           AssertionError: user tom has a weak passwordE           assert &#x27;password123&#x27; != &#x27;password123&#x27;test_user_password.py:14: AssertionError=============== 1 failed in 0.03 seconds ============\n\n分析\n\n使用@pytest.fixture装饰器可以定义feature\n在用例的参数中传递fixture的名称以便直接调用fixture，拿到fixture的返回值\n3个assert是递进关系，前1个assert断言失败后，后面的assert是不会运行的，因此重要的assert放到前面\nE AssertionError: user tom has a weak password可以很容易的判断出是哪条数据出了问题，所以定制可读性好的错误信息是很必要的\n任何1个断言失败以后，for循环就会退出，所以上面的用例1次只能发现1条错误数据，换句话说任何1个assert失败后，用例就终止运行了\n\n执行顺序\npytest是这样运行上面的用例的\n\npytest找到以test_开头的方法，也就是test_user_password方法，执行该方法时发现传入的参数里有跟fixture users名称相同的参数\npytest认定users是fixture，执行该fixture，读取json文件解析成dict实例\ntest_user_password方法真正被执行，users fixture被传入到该方法\n\n举例3\n例2中任何1条测试数据导致断言不通过后测试用例就会停止运行，这样每次只能检查出1条不符合规范的数据，很多时候需要一次性把所有的不符合结果都测出来。\nusers.test.json文件：\n[  &#123;&quot;name&quot;:&quot;jack&quot;,&quot;password&quot;:&quot;Iloverose&quot;&#125;,  &#123;&quot;name&quot;:&quot;rose&quot;,&quot;password&quot;:&quot;Ilovejack&quot;&#125;  &#123;&quot;name&quot;:&quot;tom&quot;,&quot;password&quot;:&quot;password123&quot;&#125;,  &#123;&quot;name&quot;:&quot;mike&quot;,&quot;password&quot;:&quot;password&quot;&#125;, &#123;&quot;name&quot;:&quot;james&quot;,&quot;password&quot;:&quot;AGoodPasswordWordShouldBeLongEnough&quot;&#125;]\n\n参数化fixture\n参数化fixture允许我们向fixture提供参数，参数可以是list，该list中有几条数据，fixture就会运行几次，相应的测试用例也会运行几次。\n参数化fixture的语法是\n@pytest.fixture(params=[&quot;smtp.gmail.com&quot;, &quot;mail.python.org&quot;])\n\n其中len(params)的值就是用例执行的次数\n在fixture的定义中，可以使用request.param来获取每次传入的参数，如下:\n@pytest.fixture(scope=&quot;module&quot;,                params=[&quot;smtp.gmail.com&quot;, &quot;mail.python.org&quot;])def smtp(request):    smtp = smtplib.SMTP(request.param, 587, timeout=5)    yield smtp    print (&quot;finalizing %s&quot; % smtp)    smtp.close()\n\n\n上面的代码smtp fixture会执行2次\n第1次request.param == &#39;smtp.gmail.com&#39;\n第2次request.param == &#39;mail.python.org&#39;\n\n实现用例\n我们现在使用参数化fixtures来实现一次性检查出弱密码的用例。\n# test_user_password_with_params.pyimport pytestimport jsonusers = json.loads(open(&#x27;./users.test.json&#x27;, &#x27;r&#x27;).read())  # listclass TestUserPasswordWithParam(object):    @pytest.fixture(params=users)    def user(self, request):        return request.param    def test_user_password(self, user):        passwd = user[&#x27;password&#x27;]        assert len(passwd) &gt;= 6        msg = &quot;user %s has a weak password&quot; %(user[&#x27;name&#x27;])        assert passwd != &#x27;password&#x27;, msg        assert passwd != &#x27;password123&#x27;, msg\n\n上面的例子里，我们先把所有用户信息读到users变量里，注意users这时候是list类型，可以直接传入到fixture的params\n运行\npytest test_user_password_with_params.py\n\n结果\n$ pytest test_user_password_with_params.py================== test session starts ====================platform darwin -- Python 2.7.12, pytest-3.2.3, py-1.4.34, pluggy-0.4.0rootdir: /Users/easonhan/code/testclass.net/src/pytest, inifile:collected 5 itemstest_user_password_with_params.py ..FF.====================== FAILURES =========================______ TestUserPasswordWithParam.test_user_password[user2] ____self = &lt;test_user_password_with_params.TestUserPasswordWithParam object at 0x10de1d790&gt;, user = &#123;&#x27;name&#x27;: &#x27;tom&#x27;, &#x27;password&#x27;: &#x27;password123&#x27;&#125;    def test_user_password(self, user):        passwd = user[&#x27;password&#x27;]        assert len(passwd) &gt;= 6        msg = &quot;user %s has a weak password&quot; %(user[&#x27;name&#x27;])        assert passwd != &#x27;password&#x27;, msg&gt;       assert passwd != &#x27;password123&#x27;, msgE       AssertionError: user tom has a weak passwordE       assert &#x27;password123&#x27; != &#x27;password123&#x27;test_user_password_with_params.py:15: AssertionError_____ TestUserPasswordWithParam.test_user_password[user3]_______self = &lt;test_user_password_with_params.TestUserPasswordWithParam object at 0x10de1df50&gt;, user = &#123;&#x27;name&#x27;: &#x27;mike&#x27;, &#x27;password&#x27;: &#x27;password&#x27;&#125;    def test_user_password(self, user):        passwd = user[&#x27;password&#x27;]        assert len(passwd) &gt;= 6        msg = &quot;user %s has a weak password&quot; %(user[&#x27;name&#x27;])&gt;       assert passwd != &#x27;password&#x27;, msgE       AssertionError: user mike has a weak passwordE       assert &#x27;password&#x27; != &#x27;password&#x27;test_user_password_with_params.py:14: AssertionError======== 2 failed, 3 passed in 0.05 seconds =============\n\n总共运行了5个用例,3个成功,2个失败。\n举例4\n@pytest.mark.parametrize 装饰器可以让我们每次参数化fixture的时候传入多个项目，parametrize每次多个参数，更加灵活。\nimport pytest@pytest.mark.parametrize(&quot;test_input,expected&quot;, [  (&quot;3+5&quot;, 8),  (&quot;2+4&quot;, 6),  (&quot;6*9&quot;, 42),])def test_eval(test_input, expected):    assert eval(test_input) == expected\n\ntest_eval方法中传入了2个参数，就如同@pytest.mark.parametrize装饰器中定义的那样，因此简单理解，我们可以把parametrize装饰器想象成是数据表格，有表头(test_input,expected)以及具体的数据。\n运行结果\n$ pytest======= test session starts ========platform linux -- Python 3.x.y, pytest-3.x.y, py-1.x.y, pluggy-0.x.yrootdir: $REGENDOC_TMPDIR, inifile:collected 3 itemstest_expectation.py ..F======= FAILURES ========_______ test_eval[6*9-42] ________test_input = &#x27;6*9&#x27;, expected = 42    @pytest.mark.parametrize(&quot;test_input,expected&quot;, [        (&quot;3+5&quot;, 8),        (&quot;2+4&quot;, 6),        (&quot;6*9&quot;, 42),    ])    def test_eval(test_input, expected):&gt;       assert eval(test_input) == expectedE       AssertionError: assert 54 == 42E        +  where 54 = eval(&#x27;6*9&#x27;)test_expectation.py:8: AssertionError======= 1 failed, 2 passed in 0.12 seconds ========\n\n转载自：http://www.testclass.net/pytest\n","categories":["技术","pytest"],"tags":["pytest"]},{"title":"pytest02 Installation and Getting Started","url":"/posts/2019/06/09/11123/","content":"PDF文档 ： download latest\npytest 是一个使构建简单和可伸缩的测试变得容易的框架。测试具有表达性和可读性，不需要样板代码。几分钟后就可以开始对应用程序或库进行小的单元测试或复杂的功能测试。\n安装 pytest\n在命令行中运行以下命令：\n\npip install -U pytest\n\n\n检查是否安装了正确的版本：\n\n$ pytest --versionThis is pytest version 4.x.y, imported from $PYTHON_PREFIX/lib/python3.6/site-packages/pytest.py\n\n\n\n创建第一个测试创建一个简单的测试函数：\n# content of test_sample.pydef func(x):    return x + 1def test_answer():    assert func(3) == 5\n\n现在可以执行测试功能：\n$ pytest=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 1 itemtest_sample.py F                                                     [100%]================================= FAILURES =================================_______________________________ test_answer ________________________________    def test_answer():&gt;       assert func(3) == 5E       assert 4 == 5E        +  where 4 = func(3)test_sample.py:5: AssertionError========================= 1 failed in 0.12 seconds =========================\n\n此测试返回失败报告，因为 func(3) 不返 5 .\n运行多个测试pytest 将在当前目录及其子目录中，运行所有这种形式的文件：test _*.py 或者 * _test.py。\n断言引发了某个异常使用 raises 断言某些代码引发异常：\n# content of test_sysexit.pyimport pytestdef f():    raise SystemExit(1)def test_mytest():    with pytest.raises(SystemExit):        f()\n\n以“ quiet ”报告模式执行测试功能：\n$ pytest -q test_sysexit.py.                                                                    [100%]1 passed in 0.12 seconds\n\n\n\n将一个类中的多个测试分组一旦开发了多个测试任务，可能希望将它们分组到一个类中。pytest很容易创建包含多个测试的类：\n# content of test_class.pyclass TestClass(object):    def test_one(self):        x = &quot;this&quot;        assert &#x27;h&#x27; in x    def test_two(self):        x = &quot;hello&quot;        assert hasattr(x, &#x27;check&#x27;)\n\npytest 会发现所有带 test_前缀的函数。不需要对任何内容进行子类化。我们只需通过传递模块的文件名来运行它：\n$ pytest -q test_class.py.F                                                                   [100%]================================= FAILURES =================================____________________________ TestClass.test_two ____________________________self = &lt;test_class.TestClass object at 0xdeadbeef&gt;    def test_two(self):        x = &quot;hello&quot;&gt;       assert hasattr(x, &#x27;check&#x27;)E       AssertionError: assert FalseE        +  where False = hasattr(&#x27;hello&#x27;, &#x27;check&#x27;)test_class.py:8: AssertionError1 failed, 1 passed in 0.12 seconds\n\n第一个测试函数通过，第二个失败。容易看到断言中的中间值，理解运行失败的原因。\n请求功能测试的唯一临时目录pytest 提供了 Builtin fixtures&#x2F;function arguments 请求任意资源，如唯一的临时目录：\n# content of test_tmpdir.pydef test_needsfiles(tmpdir):    print(tmpdir)\n\n在测试函数签名中列出 tmpdir 名字， pytest 将在执行测试函数调用之前查找并调用一个fixture工厂以创建资源。在测试运行之前， pytest 创建一个unique-per-test-invocation（唯一的每个测试调用的）临时目录：\n试下了，有时候这个临时目录不会自动删除，于是写一个 fixture 来删除：\nimport shutilimport pytestimport json@pytest.fixture(scope=&quot;session&quot;, autouse=True)def cleanup(request):    # 获取基临时目录    tmp_dir = request.config._tmpdirhandler.getbasetemp()    yield tmp_dir    # 测试会话结束后删除基临时目录    shutil.rmtree(tmp_dir, ignore_errors=True)def test_needsfiles(cleanup, tmp_path):    print(f&quot;cleanup: &#123;cleanup&#125;&quot;)    print(f&quot;tmp_path: &#123;tmp_path&#125;&quot;)    dict_data = &#123;&quot;hello&quot;: &quot;world&quot;&#125;    file = tmp_path / &quot;test.txt&quot;    with open(file, &quot;w&quot;) as f:        json.dump(dict_data, f)    with open(file, &quot;r&quot;) as f:        json_data = json.load(f)    assert json_data == dict_data    &quot;&quot;&quot;cleanup: C:\\Users\\yuping\\AppData\\Local\\Temp\\pytest-of-yuping\\pytest-8tmp_path: C:\\Users\\yuping\\AppData\\Local\\Temp\\pytest-of-yuping\\pytest-8\\test_needsfiles0&quot;&quot;&quot;\n\n\n\n找出其他的内置  pytest fixtures 使用以下命令：\npytest --fixtures   # shows builtin and custom fixtures\n\n\n\n常用的内置 fixture\nrequest:\nrequest 是一个非常强大的内置 fixture，它提供了对当前测试请求的访问。通过 request，你可以获取到诸如当前测试函数的名称、参数、配置选项等信息。\n常见的用法包括：request.node 获取当前节点（可以是测试函数或测试类），request.config 访问配置对象，request.param 在参数化测试中获取当前参数等。\n\n\ntmp_path 和 tmp_path_factory:\ntmp_path 提供了一个临时目录的路径，该路径在测试结束时会被自动清理。这对于需要临时文件或目录的测试非常有用。\ntmp_path_factory 可以用来创建多个临时目录，通常用于需要多个独立临时目录的场景。\n\n\ncapfd 和 capsys:\ncapfd 和 capsys 用于捕获标准输出和标准错误流。capsys 适用于捕获 stdout 和 stderr 的文本输出，而 capfd 则适用于捕获文件描述符级别的输出。\n例如，你可以使用 capsys.readouterr() 来获取捕获的输出。\n\n\nmonkeypatch:\nmonkeypatch 用于在测试期间动态修改模块、类或方法的行为。这在需要模拟外部依赖或环境变量时非常有用。\n例如，你可以使用 monkeypatch.setattr 来替换一个方法或属性，或者使用 monkeypatch.setenv 来设置环境变量。\n\n\nrecwarn:\nrecwarn 用于捕获警告。这对于测试代码中是否正确地触发了预期的警告非常有用。\n例如，你可以使用 recwarn.pop(UserWarning) 来检查是否触发了特定类型的警告。\n\n\npytestconfig:\npytestconfig 提供了对 pytest 配置对象的访问，可以用来获取命令行参数或配置文件中的选项。\n例如，你可以使用 pytestconfig.getoption 来获取某个配置选项的值。\n\n\nrecord_property, record_xml_property:\n这些 fixture 用于记录额外的测试属性，这些属性可以在测试报告中显示。\n例如，你可以使用 record_property(&quot;key&quot;, &quot;value&quot;) 来记录一个键值对。\n\n\nusefixtures:\nusefixtures 不是一个 fixture，而是一个装饰器，用于在测试函数或类上显式地使用一个或多个 fixture。\n例如，@pytest.mark.usefixtures(&quot;my_fixture&quot;) 可以用来指定某个测试函数或类使用 my_fixture。\n\n\nfilterwarnings:\nfilterwarnings 用于过滤掉特定的警告，避免它们干扰测试输出。\n例如，你可以使用 @pytest.mark.filterwarnings(&quot;ignore:.*DeprecationWarning&quot;) 来忽略所有 DeprecationWarning。\n\n\n\n","categories":["技术","pytest"],"tags":["pytest","翻译"]},{"title":"pytest04 fixtures explicit, modular, scalable","url":"/posts/2019/06/23/41647/","content":"Pytest 固件：显式、模块化、可扩展\npurpose of test fixtures 是提供一个固定的基线，在此基础上测试可以可靠地重复执行。Pytest 固件比传统的XUnit 的setup&#x2F;teardown功能提供了显著的改进：\n\n固件有明确的名称，通过声明它们在测试函数、模块、类或整个项目中的使用来激活。\n固件以模块化的方式实现，因为每个固件名称触发一个 固件功能 ， 可以使用其他固件。\n固件管理规模从简单的单元扩展到复杂的功能测试，允许根据配置和组件选项参数化固件和测试，或者跨功能、类、模块或整个测试会话范围重复使用固件。\n\n此外，pytest继续支持经典的Xunit-style setup. 你可以混合这两种样式，根据喜好，逐步从经典样式转移到新样式。你也可以从现有的 unittest.TestCase style 或 nose based 项目开始。\n\nFixtures 作为函数参数Fixtures as function arguments\n测试函数可以通过将fixture对象命名为输入参数来接收它们。对于每个参数名，具有该名称的fixture函数提供fixture对象。通过用@pytest.fixture标记fixture函数来注册fixture函数 . 让我们来看一个简单的独立测试模块，它包含一个fixture和一个使用fixture的测试函数：\n# content of ./test_smtpsimple.pyimport pytest@pytest.fixturedef smtp_connection():    import smtplib    return smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587, timeout=5)def test_ehlo(smtp_connection):    response, msg = smtp_connection.ehlo()    assert response == 250    assert 0 # for demo purposes\n\n这里， test_ehlo 需要 smtp_connection 固件值。Pytest将发现并调用 @pytest.fixture 标记 smtp_connection 固件函数。运行测试的方式如下：\n$ pytest test_smtpsimple.py=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 1 itemtest_smtpsimple.py F                                                 [100%]================================= FAILURES =================================________________________________ test_ehlo _________________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_ehlo(smtp_connection):        response, msg = smtp_connection.ehlo()        assert response == 250&gt;       assert 0 # for demo purposesE       assert 0test_smtpsimple.py:11: AssertionError========================= 1 failed in 0.12 seconds =========================\n\n在失败的回溯中，我们看到测试函数是用 smtp_connection 参数、 fixture函数创建的实例smtplib.SMTP()来调用的。测试功能失败是故意使用了 assert 0 .  pytest 以这种方式来调用测试函数：\n\npytest找到这个 test_ehlo 因为 test_ 前缀。这个测试函数需要一个名为 smtp_connection . 通过查找名为 smtp_connection 标记的固件函数，找到一个匹配的固件函数.\nsmtp_connection() 通过创建实例来调用。\ntest_ehlo(&lt;smtp_connection instance&gt;) 在测试函数的最后一行调用并失败。\n\n请注意，如果你拼错了一个函数参数，或者希望使用一个不可用的参数，你将看到一个错误，其中包含一个可用函数参数列表。\n注解\n你可以随时发布：\npytest --fixtures test_simplefactory.py\n\n查看可用的固件（带引线的固件 _ 仅当添加 -v 选择权。\n\n固件：依赖注入的主要示例fixtures：a prime example of dependency injection\nfixture 是 pytest 中的一个强大功能，它通过提供预初始化的对象来实现依赖注入。依赖注入是一种设计模式，用于减少代码之间的耦合，使代码更加模块化和可测试。\nfixture 可以定义一些预初始化的对象或环境设置，这些对象或设置可以在多个测试函数中复用。测试函数可以通过参数自动接收这些 fixture，而不需要关心这些对象是如何导入、初始化和清理的。\n在依赖注入中，依赖关系（即所需的对象或资源）是由外部提供的，而不是由对象自己创建的。fixture 函数在这里扮演了 注入器（injector）的角色，负责创建和提供这些依赖对象。\n测试函数是 消费者（consumers），它们通过参数接收这些依赖对象，并使用它们进行测试。\n小结：\n\nfixture 是 pytest 中实现依赖注入的一种方式。fixture 函数负责创建和管理依赖对象，测试函数通过参数接收这些对象。\n使用 fixture 可以减少测试代码中的重复，提高代码的可维护性和可测试性。\n通过 yield 关键字，fixture 可以在测试前后执行设置和清理操作，确保每个测试都在干净的环境中运行。\n\n\nconftest.py 共享固件功能conftest.py: sharing fixture functions\n如果在实现测试的过程中，你意识到要使用来自多个测试文件的fixture函数，可以将其移动到 conftest.py 文件。你不需要导入要在测试中使用的固件，Pytest会发现并自动获取它。fixture函数的发现从测试类开始，然后是测试模块，然后 conftest.py 文件，最后是内置插件和第三方插件。\n你也可以使用 conftest.py 文件去实现 本地目录级插件 local per-directory plugins。\n\nLocal：这些插件仅影响定义它们的目录及其子目录。\nPer-Directory：每个目录可以有自己的 conftest.py 文件，从而实现不同目录间的独立配置。\nPlugins：这些插件可以包含 fixture、hook 实现、自定义命令行选项等，用于扩展 pytest 的功能。\n\n\n共享测试数据Sharing test data\n如果你想让来自文件的测试数据对你的测试可用，一个很好的方法是将这些数据加载到一个固件中，供测试使用。这利用了pytest的自动缓存机制。\n另一个好方法是将数据文件添加到 tests 文件夹中. 这里也有可用的插件社区可以用来帮助管理这方面的testing e.g. pytest-datadir 和 pytest-datafiles （感觉不怎么会用到，不仅需要安装包，这种路径、文件名的配置，不适合做大型项目吧）。\n\nscope：在类、模块或会话中跨测试共享一个fixture实例Scope: sharing a fixture instance across tests in a class, module or session\n依赖于连接性的需要访问网络的fixtures，通常创建成本很高。扩展前面的示例，我们可以给 @pytest.fixture 调用添加一个 scope=&quot;module&quot; 参数，引起被装饰的 smtp_connection 固件函数在每个测试模块中只调用一次（默认情况下，每个测试调用一次 function）因此，一个测试模块中的多个测试功能将接收相同的 smtp_connection 固件实例（不必每次都实例化，也就是不用每次都去创建连接访问网络），节省时间提高效率。 对于scope可能值是： function ， class ， module ， package 或 session .\n下一个示例将fixture函数放入单独的 conftest.py 文件，以便目录中多个测试模块的测试可以访问fixture函数：\n# content of conftest.pyimport pytestimport smtplib@pytest.fixture(scope=&quot;module&quot;)def smtp_connection():    return smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587, timeout=5)\n\n固件的名称同样是 smtp_connection ，你可以通过列出名字smtp_connection作为一个在任何测试或fixture函数的输入参数（在 conftest.py 所在的目录中，或者所在的目录下）来访问它的结果 ：\n# content of test_module.pydef test_ehlo(smtp_connection):    response, msg = smtp_connection.ehlo()    assert response == 250    assert b&quot;smtp.gmail.com&quot; in msg    assert 0  # for demo purposesdef test_noop(smtp_connection):    response, msg = smtp_connection.noop()    assert response == 250    assert 0  # for demo purposes\n\n我们故意插入失败 assert 0 语句以检查正在进行的操作，现在可以运行测试：\n$ pytest test_module.py=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 2 itemstest_module.py FF                                                    [100%]================================= FAILURES =================================________________________________ test_ehlo _________________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_ehlo(smtp_connection):        response, msg = smtp_connection.ehlo()        assert response == 250        assert b&quot;smtp.gmail.com&quot; in msg&gt;       assert 0  # for demo purposesE       assert 0test_module.py:6: AssertionError________________________________ test_noop _________________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_noop(smtp_connection):        response, msg = smtp_connection.noop()        assert response == 250&gt;       assert 0  # for demo purposesE       assert 0test_module.py:11: AssertionError========================= 2 failed in 0.12 seconds =========================\n\n你看这两个 assert 0 失败，更重要的是，你也可以看到相同的（module-scoped模块范围） smtp_connection对象被传递到两个测试函数中，因为pytest在回溯中显示了传入的参数值。因此，两个测试函数使用 smtp_connection 像单个实例一样快速运行，因为它们重用同一个实例。\n如果你决定希望有一个会话范围装饰的 smtp_connection实例， 例如，你可以简单地声明它：\n@pytest.fixture(scope=&quot;session&quot;)def smtp_connection():    # the returned fixture value will be shared for    # all tests needing it    ...\n\n最后， class 作用域将在每个测试class中调用fixture一次 .\n注解\npytest一次只缓存一个fixture实例。这意味着当使用参数化固件时，pytest可以在给定的范围内多次调用固件。\n\n首先实例化更大范围的固件Higher-scoped fixtures are instantiated first\n在特性的功能请求中，更高范围的固件（例如 session ）先实例化，然后再实例化范围较低的固件（例如 function 或 class ）。相同范围内固件的相对顺序遵循测试函数中声明的顺序，并尊重固件之间的依赖关系。\n考虑下面的代码：\n@pytest.fixture(scope=&quot;session&quot;)def s1():    pass@pytest.fixture(scope=&quot;module&quot;)def m1():    pass@pytest.fixturedef f1(tmpdir):    pass@pytest.fixturedef f2():    passdef test_foo(f1, m1, f2, s1):    ...\n\n由 test_foo 所请求的固件将按以下顺序实例化：\n\ns1 ：是范围最高的固件 (session ）\nm1 ：是第二高范围固件 (module ）\ntmpdir 是一个 function 范围固件， f1需要 ：因为它是f1的一个依赖项，此时它需要实例化 .\nf1 是第一个在 test_foo 参数列表内的 function -范围固件。\nf2 是最后一个在 test_foo 参数列表内的 function -范围固件。\n\n\n固件定型&#x2F;执行拆卸代码Fixture finalization &#x2F; executing teardown code\n当fixture超出范围时，pytest支持fixture特定的定稿代码的执行。通过使用 yield 语句而不是 return ， yield语句之后的所有代码当做是teardown代码：\n# content of conftest.pyimport smtplibimport pytest@pytest.fixture(scope=&quot;module&quot;)def smtp_connection():    smtp_connection = smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587, timeout=5)    yield smtp_connection  # provide the fixture value    print(&quot;teardown smtp&quot;)    smtp_connection.close()\n\n这个 print 和 smtp.close() 语句将在模块中的最后一个测试完成执行后执行，而不管测试的异常状态如何。\n让我们执行它：\n$ pytest -s -q --tb=noFFteardown smtp2 failed in 0.12 seconds\n\n我们看到了 smtp_connection 实例在两个测试完成执行后完成。请注意，如果我们用 scope=&#39;function&#39;来声明固件函数， 然后在每个测试周围进行fixture setup和clearup。无论哪种情况，测试模块本身都不需要更改或了解这些固件setup的细节。\n请注意，我们还可以无缝地使用 yield 语法与 with 声明：\n# content of test_yield2.pyimport smtplibimport pytest@pytest.fixture(scope=&quot;module&quot;)def smtp_connection():    with smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587, timeout=5) as smtp_connection:        yield smtp_connection  # provide the fixture value\n\n这个 smtp_connection 连接将在测试完成执行后关闭，因为当 with 语句结束时 smtp_connection 对象会自动关闭。\n请注意，如果一个异常在 setup  代码（在 yield 关键字前）中发生，那么 teardown 代码（在 yield 后）不会被调用。\n执行 teardown  代码的替代选项是利用 addfinalizer 方法（用request-context对象注册终结函数）。\n这里是 smtp_connection 固件变化地使用addfinalizer 清理：\n# content of conftest.pyimport smtplibimport pytest@pytest.fixture(scope=&quot;module&quot;)def smtp_connection(request):    smtp_connection = smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587, timeout=5)    def fin():        print(&quot;teardown smtp_connection&quot;)        smtp_connection.close()    request.addfinalizer(fin)    return smtp_connection  # provide the fixture value\n\n相似地， yield 和 addfinalizer 方法都是通过在测试结束后调用它们的代码来工作，但是 addfinalizer 有两个关键差异点区别于 yield ：\n\n可以注册多个终结器函数。\n\n无论 fixture 的 setup 代码是否引发异常，finalizers 终结器都会被调用（面试题常问）。这对于正确关闭由固件创建的所有资源非常方便，即使其中一个资源未能创建&#x2F;获取：\n@pytest.fixturedef equipments(request):    r = []    for port in (&#x27;C1&#x27;, &#x27;C3&#x27;, &#x27;C28&#x27;):        equip = connect(port)        request.addfinalizer(equip.disconnect)        r.append(equip)    return r\n\n在上面的示例中，如果 &quot;C28&quot; 异常失败， &quot;C1&quot; 和 &quot;C3&quot; 仍将正确关闭。\n当然，如果在 addfinalizer  函数之前发生异常，则不会执行它。\n\n\n\nFixtures 可以检查请求的测试上下文Fixtures can introspect the requesting test context\n固件函数可以接受 request 对象内省“requesting”测试函数、类或模块上下文。进一步扩展前一个 smtp_connection fixture示例，让我们从使用fixture的测试模块中读取一个可选的服务器URL：\n# content of conftest.pyimport pytestimport smtplib@pytest.fixture(scope=&quot;module&quot;)def smtp_connection(request):    server = getattr(request.module, &quot;smtpserver&quot;, &quot;smtp.gmail.com&quot;)    smtp_connection = smtplib.SMTP(server, 587, timeout=5)    yield smtp_connection    print(&quot;finalizing %s (%s)&quot; % (smtp_connection, server))    smtp_connection.close()\n\n我们使用 request.module 属性来选择获取一个来自测试模块的smtpserver 属性。如果我们再执行一次，没有什么改变：\n$ pytest -s -q --tb=noFFfinalizing &lt;smtplib.SMTP object at 0xdeadbeef&gt; (smtp.gmail.com)2 failed in 0.12 seconds\n\n让我们快速创建另一个测试模块，该模块在其模块命名空间中实际设置服务器URL：\n# content of test_anothersmtp.pysmtpserver = &quot;mail.python.org&quot;  # will be read by smtp fixturedef test_showhelo(smtp_connection):    assert 0, smtp_connection.helo()\n\n运行它：\n$ pytest -qq --tb=short test_anothersmtp.pyF                                                                    [100%]================================= FAILURES =================================______________________________ test_showhelo _______________________________test_anothersmtp.py:5: in test_showhelo    assert 0, smtp_connection.helo()E   AssertionError: (250, b&#x27;mail.python.org&#x27;)E   assert 0------------------------- Captured stdout teardown -------------------------finalizing &lt;smtplib.SMTP object at 0xdeadbeef&gt; (mail.python.org)\n\n这个 smtp_connection fixture函数从模块名称空间中获取邮件服务器名称。\n\n工厂函数作为固件Factories as fixtures\n“工厂作为固件”模式有助于在单个测试中多次需要固件结果的情况下，固件不直接返回数据，而是返回一个生成数据的函数，然后可以在测试中多次调用此函数。（工厂函数：返回一个生成数据对象的函数，而不是直接返回数据对象。）\n工厂可以根据需要设置参数：\n@pytest.fixturedef make_customer_record():    def _make_customer_record(name):        return &#123;            &quot;name&quot;: name,            &quot;orders&quot;: []        &#125;    return _make_customer_recorddef test_customer_records(make_customer_record):    customer_1 = make_customer_record(&quot;Lisa&quot;)    customer_2 = make_customer_record(&quot;Mike&quot;)    customer_3 = make_customer_record(&quot;Meredith&quot;)\n\n如果工厂创建的数据需要管理，则固件可以处理：\n@pytest.fixturedef make_customer_record():    created_records = []    def _make_customer_record(name):        record = models.Customer(name=name, orders=[])        created_records.append(record)        return record    yield _make_customer_record    for record in created_records:        record.destroy()def test_customer_records(make_customer_record):    customer_1 = make_customer_record(&quot;Lisa&quot;)    customer_2 = make_customer_record(&quot;Mike&quot;)    customer_3 = make_customer_record(&quot;Meredith&quot;)\n\n为什么要使用工厂作为固件？\n\n灵活性：可以在测试中多次调用工厂函数，每次生成新的数据对象。\n参数化：工厂函数可以根据传入的参数生成不同的数据对象。\n资源管理：如果生成的数据对象需要管理（例如，需要在测试结束后销毁），固件可以处理这些管理任务。\n\n\n参数化固件Parametrizing fixtures\nfixture函数可以参数化，在这种情况下，它们将被多次调用，每次执行一组相关的测试，即测试依赖于该fixture。测试函数通常不需要知道它们的重新运行。固件参数化有助于为组件编写详尽的功能测试，这些组件本身可以通过多种方式进行配置。\n扩展前面的示例，我们可以标记fixture以创建两个 smtp_connection fixture实例，它将导致使用fixture的所有测试运行两次。fixture函数通过特殊的 request 对象来获取每个参数：\n# content of conftest.pyimport pytestimport smtplib@pytest.fixture(scope=&quot;module&quot;,                params=[&quot;smtp.gmail.com&quot;, &quot;mail.python.org&quot;])def smtp_connection(request):    smtp_connection = smtplib.SMTP(request.param, 587, timeout=5)    yield smtp_connection    print(&quot;finalizing %s&quot; % smtp_connection)    smtp_connection.close()\n\n主要变化是 params 具有 @pytest.fixture ，fixture函数将执行的每个值的列表，可以通过 request.param访问每一个值 . 无需更改测试函数代码。让我们再运行一次：\n$ pytest -q test_module.pyFFFF                                                                 [100%]================================= FAILURES =================================________________________ test_ehlo[smtp.gmail.com] _________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_ehlo(smtp_connection):        response, msg = smtp_connection.ehlo()        assert response == 250        assert b&quot;smtp.gmail.com&quot; in msg&gt;       assert 0  # for demo purposesE       assert 0test_module.py:6: AssertionError________________________ test_noop[smtp.gmail.com] _________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_noop(smtp_connection):        response, msg = smtp_connection.noop()        assert response == 250&gt;       assert 0  # for demo purposesE       assert 0test_module.py:11: AssertionError________________________ test_ehlo[mail.python.org] ________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_ehlo(smtp_connection):        response, msg = smtp_connection.ehlo()        assert response == 250&gt;       assert b&quot;smtp.gmail.com&quot; in msgE       AssertionError: assert b&#x27;smtp.gmail.com&#x27; in b&#x27;mail.python.org\\nPIPELINING\\nSIZE 51200000\\nETRN\\nSTARTTLS\\nAUTH DIGEST-MD5 NTLM CRAM-MD5\\nENHANCEDSTATUSCODES\\n8BITMIME\\nDSN\\nSMTPUTF8\\nCHUNKING&#x27;test_module.py:5: AssertionError-------------------------- Captured stdout setup ---------------------------finalizing &lt;smtplib.SMTP object at 0xdeadbeef&gt;________________________ test_noop[mail.python.org] ________________________smtp_connection = &lt;smtplib.SMTP object at 0xdeadbeef&gt;    def test_noop(smtp_connection):        response, msg = smtp_connection.noop()        assert response == 250&gt;       assert 0  # for demo purposesE       assert 0test_module.py:11: AssertionError------------------------- Captured stdout teardown -------------------------finalizing &lt;smtplib.SMTP object at 0xdeadbeef&gt;4 failed in 0.12 seconds\n\n我们看到我们的两个测试函数分别运行两次，针对的是不同的 smtp_connection 实例。还要注意的是， 在test_ehlo中mail.python.org连接第二次测试失败，因为预期的服务器字符串与实际获取的字符串不同。\npytest将构建一个字符串，该字符串是参数化fixture中每个fixture值的测试ID，例如在在上面的例子中的test_ehlo[smtp.gmail.com] 和 test_ehlo[mail.python.org] 。这些ID可用于 -k 选择要运行的特定案例，当某个案例失败时，它们还将识别该特定案例。使用pytest --collect-only 运行将显示生成的ID。\n关键字 ids数字、字符串、布尔值和None将在测试ID中使用它们通常的字符串表示形式。对于其他对象，pytest将根据参数名生成字符串。在一个测试ID中，可以通过使用 ids 关键字参数来为一个确定的fixture值定制字符串：\n# content of test_ids.pyimport pytest@pytest.fixture(params=[0, 1], ids=[&quot;spam&quot;, &quot;ham&quot;])def a(request):    return request.paramdef test_a(a):    passdef idfn(fixture_value):    if fixture_value == 0:        return &quot;eggs&quot;    else:        return None@pytest.fixture(params=[0, 1], ids=idfn)def b(request):    return request.paramdef test_b(b):    pass\n\n上面显示了如何 ids 可以是要使用的字符串列表，也可以是将使用fixture值调用的函数，然后必须返回要使用的字符串。在后一种情况下，如果函数返回 None 然后将使用pytest的自动生成的ID。\n运行上述测试将导致使用以下测试ID：\npython -m pytest .\\test_ids.py  --collect-only============================================================================== test session starts ===============================================================================platform win32 -- Python 3.12.0, pytest-7.0.1, pluggy-1.0.0rootdir: D:\\Developer\\pytest_learning\\src\\4.pytest fixtures explicit, modular, scalableplugins: allure-pytest-2.9.43, Faker-13.3.0, assume-2.4.3collected 4 items                                                                                                                                                                  &lt;Package 4.pytest fixtures explicit, modular, scalable&gt;  &lt;Module test_ids.py&gt;    &lt;Function test_a[spam]&gt;    &lt;Function test_a[ham]&gt;    &lt;Function test_b[eggs]&gt;    &lt;Function test_b[1]\n\n如果没有配置 ids，那么执行显示：\n&lt;Package 4.pytest fixtures explicit, modular, scalable&gt;  &lt;Module test_ids.py&gt;    &lt;Function test_a[0]&gt;    &lt;Function test_a[1]&gt;    &lt;Function test_b[0]&gt;    &lt;Function test_b[1]&gt;\n\n使用 -k 执行：\npython -m pytest .\\test_ids.py  --collect-only  -k &quot;test_a[spam]&quot;============================================================================== test session starts =============================================================================== platform win32 -- Python 3.12.0, pytest-7.0.1, pluggy-1.0.0rootdir: D:\\Developer\\pytest_learning\\src\\4.pytest fixtures explicit, modular, scalableplugins: allure-pytest-2.9.43, Faker-13.3.0, assume-2.4.3collected 4 items / 3 deselected / 1 selected                                                                                                                                      &lt;Package 4.pytest fixtures explicit, modular, scalable&gt;  &lt;Module test_ids.py&gt;    &lt;Function test_a[spam]&gt;================================================================== 1/4 tests collected (3 deselected) in 0.01s =================================================================== &gt; python -m pytest .\\test_ids.py  --collect-only  -k &quot;test_a[spam] or test_b[eggs]&quot;                                                                                                                            &lt;Package 4.pytest fixtures explicit, modular, scalable&gt;  &lt;Module test_ids.py&gt;    &lt;Function test_a[spam]&gt;    &lt;Function test_b[eggs]&gt;\n\n\n对参数化固件使用标记Using marks with parametrized fixtures\npytest.param()可在参数化固件的值集里应用于标记，与它们可用于@pytest.mark.parametrize 的方法相同 .\n例子：\n# content of test_fixture_marks.py@pytest.fixture(params=[0, 1,                        pytest.param(2, marks=pytest.mark.skip),                        pytest.param(3, marks=pytest.mark.xfail(reason=&quot;This is expected to fail&quot;))])def data_set(request):    return request.paramdef test_data(data_set):    assert data_set &lt; 3\n\n\n@pytest.fixture(params=[0, 1, pytest.param(2, marks=pytest.mark.skip)])：定义了一个参数化固件 data_set，参数值为 [0, 1, pytest.param(2, marks=pytest.mark.skip)]。\npytest.param(2, marks=pytest.mark.skip)：使用 pytest.param 包装参数 2，并标记为 skip。\n使用 pytest.param 包装参数 3 ，标记为 xfail，测试预期失败。\n\n python -m pytest .\\test_fixture_marks.py -v============================ test session starts==============================platform win32 -- Python 3.12.0, pytest-7.0.1, pluggy-1.0.0 -- D:\\software\\Python\\Python312\\python.execachedir: .pytest_cacherootdir: D:\\Developer\\pytest_learning\\src\\4.pytest fixtures explicit, modular, scalableplugins: allure-pytest-2.9.43, Faker-13.3.0, assume-2.4.3collected 4 items                                                                                                                                                                  test_fixture_marks.py::test_data[0] PASSED [ 25%] test_fixture_marks.py::test_data[1] PASSED [ 50%] test_fixture_marks.py::test_data[2] SKIPPED (unconditional skip) [ 75%] test_fixture_marks.py::test_data[3] XFAIL (This is expected to fail) \n\n\n模块化：使用fixture函数中的fixturesModularity: using fixtures from a fixture function\n不仅可以在测试函数中使用fixture，fixture函数还可以使用其他fixture本身。这有助于固件fixtures的模块化设计，并允许在许多项目中重用特定框架的固件。作为一个简单的示例，我们可以扩展前面的示例并实例化一个对象 app ，我们把已经定义好的 smtp_connection 资源加入进去了：\n# content of test_appsetup.pyimport pytestclass App(object):    def __init__(self, smtp_connection):        self.smtp_connection = smtp_connection@pytest.fixture(scope=&quot;module&quot;)def app(smtp_connection):    return App(smtp_connection)def test_smtp_connection_exists(app):    assert app.smtp_connection\n\n我们在此声明 app 接收先前定义的 smtp_connection fixture并实例化 App 对象。让我们运行它：\n$ pytest -v test_appsetup.py=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.y -- $PYTHON_PREFIX/bin/pythoncachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollecting ... collected 2 itemstest_appsetup.py::test_smtp_connection_exists[smtp.gmail.com] PASSED [ 50%]test_appsetup.py::test_smtp_connection_exists[mail.python.org] PASSED [100%]========================= 2 passed in 0.12 seconds =========================\n\n由于参数化 smtp_connection ，测试将运行两次 App 实例和相应的SMTP服务器。 app 固件没有必要注意 smtp_connection 参数化，因为 Pytest 将充分分析固件依赖关系图。\n请注意 app 固件的 module 范围，并使用 smtp_connection 模块范围固件。如果 smtp_connection被缓存在 session 范围也是可行的：fixture可以使用“更广”范围的fixture，但不能使用另一种方式：会话session范围的fixture不能以有意义的方式使用模块module范围的fixture。\n\n按 fixture 实例自动分组测试Automatic grouping of tests by fixture instances\n在测试运行期间，pytest最小化了活跃fixtures的数量。如果你有一个参数化的fixture，那么使用它的所有测试将首先用一个实例执行，然后在创建下一个fixture实例之前调用终结器。此外，这简化了对创建和使用全局状态的应用程序的测试。\n下面的示例使用两个参数化的fixture，其中一个在每个模块的基础上确定范围，所有功能都执行 print 调用以显示setup&#x2F;teardown流：\nimport pytest@pytest.fixture(scope=&quot;module&quot;, params=[&quot;mod1&quot;, &quot;mod2&quot;])def modarg(request):    param = request.param    print(&quot;  SETUP modarg %s&quot; % param)    yield param    print(&quot;  TEARDOWN modarg %s&quot; % param)@pytest.fixture(scope=&quot;function&quot;, params=[1,2])def otherarg(request):    param = request.param    print(&quot;  SETUP otherarg %s&quot; % param)    yield param    print(&quot;  TEARDOWN otherarg %s&quot; % param)def test_0(otherarg):    print(&quot;  RUN test0 with otherarg %s&quot; % otherarg)def test_1(modarg):    print(&quot;  RUN test1 with modarg %s&quot; % modarg)def test_2(otherarg, modarg):    print(&quot;  RUN test2 with otherarg %s and modarg %s&quot; % (otherarg, modarg))\n\n这个示例展示了 pytest 如何管理和优化参数化固件的生命周期。\n让我们在详细模式下运行测试，并查看打印输出：\n$ pytest -v -s test_module.py=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.y -- $PYTHON_PREFIX/bin/pythoncachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollecting ... collected 8 itemstest_module.py::test_0[1]   SETUP otherarg 1  RUN test0 with otherarg 1PASSED  TEARDOWN otherarg 1test_module.py::test_0[2]   SETUP otherarg 2  RUN test0 with otherarg 2PASSED  TEARDOWN otherarg 2test_module.py::test_1[mod1]   SETUP modarg mod1  RUN test1 with modarg mod1PASSEDtest_module.py::test_2[mod1-1]   SETUP otherarg 1  RUN test2 with otherarg 1 and modarg mod1PASSED  TEARDOWN otherarg 1test_module.py::test_2[mod1-2]   SETUP otherarg 2  RUN test2 with otherarg 2 and modarg mod1PASSED  TEARDOWN otherarg 2test_module.py::test_1[mod2]   TEARDOWN modarg mod1  SETUP modarg mod2  RUN test1 with modarg mod2PASSEDtest_module.py::test_2[mod2-1]   SETUP otherarg 1  RUN test2 with otherarg 1 and modarg mod2PASSED  TEARDOWN otherarg 1test_module.py::test_2[mod2-2]   SETUP otherarg 2  RUN test2 with otherarg 2 and modarg mod2PASSED  TEARDOWN otherarg 2  TEARDOWN modarg mod2========================= 8 passed in 0.12 seconds =========================\n\n可以看到参数化模块作用域 modarg 资源导致测试执行的顺序，从而导致可能的“活动”资源最少。为 mod1 参数化的资源的终结器在 mod2 资源setup前被执行。\n特别要注意，test_0是完全独立的，最先完成。然后是使用 mod1 的test_1执行，接着是使用 mod1的test_2 ，然后是用 mod2的test_1， 最后是用 mod2 的test_2.\n这个 otherarg 参数化资源（具有函数范围）在使用它的每个测试之前setup，然后在使用它的每个测试之后teardown。\n\n使用类、模块或项目中的 fixtureUsing fixtures from classes, modules or projects\n有时测试函数不需要直接访问fixture对象。例如，测试可能需要使用空目录作为当前工作目录进行操作，否则不关心具体目录。以下是如何使用标准 tempfile 和pytest fixtures 来实现它。我们将创建的fixture分入conftest.py文件：\n# content of conftest.pyimport pytestimport tempfileimport os@pytest.fixture()def cleandir():    newpath = tempfile.mkdtemp()    os.chdir(newpath)\n\n并通过一个 usefixtures 标记，在测试module中声明它的使用：\n# content of test_setenv.pyimport osimport pytest@pytest.mark.usefixtures(&quot;cleandir&quot;)class TestDirectoryInit(object):    def test_cwd_starts_empty(self):        assert os.listdir(os.getcwd()) == []        with open(&quot;myfile&quot;, &quot;w&quot;) as f:            f.write(&quot;hello&quot;)    def test_cwd_again_starts_empty(self):        assert os.listdir(os.getcwd()) == []\n\n由于 usefixtures 标记，每个测试方法的执行都需要 cleandir fixture，就像你为每个方法指定了“cleandir”函数参数一样。让我们运行它来验证fixture是否激活，测试是否通过：\n$ pytest -q..                                                                   [100%]2 passed in 0.12 seconds\n\n可以这样指定多个fixtures：\n@pytest.mark.usefixtures(&quot;cleandir&quot;, &quot;anotherfixture&quot;)def test():    ...\n\n可以使用标记机制的通用特性，在测试模块级别指定fixture使用：\npytestmark = pytest.mark.usefixtures(&quot;cleandir&quot;)\n\n注意分配的变量 必须 被称为 pytestmark ，例如 foomark 不会激活fixtures。\n也可以将项目中所有测试所需的fixtures放入一个ini文件中：\n# content of pytest.ini[pytest]usefixtures = cleandir\n\n警告\n注意这个标记在 fixture functions里没有作用 . 例如，这个 无法按预期工作 ：\n@pytest.mark.usefixtures(&quot;my_other_fixture&quot;)@pytest.fixturedef my_fixture_that_sadly_wont_use_my_other_fixture():    ...\n\n目前，这不会产生任何错误或警告.\n\n自动固定装置 autouseAutouse fixtures (xUnit setup on steroids)\n有时，你可能希望在不显式声明函数参数或 usefixtures 装饰器的情况下自动调用fixtures。作为一个实际的例子，假设我们有一个数据库设备，它有一个 begin&#x2F;rollback&#x2F;commit 体系结构，并且我们希望通过一个 transaction 和一个 rollback 自动包围每个测试方法。下面是这个想法的一个虚拟的独立实现：\n# content of test_db_transact.pyimport pytestclass DB(object):    def __init__(self):        self.intransaction = []    def begin(self, name):        self.intransaction.append(name)    def rollback(self):        self.intransaction.pop()@pytest.fixture(scope=&quot;module&quot;)def db():    return DB()class TestClass(object):    @pytest.fixture(autouse=True)    def transact(self, request, db):        db.begin(request.function.__name__)        yield        db.rollback()    def test_method1(self, db):        assert db.intransaction == [&quot;test_method1&quot;]    def test_method2(self, db):        assert db.intransaction == [&quot;test_method2&quot;]\n\n类级别 transact 固件标有 autouse&#x3D;true 这意味着类中的所有测试方法都将使用这个fixture，而不需要在测试函数签名或类级别的usefixture装饰器中声明它。\n如果我们运行它，我们会得到两个通过的测试：\n$ pytest -q..                                                                   [100%]2 passed in 0.12 seconds\n\n以下是Autouse 固件在其他范围中的工作方式：\n\nautouse fixtures遵守 scope= 关键字参数：如果一个autouse fixture具有 scope=&#39;session&#39; ，无论它在何处被定义，它将只运行一次。而 scope=&#39;class&#39; 意味着它将每个类运行一次，等等。\n如果在一个测试模块中定义了一个autouse fixture，那么它的所有测试函数都会自动使用它。\n如果在conftest.py文件中定义了一个autouse fixture，那么其目录下的所有测试模块中的所有测试都将调用该fixture。\n最后， 请小心使用 ：如果你在一个插件中定义了一个autouse fixture，它将对安装该插件的所有项目中的所有测试进行调用。如果一个fixture只在某些设置（例如在ini文件中）下工作，这是有用的。这样一个全局fixture应该总是快速确定它是否应该做任何工作，并避免其他耗费的导入或计算。\n\n注意上面 transact fixture很可能是你希望在项目中可用的一个fixture，而通常不需要它处于活动状态。实现这一点的规范方法是将transact的定义放入没有使用 autouse 的conftest.py 中：\n# content of conftest.py@pytest.fixturedef transact(request, db):    db.begin()    yield    db.rollback()\n\n然后，例如，通过声明需求，让一个testclass使用它：\n@pytest.mark.usefixtures(&quot;transact&quot;)class TestClass(object):    def test_method1(self):        ...\n\n此TestClass中的所有测试方法都将使用transact fixture，而模块中的其他测试类或函数将不使用它，除非它们还添加了 transact 参考。\n\n覆盖不同级别的设备Overriding fixtures on various levels\n在相对较大的测试套中，你很可能需要 override 一个 global 或 root fixture与 locally 定义一个，用来保持测试代码的可读性和可维护性。\n覆盖文件夹（conftest）级别的fixtureOverride a fixture on a folder (conftest) level\n假设测试文件结构为：\ntests/    __init__.py    conftest.py        # content of tests/conftest.py        import pytest        @pytest.fixture        def username():            return &#x27;username&#x27;    test_something.py        # content of tests/test_something.py        def test_username(username):            assert username == &#x27;username&#x27;    subfolder/        __init__.py        conftest.py            # content of tests/subfolder/conftest.py            import pytest            @pytest.fixture            def username(username):                return &#x27;overridden-&#x27; + username        test_something.py            # content of tests/subfolder/test_something.py            def test_username(username):                assert username == &#x27;overridden-username&#x27;\n\n以上示例，具有相同名称的fixture可以被某些测试文件夹级别的覆盖。请注意 base 或 super fixture可从 在上面的例子中很容易使用的overriding fixture中获取。\n在测试模块级别上覆盖fixtureOverride a fixture on a test module level\n假设测试文件结构为：\ntests/    __init__.py    conftest.py        # content of tests/conftest.py        @pytest.fixture        def username():            return &#x27;username&#x27;    test_something.py        # content of tests/test_something.py        import pytest        @pytest.fixture        def username(username):            return &#x27;overridden-&#x27; + username        def test_username(username):            assert username == &#x27;overridden-username&#x27;    test_something_else.py        # content of tests/test_something_else.py        import pytest        @pytest.fixture        def username(username):            return &#x27;overridden-else-&#x27; + username        def test_username(username):            assert username == &#x27;overridden-else-username&#x27;\n\n在上面的示例中，一个具有相同名称fixture可以为某些测试模块重写覆盖。\n通过直接测试参数化覆盖夹具Override a fixture with direct test parametrization\n假设测试文件结构为：\ntests/    __init__.py    conftest.py        # content of tests/conftest.py        import pytest        @pytest.fixture        def username():            return &#x27;username&#x27;        @pytest.fixture        def other_username(username):            return &#x27;other-&#x27; + username    test_something.py        # content of tests/test_something.py        import pytest        @pytest.mark.parametrize(&#x27;username&#x27;, [&#x27;directly-overridden-username&#x27;])        def test_username(username):            assert username == &#x27;directly-overridden-username&#x27;        @pytest.mark.parametrize(&#x27;username&#x27;, [&#x27;directly-overridden-username-other&#x27;])        def test_username_other(other_username):            assert other_username == &#x27;other-directly-overridden-username-other&#x27;\n\n在上面的示例中，fixture值被测试参数值覆盖。注意，即使测试没有直接使用fixture的值（在函数原型中没有提到），也可以用这种方式覆盖fixture的值。\n用非参数化固件替代参数化固件Override a parametrized fixture with non-parametrized one and vice versa\n假设测试文件结构为：\ntests/    __init__.py    conftest.py        # content of tests/conftest.py        import pytest        @pytest.fixture(params=[&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;])        def parametrized_username(request):            return request.param        @pytest.fixture        def non_parametrized_username(request):            return &#x27;username&#x27;    test_something.py        # content of tests/test_something.py        import pytest        @pytest.fixture        def parametrized_username():            return &#x27;overridden-username&#x27;        @pytest.fixture(params=[&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;])        def non_parametrized_username(request):            return request.param        def test_username(parametrized_username):            assert parametrized_username == &#x27;overridden-username&#x27;        def test_parametrized_username(non_parametrized_username):            assert non_parametrized_username in [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]    test_something_else.py        # content of tests/test_something_else.py        def test_username(parametrized_username):            assert parametrized_username in [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]        def test_username(non_parametrized_username):            assert non_parametrized_username == &#x27;username&#x27;\n\n在上面的示例中，参数化固件被非参数化版本覆盖，而非参数化固件被某些测试模块的参数化版本覆盖。显然，这同样适用于测试文件夹级别。\n","categories":["技术","pytest"],"tags":["pytest","翻译"]},{"title":"pytest03 The writing and reporting of assertions in tests","url":"/posts/2019/06/16/52979/","content":"Asserting with the assert statement断言 assert 陈述\npytest 允许你使用标准的python assert 用于验证Python测试中的期望和值。例如，可以编写以下内容：\n# content of test_assert1.pydef f():    return 3def test_function():    assert f() == 4\n\n断言函数会返回某个值。如果此断言失败，你将看到函数调用的返回值：\n$ pytest test_assert1.py=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 1 itemtest_assert1.py F                                                    [100%]================================= FAILURES =================================______________________________ test_function _______________________________    def test_function():&gt;       assert f() == 4E       assert 3 == 4E        +  where 3 = f()test_assert1.py:5: AssertionError========================= 1 failed in 0.12 seconds =========================\n\npytest 支持显示最常见的子表达式的值，包括调用、属性、比较以及二进制和一元运算符。（见 用pytest演示python失败报告 ）这允许你在不丢失自省信息的情况下使用不带样板代码的惯用python构造。\n但是，如果使用如下断言指定消息：\nassert a % 2 == 0, &quot;value was odd, should be even&quot;\n\n这样根本不进行断言内省，消息将简单地显示在追溯中。\n\nAssertions about expected exceptions关于预期异常的断言\n为了编写有关引发的异常的断言，可以使用 pytest.raises 作为这样的上下文管理器：\nimport pytestdef test_zero_division():    with pytest.raises(ZeroDivisionError):        1 / 0\n\n如果你需要访问实际的异常信息，可以使用：\ndef test_recursion_depth():    with pytest.raises(RuntimeError) as excinfo:        def f():            f()        f()    assert &#x27;maximum recursion&#x27; in str(excinfo.value)\n\nexcinfo 是一个 ExceptionInfo 实例，它是引发的实际异常的包装。感兴趣的主要特征是 .type ， .value 和 .traceback .\n你可以通过给上下文管理器传递一个match关键字参数，用于测试正则表达式是否匹配异常的字符串表示形式（类似于 unittest 中的 TestCase.assertRaisesRegexp 方法）：\nimport pytestdef f():    raise ValueError(&quot;Exception 123 raised&quot;)def test_match():    with pytest.raises(ValueError, match=r&#x27;.* 123 .*&#x27;):        myfunc()\n\n match 方法的regexp参数与 re.search 函数相同，因此在上面的示例中 match=&#39;123&#39; 也会起作用的。\n\n在这个例子中，test_match 使用 pytest.raises 来检查 f() 是否抛出了 ValueError。\n如果 f() 抛出了 ValueError，测试通过。\n如果 f() 没有抛出任何异常，测试失败。\n如果 f() 抛出了其他异常，测试失败。\n\n有另一种形式的 pytest.raises 函数，其中传递的函数将用给定的 *args 和 **kwargs 并断言引发了给定的异常：\npytest.raises(ExpectedException, func, *args, **kwargs)\n\n如果出现故障，如 no exception or wrong exception ，这份报告将为你提供有益的输出。\n请注意，也可以将“引发”参数指定为 pytest.mark.xfail ，它检查测试是否以比引发任何异常更具体的方式失败。\n\npytest.mark.xfail 是一个标记，用于标记一个测试函数，表示这个测试预计会失败。如果测试确实失败了，那么 pytest 会报告这个测试为“xfail”（预期失败），而不是失败。\n\n使用 pytest.raises 对于测试自己代码中故意引发的异常的情况，可能会更好。而使用 @pytest.mark.xfail 使用check函数可能更适合记录未修复的错误（测试描述了“应该”发生的情况）或依赖项中的错误。\n\n\n举例：\n@pytest.mark.xfail(raises=IndexError)def test_f():    f()\n\n\n在这个例子中，test_f 被标记为 xfail，并且预期 f() 会抛出 IndexError 异常。\n如果 f() 抛出了 IndexError，测试会被标记为“xfail”。\n如果 f() 没有抛出任何异常，测试会被标记为“xpass”（意外通过）。\n如果 f() 抛出了其他异常，测试会被标记为“failed”。\n\n假设你有一个函数 process_data，在处理某些数据时会抛出 ValueError，但你知道这是一个已知的问题，尚未修复：\ndef process_data(data):    if not data:        raise ValueError(&quot;Data cannot be empty&quot;)    # 处理数据的逻辑    return data@pytest.mark.xfail(raises=ValueError)def test_process_data():    process_data([])\n\npython -m pytest .\\test_xfail.py============================================================================== test session starts =============================================================================== platform win32 -- Python 3.12.0, pytest-7.0.1, pluggy-1.0.0rootdir: D:\\Developer\\pytest_learning\\pytest\\3.The writing and reporting of assertions in testsplugins: allure-pytest-2.9.43, Faker-13.3.0, assume-2.4.3collected 1 item                                                                                                                                                                   test_xfail.py x                                                                                                                                                             [100%] =============================================================================== 1 xfailed in 0.12s =============================================================================== \n\n在这个测试中，test_process_data 被标记为 xfail，并且预期 process_data([]) 会抛出 ValueError。如果 process_data([]) 抛出了 ValueError，测试会被标记为“xfail”。如果 process_data([]) 没有抛出任何异常，测试会被标记为“xpass”。\n使用场景：\n\n**pytest.raises**：适用于测试你自己代码中故意引发的异常的情况。例如，你有一个函数在某些条件下会抛出特定的异常，你希望确保这些异常被正确抛出。\n**@pytest.mark.xfail**：更适合记录未修复的错误（测试描述了“应该”发生的情况）或依赖项中的错误。例如，你知道某个测试在当前环境下会失败，但你希望在未来修复这个问题后，测试能够通过。如果是 process_data(1)，这个用例就会执行成功。\n\n\nMaking use of context-sensitive comparisons利用上下文相关的比较\n当遇到比较时pytest 对提供上下文敏感信息具有丰富的支持。例如：\n# content of test_assert2.pydef test_set_comparison():    set1 = set(&quot;1308&quot;)    set2 = set(&quot;8035&quot;)    assert set1 == set2\n\n运行此模块：\n$ pytest test_assert2.py=========================== test session starts ============================platform linux -- Python 3.x.y, pytest-4.x.y, py-1.x.y, pluggy-0.x.ycachedir: $PYTHON_PREFIX/.pytest_cacherootdir: $REGENDOC_TMPDIRcollected 1 itemtest_assert2.py F                                                    [100%]================================= FAILURES =================================___________________________ test_set_comparison ____________________________    def test_set_comparison():        set1 = set(&quot;1308&quot;)        set2 = set(&quot;8035&quot;)&gt;       assert set1 == set2E       AssertionError: assert &#123;&#x27;0&#x27;, &#x27;1&#x27;, &#x27;3&#x27;, &#x27;8&#x27;&#125; == &#123;&#x27;0&#x27;, &#x27;3&#x27;, &#x27;5&#x27;, &#x27;8&#x27;&#125;E         Extra items in the left set:E         &#x27;1&#x27;E         Extra items in the right set:E         &#x27;5&#x27;E         Use -v to get the full difftest_assert2.py:5: AssertionError========================= 1 failed in 0.12 seconds =========================\n\n对一些情况进行特殊比较：\n\n比较长字符串：显示文本差异\n比较长序列：第一个失败下标\n比较字典：不同的条目\n\n\nDefining your own explanation for failed assertions为失败的断言定义自己的解释\n可以通过执行 pytest_assertrepr_compare 钩子来增加自己细节解释。\n\npytest_assertrepr_compare(config, op, left, right)\n返回失败的断言表达式中比较解释。如果没有自定义解释，则返回“None”，否则返回字符串列表。字符串将由换行符联接，但任何字符串中的换行符将被转义。请注意，除了第一行之外，其他所有行都将略微缩进，目的是为了将第一行作为摘要。\n\n\n例如，考虑在 conftest.py 中增加如下的钩子，来为Foo对象提供替代解释：\n# content of conftest.pyfrom test_foocompare import Foodef pytest_assertrepr_compare(op, left, right):    if isinstance(left, Foo) and isinstance(right, Foo) and op == &quot;==&quot;:        return [&#x27;Comparing Foo instances:&#x27;,                &#x27;   vals: %s != %s&#x27; % (left.val, right.val)]\n\n现在，假设这个测试模块：\n# content of test_foocompare.pyclass Foo(object):    def __init__(self, val):        self.val = val    def __eq__(self, other):        return self.val == other.valdef test_compare():    f1 = Foo(1)    f2 = Foo(2)    assert f1 == f2\n\n你可以运行测试模块并在conftest文件中定义自定义输出：\n$ pytest -q test_foocompare.pyF                                                                    [100%]================================= FAILURES =================================_______________________________ test_compare _______________________________    def test_compare():        f1 = Foo(1)        f2 = Foo(2)&gt;       assert f1 == f2E       assert Comparing Foo instances:E            vals: 1 != 2test_foocompare.py:11: AssertionError1 failed in 0.12 seconds\n\n\nAssertion introspection details断言自省详细信息\n通过在运行断言语句之前重写它们，可以获得有关失败断言的报告详细信息。重写的断言语句将自省信息放入断言失败消息中。 pytest 只重写由其测试收集过程直接发现的测试模块，因此 支持模块中的断言（本身不是测试模块）将不会被重写 .\n你可以手动使能断言，为一个导入的模块重写，这个模块在导入前通过register_assert_rewrite调用。（一个很好的地方是在您的根目录中 conftest.py ）\n示例\n假设你有一个支持模块 utils.py，其中包含一些辅助函数，并且你在测试模块中使用了这些函数。\n# utils.pydef check_positive(num):    assert num &gt; 0, &quot;Number must be positive&quot;\n\n# test_utils.pyimport pytestfrom utils import check_positivedef test_check_positive():    check_positive(10)  # 应该通过    check_positive(-1)  # 应该失败\n\n默认行为\n默认情况下，pytest 不会重写 utils.py 中的断言，因此 test_check_positive 失败时，你只会看到一个简单的 AssertionError，而不会看到详细的自省信息，部分如下：\ntest_utils.py:3 (test_check_positive)def test_check_positive():        check_positive(10)  # 应该通过&gt;       check_positive(-1)  # 应该失败test_utils.py:6: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _num = -1    def check_positive(num):&gt;       assert num &gt; 0, &quot;Number must be positive&quot;E       AssertionError: Number must be positive..\\..\\utils\\__init__.py:2: AssertionError\n\n手动启用断言重写\n为了在 utils.py 中启用断言的重写，你可以在 conftest.py 中调用 pytest.register_assert_rewrite。\n# conftest.pyimport pytestdef pytest_configure(config):    pytest.register_assert_rewrite(&#x27;utils&#x27;)\n\n运行测试\n现在，当你运行 pytest 时，utils.py 中的断言也会被重写，你将获得详细的自省信息：\ntest_utils.py:3 (test_check_positive)-1 != 0Expected :0Actual   :-1&lt;Click to see difference&gt;def test_check_positive():        check_positive(10)  # 应该通过&gt;       check_positive(-1)  # 应该失败\n\n总结\n\n断言自省：pytest 通过重写断言语句来提供详细的错误信息。\n默认行为：pytest 只重写测试模块中的断言。\n手动启用：通过 pytest.register_assert_rewrite 可以在支持模块中启用断言的重写。\n最佳实践：在 conftest.py 中调用 pytest.register_assert_rewrite 来注册需要重写的模块。\n\n\nAssertion rewriting caches files on disk断言重写将文件缓存在磁盘上\npytest 会将重写的模块写回磁盘进行缓存（可以提高后续测试运行的性能，因为不需要每次都重新编译和重写模块）。\n可以通过设置 sys.dont_write_bytecode = True，来禁用 .pyc 文件的缓存。\n例如，为了避免在经常移动文件的项目中留下过时的.pyc文件。在一些项目中，文件经常被移动或重命名。如果 pytest 将重写后的模块缓存到磁盘上，可能会导致旧的 .pyc 文件残留，从而引起问题，比如重命名重跑用例会有意想不到的问题。禁用缓存可以避免这种情况。\nimport syssys.dont_write_bytecode = True\n\n请注意，你仍然可以获得断言内省的好处，唯一的变化是 .pyc 文件不会缓存在磁盘上。\n此外，如果重写无法写入新的 .pyc 文件，它将自动跳过缓存，即只读文件系统或压缩文件中的文件。\n\nDisabling assert rewriting禁用断言重写\npytest 通过使用导入钩子hook的方式写入新的 pyc 文件夹，在导入时重写测试模块。大多数时候这是透明的。但是，如果你自己操作导入机制，导入钩子可能会产生干扰。假设你有一个项目，其中包含自定义的导入机制。在这种情况下，pytest 的断言重写机制可能会干扰你的自定义导入。\n如果是这种情况，你有两个选择：\n\n通过添加字符串PYTEST_DONT_REWRITE 到它的docstring，禁用特定模块的重写 。\n通过使用 --assert=plain ，禁用所有模块的重写.\n添加断言重写作为一个可替换的自省机制\n介绍 --assert 选项。不赞成使用 --no-assert 和 --nomagic .\n移除 --no-assert 和 --nomagic 选项。移除 --assert=reinterp 选项。\n\n\n\n假设你有一个自定义的导入器 custom_importer.py，它修改了 sys.meta_path：\n# custom_importer.pyimport sysclass CustomImporter:    def find_spec(self, fullname, path, target=None):        # 自定义的导入逻辑        print(f&quot;CustomImporter: Finding spec for &#123;fullname&#125;&quot;)        return Nonesys.meta_path.insert(0, CustomImporter())\n\n测试模块\n假设你有一个测试模块 test_module.py，其中包含一个简单的测试：\n# test_module.pyimport pytestdef test_example():    assert 1 + 1 == 2\n\n运行测试\n当你运行 pytest 时，pytest 的导入钩子可能会与你的自定义导入器发生冲突：\npytest test_module.py\n\n禁用断言重写\n为了禁用 pytest 的断言重写机制，你可以在运行 pytest 时使用 --no-assert 选项：\npytest --no-assert test_module.py\n\n解释\n\n--no-assert 选项：这个选项告诉 pytest 不要使用断言重写机制。这样可以避免 pytest 的导入钩子与你的自定义导入机制发生冲突。\n影响：禁用断言重写后，你将失去断言自省的详细信息。也就是说，断言失败时，你只会看到简单的 AssertionError，而不会看到详细的上下文信息。\n\n","categories":["技术","pytest"],"tags":["pytest","翻译"]},{"title":"pytest05 Marking test functions with attributes","url":"/posts/2019/07/28/24294/","content":"通过使用 pytest.mark 可以轻松地在测试函数上设置元数据。一些内置标记，例如：\n\nskip - 总是跳过测试函数\nskipif - 如果满足某个条件，则跳过测试函数\nxfail - 如果满足某个条件，则产生“预期失败”结果\nparametrize 对同一测试函数执行多个调用\n\n很容易创建自定义标记，或将标记应用于整个测试类或模块。这些标记可以被插件使用，也常用于 select tests 在命令行上 -m 选择权。\n注解：标记只能用于测试，对 fixtures 没有作用。\n\n注册标记可以在 pytest.ini 的文件中注册自定义标记，像这样：\n[pytest]markers =    slow: marks tests as slow (deselect with &#x27;-m &quot;not slow&quot;&#x27;)    serial\n\n请注意，在 : 后面的是可选描述。\n在这个例子中，我们定义了两个标记：slow 和 serial。slow 标记有一个描述，告诉其他开发者这个标记是用来标识那些执行速度较慢的测试，并且可以通过 -m &quot;not slow&quot; 命令行参数来排除这些慢速测试。serial 没有描述，但是它的用途可能是为了确保某些测试按照特定的顺序执行。\n或者，可以在 pytest_configure 钩子中程序化地注册新的标记，这个函数会在pytest启动时调用，可以用来动态地添加或修改配置：\ndef pytest_configure(config):    config.addinivalue_line(        &quot;markers&quot;, &quot;env(name): mark test to run only on named environment&quot;    )\n\n在这个例子中，我们定义了一个 env 标记，它带有一个参数 name，表示测试仅在名为 name 的环境中运行。这种情况下，name 可以是你定义的任何环境名称，例如 production、staging 等。\n\n使用注册的标记一旦注册了自定义标记，就可以在测试函数上使用它们。例如：\n@pytest.mark.slowdef test_something_slow():    # 这是一个慢速测试    pass@pytest.mark.serialdef test_needs_serial_execution():    # 这个测试需要按顺序执行    pass\n\n当你运行pytest时，可以使用 -m 参数来选择或排除标记：\n# 运行所有标记为 &#x27;slow&#x27; 的测试$ pytest -m slow# 排除所有标记为 &#x27;slow&#x27; 的测试$ pytest -m &quot;not slow&quot;\n\n注册标记可以帮助提高测试的组织性和可读性，同时也能确保只有已知的标记被使用，从而避免错误的标记导致的问题。如果你正在开发一个pytest插件，强烈建议你注册所有使用的标记，以便用户更好地理解你的插件是如何工作的。\n\n如何配置环境名称配置环境名称通常是通过以下几种方式之一来完成的：\n1. 环境变量你可以设置环境变量来指示当前的环境。例如，在Linux或Unix系统中，你可以设置一个名为ENV或ENVIRONMENT的环境变量：\nexport ENV=production\n\n然后在应用程序中，你可以通过读取这个环境变量来确定当前的环境：\nimport oscurrent_env = os.getenv(&#x27;ENV&#x27;, &#x27;development&#x27;)  # 默认为 development\n\n2. 配置文件另一种常见的做法是在项目的配置文件中指定环境。例如，在Python项目中，你可以有一个settings.py文件，里面包含了不同的环境配置：\nclass Config:    DEBUG = False    TESTING = Falseclass DevelopmentConfig(Config):    DEBUG = Trueclass TestingConfig(Config):    TESTING = Trueclass ProductionConfig(Config):    passconfig_by_name = dict(    development=DevelopmentConfig,    testing=TestingConfig,    production=ProductionConfig)active_config = config_by_name[&#x27;development&#x27;]  # 默认为开发环境\n\n在测试中，你可以通过修改active_config来切换环境：\nactive_config = config_by_name[&#x27;production&#x27;]\n\n3. 命令行参数还可以通过命令行参数来传递环境名称。例如：\npython app.py --env=production\n\n然后在应用程序中解析这些参数：\nimport argparseparser = argparse.ArgumentParser()parser.add_argument(&#x27;--env&#x27;, default=&#x27;development&#x27;)args = parser.parse_args()current_env = args.env\n\n\n在pytest中使用环境名称在pytest测试中，你可以根据环境名称来决定是否运行某些测试。例如，如果某个特性只在生产环境中生效，你可以标记该测试并仅在生产环境中运行它：\n@pytest.mark.env(&#x27;production&#x27;)def test_production_only_feature():    # 这个测试只在生产环境中运行    pass\n\n然后，在运行pytest时，你可以使用-m选项来选择性地运行这些标记的测试：\npytest -m env=&#x27;production&#x27;\n\n这样，你就可以确保只有在正确的环境下才会运行相关的测试。\n\n在未知标记上引发错误未注册的标记应用于 @pytest.mark.name_of_the_mark 装饰器将始终发出警告，以避免由于输入错误的名称而静默地执行一些令人惊讶的操作。如前一节所述，你可以通过在你的 pytest.ini 文件中或使用自定义 pytest_configure 钩子来停止警告。\n当 --strict-markers 传递了命令行标志，任何应用于 @pytest.mark.name_of_the_markdecorator的未知标记，将触发一个错误。在项目中，你可以通过添加 --strict-markers 到 addopts来强制验证 ：\n[pytest]addopts = --strict-markersmarkers =    slow: marks tests as slow (deselect with &#x27;-m &quot;not slow&quot;&#x27;)    serial\n\n\n\n未注册的标记发出警告默认情况下，pytest会对未注册的标记发出警告。这样做是为了防止因为拼写错误或其他误操作而导致的标记无效。例如，如果你不小心把slow标记拼写成了slw：\n@pytest.mark.slwdef test_something():    pass\n\npytest会识别出slw是一个未知标记，并发出警告。这样做的目的是提醒开发者检查标记是否存在拼写错误或其他问题。\n使用 --strict-markers 选项为了进一步提高标记使用的严格性，pytest提供了一个--strict-markers命令行选项。当启用此选项时，任何未注册的标记都会导致一个错误，而不是仅仅发出警告。这意味着测试将无法运行，直到标记问题得到解决。\n例如，如果你在命令行中运行pytest并指定了--strict-markers选项：\npytest --strict-markers\n\n如果存在未注册的标记，pytest将显示错误信息，并阻止测试的执行。\n在 pytest.ini 文件中配置你还可以在pytest.ini文件中配置--strict-markers选项，使其成为项目的默认行为。这样每次运行pytest时都会自动启用严格的标记检查。例如：\n[pytest]addopts = --strict-markersmarkers =    slow: marks tests as slow (deselect with &#x27;-m &quot;not slow&quot;&#x27;)    serial\n\n在这个配置文件中，addopts项设置了默认的命令行选项，使得每次运行pytest时都会启用严格的标记检查。markers项则注册了自定义标记，如slow和serial。\n总结：使用标记可以帮助你更好地管理和运行测试。注册标记可以避免因为拼写错误或输入错误而导致的问题。通过启用--strict-markers选项，可以进一步确保标记使用的准确性。在项目配置文件中设置这些选项可以确保每次运行pytest时都遵循一致的标准。\n","categories":["技术","pytest"],"tags":["pytest"]},{"title":"python2与python3的区别","url":"/posts/2019/03/19/3466/","content":"一.性能python3.x 起始比python2.x 效率低, 但是3.x后有极大的优化空间, 性能上正在追赶.\n二.编码Python3 对Unicode字符的原生支持.\npython2中使用ASCII码作为默认的编码方式, string有两种类型: str 和 unicode. python3 只支持unicode的string. \n\n\n\nPython2\nPython3\n表现形式\n转换\n作用\n\n\n\nunicode\nstr\n字节\ndecode\n显示\n\n\nstr\nbytes\n字节\nencode\n存储, 传输\n\n\n# python2:&gt;&gt;&gt; print type(unicode(&#x27;this is like a python3 str type&#x27;))&lt;type &#x27;unicode&#x27;&gt;&gt;&gt;&gt; print type(b&#x27;byte type does not exist&#x27;)&lt;type &#x27;str&#x27;&gt;&gt;&gt;&gt; print &#x27;they are really&#x27; + b&#x27; the same&#x27;they are really the same&gt;&gt;&gt; print type(bytearray(b&#x27;bytearray oddly does exist though&#x27;))&lt;type &#x27;bytearray&#x27;&gt;\n\n# python3:&gt;&gt;&gt; print(&#x27;strings are now utf-8 \\u03BCnico\\u0394é!&#x27;)strings are now utf-8 μnicoΔé!&gt;&gt;&gt; print(type(&#x27;strings are now utf-8 \\u03BCnico\\u0394é!&#x27;))&lt;class &#x27;str&#x27;&gt;&gt;&gt;&gt; print(&#x27;python3 has&#x27;, type(b&#x27; bytes for storing data&#x27;))python3 has &lt;class &#x27;bytes&#x27;&gt;&gt;&gt;&gt; print(&#x27; also has&#x27;, type(bytearray(b&#x27;bytearrays&#x27;))) also has &lt;class &#x27;bytearray&#x27;&gt;  &gt;&gt;&gt; &#x27;note that we cannot add a string&#x27; + b&#x27;bytes for data&#x27;Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: must be str, not bytes\n\n\n\npython3默认使用utf-8编码, 使得变量名更加广泛.\n&gt;&gt;&gt; 中国 = &#x27;china&#x27; &gt;&gt;&gt;print(中国) china\n\n# python2.x&gt;&gt;&gt; str = &quot;我爱北京天安门&quot;&gt;&gt;&gt; str&#x27;\\xe6\\x88\\x91\\xe7\\x88\\xb1\\xe5\\x8c\\x97\\xe4\\xba\\xac\\xe5\\xa4\\xa9\\xe5\\xae\\x89\\xe9\\x97\\xa8&#x27;&gt;&gt;&gt; str = u&quot;我爱北京天安门&quot;&gt;&gt;&gt; stru&#x27;\\u6211\\u7231\\u5317\\u4eac\\u5929\\u5b89\\u95e8&#x27;# python3.x&gt;&gt;&gt; str = &quot;我爱北京天安门&quot;&gt;&gt;&gt; str&#x27;我爱北京天安门&#x27;\n\n\n\n三.语法1. 去除了 &lt;&gt; , 改用 !&#x3D;# python2:&gt;&gt;&gt; 1 &lt;&gt; 2True&gt;&gt;&gt; 1 != 2True# python3:&gt;&gt;&gt; 1 &lt;&gt; 2  File &quot;&lt;stdin&gt;&quot;, line 1    1 &lt;&gt; 2       ^SyntaxError: invalid syntax&gt;&gt;&gt; 1 != 2True\n\n2. 加入了 as 和 with关键字, 还有 True, False, NoneTrue 和 False 在 Python2 中是两个全局变量（名字），在数值上分别对应 1 和 0，既然是变量，那么他们就可以指向其它对象，例如：\n&gt;&gt;&gt; True = False&gt;&gt;&gt; TrueFalse&gt;&gt;&gt; True is FalseTrue&gt;&gt;&gt; False = &quot;a&quot;&gt;&gt;&gt; False&#x27;a&#x27;&gt;&gt;&gt; if False:...     print &quot;false is True&quot;...false is True\n\n上面的代码违背了 Python 的设计哲学 Explicit is better than implicit.。而 Python3 修正了这个缺陷，True 和 False 变为两个关键字，永远指向两个固定的对象，不允许再被重新赋值。\n&gt;&gt;&gt; True = False  File &quot;&lt;stdin&gt;&quot;, line 1SyntaxError: can&#x27;t assign to keyword\n\n3. 整型触发返回浮点数, 整除使用 &#x2F;&#x2F;在python 2.x中&#x2F;除法就跟我们熟悉的大多数语言，比如Java啊C啊差不多，整数相除的结果是一个整数，把小数部分完全忽略掉，浮点数除法会保留小数点的部分得到一个浮点数的结果。\n在python 3.x中&#x2F;除法不再这么做了，对于整数之间的相除，结果也会是浮点数。\n# python2:&gt;&gt;&gt; 5/31&gt;&gt;&gt; 5.0/31.6666666666666667# python3:&gt;&gt;&gt; 5/31.6666666666666667&gt;&gt;&gt; 5.0/31.6666666666666667\n\n对于&#x2F;&#x2F;除法(floor除法)，会对除法的结果自动进行一个floor操作，在python 2.x和python 3.x中是一致的。\n3. 加入nonlocal 语句在python2中,函数里面可以使用关键字global 声明某个变量为全局变量, 但是在嵌套函数中, 如果要把一个变量声明为非局部变量是没有办法实现的. 在python3中,加入了关键字nonlocal.\ndef func():  a = 1\tdef inner():    a = 11    inner()    print(a)func()  # 1def funcNonlocal():  a = 1\tdef inner():    nonlocal a    a = 11    inner()    print(a)funcNonlocal() # 11\n\n4. 去除print语句, 加入print()函数在python2中print是一条语句, 而在python3中是作为函数存在.\n# 2:print(&quot;python2&quot;)# 3:print(&quot;python3&quot;)\n\n上述代码在输出结果上是一样的, 但是在Python2中是把(“python2”)当做是一个整体, 而后者print()是接收”python3”字符串作为参数的函数.\n# python2:&gt;&gt;&gt; print(&quot;a&quot;)a&gt;&gt;&gt; print(&quot;a&quot;,&quot;b&quot;)(&#x27;a&#x27;, &#x27;b&#x27;)# python3:&gt;&gt;&gt; print(&quot;a&quot;)a&gt;&gt;&gt; print(&quot;a&quot;,&quot;b&quot;)a b\n\n由上述代码可以看出, 在python2中, print语句后面接的是一个元组对象. 相比较而言, 在python3中, print函数可以接受任意个位置参数. 如果想要在python2中把print当做函数使用, 可以导入future模块中的print_function.\n# python2:&gt;&gt;&gt; print(&quot;a&quot;)a&gt;&gt;&gt; print(&quot;a&quot;,&quot;b&quot;)(&#x27;a&#x27;, &#x27;b&#x27;)&gt;&gt;&gt; from __future__ import print_function&gt;&gt;&gt; print(&quot;a&quot;,&quot;b&quot;)a b\n\n5. 去除raw_input , 加入input函数在 Python 3 中已经解决了把用户的输入存储为一个 str 对象的问题。\n6. 新的super(), 可以不给super()传参class A(object):  \tdef __init__(self, a):      \tprint(&quot;A&quot;, a)class B(A):  \tdef __init__(self, a):      \tsuper().__init__(a)  \n\n7. 改变了顺序操作符的行为例如:  x &lt; y , 当x和y的类型不匹配时抛出TypeError ,而不是返回随机的bool值.\n# python2:&gt;&gt;&gt; 2 &lt; &quot;a&quot;True# python3:&gt;&gt;&gt; 2 &lt; &quot;a&quot;Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &#x27;&lt;&#x27; not supported between instances of &#x27;int&#x27; and &#x27;str&#x27;\n\n8. 新式的八进制变量# python2:&gt;&gt;&gt; 0666438&gt;&gt;&gt; 0777511# python3:&gt;&gt;&gt; 0666  File &quot;&lt;stdin&gt;&quot;, line 1    0666       ^SyntaxError: invalid token&gt;&gt;&gt; 0o666438&gt;&gt;&gt; 0o777511\n\n9. 字符串和字节串在python2中:字符串以 8-bit 字符串存储;\n在python3中:字符串以 16-bit Unicode 字符串存储;现在字符串只有str 一种类型.\n10. 数据类型pthon3.x 去除了long类型, 只有一种整型—-intpython3 彻底废弃了 long+int 双整数实现的方法, 统一为 int , 支持高精度整数运算.\n新增了bytes类型, 对应于2.x 版本的八位串:\n# python2:&gt;&gt;&gt; a = b&quot;china&quot;&gt;&gt;&gt; a&#x27;china&#x27;&gt;&gt;&gt; type(a)&lt;type &#x27;str&#x27;&gt;# python3:&gt;&gt;&gt; a = b&quot;china&quot;&gt;&gt;&gt; ab&#x27;china&#x27;&gt;&gt;&gt; type(a)&lt;class &#x27;bytes&#x27;&gt;\n\nstr对象和bytes对象可以使用 .encode() 将str 转换为 bytes, 或者使用 .decode() 将 bytes装换为str.\n11. 面向对象引入抽象基类\n12. 异常\n所有异常都从BaseException 继承, 并删除了 StandardError\n\npython2:  \ntry:\tpassexcept Exception, e:\tpass\n\npython3:\ntry:\tpassexcept Exception as e:\tpass\n\n13. 返回可迭代对象python2中很多返回列表对象的内置函数和方法, 在python3中都改为了返回类似于迭代器的对象(可迭代对象), 由于迭代器的惰性加载特性使得操作大数据时可以更加有效率. 比如python2中的range和xrange函数合成了 python3中的range(同时兼容2和3).\n# python2:print range(3) print type(range(3))# [0, 1, 2]# &lt; type ‘list’&gt;\n\n# python3:print(range(3))print(type(range(3)))print(list(range(3)))# range(0, 3)# &lt; class ‘range’&gt;# [0, 1, 2]\n\n除此, 字典对象的 dict.keys() ,  dict.values() ,  dict.items() 方法都不再返回列表, 而是以一个类似迭代器的 “view” 对象返回.高阶函数map, filter, zip 返回的也都 不是列表对象了. 在python2中的迭代器必须实现 next 方法,  而在Python3 改成了 __next__.\n14. for循环变量和去全局命名空间泄露在python3 中 for循环变量不会导致命名空间泄露.\n# python2:i = 1print &#x27;before: i =&#x27;, iprint &#x27;comprehension: &#x27;, [i for i in range(5)]print &#x27;after: i =&#x27;, i# before: i = 1# comprehension: [0, 1, 2, 3, 4]# after: i = 4\n\n# python3:i = 1print(&#x27;before: i =&#x27;, i)print(&#x27;comprehension:&#x27;, [i for i in range(5)])print(&#x27;after: i =&#x27;, i)# before: i = 1# comprehension: [0, 1, 2, 3, 4]# after: i = 1\n\n参考:Python 2 和 Python 3 有哪些主要区别？Python 2.7.x 与 Python 3.x 的主要差异What’s New In Python 3.0菜鸟教程\n","categories":["技术","Python"],"tags":["Python","python2"]},{"title":"pytest06 MonkeyPatching/Mocking module/environment","url":"/posts/2019/07/28/32831/","content":"这个 monkeypatch fixture为测试中的安全修补和模拟功能提供了以下帮助方法：\nmonkeypatch.setattr(obj, name, value, raising=True)monkeypatch.delattr(obj, name, raising=True)monkeypatch.setitem(mapping, name, value)monkeypatch.delitem(obj, name, raising=True)monkeypatch.setenv(name, value, prepend=False)monkeypatch.delenv(name, raising=True)monkeypatch.syspath_prepend(path)monkeypatch.chdir(path)\n\n所有修改将在请求的测试功能或固件完成后撤消。如果设置&#x2F;删除操作的目标不存在，这个 raising 参数决定了是否抛出 KeyError 或 AttributeError错误。\n考虑以下情况：\n\n为测试修改函数的行为或类的属性，例如有一个API调用或数据库连接，你将无法进行测试，但你知道预期的输出应该是什么。使用 monkeypatch.setattr() 使用所需的测试行为修补函数或属性，这可以包括你自己的功能，使用 monkeypatch.delattr() 删除测试的函数或属性。\n\n修改字典的值，例如，对于某些测试用例，你需要修改全局配置。使用 monkeypatch.setitem()为测试修改字典。 monkeypatch.delitem() 可用于删除项目。\n\n修改测试的环境变量，例如在缺少环境变量时测试程序行为，或将多个值设置为已知变量。 monkeypatch.setenv() 和 monkeypatch.delenv() 可用于这些修补。\n\n使用 monkeypatch.setenv(&quot;PATH&quot;, value, prepend=os.pathsep) 修改系统 $PATH 安全，以及 monkeypatch.chdir() 在测试期间更改当前工作目录的上下文。\n\n使用py:meth: monkeypatch.syspath_prepend  来修改sys.path，这将会调用pkg_resources.fixup_namespace_packages()` and `importlib.invalidate_caches()\n\n\n简单示例：monkeypatching 函数考虑使用用户目录的场景，在测试环境中，你不希望测试依赖于正在运行的用户。 monkeypatch 可用于修补依赖于用户的函数，以始终返回特定值。\n在这个例子中， monkeypatch.setattr() 用于修补 Path.home 使已知的测试路径 Path(&quot;/abc&quot;) 总是在运行测试时使用。这将删除出于测试目的对正在运行的用户的任何依赖。 monkeypatch.setattr() 必须在调用将使用修补函数的函数之前调用。测试功能完成后， Path.home 修改将被撤消。\n# contents of test_module.py with source code and the testfrom pathlib import Pathdef getssh():    &quot;&quot;&quot;Simple function to return expanded homedir ssh path.&quot;&quot;&quot;    return Path.home() / &quot;.ssh&quot;def test_getssh(monkeypatch):    # mocked return function to replace Path.home    # always return &#x27;/abc&#x27;    def mockreturn():        return Path(&quot;/abc&quot;)    # Application of the monkeypatch to replace Path.home    # with the behavior of mockreturn defined above.    monkeypatch.setattr(Path, &quot;home&quot;, mockreturn)    # Calling getssh() will use mockreturn in place of Path.home    # for this test with the monkeypatch.    x = getssh()    assert x == Path(&quot;/abc/.ssh&quot;)\n\n定义 mockreturn 函数：\ndef mockreturn():    return Path(&quot;/abc&quot;)\n\n\nmockreturn 是一个模拟函数，用于替换 Path.home() 的行为，使其始终返回 Path(&quot;/abc&quot;)，即一个虚拟的路径 /abc。\n\n使用 monkeypatch 替换 Path.home 方法：\nmonkeypatch.setattr(Path, &quot;home&quot;, mockreturn)\n\n\nmonkeypatch.setattr 用于在测试期间临时替换 Path.home 方法，使其行为变为 mockreturn。\n这样，在 test_getssh 测试中，调用 Path.home() 就会返回 /abc，而不是实际的主目录路径。\n\n调用 getssh 并断言结果：\nx = getssh()assert x == Path(&quot;/abc/.ssh&quot;)\n\n\n调用 getssh() 时，由于 Path.home() 已被替换为 mockreturn，所以 getssh 会返回 Path(&quot;/abc&quot;) / &quot;.ssh&quot;，即 Path(&quot;/abc/.ssh&quot;)。\nassert 语句用于验证 getssh() 的返回值是否为 Path(&quot;/abc/.ssh&quot;)。如果返回值匹配，则测试通过；否则测试失败。\n\n\nMonkeyPatching返回的对象：构建模拟类monkeypatch.setattr() 可以与类一起使用，模拟从函数而不是值返回的对象。设想一个简单的函数获取一个API URL并返回JSON响应。我们需要模拟r ，返回的响应对象用于测试目的。 r 需要一个 .json() 返回字典的方法。这可以在我们的测试文件中通过定义一个类来表示 r .\n# app.pyimport requestsdef get_json(url):    &quot;&quot;&quot;Takes a URL, and returns the JSON.&quot;&quot;&quot;    r = requests.get(url)    return r.json()\n\n# test_mock_response.pyimport pytestimport requestsimport app# custom class to be the mock return value of requests.get()class MockResponse:    @staticmethod    def json():        return &#123;&quot;mock_key&quot;: &quot;mock_response&quot;&#125;# monkeypatched requests.get moved to a fixture@pytest.fixturedef mock_response(monkeypatch):    &quot;&quot;&quot;Requests.get() mocked to return &#123;&#x27;mock_key&#x27;:&#x27;mock_response&#x27;&#125;.&quot;&quot;&quot;    def mock_get(*args, **kwargs):        return MockResponse()    monkeypatch.setattr(requests, &quot;get&quot;, mock_get)# notice our test uses the custom fixture instead of monkeypatch directlydef test_get_json(mock_response):    result = app.get_json(&quot;https://fakeurl&quot;)    assert result[&quot;mock_key&quot;] == &quot;mock_response&quot;\n\nmonkeypatch 将 mock_get 功能模拟应用于 requests.get ，这个 mock_get 函数返回 MockResponse 类，其中有一个 json() 方法定义为返回已知的测试字典，不需要任何外部API连接， 调用 app.get_json(&quot;https://fakeurl&quot;) 时，不会实际发送请求。\n可以建立 MockResponse 为你正在测试的场景使用适当的复杂性来初始化。例如，它可以包括始终返回 True ok属性 或者基于输入字符串返回不同的值 json() 的模拟方法。\n小结，使用 MockResponse 模拟返回对象：通过自定义 MockResponse 类模拟 HTTP 响应，以控制测试环境中的数据。**monkeypatch 替换 requests.get**：通过 monkeypatch 将 requests.get 替换为 mock_get，实现对外部依赖的隔离。\n此外，如果模拟模型设计用于所有测试，则 fixture 可以移动到 conftest.py 归档并与一起使用 autouse=True 选择项。\n\n全局补丁示例：防止远程操作的“请求”如果要阻止“请求”库在所有测试中执行HTTP请求，可以执行以下操作：\n# contents of conftest.pyimport pytest@pytest.fixture(autouse=True)def no_requests(monkeypatch):    &quot;&quot;&quot;Remove requests.sessions.Session.request for all tests.&quot;&quot;&quot;    monkeypatch.delattr(&quot;requests.sessions.Session.request&quot;)\n\n将为每个测试功能执行该autouse fixture，并将删除该方法 request.session.Session.request 。因此，测试中创建HTTP请求的任何尝试都将失败。\n\n建议不要修补内置函数，例如 open ， compile 等等，因为它可能会破坏pytest的内部。如果那是不可避免的，传递参数 --tb=native ， --assert=plain 和 --capture=no 可能会有帮助，尽管没有保证。\n\n修补 Python 内置函数（如 open、compile 等）或 Pytest 依赖的函数可能会导致 Pytest 及其功能（如断言和捕获输出）异常。因为 Pytest 本身依赖于这些函数，过度修补会干扰其正常运行。如果必须修补，可以尝试通过添加 --tb=native、--assert=plain 和 --capture=no 参数来减轻影响，不过这些参数并不总能保证避免问题。\n\n注意修补 stdlib函数和 pytest 使用的函数和一些第三方库可能会破坏pytest本身，因此在这些情况下，建议使用 MonkeyPatch.context() 将修补限制到要测试的块，请执行以下操作：\n\nimport functoolsdef test_partial(monkeypatch):    with monkeypatch.context() as m:        m.setattr(functools, &quot;partial&quot;, 3)        assert functools.partial == 3\n\n使用 monkeypatch.context() 可以将修补作用域限制在 with 语句内的代码块，确保修补仅在该代码块内有效，代码块结束后修补会自动撤销。\n这是对标准库函数、Pytest 依赖的函数或第三方库函数进行修补的更安全方式，因为它最小化了修补的作用范围，降低了对 Pytest 或系统行为的干扰风险。\n\nMonkeyPatching 环境变量如果你正在使用环境变量，为了测试的目的你需要安全地更改这些值或从系统中删除它们， monkeypatch 提供了一种使用 setenv 和 delenv 机制，我们要测试的示例代码：\nimport osdef get_os_user_lower():    &quot;&quot;&quot;    Returns lowercase USER or raises EnvironmentError.&quot;&quot;&quot;    username = os.getenv(&quot;USER&quot;)    if username is None:        raise EnvironmentError(&quot;USER environment is not set.&quot;)    return username.lower()\n\n有两条可能的路径。首先， USER 环境变量设置为值，其次， USER 环境变量不存在。使用 monkeypatch 两条路径都可以在不影响运行环境的情况下进行安全测试：\nimport pytestdef test_upper_to_lower(monkeypatch):    &quot;&quot;&quot;Set the USER env var to assert the behavior.&quot;&quot;&quot;    monkeypatch.setenv(&quot;USER&quot;, &quot;TestingUser&quot;)    assert get_os_user_lower() == &quot;testinguser&quot;def test_raise_exception(monkeypatch):    &quot;&quot;&quot;Remove the USER env var and assert EnvironmentError is raised.&quot;&quot;&quot;    monkeypatch.delenv(&quot;USER&quot;, raising=False)    with pytest.raises(EnvironmentError):        _ = get_os_user_lower()\n\n此行为可以移入 fixture 结构和跨测试共享：\n# test_monkeypatching_env.pyimport pytest@pytest.fixturedef mock_env_user(monkeypatch):    monkeypatch.setenv(&quot;USER&quot;, &quot;TestingUser&quot;)@pytest.fixturedef mock_env_missing(monkeypatch):    monkeypatch.delenv(&quot;USER&quot;, raising=False)# notice the tests reference the fixtures for mocksdef test_upper_to_lower(mock_env_user):    assert get_os_user_lower() == &quot;testinguser&quot;def test_raise_exception(mock_env_missing):    with pytest.raises(EnvironmentError):        _ = get_os_user_lower()\n\n\n\n\nMonkeyPatching 字典monkeypatch.setitem() 可用于在测试期间安全地将字典值设置为特定值，使用 monkeypatch.delitem() 删除值。\n# app_dict.pyDEFAULT_CONFIG = &#123;&quot;user&quot;: &quot;user1&quot;, &quot;database&quot;: &quot;db1&quot;&#125;def create_connection_string(config=None):    &quot;&quot;&quot;Creates a connection string from input or defaults.&quot;&quot;&quot;    config = config or DEFAULT_CONFIG    return f&quot;User Id=&#123;config[&#x27;user&#x27;]&#125;; Location=&#123;config[&#x27;database&#x27;]&#125;;&quot;\n\n# test_monkeypatchDict_fixture.pyimport pytestimport app_dictdef test_connection(monkeypatch):    # Patch the values of DEFAULT_CONFIG to specific    # testing values only for this test.    monkeypatch.setitem(app_dict.DEFAULT_CONFIG, &quot;user&quot;, &quot;test_user&quot;)    monkeypatch.setitem(app_dict.DEFAULT_CONFIG, &quot;database&quot;, &quot;test_db&quot;)    # expected result based on the mocks    expected = &quot;User Id=test_user; Location=test_db;&quot;    # the test uses the monkeypatched dictionary settings    result = app_dict.create_connection_string()    assert result == expecteddef test_missing_user(monkeypatch):    # patch the DEFAULT_CONFIG t be missing the &#x27;user&#x27; key    monkeypatch.delitem(app_dict.DEFAULT_CONFIG, &quot;user&quot;, raising=False)    # Key error expected because a config is not passed, and the    # default is now missing the &#x27;user&#x27; entry.    with pytest.raises(KeyError):        _ = app_dict.create_connection_string()\n","categories":["技术","pytest"],"tags":["pytest"]},{"title":"python多线程原理及其实现","url":"/posts/2019/02/17/51544/","content":"1  线程基本概念1.1 线程是什么？线程是指进程内的一个执行单元,也是进程内的可调度实体.\n与进程的区别:(1) 地址空间:进程内的一个执行单元;进程至少有一个线程;它们共享进程的地址空间;而进程有自己独立的地址空间;(2) 资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源(3) 线程是处理器调度的基本单位,但进程不是.(4) 二者均可并发执行.\n简而言之,一个程序至少有一个进程,一个进程至少有一个线程. \n线程的划分尺度小于进程，使得多线程程序的并发性高。另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。 \n1.2  线程和进程关系？进程就是一个应用程序在处理机上的一次执行过程，它是一个动态的概念，而线程是进程中的一部分，进程包含多个线程在运行。\n多线程可以共享全局变量，多进程不能。多线程中，所有子线程的进程号相同；多进程中，不同的子进程进程号不同。\n进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动, 进程是系统进行资源分配和调度的一个独立单位. \n线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.\n​    \n2  Python线程模块python主要是通过thread和threading这两个模块来实现多线程支持。python的thread模块是比较底层的模块，python的threading模块是对thread做了一些封装，可以更加方便的被使用。但是python（cpython）由于GIL的存在无法使用threading充分利用CPU资源，如果想充分发挥多核CPU的计算能力需要使用multiprocessing模块(Windows下使用会有诸多问题)。\npython3.x中已经摒弃了Python2.x中采用函数式thread模块中的start_new_thread()函数来产生新线程方式。\npython3.x中通过threading模块创建新的线程有两种方法：一种是通过threading.Thread(Target&#x3D;executable Method)-即传递给Thread对象一个可执行方法（或对象）;第二种是继承threading.Thread定义子类并重写run()方法。第二种方法中，唯一必须重写的方法是run()\n（1）通过threading.Thread进行创建多线程\nimport threadingimport timedef target():    print(&quot;the current threading %s is runing&quot;       %(threading.current_thread().name))    time.sleep(1)    print(&quot;the current threading %s is ended&quot;%(threading.current_thread().name))    print(&quot;the current threading %s is runing&quot;%(threading.current_thread().name))## 属于线程t的部分t = threading.Thread(target=target)t.start()## 属于线程t的部分t.join() # join是阻塞当前线程(此处的当前线程时主线程) 主线程直到Thread-1结束之后才结束print(&quot;the current threading %s is ended&quot;%(threading.current_thread().name))\n\n\n\n（2）通过继承threading.Thread定义子类创建多线程\n使用Threading模块创建线程，直接从threading.Thread继承，然后重写__init__方法和run方法：\n\nimport threadingimport timeclass myThread(threading.Thread):  # 继承父类threading.Thread   def __init__(self, threadID, name, counter):      threading.Thread.__init__(self)      self.threadID = threadID      self.name = name      self.counter = counter   def run(self):  # 把要执行的代码写到run函数里面 线程在创建后会直接运行run函数      print(&quot;Starting &quot; + self.name)      print_time(self.name, self.counter, 5)      print(&quot;Exiting &quot; + self.name)def print_time(threadName, delay, counter):   while counter:      time.sleep(delay)      print(&quot;%s process at: %s&quot; % (threadName, time.ctime(time.time())))      counter -= 1# 创建新线程thread1 = myThread(1, &quot;Thread-1&quot;, 1)thread2 = myThread(2, &quot;Thread-2&quot;, 2)# 开启线程thread1.start()thread2.start()# 等待线程结束thread1.join()thread2.join()print(&quot;Exiting Main Thread&quot;)\n\n通过以上案例可以知道，thread1和thread2执行顺序是乱序的。要使之有序，需要进行线程同步\n3  线程间同步如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。\n使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。\n需要注意的是，Python有一个GIL（Global Interpreter Lock）机制，任何线程在运行之前必须获取这个全局锁才能执行，每当执行完100条字节码，全局锁才会释放，切换到其他线程执行。\n多线程实现同步有四种方式：\n锁机制，信号量，条件判断和同步队列。\n下面主要关注两种同步机制：锁机制和同步队列。\n（1）锁机制\n  threading的Lock类，用该类的acquire函数进行加锁，用realease函数进行解锁\nimport threadingimport timeclass myThread(threading.Thread):   def __init__(self, threadID, name, counter):      threading.Thread.__init__(self)      self.threadID = threadID      self.name = name      self.counter = counter   def run(self):      print(&quot;Starting &quot; + self.name)      # 获得锁，成功获得锁定后返回True      # 可选的timeout参数不填时将一直阻塞直到获得锁定      # 否则超时后将返回False      threadLock.acquire()      print_time(self.name, self.counter, 5)      # 释放锁      threadLock.release()def print_time(threadName, delay, counter):   while counter:      time.sleep(delay)      print(&quot;%s: %s&quot; % (threadName, time.ctime(time.time())))      counter -= 1    threadLock = threading.Lock()threads = []# 创建新线程thread1 = myThread(1, &quot;Thread-1&quot;, 1)thread2 = myThread(2, &quot;Thread-2&quot;, 2)# 开启新线程thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads:   t.join()print(&quot;Exiting Main Thread&quot;)\n\n​    \n(2) 线程同步队列queue\npython2.x中提供的Queue， Python3.x中提供的是queue\n见import  queue.\nPython的queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步。\nqueue模块中的常用方法:\n\nqueue.qsize() 返回队列的大小\nqueue.empty() 如果队列为空，返回True,反之False\nqueue.full() 如果队列满了，返回True,反之False\nqueue.full 与 maxsize 大小对应\nqueue.get([block[, timeout]])获取队列，timeout等待时间\nqueue.get_nowait() 相当Queue.get(False)\nqueue.put(item) 写入队列，timeout等待时间\nqueue.put_nowait(item) 相当Queue.put(item, False)\nqueue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号\nqueue.join() 实际上意味着等到队列为空，再执行别的操作\n\n案例1：\nimport queueimport threadingimport timeexitFlag = 0class myThread(threading.Thread):   def __init__(self, threadID, name, q):      threading.Thread.__init__(self)      self.threadID = threadID      self.name = name      self.q = q   def run(self):      print(&quot;Starting &quot; + self.name)      process_data(self.name, self.q)      print(&quot;Exiting &quot; + self.name)def process_data(threadName, q):   while not exitFlag:      queueLock.acquire()      if not workQueue.empty():         data = q.get()         queueLock.release()         print(&quot;%s processing %s&quot; % (threadName, data))      else:         queueLock.release()      time.sleep(1)threadList = [&quot;Thread-1&quot;, &quot;Thread-2&quot;, &quot;Thread-3&quot;]nameList = [&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;]queueLock = threading.Lock()workQueue = queue.Queue(10)threads = []threadID = 1# 创建新线程for tName in threadList:   thread = myThread(threadID, tName, workQueue)   thread.start()   threads.append(thread)   threadID += 1# 填充队列queueLock.acquire()for word in nameList:   workQueue.put(word)queueLock.release()# 等待队列清空while not workQueue.empty():   pass# 通知线程是时候退出exitFlag = 1# 等待所有线程完成for t in threads:   t.join()print(&quot;Exiting Main Thread&quot;)\n\n\n\n案例2：\nimport timeimport threadingimport queueclass Worker(threading.Thread):    def __init__(self, name, queue):        threading.Thread.__init__(self)        self.queue = queue        self.start()    #执行run()    def run(self):        #循环，保证接着跑下一个任务        while True:            # 队列为空则退出线程            if self.queue.empty():                break            # 获取一个队列数据            foo = self.queue.get()            # 延时1S模拟你要做的事情            time.sleep(1)            # 打印            print(self.getName() + &quot; process &quot; + str(foo))            # 任务完成            self.queue.task_done()# 队列queue = queue.Queue()# 加入100个任务队列for i in range(100):    queue.put(i)# 开10个线程for i in range(10):    threadName = &#x27;Thread&#x27; + str(i)    Worker(threadName, queue)# 所有线程执行完毕后关闭queue.join()\n\n\n\n4 线程池4.1 传统多线程问题？传统多线程方案会使用“即时创建， 即时销毁”的策略。尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数极其频繁，那么服务器将处于不停的创建线程，销毁线程的状态。\n一个线程的运行时间可以分为3部分：线程的启动时间、线程体的运行时间和线程的销毁时间。在多线程处理的情景中，如果线程不能被重用，就意味着每次创建都需要经过启动、销毁和运行3个过程。这必然会增加系统相应的时间，降低了效率。\n有没有一种高效的解决方案呢？ —— 线程池\n4.2 线程池基本原理：我们把任务放进队列中去，然后开N个线程，每个线程都去队列中取一个任务，执行完了之后告诉系统说我执行完了，然后接着去队列中取下一个任务，直至队列中所有任务取空，退出线程。\n使用线程池：      由于线程预先被创建并放入线程池中，同时处理完当前任务之后并不销毁而是被安排处理下一个任务，因此能够避免多次创建线程，从而节省线程创建和销毁的开销，能带来更好的性能和系统稳定性。\n线程池要设置为多少？\n服务器CPU核数有限，能够同时并发的线程数有限，并不是开得越多越好，以及线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低\n线程执行过程中，计算时间分为两部分：\n\nCPU计算，占用CPU\n不需要CPU计算，不占用CPU，等待IO返回，比如recv(), accept(), sleep()等操作，具体操作就是比如访问cache、RPC调用下游service、访问DB，等需要网络调用的操作\n\n那么如果计算时间占50%， 等待时间50%，那么为了利用率达到最高，可以开2个线程：假如工作时间是2秒， CPU计算完1秒后，线程等待IO的时候需要1秒，此时CPU空闲了，这时就可以切换到另外一个线程，让CPU工作1秒后，线程等待IO需要1秒，此时CPU又可以切回去，第一个线程这时刚好完成了1秒的IO等待，可以让CPU继续工作，就这样循环的在两个线程之前切换操作。\n那么如果计算时间占20%， 等待时间80%，那么为了利用率达到最高，可以开5个线程：可以想象成完成任务需要5秒，CPU占用1秒，等待时间4秒，CPU在线程等待时，可以同时再激活4个线程，这样就把CPU和IO等待时间，最大化的重叠起来\n抽象一下，计算线程数设置的公式就是：N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)&#x2F;x，能让CPU的利用率最大化。由于有GIL的影响，python只能使用到1个核，所以这里设置N&#x3D;1\nimport queueimport threadingimport time# 声明线程池管理类class WorkManager(object):   def __init__(self, work_num=1000, thread_num=2):      self.work_queue = queue.Queue()  # 任务队列      self.threads = []  # 线程池      self.__init_work_queue(work_num)  # 初始化任务队列，添加任务      self.__init_thread_pool(thread_num) # 初始化线程池，创建线程   &quot;&quot;&quot;      初始化线程池   &quot;&quot;&quot;   def __init_thread_pool(self, thread_num):      for i in range(thread_num):         # 创建工作线程(线程池中的对象)         self.threads.append(Work(self.work_queue))   &quot;&quot;&quot;      初始化工作队列   &quot;&quot;&quot;   def __init_work_queue(self, jobs_num):      for i in range(jobs_num):         self.add_job(do_job, i)   &quot;&quot;&quot;      添加一项工作入队   &quot;&quot;&quot;   def add_job(self, func, *args):      self.work_queue.put((func, list(args)))  # 任务入队，Queue内部实现了同步机制   &quot;&quot;&quot;      等待所有线程运行完毕   &quot;&quot;&quot;   def wait_allcomplete(self):      for item in self.threads:         if item.isAlive(): item.join()class Work(threading.Thread):   def __init__(self, work_queue):      threading.Thread.__init__(self)      self.work_queue = work_queue      self.start()   def run(self):      # 死循环，从而让创建的线程在一定条件下关闭退出      while True:         try:            do, args = self.work_queue.get(block=False)  # 任务异步出队，Queue内部实现了同步机制            do(args)            self.work_queue.task_done()  # 通知系统任务完成         except:            break# 具体要做的任务def do_job(args):   time.sleep(0.1)  # 模拟处理时间   print(threading.current_thread())   print(list(args))if __name__ == &#x27;__main__&#x27;:   start = time.time()   work_manager = WorkManager(100, 10)  # 或者work_manager =  WorkManager(10000, 20)   work_manager.wait_allcomplete()   end = time.time()   print(&quot;cost all time: %s&quot; % (end - start))\n\n\n\n5  协程 在python  GIL之下，同一时刻只能有一个线程在运行，那么对于CPU计算密集的程序来说，线程之间的切换开销就成了拖累，而以I&#x2F;O为瓶颈的程序正是协程所擅长的： \nPython中的协程经历了很长的一段发展历程。其大概经历了如下三个阶段：\n\n\n最初的生成器变形yield&#x2F;send\n引入@asyncio.coroutine和yield from\n在最近的Python3.5版本中引入async&#x2F;await关键字\n\n\n5.1 从yield说起  先看一段普通的计算斐波那契续列的代码\nnewlist =[1]def newfib(n):    a=0    b=1    while n-1:        a,b=b,a+b        n =n-1        newlist.append(b)    return newlistprint(newfib(10))# [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n\n 如果我们仅仅是需要拿到斐波那契序列的第n位，或者仅仅是希望依此产生斐波那契序列，那么上面这种传统方式就会比较耗费内存。\n\n这时，yield就派上用场了。\ndef fib(n):   a = 0   b = 1   while n:      yield b      a, b = b, a + b      n-=1for fib_res in fib(20):   print(fib_res)\n\n 当一个函数中包含yield语句时，python会自动将其识别为一个生成器。这时fib(20)并不会真正调用函数体，而是以函数体生成了一个生成器对象实例。\n yield在这里可以保留fib函数的计算现场，暂停fib的计算并将b返回。而将fib放入for…in循环中时，每次循环都会调用next(fib(20))，唤醒生成器，执行到下一个yield语句处，直到抛出StopIteration异常。此异常会被for循环捕获，导致跳出循环。\n5.2 Send来了 从上面的程序中可以看到，目前只有数据从fib(20)中通过yield流向外面的for循环；如果可以向fib(20)发送数据，那不是就可以在Python中实现协程了嘛。\n于是，Python中的生成器有了send函数，yield表达式也拥有了返回值。\n我们用这个特性，模拟一个慢速斐波那契数列的计算：\nimport time,randomdef stupid_fib(n):   a = 0   b = 1   while n:      sleep_cnt = yield b      print(&#x27;let me think &#123;0&#125; secs&#x27;.format(sleep_cnt))      time.sleep(sleep_cnt)      a, b = b, a + b      n-= 1print(&#x27;-&#x27; * 10 + &#x27;test yield send&#x27; + &#x27;-&#x27; * 10)N = 20sfib = stupid_fib(N)fib_res = next(sfib)while True:   print(fib_res)   try:      fib_res = sfib.send(random.uniform(0, 0.5))   except StopIteration:      break\n\n\n\n6. python 进行并发编程 在Python 2的时代，高性能的网络编程主要是使用Twisted、Tornado和Gevent这三个库，但是它们的异步代码相互之间既不兼容也不能移植。\n asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。\n asyncio的编程模型就是一个消息循环。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。\n Python的在3.4中引入了协程的概念，可是这个还是以生成器对象为基础。\n Python 3.5添加了async和await这两个关键字，分别用来替换asyncio.coroutine和yield from。\n python3.5则确定了协程的语法。下面将简单介绍asyncio的使用。实现协程的不仅仅是asyncio，tornado和gevent， vloop都实现了类似的功能。\n6.1  使用asyncio用asyncio实现Hello world代码如下：\nimport asyncio@asyncio.coroutinedef hello():    print(&quot;Hello world!&quot;)    # 异步调用asyncio.sleep(1):    r = yield from asyncio.sleep(1)    print(&quot;Hello again!&quot;)# 获取EventLoop:loop = asyncio.get_event_loop()# 执行coroutineloop.run_until_complete(hello())loop.close()\n\n @asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。 hello()会首先打印出Hello world!，然后，yield from语法可以让我们方便地调用另一个generator。由于asyncio.sleep()也是一个coroutine，所以线程不会等待asyncio.sleep()，而是直接中断并执行下一个消息循环。当asyncio.sleep()返回时，线程就可以从yield from拿到返回值（此处是None），然后接着执行下一行语句。\n   把asyncio.sleep(1)看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。\n我们用Task封装两个coroutine试试：\nimport threadingimport asyncio@asyncio.coroutinedef hello():    print(&#x27;Hello world! (%s)&#x27; % threading.currentThread())    yield from asyncio.sleep(1)    print(&#x27;Hello again! (%s)&#x27; % threading.currentThread())loop = asyncio.get_event_loop()tasks = [hello(), hello()]loop.run_until_complete(asyncio.wait(tasks))loop.close()\n\n观察执行过程：\nHello world! (&lt;_MainThread(MainThread, started 140735195337472)&gt;)Hello world! (&lt;_MainThread(MainThread, started 140735195337472)&gt;)(暂停约1秒)Hello again! (&lt;_MainThread(MainThread, started 140735195337472)&gt;)Hello again! (&lt;_MainThread(MainThread, started 140735195337472)&gt;)\n\n由打印的当前线程名称可以看出，两个coroutine是由同一个线程并发执行的。\n如果把asyncio.sleep()换成真正的IO操作，则多个coroutine就可以由一个线程并发执行。\nasyncio案例实战\n我们用asyncio的异步网络连接来获取sina、sohu和163的网站首页：\nasync_wget.py\nimport asyncio@asyncio.coroutinedef wget(host):    print(&#x27;wget %s...&#x27; % host)    connect = asyncio.open_connection(host, 80)    reader, writer = yield from connect    header = &#x27;GET / HTTP/1.0\\r\\nHost: %s\\r\\n\\r\\n&#x27; % host    writer.write(header.encode(&#x27;utf-8&#x27;))    yield from writer.drain()    while True:        line = yield from reader.readline()        if line == b&#x27;\\r\\n&#x27;:            break        print(&#x27;%s header &gt; %s&#x27; % (host, line.decode(&#x27;utf-8&#x27;).rstrip()))    # Ignore the body, close the socket    writer.close()loop = asyncio.get_event_loop()tasks = [wget(host) for host in [&#x27;www.sina.com.cn&#x27;, &#x27;www.sohu.com&#x27;, &#x27;www.163.com&#x27;]]loop.run_until_complete(asyncio.wait(tasks))loop.close()\n\n结果信息如下：\nwget www.sohu.com...wget www.sina.com.cn...wget www.163.com...(等待一段时间)(打印出sohu的header)www.sohu.com header &gt; HTTP/1.1 200 OKwww.sohu.com header &gt; Content-Type: text/html...(打印出sina的header)www.sina.com.cn header &gt; HTTP/1.1 200 OKwww.sina.com.cn header &gt; Date: Wed, 20 May 2015 04:56:33 GMT...(打印出163的header)www.163.com header &gt; HTTP/1.0 302 Moved Temporarilywww.163.com header &gt; Server: Cdn Cache Server V2.0...\n\n可见3个连接由一个线程通过coroutine并发完成。\n6.2 使用async&#x2F;awaitimport asyncioimport reasync def browser(host, port=80):    # 连接host    reader, writer = await asyncio.open_connection(host, port)    print(host, port, &#x27;连接成功!&#x27;)    # 发起 / 主页请求(HTTP协议)    # 发送请求头必须是两个空行    index_get = &#x27;GET &#123;&#125; HTTP/1.1\\r\\nHost:&#123;&#125;\\r\\n\\r\\n&#x27;.format(&#x27;/&#x27;, host)    writer.write(index_get.encode())    await writer.drain()  # 等待向连接写完数据（请求发送完成）    # 开始读取响应的数据报头    while True:        line = await reader.readline()  # 等待读取响应数据        if line == b&#x27;\\r\\n&#x27;:            break        print(host, &#x27;&lt;header&gt;&#x27;, line)    # 读取响应的数据body    body = await reader.read()    print(encoding)    print(host, &#x27;&lt;content&gt;&#x27;, body)if __name__ == &#x27;__main__&#x27;:    loop = asyncio.get_event_loop()    tasks = [browser(host) for host in [&#x27;www.dushu.com&#x27;, &#x27;www.sina.com.cn&#x27;, &#x27;www.baidu.com&#x27;]]    loop.run_until_complete(asyncio.wait(tasks))    loop.close()    print(&#x27;---over---&#x27;)\n\n\n\n7 小结asyncio提供了完善的异步IO支持；\n异步操作需要在coroutine中通过yield from完成；\n多个coroutine可以封装成一组Task然后并发执行。\n","categories":["技术","Python"],"tags":["Python","code","多线程"]},{"title":"python多进程，多线程，协程","url":"/posts/2019/03/21/61141/","content":"多进程与多线程的对比多任务的实现原理一般地, 设计Master-Worker模式, Master负责分配任务, Worker负责执行任务, 所以在多任务环境下, 一般是由一个Master, 多个Worker.\n多进程主进程就是Master, 其他进程就是Worker\n\n优点:稳定性好:一个子进程崩溃了, 不会影响主进程和其他子进程. 当然的, 主进程挂了后, 所有进程就全挂了, 但是Master进程只负责分配任务, 挂掉的概率很低.\n\n缺点: \n\n创建进程的代价大:在Unix&#x2F;Linux系统下, 用fork调用还行, 在windows下创建进程开销巨大.\n\n操作系统能同时运行的进程数也是有限的:在内存和CPU的限制下, 如果有几千个进程同时运行, 操作系统连调度都成问题.\n\n\n\n\n多线程主线程就是Master, 其他线程就是Worker\n\n优点:\n多线程模式模式通常比多进程快一点, 但是也快的不多\n在windows下, 多线程的效率比多进程要高\n\n缺点:\n任何一个线程挂掉都可能直接造成整个进程崩溃(所有线程共享进程的内存. 在windows上, 如果一个线程执行的代码除出了问题, 可以进程看到这样的提示:”该程序执行了非法操作, 即将关闭”, 其实往往是某个线程出了问题, 但是操作系统会强制结束整个进程)\n\n\n计算密集型 与 IO密集型\n计算密集型:  适合多进程\n要进行大量的计算, 消耗CPU资源, 比如计算圆周率&#x2F;对视频进行高清解码等, 全靠CPU的运算能力. 这种计算密集型任务虽然也可以用于多任务完成, 但是任务越多, 花在任务切换的时间也越多, CPU执行任务的效率就会越低. 因此, 要最高效地利用CPU, 计算密集型任务同时进行的数量应该等于CPU的核心数\n\nIO密集型:  适合多线程\n设计到网络&#x2F;磁盘IO的任务都是IO密集型任务, 这类任务特点是CPU消耗很少, 任务的大部分时间都在等待IO操作完成(因为IO的速度远远低于CPU和内存的速度). 对于IO密集型任务, 任务越多, CPU效率越高, 但也有一个限度. 常见的大部分任务都是IO密集型任务, 比如Web任务\n\n\n\n进程对于操作系统而言，一个任务就是一个进程。进程是系统中程序执行和资源分配的基本单位。每个进程都有自己的数据段、代码段、和堆栈段。\n一个进程的举例from time import sleepdef run():    while True:        print(&quot;this is a  run function&quot;)        sleep(1.2)if __name__ == &quot;__main__&quot;:    while True:        print(&quot;this is mian function&quot;)        sleep(1)    # 不会执行到run方法，只有上面的while循环结束才可以执行    run()\n\n\n\n启动多个进程实现多任务现代操作系统(Windows、Mac OS X、Linux、UNIX等)都支持“多任务”\n什么叫多任务？？？操作系统同时可以运行多个任务\n单核CPU实现多任务原理：操作系统轮流让各个任务交替执行，QQ执行2us，切换到微信，在执行2us，再切换到微博，执行2us……。表面是看，每个任务反复执行下去，但是CPU调度执行速度太快了，导致我们感觉就行所有任务都在同时执行一样\n多核CPU实现多任务原理：真正的秉性执行多任务只能在多核CPU上实现，但是由于任务数量远远多于CPU的核心数量，所以，操作西永也会自动把很多任务轮流调度到每个核心上执行并发：看上去一起执行，任务书多于CPU核心数并行：真正一起执行，任务数小于等于CPU核心数\n实现多任务的方式：1、多进程模式2、多线程模式3、协程模式4、多进程+多线程模式\n&#x27;&#x27;&#x27;multiprocessing 库跨平台版本的多进程模块，提供了一个Process类来代表一个进程对象&#x27;&#x27;&#x27;from multiprocessing import Processfrom time import sleepimport os#子进程需要执行的买吗def run(str):    while True:        # os.getpid()获取当前进程id号        # os.getppid()获取当前进程的父进程id号        print(&quot;str %s, current process %s,  parrent process %s&quot;%(str, os.getpid(), os.getppid()))        sleep(1)if __name__ == &quot;__main__&quot;:    print(&quot;主(父)进程启动-%s&quot;%(os.getpid()))    #创建子进程    #target说明进程执行的任务    p = Process(target=run, args=(&quot;first&quot;,))    #启动进程    p.start()    # sleep(1)    while True:        print(&quot;main process : while True&quot;)        sleep(1)        # 主(父)进程启动-21240# main process : while True# main process : while True# str first, current process 17920,  parrent process 21240# main process : while True# str first, current process 17920,  parrent process 21240# main process : while True# str first, current process 17920,  parrent process 21240# ...\n\n\n\n使用 .join() 等待子进程结束后再执行父进程from multiprocessing import Processfrom time import sleepimport osdef run(string_):    print(&quot;子进程启动&quot;)    sleep(string_)    print(&quot;子进程结束&quot;)if __name__ == &quot;__main__&quot;:    print(&quot;父进程启动&quot;)    p = Process(target=run, args=(&quot;nice&quot;,))    p.start()    #父进程的结束不能影响子进程，让父进程等待子进程结束再执行父进程    p.join()    print(&quot;父进程结束&quot;)# 父进程启动# 子进程启动# nice# 子进程结束# 父进程结束# 如果不加 p.join() 的运行结果:# 父进程启动# 父进程结束# 子进程启动# nice# 子进程结束\n\n\n\n全局变量在多个进程中不能被共享from multiprocessing import Processnum = 100def run():    print(&quot;子进程开始&quot;)    global num # num = 100    num += 1    print(num)    print(&quot;子进程结束,num=&#123;0&#125;&quot;.format(num))if __name__ == &quot;__main__&quot;:    print(&quot;父进程开始&quot;)    p = Process(target=run)    p.start()    p.join()    # 在子进程中修改全局变量对父进程中的全局变量没有影响    # 在创建子进程时对全局变量做了一个备份，父进程中的与子进程中的num是完全不同的两个变量    print(&quot;父进程结束,num=%d&quot;%num)    # 父进程开始# 子进程开始# 101# 子进程结束,num=101# 父进程结束,num=100\n\n\n\n使用进程池 启动多个子进程from multiprocessing import Poolimport os, time, randomdef run(name):    print(&quot;子进程%d启动--%s&quot; % (name, os.getpid()))    start = time.time()    time.sleep(random.choice([1,2,3]))    end = time.time()    print(&quot;子进程%d结束--%s--耗时%.2f&quot; % (name, os.getpid(), end-start))if __name__ == &quot;__main__&quot;:    print(&quot;父进程启动&quot;)    # 使用进程池 Pool: 创建多个进程    # 表示可以同时执行的进程数量    # Pool默认大小是CPU核心数    # pp = Pool(1)        # 一个进程启动,结束后再启动下一个    pp = Pool(2)   \t\t\t\t# 两个进程启动,结束后再启动下两个    for i in range(6):        #创建进程，放入进程池统一管理        pp.apply_async(run,args=(i,))    # pp.apply_async(run_new)  # 也可以增加其他进程    #在调用join之前必须先调用close,调用close之后就不能再继续添加新的进程了    pp.close()    #进程池对象调用join，会等待进程池中所有的子进程结束完毕再去执行父进程    pp.join()    print(&quot;父进程结束&quot;)\n\n举例: 多进程来拷贝文件\nimport os, timefrom multiprocessing import Pool# 实现文件的拷贝def copyFile(rPath, wPath):    fr = open(rPath, &quot;rb&quot;)    fw = open(wPath, &quot;wb&quot;)    context = fr.read()    fw.write(context)    fr.close()    fw.close()path = r&quot;D:\\file&quot;toPath =r&quot;D:\\toFile&quot;if __name__ == &quot;__main__&quot;:    # 读取path下的都有的文件    filesList = os.listdir(path)    start = time.time()    pp = Pool(4)    for fileName in filesList:        pp.apply_async(copyFile, args=(os.path.join(path,fileName), os.path.join(toPath,fileName)))    pp.close()    pp.join()    end = time.time()    print(&quot;总耗时：%0.2f&quot; % (end-start))\n\n\n\n简单的进程间通信_Queuefrom multiprocessing import Process, Queueimport os, timedef write(q):    print(&quot;启动写子进程%s&quot; % (os.getpid()))    for chr in [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]:        q.put(chr)        time.sleep(1)    print(&quot;结束写子进程%s&quot; % (os.getpid()))def read(q):    print(&quot;启动读子进程%s&quot; % (os.getpid()))    while True:        value = q.get(True)        print(&quot;value = &quot; + value)    print(&quot;结束读子进程%s&quot; % (os.getpid()))  # 执行不到该行if __name__ == &quot;__main__&quot;:    #父进程创建队列，并传递给子进程    q = Queue()    pw = Process(target=write, args=(q,))    pr = Process(target=read, args=(q,))    pw.start()    pr.start()    pw.join()    #pr进程里是个死循环，无法等待其结束，只能强行结束    pr.terminate()    print(&quot;父进程结束&quot;)\n\n\n\n封装进程对象from multiprocessing import Processimport os, timeclass MyProcess(Process):      # 继承 Process 类    def __init__(self,name):        Process.__init__(self)        self.name = name    def run(self):        print(&quot;子进程(%s-%s)启动&quot; % (self.name, os.getpid()))        #子进程的功能        time.sleep(3)        print(&quot;子进程(%s-%s)结束&quot; % (self.name, os.getpid()))        myProcess = MyProcess(&quot;zyp&quot;)myProcess.run()# 子进程(zyp-13804)启动# 子进程(zyp-13804)结束      \n\n\n线程线程在一个进程的内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”叫做线程。\n线程通常叫做轻型的进程。线程是共享内存空间的并发执行的多任务，每一个线程都共享一个进程的资源,共享一个堆栈。\n线程是最小的执行单元，而进程由至少一个线程组成。如何调度进程和线程，完全由操作系统绝对，程序自己不能决定什么时候执行，执行多长时间。\n模块1、_thread模块       低级模块2、threading模块     高级模块，对_thread进行了封装\n启动一个线程import threading, timedef run(num):    print(&quot;子线程(%s)开始&quot; % (threading.current_thread().name))    # 实现线程的功能    time.sleep(2)    print(&quot;num:&quot;, num)    time.sleep(2)    print(&quot;子线程(%s)结束&quot; % (threading.current_thread().name))if __name__ == &quot;__main__&quot;:    # 任何进程默认就会启动一个线程，称为主线程，主线程可以启动新的子线程    # current_thread()：返回返回当前线程的实例    print(&quot;主线程(%s)启动&quot; % (threading.current_thread().name))    # 创建子线程                     线程的名称    t = threading.Thread(target=run, name=&quot;runThread&quot;, args=(1,))    t.start()    # 等待线程结束    t.join()    print(&quot;主线程(%s)结束&quot; % (threading.current_thread().name))\n\n\n\n线程间的共享数据多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在每个进程中，互不影响。多线程中，所有变量都由所有线程共享。所以，任何一个变量都可以被任意一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时修改一个变量，容易把内容改乱了。\nimport threadingnum = 0def run(n):    global num    for i in range(1000000):        num = num + n    #  15 = 9 + 6        num = num - n    #  9if __name__ == &quot;__main__&quot;:    iTimeStart = time.time()    t1 = threading.Thread(target=run, args=(6,))    t2 = threading.Thread(target=run, args=(9,))    t1.start()    t2.start()    t1.join()    t2.join()    print(&quot;num =&quot;,num)    iTimeEnd = time.time()    print(iTimeEnd - iTimeStart)   # 1.1113207340240479\n\n\n\n线程锁解决数据混乱import threadingimport time# 锁对象lock = threading.Lock()num = 0def run(n):    global num    for i in range(1000000):        # 锁 Lock 确保了这段代码只能由一个线程从头到尾的完整执行        # 阻止了多线程的并发执行，包含锁的某段代码实际上只能以单线程模式执行，所以效率大大滴降低了        # 由于可以存在多个锁，不同线程持有不同的锁，并试图获取其他的锁，可能造成死锁，导致多个线程挂起。只能靠操作系统强制终止        &#x27;&#x27;&#x27;        lock.acquire()        try:            num = num + n                num = num - n           finally:            #修改完一定要释放锁            lock.release()        &#x27;&#x27;&#x27;        #与上面代码功能相同，with lock可以自动上锁与解锁        with lock:            num = num + n            num = num - nif __name__ == &quot;__main__&quot;:    iTimeStart = time.time()    t1 = threading.Thread(target=run, args=(6,))    t2 = threading.Thread(target=run, args=(9,))    t1.start()    t2.start()    t1.join()    t2.join()    print(&quot;num =&quot;,num)    iTimeEnd = time.time()    print(iTimeEnd - iTimeStart)     # 6.983535051345825# 通过对比时间, 发现加锁后运行所需要的时间是 不加锁的近乎5倍以上!\n\n\n\n创建全局的ThreadLocal 对象创建一个全局的ThreadLocal对象每个线程有独立的存储空间每个线程对ThreadLocal对象都可以读写，但是互不影响\nimport threading# 创建全局ThreadLocal对象:local = threading.local()def process_student():    # 获取当前线程关联的student:    print(&#x27;local.student: %s , current_thread : %s&#x27; % (local.student, threading.current_thread().name))def process_thread(stu_name):    # 绑定ThreadLocal的student:    local.student = stu_name    process_student()t1 = threading.Thread(target= process_thread, args=(&#x27;Alice&#x27;,), name=&#x27;Thread-A&#x27;)t2 = threading.Thread(target= process_thread, args=(&#x27;Bob&#x27;,), name=&#x27;Thread-B&#x27;)t1.start()t2.start()t1.join()t2.join()# local.student: Alice , current_thread : Thread-A# local.student: Bob , current_thread : Thread-B&#x27;&#x27;&#x27;全局变量local就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把local看成全局变量，但每个属性如local.student都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。可以理解为全局变量local是一个dict，不但可以用local.student，还可以绑定其他变量，如local.teacher等等。应用:ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。&#x27;&#x27;&#x27;\n\n小结一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。\nimport threading, timelocal = threading.local()  # 创建一个全局的ThreadLocal对象num = 0  # 将线程中需要访问的变量绑定到全局ThreadLocal对象上def run(x, n):    x = x + n    x = x - n    return  xdef func(n):    #每个线程都有local.x，就是线程的局部变量    local.x = num\t\t\t\t\t\t\t # 在线程调用的函数中, 将访问的变量和ThreadLock绑定    for i in range(1000000):        run(local.x, n)    print(&quot;%s-  local.x =%d&quot;%(threading.current_thread().name, local.x))if __name__ == &quot;__main__&quot;:    iTimeStart = time.time()    t1 = threading.Thread(target=func, args=(6,))    t2 = threading.Thread(target=func, args=(9,))    t1.start()    t2.start()    t1.join()    t2.join()    print(&quot;num =&quot;,num)    iTimeEnd = time.time()    print(iTimeEnd - iTimeStart)   # 1.6630573272705078# 不仅不会导致数据混乱, 而且所用时间已经接近不加锁的时间.\n\n\n\n定时线程import threading, timedef run():    print(&quot;sunck is a good man&quot;)#延时执行线程t = threading.Timer(3, run)t.start()t1 = time.time()t.join()t2 =time.time()print(&quot;父线程结束&quot;)print(t2 - t1)\n\n\n\n线程通信import threading, timedef func():    #事件对象    event = threading.Event()    def run():        for i in range(5):            #阻塞，等待事件的触发            event.wait()            #重置            # event.clear()            print(&quot;sunck is a good man!!%d&quot;%i)    t = threading.Thread(target=run).start()    return evente = func()#触发事件for i in range(5):    time.sleep(2)    e.set()\n\n\n\n生产者与消费者import threading,queue,time,random#生产者def product(id, q):    while True:        num = random.randint(0, 10000)        q.put(num)        print(&quot;生产者%d生产了%d数据放入了队列&quot; % (id, num))        time.sleep(3)    #任务完成    q.task_done()#消费者def customer(id, q):    while True:        item = q.get()        if item is None:            break        print(&quot;消费者%d消费了%d数据&quot; % (id, item))        time.sleep(2)    # 任务完成    q.task_done()if __name__ == &quot;__main__&quot;:    # 消息队列    q = queue.Queue()    # 启动生产者    for i in range(4):        threading.Thread(target=product, args=(i,q)).start()    # 启动消费者    for i in range(3):        threading.Thread(target=customer, args=(i,q)).start()\n\n\n协程子程序&#x2F;函数：在所有语言中都是层级调用，比如A调用B，在B执行的过程中又可以调用C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。是通过栈实现的，一个线程就是执行一个子程序，子程序调用总是一个入口，一次返回，调用的顺序是明确的\n概述：看上去也是子程序，但执行过程中，在子程序的内部可中断，然后转而执行别的子程序，不是函数调用。\n协程举例# Python对协程的支持是通过generator实现的def run():    print(&#x27;start&#x27;)    print(1)    yield 10    print(2)    yield 20    print(3)    yield 30# 协程的最简单风格，控制函数的阶段执行，节约线程或者进程的切换# 返回值是一个生成器m = run()next(m)   # 1next(m)\t\t# 2next(m)\t\t# 3# print(next(m))\t\t# 1  10# print(next(m))\t\t# 2  20# print(next(m))\t\t# 3  30\n\n\n\n数据传输def run():    #空变量，存储的作用data始终为空    data = &quot;&quot;    print(0, data)    r = yield data  # 接受除了第二个send来的数据( 第一个send 的是None 来启动)    print(1, r, data)    r = yield &quot;aa&quot;    print(2, r, data)    r = yield &quot;bb&quot;    print(3, r, data)    r = yield &quot;cc&quot;m = run()#启动m, 首先需要使用 send(None)m.send(None)print(&quot;-----------&quot;)print(1,m.send(&quot;a&quot;))print(&quot;-----------&quot;)print(2,m.send(&quot;b&quot;))print(&quot;-----------&quot;)print(3,m.send(&quot;c&quot;))\n\n\n\n生产者与消费者def product(c):    c.send(None)    for i in range(5):        print(&quot;生产者产生数据%d&quot;%i)        r = c.send(str(i))        print(&quot;消费者消费了数据%s&quot;%r)    c.close()def customer():    data = &quot;&quot;    while True:        n = yield data        if not n:            return        print(&quot;消费者消费了%s&quot;%n)        data = &quot;200&quot;c = customer()product(c)\n","categories":["技术","Python"],"tags":["Python"]},{"title":"必不可少的Pycharm技能：极大提升效率的快捷键","url":"/posts/2019/08/03/6359/","content":"1. 常用快捷键查看代码大纲：Ctrl + F12\n查看脚本中的结构图：Ctrl + Shift + Alt + U   对于刚开始接触学习一个新框架很有用\n类继承结构、方法调用层次：\n\n查看类继承关系：Ctrl + H \n查看调用关系：Ctrl + Shift + H\n\n例：类的继承关系\n例：函数方法的调用关系\n\n新建一个python脚本：Alt + Insert\n复制当前行：Ctrl + C\n复制当前行到下一行：Ctrl + D\n剪切板：查看多次复制的内容：Ctrl + Shift +V\n剪切当前行：Ctrl + X\n删除当前行：Ctrl + Y\n代码折叠&#x2F;展开：Ctrl + - /Ctrl + +\n快速定位到错误代码: F2\n\n将一行代码上下移动：Ctrl + Shift + 上下键\n定位到具体某一行：Crtl + G\n定位到最后一次编辑的位置：Ctrl + Shift + Backspace\n查找：\n\nSearch Everywhere: Double Shift\nFind in current file：Ctrl + F\nFind in path：Ctrl + Shift + F\nFind in class：Ctrl + N\nFind file with filename：Ctrl +Shift +N\n\n查看函数、类、方法的定义(源码)：Ctrl + B 或 Ctrl + 单击\n万能代码修复、补全：Alt + Enter\n显示可用的代码模板：Ctrl + J\n整理格式化代码：Ctrl + Alt + L\n提交代码：\n\ncommit：Ctrl + K\npush：Ctrl + Shift +K\n\n退出所有快捷键调出的界面：Esc\n\nAlt + 1/2/3…. 打开界面的一些边框栏比如查看所有的书签 Favorites：Alt  + 2\nfind action 查找动作键：Ctrl + Shift + A    \nhelp -&gt; plugins添加&#x2F;安装插件：Ctrl + Shift + A  -&gt; plugins\nrecent files 最近使用的文件：Ctrl+E\nbookmark 书签添加：F11，Ctrl+ F11 选择num 添加书签num\nnavigate (以下快捷键按两下可以展示出非当前文件)\n\n查找类：Ctrl+N\n查找文件名：Ctrl + Shift + N\n查找符号：Ctrl + Shift + Alt + N\n\n光标移至下一个单词末尾（move caret to next word）：Ctrl + 左右键\n选中下一个单词或多个单词：Ctrl + Shift + 左右键\n大小写切换：光标移至所要切换的单词处，Ctrl + Shift + U\n选择所有上下行的相似处（select all occurrences ）：Ctrl + Alt + Shift + J\n\n2. 模板（live templates）自定义模板：比如创建一个函数模板时，以后只要敲def后直接输入函数名和函数主体了，经常使用的也有创建类。\n\n3. postfixpycharm提供的有 if, ifn, ifnn, main, not, par, print, return, while.\n\n4. Alt+Enter\n对未创建的函数进行自动创建；\na = 1  # step1：先定义一个变量adef func(a):   # 这是step2后自动创建的    passfunc(a)  # step2：写一个func(a), 然后发现没有定义func函数，于是在func位置按Alt+Enter，pycharm会在这行func(a)的上面自动创建一个func函数\n\n导包\n\n不知道干嘛时，在代码上按下Alt+Enter，会有相关提示操作，有惊喜。\n# 例如我定义了一个字符串b，如果后期优化代码时需要给提示该b为字符串b = &quot;bb&quot;   # Alt+Enterb: str = &quot;bb&quot;  # Alt+Enter后的结果\n\n\n5. 重构（refactor）\n重构变量：Shift + F6\n\n重构函数名：Ctrl+F6；如果需要添加入参，可以直接添加后Alt+Enter\n\n抽取\n\n抽取变量：Ctrl + Alt + V\n有时候代码中反复使用某个长字符串或者其他，需要简化为更易读易理解的变量。\n# 抽取前def refactor_test():    print(&quot;refactor&quot;)    print(&quot;refactor&quot;)    print(&quot;refactor&quot;)    print(&quot;refactor&quot;)    # 抽取后def refactor_test():    test_factor = &quot;refactor&quot;    print(test_factor)    print(test_factor)    print(test_factor)    print(test_factor)# 在非函数体中同样适用\n\n抽取静态变量：Ctrl + Alt + C\n# 抽取前def refactor_test():    print(&quot;refactor&quot;)    print(&quot;refactor&quot;)    print(&quot;refactor&quot;)    print(&quot;refactor&quot;)# 抽取后REFACTOR = &quot;refactor&quot;def refactor_test():    print(REFACTOR)    print(REFACTOR)    print(REFACTOR)    print(REFACTOR)\n\n抽取成员变量：Ctrl + Alt + F\n# 抽取前class TestRefactor(object):    def test_factor(self):        print(&quot;test_factor&quot;)        print(&quot;test_factor&quot;)        print(&quot;test_factor&quot;)        print(&quot;test_factor&quot;)# 抽取后class TestRefactor(object):    def test_factor(self):        self.test_factor = &quot;test_factor&quot;        print(self.test_factor)        print(self.test_factor)        print(self.test_factor)        print(self.test_factor)\t\n\n抽取方法参数：Ctrl + Alt + P\n有时候函数内部代码复杂，为了使得逻辑和数据分离开。\n# 抽取修改前class TestRefactor():    origin_name = &quot;origin&quot;    def test_factor(self, add_name):        refactor_name = self.origin_name + add_name        return refactor_name    def get_refactor(self):        return self.test_factor(&quot;myname&quot;)# 抽取修改后class TestRefactor():    origin_name = &quot;origin&quot;    def test_factor(self, add_name, origin_name):        refactor_name = origin_name + add_name        return refactor_name    def get_refactor(self):        return self.test_factor(&quot;myname&quot;,origin_name=self.origin_name)\n\n抽取函数：Ctrl + Alt + M\n有时候一个函数内部逻辑复杂，业务较多，可以将部分分开抽取出来。\n# 抽取前def test_refactor():    print(&quot;step1 get something&quot;)    print(&quot;step1 get something&quot;)    print(&quot;step2 put something&quot;)    print(&quot;step2 put something&quot;)    print(&quot;step3 check something&quot;)    print(&quot;step3 check something&quot;)    # 抽取后def test_refactor():    get_something()    put_something()    check_something()def check_something():    print(&quot;step3 check something&quot;)    print(&quot;step3 check something&quot;)def put_something():    print(&quot;step2 put something&quot;)    print(&quot;step2 put something&quot;)def get_something():    print(&quot;step1 get something&quot;)    print(&quot;step1 get something&quot;)\n\n\n\n\n6. Debug 快捷键添加&#x2F;删除断点（toggle line breakpoint）：Ctrl + F8\ndebug：Shift + F9\n禁止所有断点：mute breakpoint，一般后续配合着F9\n查看所有断点：Ctrl + Shift + F8\n条件断点：在当前断点行按住 Ctrl + Shift + F8\nstep over（F8）：在单步执行时，在函数内遇到子函数时不会进入子函数内单步执行，而是将子函数整个执行完再停止，也就是把子函数整个作为一步。在不存在子函数的情况下是和step into效果一样的。简单的说就是，程序代码越过子函数，但子函数会执行，且不进入。\nstep into（F7）：在单步执行时，遇到子函数就进入并且继续单步执行，有的会跳到源代码里面去执行。\nstep into my code（Alt + Shift + F7）：在单步执行时，遇到子函数就进入并且继续单步执行，不会进入到源码中。\nstep out（Shift + F8）：假如进入了一个函数体中，跳出当前函数体内，返回到调用此函数的地方。\nrun to cursor（Alt + F9）: 如果需要略过中间一些代码块，跳转到光标点击的所在行。\nResume program(F9)：继续恢复程序，直接运行到下一断点处，若后面没有断点了就运行所有后结束。\nSetValue（F2）:在调试窗口可以点击某变量按F2改变当前的值来进行调试。\nEvaluate Expression(Alt + F8)：打开强大的计算表达式窗口。\n以上就是最常用的功能，一般操作步骤就是，设置好断点，debug运行，然后 F8 单步调试，遇到想进入的函数 F7 进去，想出来在 shift + F8，跳过不想看的地方，直接设置下一个断点，然后 F9 过去\n\n7. Git 集成寻找修改轨迹\n\nCtrl +Shift +A：annotate 查询\n撤销某处（一般在版本控制基础上）的修改：Ctrl + Alt + Z\n撤销文件所有修改（Revert Changes）：在该文件中没有改动处按下Ctrl + Alt + Z\nlocal history：当项目没有版本控制时用比较方便，可以put label\n\n\n学习来源之一：https://www.imooc.com/video/16211\n","categories":["生产力","工具"],"tags":["Pycharm"]},{"title":"截取bin文件内容，指定位置和长度","url":"/posts/2019/01/19/27577/","content":"方法一:\nimport osdef cutBinFile(strFile, iStart=0, iLength=None):    if iLength is None:        iLength = os.path.getsize(strFile)    if not os.path.exists(strFile):        print(&quot;%s is not exist&quot;%strFile)        return False    with open(strFile, &quot;rb&quot;) as  f1:        f1.seek(iStart, 0)         # 0 表示从文件开头开始算起,  第一个参数表示定位到该位置        strContent = f1.read(iLength)   # 读取 iLength 这么多的内容        strNewFile = strFile + &quot;.bin&quot;      # 给新文件命名, 后缀自己决定        with open(strNewFile, &quot;wb&quot;) as f2:            f2.write(strContent)    return True\n\n方法二:python内置了文件处理的方法\ntruncate() 方法用于截断文件，如果指定了可选参数 size，则表示截断文件为 size 个字符。 如果没有指定 size，则从当前位置起截断；截断之后 size 后面的所有字符被删除。使用方法:\nfileObject.truncate( [ size ])\ntruncate用法点击此链接\ndef cutBinFile2(strFile, iStart=0, iLength=None):    if iLength is None:        iLength = os.path.getsize(strFile)    if  not os.path.exists(strFile):        print(&quot;%s is not exist&quot;%strFile)        return False    with open(strFile, &quot;rb+&quot;) as  f1:        f1.seek(iStart, 0)        f1.truncate(iLength)        strContent = f1.read()        strNewFile = strFile + &quot;new.bin&quot;        with open(strNewFile, &quot;wb&quot;) as f2:            f2.write(strContent)    return True\n","categories":["技术","Python"],"tags":["Python","code"]},{"title":"python多进程原理及其实现","url":"/posts/2019/02/16/36785/","content":"1  进程的基本概念什么是进程？\n进程就是一个程序在一个数据集上的一次动态执行过程。进程一般由程序、数据集、进程控制块三部分组成。我们编写的程序用来描述进程要完成哪些功能以及如何完成；数据集则是程序在执行过程中所需要使用的资源；进程控制块用来记录进程的外部特征，描述进程的执行变化过程，系统可以利用它来控制和管理进程，它是系统感知进程存在的唯一标志。\n进程的过程: 创建，就绪，运行，阻塞, 消亡。\n2  父进程和子进程Linux 操作系统提供了一个 fork() 函数用来创建子进程，这个函数很特殊，调用一次，返回两次，因为操作系统是将当前的进程（父进程）复制了一份（子进程），然后分别在父进程和子进程内返回。子进程永远返回0，而父进程返回子进程的 PID。我们可以通过判断返回值是不是 0 来判断当前是在父进程还是子进程中执行。\n在 Python 中同样提供了 fork() 函数，此函数位于 os 模块下。\n# -*- coding: utf-8 -*-  import osimport timeprint(f&quot;在创建子进程前: pid=&#123;os.getpid()&#125;, ppid=&#123;os.getppid()&#125;&quot;)pid = os.fork()if pid == 0:    print(f&quot;子进程创建完后: pid=&#123;os.getpid()&#125;, ppid=&#123;os.getppid()&#125;&quot;)    time.sleep(5)else:    print(f&quot;父进程创建完后: pid=&#123;os.getpid()&#125;, ppid=&#123;os.getppid()&#125;&quot;)    # pid表示回收的子进程的pid, result表示子进程的退出状态    # pid, result = os.wait()    time.sleep(5)    # print(f&quot;父进程：回收的子进程pid=&#123;pid&#125;, 子进程退出时result=&#123;result&#125;&quot;)# 下面的内容会被打印两次，一次是在父进程中，一次是在子进程中。# 父进程中拿到的返回值是创建的子进程的pid，大于0print(&quot;fork创建完后: pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))# 在创建子进程前: pid=8122, ppid=8075# 父进程信息:    pid=8122, ppid=8075# 子进程信息：   pid=8123, ppid=8122# fork创建完后:  pid=8122, ppid=8075# fork创建完后:  pid=8123, ppid=8122# 取消13,14,15,16行注释后:# 在创建子进程前: pid=8133, ppid=8075# 父进程信息  : pid=8133, ppid=8075# 子进程信息  ： pid=8134, ppid=8133# fork创建完后 : pid=8134, ppid=8133# 父进程：回收的子进程pid=8134# 父进程：子进程退出时 result=0# fork创建完后 : pid=8133, ppid=8075# getpid()得到本身进程id，getppid()得到父进程进程id，如果已经是父进程，得到系统进程id\n\n\n\n2.1 父子进程如何区分?子进程是父进程通过fork()产生出来的，pid &#x3D; os.fork()\n通过返回值pid是否为0，判断是否为子进程，如果是0，则表示是子进程\n由于 fork() 是 Linux 上的概念，所以如果要跨平台，最好还是使用 subprocess 模块来创建子进程。\n2.2 子进程如何回收？python中采用os.wait()方法用来回收子进程占用的资源\npid, result &#x3D; os.wait()    # 回收子进程资源　阻塞，等待子进程执行完成回收\n如果有子进程没有被回收的，但是父进程已经死掉了，这个子进程就是僵尸进程。\n3. Python进程模块python的进程multiprocessing模块有多种创建进程的方式，每种创建方式和进程资源的回收都不太相同，下面分别针对Process、Pool及系统自带的fork三种进程分析。\n3.1  fork()import ospid = os.fork() # 创建一个子进程os.wait() # 等待子进程结束释放资源# pid为0的代表子进程。\n\n缺点：    1.兼容性差，只能在类linux系统下使用，windows系统不可使用；    2.扩展性差，当需要多条进程的时候，进程管理变得很复杂；    3.会产生“孤儿”进程和“僵尸”进程，需要手动回收资源。优点：    是系统自带的接近低层的创建方式，运行效率高。\n3.2 Process进程multiprocessing模块提供Process类实现新建进程\n# -*- coding: utf-8 -*-import osfrom multiprocessing  import Processimport timedef fun(name):\tprint(&quot;2 子进程信息： pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))\tprint(&quot;hello &quot; + name)\tdef test():\tprint(&#x27;ssss&#x27;)if __name__ == &quot;__main__&quot;:\tprint(&quot;1 主进程信息： pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))  \tps = Process(target=fun, args=(&#x27;jingsanpang&#x27;, ))\tprint(&quot;111 ##### ps pid: &quot; + str(ps.pid) + &quot;, ident:&quot; + str(ps.ident))\tprint(&quot;3 进程信息： pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))\tprint(ps.is_alive())\tps.start()\tprint(ps.is_alive())\tprint(&quot;222 #### ps pid: &quot; + str(ps.pid) + &quot;, ident:&quot; + str(ps.ident))\tprint(&quot;4 进程信息： pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))\tps.join()\tprint(ps.is_alive())\tprint(&quot;5 进程信息： pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))\tps.terminate()\tprint(&quot;6 进程信息： pid=%s, ppid=%s&quot; % (os.getpid(), os.getppid()))    # 1 主进程信息： pid=8143, ppid=8075# 111 ##### ps pid: None, ident:None# 3 进程信息： pid=8143, ppid=8075# False# True# 222 #### ps pid: 8144, ident:8144# 4 进程信息： pid=8143, ppid=8075# 2 子进程信息： pid=8144, ppid=8143# hello jingsanpang# False# 5 进程信息： pid=8143, ppid=8075# 6 进程信息： pid=8143, ppid=8075\n\n特点：   1.注意：Process对象可以创建进程，但Process对象不是进程，其删除与否与系统资源是否被回收没有直接的关系。   2.主进程执行完毕后会默认等待子进程结束后回收资源，不需要手动回收资源；join()函数用来控制子进程    结束的顺序,其内部也有一个清除僵尸进程的函数，可以回收资源；   3.Process进程创建时，子进程会将主进程的Process对象完全复制一份，这样在主进程和子进程各有一个 Process对象，但是p.start()启动的是子进程，主进程中的Process对象作为一个静态对象存在，不执行。\n   4.当子进程执行完毕后，会产生一个僵尸进程，其会被join函数回收，或者再有一条进程开启，start函数也会回收僵尸进程，所以不一定需要写join函数。   5.windows系统在子进程结束后会立即自动清除子进程的Process对象，而linux系统子进程的Process对象如果没有join函数和start函数的话会在主进程结束后统一清除。\n另外还可以通过继承Process对象来重写run方法创建进程\n3.3  进程池POOL (多个进程)# -*- coding: utf-8 -*-import multiprocessingimport timedef work(msg):\tmult_proces_name = multiprocessing.current_process().name    time.sleep(2)\tprint(&#x27;process: &#x27; + mult_proces_name + &#x27;-&#x27; + msg)\tif __name__ == &quot;__main__&quot;:\tpool = multiprocessing.Pool(processes=5) # 创建5个进程\tfor i in range(10):\t\tmsg = &quot;process %d&quot; %(i)\t\tpool.apply_async(work, (msg, ))\tpool.close() # 关闭进程池，表示不能在往进程池中添加进程\tpool.join() # 等待进程池中的所有进程执行完毕，必须在close()之后调用\tprint(&quot;Sub-process all done.&quot;)# process: ForkPoolWorker-3-process 3# process: ForkPoolWorker-2-process 0# process: ForkPoolWorker-4-process 2# process: ForkPoolWorker-1-process 1# process: ForkPoolWorker-5-process 4  每5个进程一起# process: ForkPoolWorker-3-process 5# process: ForkPoolWorker-2-process 6# process: ForkPoolWorker-4-process 7# process: ForkPoolWorker-1-process 8# process: ForkPoolWorker-5-process 9# Sub-process all done.\n\n上述代码中的pool.apply_async()是apply()函数的变体，apply_async()是apply()的并行版本，apply()是apply_async()的阻塞版本，使用apply()主进程会被阻塞直到函数执行结束，所以说是阻塞版本。apply()既是Pool的方法，也是Python内置的函数，两者等价。可以看到输出结果并不是按照代码for循环中的顺序输出的。 async 异步\n多个子进程并返回值\napply_async()本身就可以返回被进程调用的函数的返回值。上一个创建多个子进程的代码中，如果在函数func中返回一个值，那么pool.apply_async(func, (msg, ))的结果就是返回pool中所有进程的值的对象（注意是对象，不是值本身）。\nimport multiprocessingimport timedef func(msg):    time.sleep(2)    return multiprocessing.current_process().name + &#x27;-&#x27; + msgif __name__ == &quot;__main__&quot;:    pool = multiprocessing.Pool(processes=4) # 创建4个进程    results = []    for i in range(10):        msg = &quot;process %d&quot; %(i)        results.append(pool.apply_async(func, (msg, )))    pool.close() # 关闭进程池，表示不能再往进程池中添加进程，需要在join之前调用    pool.join() # 等待进程池中的所有进程执行完毕    print (&quot;Sub-process(es) done.&quot;)    for res in results:        print (res.get())        # Sub-process(es) done.# ForkPoolWorker-2-process 0# ForkPoolWorker-4-process 1# ForkPoolWorker-3-process 2# ForkPoolWorker-1-process 3# ForkPoolWorker-3-process 4# ForkPoolWorker-2-process 5# ForkPoolWorker-1-process 6# ForkPoolWorker-4-process 7# ForkPoolWorker-2-process 8# ForkPoolWorker-3-process 9# ForkPoolWorker-1-process 10# ForkPoolWorker-4-process 11\n\n与之前的输出不同，这次的输出是有序的。如果电脑是八核，建立8个进程，在Ubuntu下输入top命令再按下大键盘的1，可以看到每个CPU的使用率是比较平均的\n4  进程间通信方式\n管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 \n命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。\n消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。\n共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。\n\n以上几种进程间通信方式中，消息队列是使用的比较频繁的方式。\n（1）管道pipe\nimport multiprocessingdef foo(sk):   sk.send(&#x27;hello father&#x27;)   print(sk.recv())if __name__ == &#x27;__main__&#x27;:   conn1,conn2=multiprocessing.Pipe()    #开辟两个口，都是能进能出，括号中如果False即单向通信   p=multiprocessing.Process(target=foo,args=(conn1,))  #子进程使用sock口，调用foo函数   p.start()   print(conn2.recv())  #主进程使用conn口接收   conn2.send(&#x27;hi son&#x27;) #主进程使用conn口发送\n\n\n\n（2）消息队列Queue\nQueue是多进程的安全队列，可以使用Queue实现多进程之间的数据传递。\nQueue的一些常用方法：\n\nQueue.qsize()：返回当前队列包含的消息数量；\nQueue.empty()：如果队列为空，返回True，反之False ；\nQueue.full()：如果队列满了，返回True,反之False；\nQueue.get():获取队列中的一条消息，然后将其从列队中移除，可传参超时时长。\nQueue.get_nowait()：相当Queue.get(False),取不到值时触发异常：Empty；\nQueue.put():将一个值添加进数列，可传参超时时长。\nQueue.put_nowait():相当于Queue.get(False),当队列满了时报错：Full。\n\n案例：\nfrom multiprocessing import Process, Queueimport timedef write(q):   for i in [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;]:      print(&#x27;Put %s to queue&#x27; % i)      q.put(i)      time.sleep(0.5)def read(q):   while True:      v = q.get(True)      print(&#x27;get %s from queue&#x27; % v)if __name__ == &#x27;__main__&#x27;:   q = Queue()   pw = Process(target=write, args=(q,))   pr = Process(target=read, args=(q,))   print(&#x27;write process = &#x27;, pw)   print(&#x27;read  process = &#x27;, pr)   pw.start()   pr.start()   pw.join()   pr.join()   pr.terminate()   pw.terminate()\n\n\n\nQueue和pipe只是实现了数据交互，并没实现数据共享，即一个进程去更改另一个进程的数据。\n注：进程间通信应该尽量避免使用共享数据的方式\n5   多进程实现生产者消费者以下通过多进程实现生产者，消费者模式\nimport multiprocessingfrom multiprocessing import Processfrom time import sleepimport timeclass MultiProcessProducer(multiprocessing.Process):   def __init__(self, num, queue):      &quot;&quot;&quot;Constructor&quot;&quot;&quot;      multiprocessing.Process.__init__(self)      self.num = num      self.queue = queue   def run(self):      t1 = time.time()      print(&#x27;producer start &#x27; + str(self.num))      for i in range(1000):         self.queue.put((i, self.num))      # print &#x27;producer put&#x27;, i, self.num      t2 = time.time()      print(&#x27;producer exit &#x27; + str(self.num))      use_time = str(t2 - t1)      print(&#x27;producer &#x27; + str(self.num) + &#x27;,       use_time: &#x27;+ use_time)class MultiProcessConsumer(multiprocessing.Process):   def __init__(self, num, queue):      &quot;&quot;&quot;Constructor&quot;&quot;&quot;      multiprocessing.Process.__init__(self)      self.num = num      self.queue = queue   def run(self):      t1 = time.time()      print(&#x27;consumer start &#x27; + str(self.num))      while True:         d = self.queue.get()         if d != None:            # print &#x27;consumer get&#x27;, d, self.num            continue         else:            break      t2 = time.time()      print(&#x27;consumer exit &#x27; + str(self.num))      print(&#x27;consumer &#x27; + str(self.num) + &#x27;, use time:&#x27; + str(t2 - t1))def main():   # create queue   queue = multiprocessing.Queue()   # create processes   producer = []   for i in range(5):      producer.append(MultiProcessProducer(i, queue))   consumer = []   for i in range(5):      consumer.append(MultiProcessConsumer(i, queue))   # start processes   for i in range(len(producer)):      producer[i].start()   for i in range(len(consumer)):      consumer[i].start()   # wait for processs to exit   for i in range(len(producer)):      producer[i].join()   for i in range(len(consumer)):      queue.put(None)   for i in range(len(consumer)):      consumer[i].join()   print(&#x27;all done finish&#x27;)if __name__ == &quot;__main__&quot;:   main()\n\n\n\n6  总结python中的多进程创建有以下两种方式：\n   （1）fork子进程 ( linux )\n   （2）采用 multiprocessing 这个库创建子进程\n需要注意的是队列中Queue.Queue是线程安全的，但并不是进程安全，所以多进程一般使用线程、进程安全的multiprocessing.Queue()\n另外, 进程池使用 multiprocessing.Pool实现，pool &#x3D; multiprocessing.Pool(processes &#x3D; 3)，产生一个进程池，pool.apply_async实现非租塞模式，pool.apply实现阻塞模式。\n apply_async和 apply函数，前者是非阻塞的，后者是阻塞。可以看出运行时间相差的倍数正是进程池数量。\n同时可以通过result.append(pool.apply_async(func, (msg, )))获取非租塞式调用结果信息的。\n","categories":["技术","Python"],"tags":["Python","code","多进程"]},{"title":"python装饰器","url":"/posts/2019/03/15/45122/","content":"一、什么是装饰器python的装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。简单的说装饰器就是一个用来返回函数的函数。\n它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、统计、权限校验、参数、结果检查、重试等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。\n概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。或者说, 在被装饰的函数或者类的基础上进行功能扩展，实现逻辑上的切面编程。\n二、为什么需要装饰器1、先来看一个简单例子：\ndef foo():\tprint(&#x27;i am foo&#x27;)\n\n2、增加需求\n现在有一个新的需求，希望可以记录下函数的执行日志，于是在代码中添加日志代码：\ndef foo():    print(&#x27;i am foo&#x27;)    print(&quot;foo is running&quot;)\n\n3、又有需求\n假设现在有100个函数需要增加这个需求，并且后续可能还要对这一百个函数都增加执行前打印日志的需求，怎么办？还一个个改吗？\n当然不了，这样会造成大量雷同的代码，为了减少重复写代码，我们可以这样做，重新定义一个函数：专门处理日志 ，日志处理完之后再执行真正的业务代码。\ndef use_logging(func):    print(&quot;%s is running&quot; % func.__name__)    func()def bar():    print(&#x27;i am bar&#x27;)use_logging(bar)# bar is running# i am bar\n\n通过以上use_logging函数我们增加了日志功能，不管以后有多少函数需要增加日志或者修改日志的格式我们只需要修改use_logging函数，并执行use_logging(被装饰的函数)就达到了我们想要的效果。实现代码复用\ndef use_logging(func):    print(&quot;%s is running&quot; % func.__name__)    return func@use_loggingdef bar():    print(&#x27;i am bar&#x27;)bar()\n\n三、基础装饰器入门\n装饰器语法糖\n\npython提供了@符号作为装饰器的语法糖，使我们更方便的应用装饰函数。但使用语法糖要求装饰函数必须return一个函数对象。因此我们将上面的func函数使用内嵌函数包裹并return。\n装饰器相当于执行了装饰函数use_loggin后又返回被装饰函数bar,因此bar()被调用的时候相当于执行了两个函数。等价于use_logging(bar)()\ndef use_logging(func):    def _deco():        print(&quot;%s is running&quot; % func.__name__)        func()        return _deco@use_loggingdef bar():    print(&#x27;i am bar&#x27;)bar()\n\n\n对带参数的函数进行装饰\n\n现在我们的参数需要传入两个参数并计算值，因此我们需要对内层函数进行改动传入我们的两个参数a和b，等价于use_logging(bar)(1,2)\ndef use_logging(func):    def _deco(a, b):        print(&quot;%s is running&quot; % func.__name__)        func(a, b)        return _deco@use_loggingdef bar(a, b):    print(&#x27;i am bar:%s&#x27; % (a + b))bar(1, 2)\n\n我们装饰的函数可能参数的个数和类型都不一样，每一次我们都需要对装饰器做修改吗？这样做当然是不科学的，因此我们使用python的变长参数*args和**kwargs来解决我们的参数问题。\n\n函数参数数量不确定\n\n不带参数装饰器版本，这个格式适用于不带参数的装饰器。\n针对各种长度和类型的参数。这个版本的装饰器已经可以任意类型的无参数函数。\ndef use_logging(func):    def _deco(*args, **kwargs):        print(&quot;%s is running&quot; % func.__name__)        func(*args, **kwargs)        return _deco@use_loggingdef bar(a, b):    print(&#x27;i am bar:%s&#x27; % (a + b))@use_loggingdef foo(a, b, c):    print(&#x27;i am bar:%s&#x27; % (a + b + c))bar(1, 2)foo(1, 2, 3)\n\n\n装饰器带参数\n\n带参数的装饰器，这个格式适用于带参数的装饰器。\n某些情况我们需要让装饰器带上参数，那就需要编写一个返回一个装饰器的高阶函数，写出来会更复杂。比如：\nfrom functools import wrapsdef para_decorate(level):    def _outter(func):        @wraps(func)        def _inner(*args, **kwargs):            if level == &quot;warning&quot;:                print(&quot;level 1&quot;)            func(*args, **kwargs)            # return func(*args, **kwargs)        return _inner    return _outter@para_decorate(level=&quot;warning&quot;)def myParaDecorate(a, b):    print(&quot;myParaDecorate run : a+b =&quot;, a + b)    print(myParaDecorate.__name__)myParaDecorate(10, 10)# level 1# myParaDecorate run : a+b = 20# myParaDecorate\n\n\n还原被装饰器修改的原函数属性 functools.wraps\n\n使用装饰器极大地复用了代码，但是他有一个缺点就是原函数的元信息不见了，比如函数的docstring、name、参数列表，先看例子：\ndef use_logging(func):    def _deco(*args, **kwargs):        print(&quot;%s is running&quot; % func.__name__)        func(*args, **kwargs)        return _deco@use_loggingdef bar():    print(&#x27;i am bar&#x27;)    print(bar.__name__)bar()# bar is running# i am bar# _deco# 函数名变为_deco而不是bar，这个情况在使用反射的特性的时候就会造成问题\n\n使用functools.wraps:\nfrom functools import wrapsdef use_logging(func):    @wraps(func)    def _deco(*args, **kwargs):        print(&quot;%s is running&quot; % func.__name__)        func(*args, **kwargs)        return _deco@use_loggingdef bar():    print(&#x27;i am bar&#x27;)    print(bar.__name__)bar()# result:# bar is running# i am bar# bar \n\n\n实现带参数和不带参数的装饰器自适应from functools import wrapsdef use_logging(arg):    print(arg)    if callable(arg):   \t# 判断参入的参数是否是函数，不带参数的装饰器调用这个分支        @wraps(arg)        def _decorate(*args,**kwargs):            print(&quot;callable running is &quot;, arg.__name__)            return arg(*args,**kwargs)        return _decorate    else:    # 带参数的装饰器调用这个分支        def _decorate(func):            @wraps(func)            def __decorate(*args,**kwargs):                if arg == &quot;warning&quot;:                    print(&quot;running is &quot;,func.__name__)                return func(*args, **kwargs)            return __decorate        return _decorate# @use_logging(&quot;warning&quot;)         #  arg 是 warning  ----&gt;  not callable@use_logging        # arg 是&lt;function myDecorate at 0x00000183419B4F28&gt;   callbaledef myDecorate():    print(&quot;this is test&quot;)    print(&quot;continue test &quot;,myDecorate.__name__)myDecorate()\n\n练习1: 写一个 timer 装饰器, 计算被装饰函数调用一次花多长时间, 把时间打印出来\nimport timefrom functools import wrapsdef timer(func):    @wraps(func)    def wrap(*args, **kwargs):        time0 = time.time()        result = func(*args, **kwargs)        time1 = time.time()        print(time1 - time0)        return result    return wrap@timerdef test():    for i in range(1000000):        passtest()\n\n练习2:  写一个 Retry 装饰器 \nimport timefrom functools import wrapsclass Retry(object):    def __init__(self, maxRetries=3, wait=0, exceptions=(Exception,)):        self.maxRetries = maxRetries        self.wait = wait        self.exceptions = exceptions    def __call__(self, func):        @wraps(func)        def _decorate(*args, **kwargs):            for i in range(self.maxRetries):                try:                    result = func(*args, **kwargs)                except self.exceptions:                    time.sleep(self.wait)                    continue                else:                    return result  # 一个函数一个返回值        return _decorate  # 这是__call__函数的返回值(一定要注意缩进)@Retry()def printFunc(a, b):    print(&quot;a + b = &quot;, a + b)    print(printFunc.__name__)printFunc(1, 1)\n\n四、类装饰器使用类装饰器可以实现带参数装饰器的效果，但实现的更加优雅简洁,而且可以通过继承来灵活的扩展.\n1、类装饰器\nimport functoolsclass Loging(object):    def __init__(self, level=&quot;warning&quot;):        self.level = level    def __call__(self, func):        @functools.wraps(func)        def _decorate(*args, **kwargs):            if self.level == &quot;warning&quot;:                self.printLogInfo(func)            print(&quot;do it here&quot;)            return func(*args, **kwargs)        return _decorate    def printLogInfo(self, func):        print(&quot;warning: currently running is &quot;, func.__name__)# @Loging(level=&quot;warning&quot;)# @Loging(level=&quot;normal&quot;)@Loging()def myExecuting(a, b):    print(&quot;a + b = &quot;, a + b)    print(&quot;this is &quot;, myExecuting.__name__)myExecuting(1, 1)\n\n2、继承扩展类装饰器\n# 一个loging的实现版本，可以在函数调用时发送email给管理员class email_loging(Loging):    def __init__(self, email=&quot;admin@163.com&quot;, *args, **kwargs):        self.email = email        super(email_loging, self).__init__(*args, **kwargs)    def printLogInfo(self, func):        print(&quot;email warning: currently running is &quot;, func.__name__)        print(&quot;send email to &quot;, self.email)@email_loging()def sendEmail():    print(&quot;send success&quot;)sendEmail()\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：函数装饰器和闭包一","url":"/posts/2019/12/08/9970/","content":"1.基础函数装饰器用于在源码中“标记”函数，以某种方式增强函数的行为。这是一项强大的功能，但是若想掌握，必须理解闭包。\n装饰器是可调用的对象，其参数是另一个函数（被装饰的函数）。装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用对象。\ndemo：\ndef decor(func):    def inner():        print(&quot;innner&quot;)    return inner  # 返回inner函数对象@decordef test():  # 用deco装饰test    print(&quot;test func&quot;)test()# innner# 以上相当于：def decor(func):    def inner():        print(&quot;innner&quot;)    return innerdef test():    print(&quot;test func&quot;)test = decor(test)test()\n\n严格来说，装饰器只是语法糖。如前所示，装饰器可以像常规的可调用对象那样调用，其参数是另一个函数。有时，这样做更方便，尤其是做元编程（在运行时改变程序的行为）时。\n综上，装饰器的一大特性是，能把被装饰的函数替换成其他函数。第二个特性是，装饰器在加载模块时立即执行。\n\n2. Python何时执行装饰器装饰器的一个关键特性是，它们在被装饰的函数定义之后立即运行。这通常是在导入时（即 Python 加载模块时）。\n# registration.pyregistry_list = []def register(func):    print(f&#x27;running register &#123;func&#125;&#x27;)    registry_list.append(func)    return func@registerdef f1():    print(f&#x27;running f1()&#x27;)@registerdef f2():    print(f&#x27;running f2()&#x27;)def f3():    print(f&#x27;running f3()&#x27;)def main():    print(&#x27;running main()&#x27;)    print(f&#x27;registry_list:&#123;registry_list&#125;&#x27;)    f1()    f2()    f3()if __name__ == &#x27;__main__&#x27;:    main()\n\n把 registration.py 当作脚本运行得到的输出如下：\n$ python3 registration.pyrunning register &lt;function f1 at 0x000001EECF194F28&gt;running register &lt;function f2 at 0x000001EED61FA378&gt;running main()registry_list:[&lt;function f1 at 0x000001EECF194F28&gt;, &lt;function f2 at 0x000001EED61FA378&gt;]running f1()running f2()running f3()\n\nregister 在模块中其他函数之前运行（两次）。调用 register 时，传给它的参数是\n被装饰的函数，例如&lt;function f1 at 0x000001EECF194F28&gt;。\n加载模块后，registry 中有两个被装饰函数的引用：f1 和 f2。这两个函数，以及 f3，只在 main 明确调用它们时才执行。\n如果导入 registration.py 模块（不作为脚本运行），输出如下：\n&gt;&gt;&gt;import registrationrunning register &lt;function f1 at 0x000002494681A400&gt;running register &lt;function f2 at 0x000002494681A488&gt;\n\n此时查看 registry 的值，得到的输出如下：\t\n&gt;&gt;&gt; registration.registry[&lt;function f1 at 0x000002494681A400&gt;, &lt;function f2 at 0x000002494681A488&gt;]\n\n虽然示例中的 register 装饰器原封不动地返回被装饰的函数，但是这种技术并非没有用处。很多 Python Web 框架使用这样的装饰器把函数添加到某种中央注册处，例如把URL 模式映射到生成 HTTP 响应的函数上的注册处。\n通过上例可以得出结论：函数装饰器在导入模块时立即执行，而被装饰的函数只在明确调用时运行。\n考虑到装饰器在真实代码中的常用方式，上例有两个不寻常的地方：\n\n装饰器函数与被装饰的函数在同一个模块中定义。实际情况是，装饰器通常在一个模块中定义，然后应用到其他模块中的函数上。\nregister 装饰器返回的函数与通过参数传入的相同。实际上，大多数装饰器会在内部定义一个函数，然后将其返回。\n\n\n3. 使用装饰器改进“策略”模式# 选择最佳策略(使用装饰器)promo_list = []def promotion(promo_func):  \t&quot;&quot;&quot;promotion 把 promo_func 添加到promo_list中，然后原封不动地将其返回。&quot;&quot;&quot;    promo_list.append(promo_func)    return promo_func@promotion  # 被 @promotion 装饰的函数都会添加到promo_list中。def fidelity_promo(order):    &quot;&quot;&quot;1000积分以上顾客，5%折扣&quot;&quot;&quot;    return order.total() * 0.05 if order.customer.fidelity &gt;= 1000 else 0@promotiondef bulk_item_promo(order):    &quot;&quot;&quot;单个商品20个以上，10%折扣&quot;&quot;&quot;    discount = 0    for item in order.cart:        if item.quantity &gt;= 20:            discount += item.total() * 0.1    return discount@promotiondef large_order_promo(order):    &quot;&quot;&quot;不同商品10个以上，7%折扣&quot;&quot;&quot;    distinct_items = &#123;item.product for item in order.cart&#125;    if len(distinct_items) &gt;= 10:        return order.total() * 0.07    return 0def best_promo(order):  # best_promos无需修改，它依赖promo_list    &quot;&quot;&quot;    与其他几个 *_promo 函数一样，best_promo 函数的参数是一个Order实例;    使用生成器表达式把 order 传给 promos 列表中的各个函数，    返回折扣额度最大的那个函数。    &quot;&quot;&quot;    return max(promo(order) for promo in promo_list)\n\n与之前给出的方案相比，这个方案有几个优点：\n\n促销策略函数无需使用特殊的名称（即不用以 _promo 结尾）。\n\n@promotion 装饰器突出了被装饰的函数的作用，还便于临时禁用某个促销策略：只需把装饰器注释掉。\n\n促销折扣策略可以在其他模块中定义，在系统中的任何地方都行，只要使用 @promotion装饰即可。\n\n\n不过，多数装饰器会修改被装饰的函数。通常，它们会定义一个内部函数，然后将其返回，替换被装饰的函数。使用内部函数的代码几乎都要靠闭包才能正确运作。\n\n4. 变量作用域规则先看一个demo：\n&gt;&gt;&gt; b = 1&gt;&gt;&gt; def f1(a):      print(a)      print(b)      b = 2      &gt;&gt;&gt; f1(0)0Traceback (most recent call last):  File &quot;&lt;pyshell#9&gt;&quot;, line 1, in &lt;module&gt;    f1(0)  File &quot;&lt;pyshell#8&gt;&quot;, line 3, in f1    print(b)UnboundLocalError: local variable &#x27;b&#x27; referenced before assignment\n\nPython 编译函数的定义体时，它判断 b 是局部变量，因为在函数中给它赋值了。生成的字节码证实了这种判断，Python 会尝试从本地环境获取 b。后面调用 f1(0) 时，f1 的定义体会获取并打印局部变量 a 的值，但是尝试获取局部变量 b 的值时，发现 b 没有绑定值。\n如果在函数中赋值时想让解释器把 b 当成全局变量，要使用 global 声明。\n&gt;&gt;&gt; def f1(a):      global b      print(a)      print(b)      b = 2      &gt;&gt;&gt; f1(0)01\n\n比较字节码：dis 模块为反汇编 Python 函数字节码提供了简单的方式\n一个函数，读取一个局部变量和一个全局变量：\n\nb是局部变量，因为在函数的定义体中给它赋值了：这里的LOAD_GLOBAL  1 (b)：加载本地名称 b，这表明，编译器把 b 视作局部变量，即使在后面才为 b 赋值，因为变量的种类（是不是局部变量)不能改变函数的定义体。\n\n5. 闭包闭包指延伸了作用域的函数，其中包含函数定义体中引用、但是不在定义体中定义的非全局变量。函数是不是匿名的没有关系，关键是它能访问定义体之外定义的非全局变量。\n假如有个名为 avg 的函数，它的作用是计算不断增加的系列值的均值：\n# 使用classclass Avg(object):    def __init__(self):        self.series = []        def __call__(self, newvalue):        self.series.append(newvalue)        return sum(self.series)/len(self.series)avg = Avg()print(avg(1))print(avg(3))# 使用函数def average():    series = []    def avg(new_value):        series.append(new_value)        total = sum(series)        return total / len(series)    return avgavg2 = average()print(avg2(3))  # 3.0print(avg2(9))  # 6.0\n\navg 的闭包延伸到那个函数的作用域之外，包含自由变量 series 的绑定。\n审查返回的 averager 对象，我们发现 Python 在__code__属性（表示编译后的函数定义体）中保存局部变量(co_varnames)和自由变量(co_freevars)的名称。\navg2.__code__.co_varnames  # (&#x27;new_value&#x27;, &#x27;total&#x27;)avg2.__code__.co_freevars  # (&#x27;series&#x27;,)\n\nseries 的绑定在返回的 avg2 函数的__closure__属性中。avg2.__closure__ 中的各个元素对应于 avg2.__code__.co_freevars 中的一个名称。这些元素是 cell 对象，有个 cell_contents 属性，保存着真正的值。\nprint(avg2.__closure__[0].cell_contents)  # [3, 9]\n\n综上，闭包是一种函数，它会保留定义函数时存在的自由变量的绑定，这样调用函数时，虽然定义作用域不可用了，但是仍能使用那些绑定。注意，只有嵌套在其他函数中的函数才可能需要处理不在全局作用域中的外部变量。\n\n6. nonlocal声明之前我们把所有值存储在历史数列中，然后在每次调用 avg时使用 sum 求和。更好的实现方式是，只存储目前的总值和元素个数，然后使用这两个数计算均值。\n# 计算移动平均值的高阶函数，不保存所有历史值，但有bugdef average():    total = count = 0    def avg(new_var):        total += new_var        count += 1        return total / count    return avgavg = average()print(avg(2))print(avg(8))\n\n如果是用pycharm编码，这里有红色的波浪线直接提示报错（This inspection detects names that should resolve but don&#39;t. Due to dynamic dispatch and duck typing, this is possible in a limited but useful number of cases. Top-level and class-level items are supported better than instance items.）， 强行执行后报错:UnboundLocalError: local variable &#39;summary&#39; referenced before assignment\n问题是，当 count 是数字或任何不可变类型时，count +&#x3D; 1 语句的作用其实与 count &#x3D; count + 1 一样。因此，在 averager 的定义体中给 count 赋值时，会将 count 变成局部变量。total 变量也受这个问题影响。\n之前没遇到这个问题，因为没有给 series 赋值，我们只是调用 series.append，并把它传给 sum 和 len。也就是说，我们利用了列表是可变的对象这一事实。\n但是对数字、字符串、元组等不可变类型来说，只能读取，不能更新。如果尝试重新绑定，例如 count &#x3D; count + 1，其实会隐式创建局部变量 count。这样，count 就不是自由变量了，因此不会保存在闭包中。\n为了解决这个问题，Python3 引入了 nonlocal 声明。它的作用是把变量标记为自由变量，即使在函数中为变量赋予新值了，也会变成自由变量。如果为 nonlocal 声明的变量赋予新值，闭包中保存的绑定会更新。\ndef average():    total = count = 0    def avg(new_var):        nonlocal total, count        total += new_var        count += 1        return total / count    return avg\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：一等函数实现设计模式","url":"/posts/2019/12/01/5641/","content":"《设计模式：可复用面向对象软件的基础》一书是这样概述“策略”模式的：定义一系列算法，把它们一一封装起来，并且使它们可以相互替换。本模式使得算法可以独立于使用它的客户而变化。\n\n1. 经典的“策略”模式电商领域有个功能明显可以使用“策略”模式，即根据客户的属性或订单中的商品计算折扣。假如一个网店制定了下述折扣规则。 \n\n有 1000 或以上积分的顾客，每个订单享 5% 折扣。 \n同一订单中，单个商品的数量达到 20 个或以上，享 10% 折扣。\n订单中的不同商品达到 10 个或以上，享 7% 折扣。\n(简单起见，我们假定一个订单一次只能享用一个折扣。)\n\n上下文: 把一些计算委托给实现不同算法的可互换组件，它提供服务。在这个电商示例中，上下文是 Order，它会根据不同的算法计算促销折扣。 \n策略:  实现不同算法的组件共同的接口。在这个示例中，名为 Promotion 的抽象类扮演这个角色。 \n具体策略:  “策略”的具体子类。fidelityPromo、BulkPromo 和 LargeOrderPromo 是这里实现的三个具体策略。\nfrom abc import ABC, abstractmethodfrom collections import namedtupleCustomer = namedtuple(&#x27;Customer&#x27;, &#x27;name fidelity&#x27;)class LineItem(object):    def __init__(self, product, quantity, price):        self.product = product        self.quantity = quantity        self.price = price    def total(self):        return self.price * self.quantityclass Order(object):    def __init__(self, customer, cart, promotion=None):        self.customer = customer        self.cart = cart        self.promotion = promotion    def total(self):        if not hasattr(self, &#x27;__total&#x27;):            self.__total = sum(item.total() for item in self.cart)        return self.__total    def due(self):        if self.promotion is None:            discount = 0        else:            discount = self.promotion.discount(self)        return self.total() - discount    def __repr__(self):        fmt = f&#x27;&lt;Order total:&#123;self.total()&#125;, due:&#123;self.due()&#125;&gt;&#x27;        return fmtclass Promotion(ABC):    @staticmethod    def discount(self, order):        &quot;&quot;&quot;返回折扣金额&quot;&quot;&quot;class FidelityPromo(Promotion):    &quot;&quot;&quot;1000积分以上顾客，5%折扣&quot;&quot;&quot;    def discount(self, order):        return order.total() * 0.05 if order.customer.fidelity &gt;= 1000 else 0class BulkItemPromo(Promotion):    &quot;&quot;&quot;单个商品20个以上，10%折扣&quot;&quot;&quot;    def discount(self, order):        discount = 0        for item in order.cart:            if item.quantity &gt;= 20:                discount += item.total * 0.1        return discountclass LargeOrderPromo(Promotion):    &quot;&quot;&quot;不同商品10个以上，7%折扣&quot;&quot;&quot;    def discount(self, order):        distinct_items = &#123;item.product for item in order.cart&#125;        if len(distinct_items) &gt;= 10:            return order.total() * 0.07        return 0joe = Customer(&#x27;John Doe&#x27;, 0)ann = Customer(&#x27;Ann Smith&#x27;, 1100)cart = [LineItem(&#x27;banana&#x27;, 4, .5), LineItem(&#x27;apple&#x27;, 10, 1.5), LineItem(&#x27;watermellon&#x27;, 5, 5.0)]Order(joe, cart, FidelityPromo()) # &lt;Order total: 42.00 due: 42.00&gt;Order(ann, cart, FidelityPromo()) # &lt;Order total: 42.00 due: 39.90&gt;banana_cart = [LineItem(&#x27;banana&#x27;, 30, .5), LineItem(&#x27;apple&#x27;, 10, 1.5)]Order(joe, banana_cart, BulkItemPromo()) # &lt;Order total: 30.00 due: 28.50&gt;long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)]Order(joe, long_order, LargeOrderPromo()) # &lt;Order total: 10.00 due: 9.30&gt;Order(joe, cart, LargeOrderPromo())\n\n分析：每个具体策略都是一个类，而且都只定义了一个方法，即 discount。此外，策略实例没有状态（没有实例属性）。你可能会说，它们看起来像是普通的函数——的确如此。以下示例是对上例的重构，把具体策略换成了简单的函数，而且去掉了 Promo抽象类。\n没必要在新建订单时实例化新的促销对象，函数拿来即用。\n\n2. 使用函数实现“策略”模式from abc import ABC, abstractmethodfrom collections import namedtupleCustomer = namedtuple(&#x27;Customer&#x27;, &#x27;name fidelity&#x27;)class LineItem(object):    def __init__(self, product, quantity, price):        self.product = product        self.quantity = quantity        self.price = price    def total(self):        return self.price * self.quantityclass Order(object):    def __init__(self, customer, cart, promotion=None):        self.customer = customer        self.cart = cart        self.promotion = promotion    def total(self):        if not hasattr(self, &#x27;__total&#x27;):            self.__total = sum(item.total() for item in self.cart)        return self.__total    def due(self):        if self.promotion is None:            discount = 0        else:            discount = self.promotion(self)  # 计算折扣只需调用self.promotion()函数。        return self.total() - discount    def __repr__(self):        fmt = f&#x27;&lt;Order total:&#123;self.total()&#125;, due:&#123;self.due()&#125;&gt;&#x27;        return fmt# 没有抽象类def fidelity_promo(order):  # 各个策略都是函数    &quot;&quot;&quot;1000积分以上顾客，5%折扣&quot;&quot;&quot;    return order.total() * 0.05 if order.customer.fidelity &gt;= 1000 else 0# 没必要在新建订单时实例化新的促销对象，函数拿来即用。def bulk_item_promo(order):    &quot;&quot;&quot;单个商品20个以上，10%折扣&quot;&quot;&quot;    discount = 0    for item in order.cart:        if item.quantity &gt;= 20:            discount += item.total() * 0.1    return discountdef large_order_promo(order):    &quot;&quot;&quot;不同商品10个以上，7%折扣&quot;&quot;&quot;    distinct_items = &#123;item.product for item in order.cart&#125;    if len(distinct_items) &gt;= 10:        return order.total() * 0.07    return 0joe = Customer(&#x27;John Doe&#x27;, 0)ann = Customer(&#x27;Ann Smith&#x27;, 1100)cart = [LineItem(&#x27;banana&#x27;, 4, .5), LineItem(&#x27;apple&#x27;, 10, 1.5), LineItem(&#x27;watermellon&#x27;, 5, 5.0)]Order(joe, cart, fidelity_promo)  # 没必要在新建订单时实例化新的促销对象，函数拿来即用。# &lt;Order total: 42.00 due: 42.00&gt;Order(ann, cart, fidelity_promo)# &lt;Order total: 42.00 due: 39.90&gt;banana_cart = [LineItem(&#x27;banana&#x27;, 30, .5), LineItem(&#x27;apple&#x27;, 10, 1.5)]Order(joe, banana_cart, bulk_item_promo)# &lt;Order total: 30.00 due: 28.50&gt;long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)]Order(joe, long_order, large_order_promo)# &lt;Order total: 10.00 due: 9.30&gt;Order(joe, cart, large_order_promo)# &lt;Order total:42.0, due:42.0&gt;\n\n\n\n值得注意的是，《设计模式：可复用面向对象软件的基础》一书的作者指出：“策略对象通常是很好的享元（flyweight）。”那本书的另一部分对“享元”下了定义：“享元是可共享的对象，可以同时在多个上下文中使用。” 共享是推荐的做法，这样不必在每个新的上下文（这里是 Order 实例）中使用相同的策略时不断新建具体策略对象，从而减少消耗。因此，为了避免“策略”模式的一个缺点（运行时消耗），《设计模式：可复用面向对象软件的基础》的作者建议再使用另一个模式。但此时，代码行数和维护成本会不断攀升。\n在复杂的情况下，需要具体策略维护内部状态时，可能需要把“策略”和“享元”模式结合起来。但是，具体策略一般没有内部状态，只是处理上下文中的数据。此时，一定要使用普通的函数，别去编写只有一个方法的类，再去实现另一个类声明的单函数接口。函数比用户定义的类的实例轻量，而且无需使用“享元”模式，因为各个策略函数在 Python 编译模块时只会创建一次。普通的函数也是“可共享的对象，可以同时在多个上下文中使用”。\n\n3. 选择最佳策略：简单的方式promo_list = [fidelity_promo, bulk_item_promo, large_order_promo]def best_promo(order):    &quot;&quot;&quot;    与其他几个 *_promo 函数一样，best_promo 函数的参数是一个Order实例;    使用生成器表达式把 order 传给 promos 列表中的各个函数，    返回折扣额度最大的那个函数。    &quot;&quot;&quot;    return max(promo(order) for promo in promo_list)\n\npromos 是函数列表。习惯函数是一等对象后，自然而然就会构建那种数据结构存储函数。\n该例可用，而且易于阅读，但是有些重复可能会导致不易察觉的缺陷：若想添加新的促销策略，要定义相应的函数，还要记得把它添加到 promos 列表中；否则，当新促销函数显式地作为参数传给 Order 时，它是可用的，但是 best_promo 不会考虑它。\n\n4. 找出模式中的全部策略globals() 返回一个字典，表示当前的全局符号表。这个符号表始终针对当前模块（对函数或方法来说，是指定义它们的模块，而不是调用它们的模块）。\n# test.pydef test1():    passclass Test2(object):    def test3(self):        passfor i in list(globals()):    print(i)\n\n__name____doc____package____loader____spec____annotations____builtins____file____cached__test1Test2\n\n在上例中修改：迭代 globals() 返回字典中的各个 name，只选择以 _promo 结尾的名称，过滤掉 best_promo 自身，防止无限递归，best_promo 内部的代码没有变化。\n# 选择最佳策略：方法二promo_list2 = [globals()[name] for name in globals()          if name.endswith(&#x27;_promo&#x27;) and name != &#x27;best_promo&#x27;]def best_promo2(order):    # 选择可用的最佳折扣    return max(promo(order) for promo in promo_list2)print(Order(joe, banana_cart, bulk_item_promo))print(Order(joe, long_order, large_order_promo))print(Order(joe, cart, best_promo2))# &lt;Order total:30.0, due:28.5&gt;# &lt;Order total:10.0, due:9.3&gt;# &lt;Order total:42.0, due:42.0&gt;\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：函数装饰器和闭包二","url":"/posts/2019/12/08/17395/","content":"1. 一个简单的装饰器定义了一个装饰器，它会在每次调用被装饰的函数时计时，然后把经过的时间、传入的参数和调用的结果打印出来。\n# a3_4_decorate.pyimport timedef clock(func):    def clocked(*args):  # 定义内部函数 clocked        t0 = time.perf_counter()        res = func(*args)   # 这行代码可用，是因为 clocked 的闭包中包含自由变量 func        elapsed = time.perf_counter() - t0        name = func.__name__        args_str = &#x27;, &#x27;.join(repr(arg) for arg in args)        print(f&#x27;[&#123;elapsed:&gt;2.8&#125;s], &#123;name&#125;(&#123;args_str&#125;)--&gt; &#123;res&#125;&#x27;)        return res    return clocked  # 返回内部函数，取代被装饰的函数。\n\n# a3_4_decorate_func.pyimport timefrom a3_4_decorate import clock@clockdef test_sleep(seconds):    time.sleep(seconds)@clockdef test_factorial(n):    return 1 if n &lt; 2 else n * test_factorial(n-1)if __name__ == &#x27;__main__&#x27;:    test_sleep(1.2)    test_factorial(6)    print(test_factorial.__name__)  # clocked    print(test_sleep.__name__)  # clocked# [1.2008935s], test_sleep(1.2)--&gt; None# [2e-06s], test_factorial(1)--&gt; 1# [0.0001048s], test_factorial(2)--&gt; 2# [0.0001478s], test_factorial(3)--&gt; 6# [0.0001863s], test_factorial(4)--&gt; 24# [0.0002236s], test_factorial(5)--&gt; 120# [0.0002705s], test_factorial(6)--&gt; 720# clocked# clocked\n\n在示例中，test_factorial 会作为 func 参数传给 clock。然后，clock 函数会返回 clocked 函数，Python 解释器在背后会把 clocked 赋值给 test_factorial 。其实，导入 clockdeco_demo 模块后查看 test_factorial 的 __name__ 属性:\n# a3_4_decorate_func_import.pyimport a3_4_decorate_funcprint(a3_4_decorate_func.test_factorial.__name__)print(a3_4_decorate_func.test_sleep.__name__)# clocked# clocked\n\n所以，现在 test_factorial 保存的是 clocked 函数的引用。自此之后，每次调用 test_factorial(n)，执行的都是 clocked(n)。\n这是装饰器的典型行为：把被装饰的函数替换成新函数，二者接受相同的参数，而且（通常）返回被装饰的函数本该返回的值，同时还会做些额外操作。\n本例中实现的 clock 装饰器有几个缺点：不支持关键字参数，而且遮盖了被装饰函数的__name__和__doc__属性。下面将使用 functools.wraps 装饰器把相关的属性从 func复制到 clocked 中。\n# a3_4_decorate_wraps.pyimport timefrom functools import wrapsdef clock(func):    @wraps(func)    def clocked(*args, **kwargs):        t0 = time.perf_counter()        res = func(*args, **kwargs)        elapsed = time.perf_counter() - t0        name = func.__name__        args_list = []        if args:            args_list.append(&#x27;, &#x27;.join(repr(arg) for arg in args))        if kwargs:            pairs = [f&#x27;&#123;k&#125;=&#123;v&#125;&#x27; for k, v in sorted(kwargs.items())]            args_list.append(&#x27;, &#x27;.join(pairs))        args_str = &#x27;, &#x27;.join(args_list)        print(f&#x27;[&#123;elapsed:&gt;2.8&#125;s], &#123;name&#125;(&#123;args_str&#125;)--&gt; &#123;res&#125;&#x27;)        return res    return clocked\n\n# a3_4_decorate_wraps_run.pyimport timefrom a3_4_decorate_wraps import clock@clockdef test_sleep(seconds, name=None):    time.sleep(seconds)@clockdef test_factorial(n, name=&quot;fi&quot;):    return 1 if n &lt; 2 else n * test_factorial(n - 1)if __name__ == &#x27;__main__&#x27;:    test_sleep(1.2, name=&#x27;xiaoming&#x27;)    test_factorial(6, name=&#x27;fi&#x27;)    print(test_sleep.__name__)  # test_sleep    print(test_factorial.__name__)  # test_factorial# [1.200119s], test_sleep(1.2, name=xiaoming)--&gt; None# [1.7e-06s], test_factorial(1)--&gt; 1# [6.01e-05s], test_factorial(2)--&gt; 2# [8.98e-05s], test_factorial(3)--&gt; 6# [0.0001158s], test_factorial(4)--&gt; 24# [0.0001468s], test_factorial(5, name=fi)--&gt; 120# test_sleep# test_factorial\n\n\n2. 标准库中的装饰器Python 内置了三个用于装饰方法的函数：property、classmethod 和 staticmethod。\n另一个常见的装饰器是 functools.wraps，它的作用是协助构建行为良好的装饰器。\n标 准 库 中 最 值 得 关 注 的 两 个 装 饰 器 是 lru_cache 和全新的singledispatch（Python 3.4 新增）。这两个装饰器都在 functools 模块中定义。\n2.1 使用functools.lru_cache做备忘functools.lru_cache 是非常实用的装饰器，它实现了备忘（memoization）功能。这是一项优化技术，它把耗时的函数的结果保存起来，避免传入相同的参数时重复计算。LRU 三个字母是“Least Recently Used”的缩写，表明缓存不会无限制增长，一段时间不用的缓存条目会被扔掉。\n生成第 n 个斐波纳契数这种慢速递归函数适合使用 lru_cache：\nfrom a3_4_decorate import clock@clockdef fibonacci(n):    if n &lt; 2:        return n    return fibonacci(n-2) + fibonacci(n-1)if __name__==&#x27;__main__&#x27;:    print(fibonacci(6))&#x27;&#x27;&#x27;[9e-07s], fibonacci(0)--&gt; 0[1.2e-06s], fibonacci(1)--&gt; 1[9.52e-05s], fibonacci(2)--&gt; 1[8e-07s], fibonacci(1)--&gt; 1[1e-06s], fibonacci(0)--&gt; 0[9e-07s], fibonacci(1)--&gt; 1[4.64e-05s], fibonacci(2)--&gt; 1[9.12e-05s], fibonacci(3)--&gt; 2[0.0002324s], fibonacci(4)--&gt; 33&#x27;&#x27;&#x27;\n\n这里生成第 n 个斐波纳契数，递归方式非常耗时，fibonacci(0) 调用了 2 次，fibonacci(1) 调用了 3 次……但是，\n如果增加两行代码，使用 lru_cache，使用缓存实现，速度更快，性能会显著改善。\nfrom functools import lru_cachefrom a3_4_decorate import clock@lru_cache()@clockdef fibonacci(n):    if n &lt; 2:        return n    return fibonacci(n-2) + fibonacci(n-1)if __name__==&#x27;__main__&#x27;:    print(fibonacci(4))&#x27;&#x27;&#x27;[1.6e-06s], fibonacci(0)--&gt; 0[2e-06s], fibonacci(1)--&gt; 1[0.0001693s], fibonacci(2)--&gt; 1[3.3e-06s], fibonacci(3)--&gt; 2[0.0002637s], fibonacci(4)--&gt; 33&#x27;&#x27;&#x27;\n\n需要注意的是：必须像常规函数那样调用 lru_cache。这一行中有一对括号：@functools.lru_cache()。这么做的原因是，lru_cache 可以接受配置参数。另外，这里叠放了装饰器：@lru_cache() 应用到 @clock 返回的函数上。\n特别要注意，lru_cache 可以使用两个可选的参数来配置。它的签名是：functools.lru_cache(maxsize&#x3D;128, typed&#x3D;False)：maxsize 参数指定存储多少个调用的结果。缓存满了之后，旧的结果会被扔掉，腾出空间。为了得到最佳性能，maxsize 应该设为 2 的幂。typed 参数如果设为 True，把不同参数类型得到的结果分开保存，即把通常认为相等的浮点数和整数参数（如 1 和 1.0）区分开。顺便说一下，因为 lru_cache 使用字典存储结果，而且键根据调用时传入的定位参数和关键字参数创建，所以被 lru_cache 装饰的函数，它的所有参数都必须是可散列的。\n\n2.2 单分派泛函数假设我们在开发一个调试 Web 应用的工具，我们想生成 HTML，显示不同类型的 Python对象。\nimport htmldef htmlize(obj):    content = html.escape(repr(obj))    return &#x27;&lt;pre&gt;&#123;&#125;&lt;/pre&gt;&#x27;.format(content)\n\n这个函数适用于任何 Python 类型，但是现在我们想做个扩展，让它使用特别的方式显示某些类型。\n\nstr：把内部的换行符替换为 &#39;&lt;br&gt;\\n&#39;；不使用 &lt;pre&gt;，而是使用 &lt;p&gt;。\n\nint：以十进制和十六进制显示数字。\n\nlist：输出一个 HTML 列表，根据各个元素的类型进行格式化。\n\n\n因为 Python 不支持重载方法或函数，所以我们不能使用不同的签名定义 htmlize 的变体，也无法使用不同的方式处理不同的数据类型。在 Python 中，一种常见的做法是把 htmlize变成一个分派函数，使用一串 if&#x2F;elif&#x2F;elif，调用专门的函数，如 htmlize_str、htmlize_int，等等。这样不便于模块的用户扩展，还显得笨拙：时间一长，分派函数 htmlize 会变得很大，而且它与各个专门函数之间的耦合也很紧密。\nPython 3.4 新增的 functools.singledispatch 装饰器可以把整体方案拆分成多个模块，甚至可以为你无法修改的类提供专门的函数。使用 @singledispatch 装饰的普通函数会变成泛函数（generic function）：根据第一个参数的类型，以不同方式执行相同操作的一组函数。\n# singledispatch 创建一个自定义的 htmlize.register 装饰器，# 把多个函数绑在一起组成一个泛函数from functools import singledispatchimport numbersimport htmlfrom collections import abc@singledispatch  # @singledispatch 标记处理 object 类型的基函数def htmlize(obj):    content = html.escape(repr(obj))    return &#x27;&lt;pre&gt;&#123;&#125;&lt;/pre&gt;&#x27;.format(content)@htmlize.register(str)def _(text):   # 专门函数的名称无关紧要；_ 是个不错的选择，简单明了。    content = html.escape(text).replace(&#x27;\\n&#x27;, &#x27;&lt;br&gt;\\n&#x27;)    return &#x27;&lt;p&gt;&#123;0&#125;&lt;/p&gt;&#x27;.format(content)@htmlize.register(numbers.Integral)def _(n):    return &#x27;&lt;pre&gt;&#123;0&#125; (0x&#123;0:x&#125;)&lt;/pre&gt;&#x27;.format(n)@htmlize.register(tuple)   # 可以叠放多个register装饰器，让同一个函数支持不同类型@htmlize.register(abc.MutableSequence)def _(seq):    inner = &#x27;&lt;/li&gt;\\n&lt;li&gt;&#x27;.join(htmlize(item) for item in seq)    return &#x27;&lt;ul&gt;\\n&lt;li&gt;&#x27; + inner + &#x27;&lt;/li&gt;\\n&lt;/ul&gt;&#x27;print(htmlize(&#123;1, 2, 3&#125;))  # &lt;pre&gt;&#123;1, 2, 3&#125;&lt;/pre&gt;print(htmlize(abs))  # &lt;pre&gt;&amp;lt;built-in function abs&amp;gt;&lt;/pre&gt;print(htmlize(&#x27;Heimlich &amp; Co.\\n- a game&#x27;))# &lt;p&gt;Heimlich &amp;amp; Co.&lt;br&gt;# - a game&lt;/p&gt;print(htmlize(42))  # &lt;pre&gt;42 (0x2a)&lt;/pre&gt;print(htmlize([&#x27;alpha&#x27;, 66, &#123;3, 2, 1&#125;]))# &lt;ul&gt;# &lt;li&gt;&lt;p&gt;alpha&lt;/p&gt;&lt;/li&gt;# &lt;li&gt;&lt;pre&gt;66 (0x42)&lt;/pre&gt;&lt;/li&gt;# &lt;li&gt;&lt;pre&gt;&#123;1, 2, 3&#125;&lt;/pre&gt;&lt;/li&gt;# &lt;/ul&gt;\n\n只要可能，注册的专门函数应该处理抽象基类（如 numbers.Integral 和 abc.MutableSequence），不要处理具体实现（如 int 和 list）。这样，代码支持的兼容类型更广泛。例如，Python扩展可以子类化numbers.Integral，使用固定的位数实现 int 类型。\nsingledispatch 机制的一个显著特征是，你可以在系统的任何地方和任何模块中注册专门函数。如果后来在新的模块中定义了新的类型，可以轻松地添加一个新的专门函数来处理那个类型。此外，你还可以为不是自己编写的或者不能修改的类添加自定义函数。\n\n3. 叠放装饰器把 @d1 和 @d2 两个装饰器按顺序应用到 f 函数上，作用相当于 f &#x3D; d1(d2(f))。\ndef d1(func):    def decorate():        pass    return decoratedef d2(func):    def decorate():        pass    return decorate@d1 @d2 def f():     print(&#x27;f&#x27;) # 等同于：def f():     print(&#x27;f&#x27;) f = d1(d2(f))\n\n\n4. 参数化装饰器解析源码中的装饰器时，Python 把被装饰的函数作为第一个参数传给装饰器函数。那怎么让装饰器接受其他参数呢？答案是：创建一个装饰器工厂函数，把参数传给它，返回一个装饰器，然后再把它应用到要装饰的函数上。\nregistry = set()def register(active=True):    def decorate(func):  # decorate 这个内部函数是真正的装饰器；它的参数是一个函数。        print(f&#x27;running register(active=&#123;active&#125;)-&gt;decorate(&#123;func&#125;)&#x27;)        if active:            registry.add(func)        else:            registry.discard(func)        return func  # decorate 是装饰器，必须返回一个函数。    return decorate  # register 是装饰器工厂函数，因此返回 decorate。@register(active=False)  # 为了接受参数，新的register装饰器必须作为函数调用。def f1():    print(&#x27;running f1()&#x27;)@register()def f2():    print(&#x27;running f2()&#x27;)def f3():    print(&#x27;running f3()&#x27;)if __name__ == &#x27;__main__&#x27;:    print(f&#x27;registry:&#123;registry&#125;&#x27;)    f1()    f2()    f3()    print(f&#x27;registry:&#123;registry&#125;&#x27;)    &#x27;&#x27;&#x27;running register(active=False)-&gt;decorate(&lt;function f1 at 0x000001EDB675B378&gt;)running register(active=True)-&gt;decorate(&lt;function f2 at 0x000001EDB675B400&gt;)registry:&#123;&lt;function f2 at 0x000001EDB675B400&gt;&#125;running f1()running f2()running f3()registry:&#123;&lt;function f2 at 0x000001EDB675B400&gt;&#125;&#x27;&#x27;&#x27;\n\n@register 工厂函数必须作为函数调用，并且传入所需的参数。即使不传入参数，register 也必须作为函数调用（@register()），即要返回真正的装饰器 decorate。\n关键是，register() 要返回 decorate，然后把它应用到被装饰的函数上。\n如果不使用 @ 句法，那就要像常规函数那样使用 register；若想把 f 添加到 registry中，则装饰 f 函数的句法是 register()(f)；不想添加（或把它删除）的话，句法是register(active&#x3D;False)(f)。\nfrom a3_5_decorate_parameter import register, registry, f1, f2, f3# running register(active=False)-&gt;decorate(&lt;function f1 at 0x000002183A36B400&gt;)# running register(active=True)-&gt;decorate(&lt;function f2 at 0x000002183A36B488&gt;)print(registry)# &#123;&lt;function f2 at 0x000002183A36B488&gt;&#125;register()(f3)# running register(active=True)-&gt;decorate(&lt;function f3 at 0x000002183A36B378&gt;)print(registry)# &#123;&lt;function f2 at 0x000002183A36B488&gt;, &lt;function f3 at 0x000002183A36B378&gt;&#125;register(active=False)(f2)# running register(active=False)-&gt;decorate(&lt;function f2 at 0x000002183A36B488&gt;)print(registry)# &#123;&lt;function f3 at 0x000002183A36B378&gt;&#125;\n\n\n5. 参数化clock装饰器为clock添加一个功能：让用户传入一个格式字符串，控制被装饰函数的输出。\nimport timeDEFAULT_FMT = &#x27;[&#123;elapsed:0.8f&#125;s] &#123;name&#125;(&#123;args&#125;) -&gt; &#123;result&#125;&#x27;def clock(fmt=DEFAULT_FMT):  # clock 是参数化装饰器工厂函数。    def decorate(func):\t\t\t# decorate 是真正的装饰器        def clocked(*args):\t\t# clocked 包装被装饰的函数            t0 = time.time()            _res = func(*args)            result = repr(_res)            elapsed = time.time() - t0            name = func.__name__            args_str = &#x27;, &#x27;.join(repr(arg) for arg in args)            print(fmt.format(**locals()))  # 使用 **locals() 是为了在 fmt 中引用 clocked 的局部变量            return _res        return clocked    return decorateif __name__ == &#x27;__main__&#x27;:    @clock()    def snooze(seconds):        time.sleep(seconds)    for i in range(3):        snooze(.123)&#x27;&#x27;&#x27;[0.12307549s] snooze((0.123,)) -&gt; None[0.12305403s] snooze((0.123,)) -&gt; None[0.12399721s] snooze((0.123,)) -&gt; None&#x27;&#x27;&#x27;\n\n@clock(&#x27;&#123;name&#125;: &#123;elapsed&#125;s&#x27;)def snooze(seconds):    time.sleep(seconds)# snooze: 0.12392497062683105s@clock(&#x27;&#123;name&#125;(&#123;args&#125;) dt=&#123;elapsed:0.3f&#125;s&#x27;)def snooze(seconds):    time.sleep(seconds)# snooze((0.123,)) dt=0.123s\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：字典","url":"/posts/2019/11/03/18765/","content":"泛映射类型dict 类型不但在各种程序里广泛使用，它也是 Python 语言的基石。模块的命名空间、实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在_builtins__.__dict__ 模块中。\n\n常见的字典方法\n如何处理查找不到的键 \n标准库中 dict 类型的变种\nset 和 frozenset 类型\n散列表的工作原理\n散列表带来的潜在影响（什么样的数据类型可作为键、不可预知的顺序，等等）\n\n标准库里的所有映射类型都是利用 dict 来实现的，因此它们有个共同的限制，即只有可散列的数据类型才能用作这些映射里的键（只有键有这个要求，值并不需要是可散列的数据类型）。\n什么是可散列的数据类型:\n如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 \t__hash__() 方法。另外可散列对象还要有__qe__()方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的……\n原子不可变数据类型（str、bytes 和数值类型）都是可散列类型，frozenset 也是可散列的，因为根据其定义，frozenset 里只能容纳可散列类型。元组的话，只有当一个元组包含的所有元素都是可散列类型的情况下，它才是可散列的。\ntu1 = (1,2,(3,4))hash(tu1)Out[3]: -2725224101759650258tu2 = (1,2,[3,4])hash(tu2)Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-28-fe78ef742d85&gt;&quot;, line 1, in &lt;module&gt;    hash(tu2)TypeError: unhashable type: &#x27;list&#x27;    frozenset1 = frozenset(range(3))frozenset1Out[3]: frozenset(&#123;0, 1, 2&#125;)tu2 = (1,2,frozenset1)hash(tu2)Out[4]: -2745387924187706777\n\n字典创建的不同方式：\na = dict(one=1,two=2,three=3)b = &#123;&#x27;one&#x27;:1,&#x27;two&#x27;:2,&#x27;three&#x27;:3&#125;c = dict(zip([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;],[1,2,3]))d = dict([(&#x27;one&#x27;,1),(&#x27;two&#x27;,2),(&#x27;three&#x27;,3)])a == b == c == d\n\n\n字典推导字典推导（dictcomp）可以从任何以键值对作为元素的可迭代对象中构建出字典。\ndict、collections.defaultdict和collections.OrderedDict这三种映射类型的方法列表（依然省略了继承自object的常见方法）；可选参数以[…]表示\n\n\n\n\ndict\ndefaultdict\nOrderedDict\n\n\n\n\nd.clear()\n√\n√\n√\n移除所有元素\n\n\nd.__contains__(k)\n√\n√\n√\n检查键k是否在d中\n\n\nd.copy()\n√\n√\n√\n浅复制\n\n\nd.__copy__()\n\n√\n\n用于支持copy.copy\n\n\nd.default_factoy\n\n√\n\n在__missing__函数中被调用的函数，用以未找到的元素设置值\n\n\nd.__delitem__(k)\n√\n√\n√\ndel d[k], 移除键为k的元素\n\n\nd.fromkeys(it, [initial])\n√\n√\n√\n将迭代器it里的元素设置为映射里的键，若有initial参数，就把它作为这些键对应的值（默认是None）\n\n\nd.get(k, [default])\n√\n√\n√\n返回键k对应的值，若字典里没有键k，则返回None或default\n\n\nd.__getitem__(k)\n√\n√\n√\n让字典d能用d[k]的形式返回键k对应的值\n\n\nd.items()\n√\n√\n√\n返回d里所有对的键值对\n\n\nd.__iter__()\n√\n√\n√\n获取键的迭代器\n\n\nd.keys()\n√\n√\n√\n获取所有的键\n\n\nd.__len__()\n√\n√\n√\n可用len(d)得到字典里键值对的数量\n\n\nd.__missing__(k)\n\n√\n\n当__getitem__找不到对应键时被调用\n\n\nd.move_to_end(k, [last])\n\n\n√\n把键为k的元素移动到最靠前或最靠后的位置（last的默认值为True）\n\n\nd.pop(k, [default])\n√\n√\n√\n返回键k所对应的值，然后移除这个键值对。若没有这个键，返回None或default\n\n\nd.popitem()\n√\n√\n√\n随机返回一个键值对，并从字典里移除它\n\n\nd.__reversed__()\n\n\n√\n返回倒序的键的迭代器\n\n\nd.setdefault(k, [default])\n√\n√\n√\n若字典里有键k，则把它对应的值设置为default，然后返回这个值；若无，则让d[k]&#x3D;default, 然后返回default\n\n\nd.__setitem__(k, v)\n√\n√\n√\n实现d[k]&#x3D;v操作，把k对应的值设为v\n\n\nd.update(m, [**kargs])\n√\n√\n√\nm可以是映射或键值对迭代器，用来更新d里对应的条目\n\n\nd.values()\n√\n√\n√\n返回字典里的所有值\n\n\n注：default_factory 并不是一个方法，而是一个可调用对象（callable），它的值在 defaultdict 初始化的时候由用户设定。 OrderedDict.popitem() 会移除字典里最先插入的元素（先进先出）；同时这个方法还有一个可选的 last 参数，若为真，则会移除最后插入的元素（后进先出）。\n\n用setdefault处理找不到的键当字典 d[k] 不能找到正确的键的时候，Python 会抛出异常，这个行为符合 Python 所信奉的“快速失败”哲学。可以用 d.get(k, default) 来代替 d[k]， 给找不到的键一个默认的返回值（这比处理 KeyError 要方便不少）。但是要更新某个键对应 的值的时候，不管使用 __getitem__ 还是 get 都会不自然，而且效率低。就像以下示例中的还没有经过优化的代码所显示的那样，dict.get 并不是处理找不到的键的最好方法。\n从索引中获取单词出现的频率信息，并把它们写进对应的列表里：\nimport sysimport reword_re = re.compile(r&#x27;\\w+&#x27;)index = &#123;&#125;# with open(sys.argv[1], encoding=&#x27;utf-8&#x27;) as f:with open(&#x27;test.py&#x27;, encoding=&#x27;utf-8&#x27;) as f:    for line_index, line in enumerate(f, 1):  # line_index从1开始        # print(line)        for match_obj in word_re.finditer(line):            # print(match_obj)            word = match_obj.group()            column_index = match_obj.start() + 1            location_tup = (line_index, column_index)            # word_list = index.get(word,[])            # word_list.append(location_tup)            # index[word] =word_list            # 获取单词的出现情况列表，如果单词不存在，把单词和一个空列表放进映射，            # 然后返回这个空列表，这样就能在不进行第二次查找的情况下更新列表了。            index.setdefault(word, []).append(location_tup)  # 优化后# 以字母顺序打印出结果for word in sorted(index, key=str.upper):    print(word, index[word])\n\n# index.setdefault(word, []).append(location_tup)的效果等价于以下，只不过至少两次键查询：if word not in index:  index[word] = []index[word].append(location_tup)\n\n如何单纯地查找取值（而不是通过查找来插入新值）？\n\n映射的弹性键查询\n通过defaultdict类型，而不是普通的dict\n自定义一个dict子类，在子类中实现__missing__方法\n\n1. 通过defaultdict类型，而不是普通的dict\n使用collections.defaultdict，在用户创建 defaultdict 对象的时候，就需要给它配置一个为找不到的键创造默认值的方法。在实例化一个 defaultdict 的时候，需要给构造方法提供一个可调用对象，这个可调用对象会在 __getitem__ 碰到找不到的键的时候被调用，让__getitem__返回某种默认值。如果在创建 defaultdict 的时候没有指定 default_factory，查询不存在的键会触发KeyError。\ndefaultdict 里的 default_factory 只会在__getitem__里被调用，在其他的 方法里完全不会发挥作用。比如，dd 是个 defaultdict，k 是个找不到的键，dd[k] 这个表达式会调用 default_factory 创造某个默认值，而 dd.get(k) 则会返回 None。\nimport reimport collectionsword_re = re.compile(r&#x27;\\w+&#x27;)index_dict = collections.defaultdict(list)  # 把list构造方法作为 default_factory 来创建一个 defaultdict。with open(&#x27;test.py&#x27;, encoding=&#x27;utf-8&#x27;) as f:    for line_index, line in enumerate(f, 1):        print(line)        for match_obj in word_re.finditer(line):            print(match_obj)            word = match_obj.group()            column_index = match_obj.start() + 1            location_tup = (line_index, column_index)            index_dict[word].append(location_tup)              # 若index_dict没有word，则default_factory会被调用，为查询不到的键创造一个值。            # 这个值在这里是一个空的列表，然后这个空列表被赋值给 index_dict[word]，            # 继而被当作返回值返回，因此 .append(location_tup) 操作总能成功。\n\n2. 自定义一个dict子类，在子类中实现__missing__方法\n# 在查询的时候把非字符串的键转换为字符串class StrKeyDict(dict):  # 继承dict    def __missing__(self, key):        if isinstance(key, str):            raise KeyError(key)  # 若找不到的键本身就是字符串，抛出异常        return self[str(key)]  # 否则，把它转换成字符串再查找    def get(self, key, default=None):        # get 方法把查找工作用 self[key] 的形式委托给 __getitem__，        # 在查找失败前，还能通过 __missing__ 再给某个键通过self[str(key)]查找的机会        try:            return self[key]        except KeyError:  # 若抛出KeyError，说明 __missing__ 也失败了，返回 default。            return default    def __contains__(self, key):        return key in self.keys() or str(key) in self.keys()strDict = StrKeyDict(&#123;&#x27;one&#x27;: 1, 2: 2, &#x27;3&#x27;: &#x27;three&#x27;&#125;)print(strDict[3])print(strDict.get(4, 0))\n\n为什么 isinstance(key, str) 在上面例子中是必需的。如果没有这个测试，只要 str(k) 返回的是一个存在的键，那么 __missing__ 方法是没问题的，不管是字符串键还是非字符串键，它都能正常运行。但是如果 str(k) 不是一个存在的键，代码就会陷入无限递归。这是因为 __missing__ 的最后一行中的 self[str(key)] 会调用 __getitem__，而这个 str(key) 又不存在，于是 __missing__ 又会被调用。\n为了保持一致性，__contains__ 方法在这里也是必需的。这是因为 key in dict 操作会调用它，但是我们从 dict 继承到的__contains__方法不会在找不到键的时候调用 __missing__方法。__contains__ 里还有个细节，就是我们这里没有用更具 Python 风格的方式——k in my_dict——来检查键是否存在，因为那也会导致 __contains__ 被递归调用。为了避免这一情况，这里采取了更显式的方法，直接在这个 self.keys() 里查询。\n\n字典的变种标准库里 collections 模块中，除了 defaultdict 之外的不同映射类型：\n\ncollections.OrderedDict\n这个类型在添加键的时候会保持顺序，因此键的迭代次序总是一致的。OrderedDict 的 popitem 方法默认删除并返回的是字典里的最后一个元素，但是如果像 my_odict.popitem(last&#x3D;False) 这样调用它，那么它删除并返回第一个被添加进去的元素。 \n\ncollections.ChainMap\n该类型可以容纳数个不同的映射对象，然后在进行键查找操作的时候，这些对象会被当作一个整体被逐个查找，直到键被找到为止。\n\ncolllections.Counter\n这个映射类型会给键准备一个整数计数器。每次更新一个键的时候都会增加这个计数器。所以这个类型可以用来给可散列表对象计数，或者是当成多重集来用——多重集合就是集合里的元素可以出现不止一次。Counter 实现了 + 和 - 运算符用来合并记录，还有像 most_common([n]) 这类很有用的方法。most_common([n]) 会按照次序返回映射里最常见的 n 个键和它们的计数\nc = collections.Counter(&#x27;qwerqwewqq&#x27;)cOut[3]: Counter(&#123;&#x27;q&#x27;: 4, &#x27;w&#x27;: 3, &#x27;e&#x27;: 2, &#x27;r&#x27;: 1&#125;)c.update(&#x27;abaaa&#x27;)cOut[4]: Counter(&#123;&#x27;q&#x27;: 4, &#x27;w&#x27;: 3, &#x27;e&#x27;: 2, &#x27;r&#x27;: 1, &#x27;a&#x27;: 4, &#x27;b&#x27;: 1&#125;)c.most_common(2)Out[5]: [(&#x27;q&#x27;, 4), (&#x27;a&#x27;, 4)]colllections.UserDict \n\ncolllections.UserDict \n这个类其实就是把标准 dict 用纯 Python 又实现了一遍。跟 OrderedDict、ChainMap 和 Counter 这些开箱即用的类型不同，UserDict 是让用户继承写子类的。\n\n\n\n不可变映射类型标准库里所有的映射类型都是可变的，但有时候你会有这样的需求，比如不能让用户错误地修改某个映射。\n从 Python 3.3 开始，types 模块中引入了一个封装类名叫 MappingProxyType。如果给这个类一个映射，它会返回一个只读的映射视图。虽然是个只读视图，但是它是动态的。这意味着如果对原映射做出了改动，我们通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。\nfrom types import MappingProxyTypeadict = &#123;1:&#x27;A&#x27;, 2:&#x27;B&#x27;&#125;adict_proxy = MappingProxyType(adict)adict_proxyOut[3]: mappingproxy(&#123;1: &#x27;A&#x27;, 2: &#x27;B&#x27;&#125;)  adict_proxy[1]Out[4]: &#x27;A&#x27;adict_proxy[2]Out[5]: &#x27;B&#x27;adict_proxy[2] = &quot;c&quot;Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-145-372f87dbe97b&gt;&quot;, line 1, in &lt;module&gt;    adict_proxy[2] = &quot;c&quot;TypeError: &#x27;mappingproxy&#x27; object does not support item assignment  adict[2] = &#x27;C&#x27;adict_proxyOut[6]: mappingproxy(&#123;1: &#x27;A&#x27;, 2: &#x27;C&#x27;&#125;)adict_proxy[2]Out[7]: &#x27;C&#x27;\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python对象引用、可变性和垃圾回收","url":"/posts/2019/12/21/23193/","content":"1. 变量不是盒子人们经常使用“变量是盒子”这样的比喻解释变量，但是这有碍于理解面向对象语言中的引用式变量。Python 变量类似于 Java 中的引用式变量，因此最好把它们理解为附加在对象上的标注。\nclass Gi():    def __init__(self):        print(f&#x27;Gi id:&#123;id(self)&#125;&#x27;)        gi = Gi()# Gi id:2323558943432gi2 = Gi()# Gi id:2323559105872\n\n变量只不过是标注，所以无法阻止为对象贴上多个标注。贴的多个标注，就是别名。\n\n2. 标识、相等性和别名tom = &#123;&#x27;name&#x27;:&#x27;TOM&#x27;, &#x27;age&#x27;:10, &#x27;sex&#x27;:&#x27;m&#x27;&#125;tomy = tomtomy is tom# Trueid(tomy), id(tom)# (2323559005352, 2323559005352)tomy == tom# True  tam = &#123;&#x27;name&#x27;:&#x27;TOM&#x27;, &#x27;age&#x27;:10, &#x27;sex&#x27;:&#x27;m&#x27;&#125;tom is tam# Falseid(tom), id(tam)# (2323559005352, 2323558896264)tom == tam# True\n\ntomy和tom 是别名，即两个变量绑定同一个对象&#123;&#39;name&#39;:&#39;TOM&#39;, &#39;age&#39;:10, &#39;sex&#39;:&#39;m&#39;&#125;。而 tam 不是 tom的别名，因为二者绑定的是不同的对象。tam 和 tom 绑定的对象具有相同的值（&#x3D;&#x3D; 比较的就是值），但是它们的标识不同。\n每个变量都有标识、类型和值。\n\n对象一旦创建，它的标识绝不会变；\n可以把标识理解为对象在内存中的地址。\nis 运算符比较两个对象的标识；\nid() 函数返回对象标识的整数表示。\n\n编程中很少使用 id() 函数。标识最常使用 is 运算符检查，而不是直接比较 ID。\n\n3. 在**&#x3D;&#x3D;**和is之间选择&#x3D;&#x3D; 运算符比较两个对象的值（对象中保存的数据），而 is 比较对象的标识。\n通常，我们关注的是值，而不是标识，因此 Python 代码中 &#x3D;&#x3D; 出现的频率比 is 高。\n在变量和单例值之间比较时，应该使用 is。目前，最常使用 is 检查变量绑定的值是不是 None。推荐的写法：x is None，否定的正确写法是：x is not None 。\nis 运算符比 &#x3D;&#x3D; 速度快，因为它不能重载，所以 Python 不用寻找并调用特殊方法，而是直接比较两个整数 ID。而 a &#x3D;&#x3D; b 是语法糖，等同于 a.__eq__(b)。继承自 object 的 __eq__方法比较两个对象的 ID，结果与 is 一样。但是多数内置类型使用更有意义的方式覆盖了__eq__ 方法，会考虑对象属性的值。相等性测试可能涉及大量处理工作，例如，比较大型集合或嵌套层级深的结构时。\n\n4. 元组的相对不可变性元组与多数 Python 集合（列表、字典、集，等等）一样，保存的是对象的引用。如果引用的元素是可变的，即便元组本身不可变，元素依然可变。也就是说，元组的不可变性其实是指 tuple 数据结构的物理内容（即保存的引用）不可变，与引用的对象无关。\nt1 = (1,2,[3,4,5])t2 = (1,2,[3,4,5])t1 == t2# Trueid(t1[-1])  # 2323559065032t1[-1].append(0)   # t1 不可变，但是 t1[-1] 可变id(t1[-1])# 2323559065032   t1[-1] 的标识没变t1 == t2  # False   t1[-1]只是值变了, 导致t1不等于t2。\n\n可以说，元组具有相对不可变性，这也是有些元组（元素中有可变的类型）不可散列的原因。\n\n5. 默认做浅复制复制列表（或多数内置的可变集合）最简单的方式是使用内置的类型构造方法。\nl1 = [1, [2, 3, 4], (5, 6, 7)]l2 = list(l1)l1 is l2# Falsel1 == l2# Trueid(l1), id(l2)# (2323559065672, 2323561081096)\n\n对列表和其他可变序列来说，还能使用简洁的 l2 &#x3D; l1[:] 语句创建副本。然而，构造方法或 [:] 做的是浅复制（即复制了最外层容器，副本中的元素是源容器中元素的引用）。如果所有元素都是不可变的，那么这样没有问题，还能节省内存。但是，如果有可变的元素，可能就会导致意想不到的问题。\nl1 = [3, [66, 55, 44], (7, 8, 9)]l2 = list(l1)l1.append(100)l1[1].remove(55)  # l2[1] 绑定的列表与 l1[1] 是同一个print(&#x27;l1:&#x27;, l1) print(&#x27;l2:&#x27;, l2)# l1: [3, [66, 44], (7, 8, 9), 100]# l2: [3, [66, 44], (7, 8, 9)]l2[1] += [33, 22]   # += 运算符就地修改列表l2[2] += (10, 11)   # += 运算符创建一个新元组，然后重新绑定给变量 l2[2]print(&#x27;l1:&#x27;, l1) print(&#x27;l2:&#x27;, l2)# l1: [3, [66, 44, 33, 22], (7, 8, 9), 100]# l2: [3, [66, 44, 33, 22], (7, 8, 9, 10, 11)]\n\n\n6.为任意对象做深复制和浅复制演示 copy() 和 deepcopy() 的用法：\nimport copyclass Bus(object):    def __init__(self, passengers = None):        if passengers is None:            self.passagers = []        else:            self.passagers = list(passengers)    def up(self, someone):        if someone in self.passagers:            assert 0, f&#x27;&#123;someone&#125; is in bus already&#x27;        self.passagers.append(someone)    def down(self, someone):        if someone not in self.passagers:            assert 0, f&#x27;&#123;someone&#125; is not in bus now&#x27;        self.passagers.remove(someone)        bus1 = Bus([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;])bus2 = copy.copy(bus1)   # 浅复制副本（bus2）bus3 = copy.deepcopy(bus1)  # 是深复制副本（bus3）\n\nid(bus1), id(bus2), id(bus3)# (2057602206352, 2057602063440, 2057602206296)id(bus1.passagers), id(bus2.passagers), id(bus3.passagers)# (2057599601928, 2057599601928, 2057599601736)bus1.down(&#x27;d&#x27;)print(bus1.passagers, bus2.passagers, bus3.passagers)# [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]\n\n观察 passengers 属性后发现，bus1 和 bus2 共享同一个列表对象，因为 bus2 是 bus1 的浅复制副本。bus3 是 bus1 的深复制副本，因此它的 passengers 属性指代另一个列表。\n一般来说，深复制不是件简单的事。如果对象有循环引用，那么这个朴素的算法会进入无限循环。deepcopy 函数会记住已经复制的对象，因此能优雅地处理循环引用。\na = [1,2]b = [a, 0]a.append(b)a# [1, 2, [[...], 0]]\n\n\n7. 函数的参数作为引用时Python 唯一支持的参数传递模式是 共享传参（call by sharing）。多数面向对象语言都采用这一模式，包括 Ruby、Smalltalk 和 Java（Java 的引用类型是这样，基本类型按值传参）。\n共享传参指函数的各个形式参数获得实参中各个引用的副本。也就是说，函数内部的形参是实参的别名。\n这种方案的结果是，函数可能会修改作为参数传入的可变对象，但是无法修改那些对象的标识（即不能把一个对象替换成另一个对象）。\ndef test(a, b):    a += b    return a  x, y = 1, 2test(x, y)# 3x, y# (1, 2)lx, ly = [1,2], [3,4]test(lx, ly)# [1, 2, 3, 4]lx, ly# ([1, 2, 3, 4], [3, 4])t1, t2 = (1,2), (3,4)test(t1, t2)# (1, 2, 3, 4)t1, t2# ((1, 2), (3, 4))\n\n不要使用可变类型作为参数的默认值可选参数可以有默认值，这是 Python 函数定义的一个很棒的特性，这样我们的 API 在进化的同时能保证向后兼容。然而，我们应该避免使用可变的对象作为参数的默认值。\nclass Bus(object):    def __init__(self, passengers = []):        self.passagers = passengers    def up(self, someone):        self.passagers.append(someone)    def down(self, someone):        self.passagers.remove(someone)        bus1 = Bus([&#x27;A&#x27;, &#x27;B&#x27;])bus1.passagersOut[3]: [&#x27;A&#x27;, &#x27;B&#x27;]bus1.up(&#x27;C&#x27;)bus1.down(&#x27;A&#x27;)bus1.passagersOut[6]: [&#x27;B&#x27;, &#x27;C&#x27;]  bus2 = Bus()bus2.passagersOut[8]: []bus2.up(&#x27;D&#x27;)bus2.passagersOut[10]: [&#x27;D&#x27;]  bus3 = Bus()bus3.passagersOut[12]: [&#x27;D&#x27;]bus3.up(&#x27;E&#x27;)bus2.passagersOut[14]: [&#x27;D&#x27;, &#x27;E&#x27;]   # 登上bus3的E在bus2中  bus2.passagers is bus3.passagers  # bus2.passagers 和bus3.passagers 指代同一个列表Out[15]: Truebus1.passagersOut[16]: [&#x27;B&#x27;, &#x27;C&#x27;]  # bus1.passagers 是不同的列表\n\n问题在于，没有指定初始乘客的 Bus 实例会共享同一个乘客列表。\t\n实例化 Bus 时，如果传入乘客，会按预期运作。但是不为 Bus 指定乘客的话，奇怪的事就发生了，这是因为 self.passengers 变成了 passengers 参数默认值的别名。出现这个问题的根源是，默认值在定义函数时计算（通常在加载模块时），因此默认值变成了函数对象的属性。因此，如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会受到影响。\n 审 查Bus.__init__ 对 象， 看 看 它 的__defaults__属性中的元素：\nBus.__init__.__defaults__Out[18]: ([&#x27;D&#x27;, &#x27;E&#x27;],)\n\n可以验证 bus2.passengers 是一个别名，它绑定到Bus.__init__.__defaults__ 属性的第一个元素上：\nBus.__init__.__defaults__[0] is bus2.passagersOut[19]: TrueBus.__init__.__defaults__[0] is bus3.passagersOut[20]: True\n\n可变默认值导致的这个问题说明了为什么通常使用 None 作为接收可变值的参数的默认值 （我的理解：之前的正确代码是通过 if passengers is None判断 passengers 是否为空，如果为空，通过self.passagers &#x3D; [] 空列表赋值给self.passagers， 这样就在函数体里面执行，而不是在def定义时执行，空列表也就不会成为函数对象的属性了）。在之前正确的示例中，__init__ 方法检查 passengers 参数的值是不是 None，如果是就把一个新的空列表赋值给 self.passengers。如果 passengers 不是 None，正确的实现会把 passengers 的副本赋值给 self.passengers。\n\n8. 防御可变参数如果定义的函数接收可变参数，应谨慎考虑调用方是否期望修改传入的参数。\n例如，若函数接收一个字典，且在处理的过程中要修改它，那么这个副作用要不要体现到函数外部？应该具体情况具体分析。\nclass Bus(object):    def __init__(self, passengers = None):        if passengers  is None:            self.passengers  = []        else:            self.passengers  = passengers   # 这里不是list(passengers)    def up(self, someone):        self.passengers .append(someone)    def down(self, someone):        self.passengers .remove(someone)        team = [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;]bus = Bus(team)bus.passengers # [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;]bus.down(&#x27;A&#x27;)bus.down(&#x27;B&#x27;)bus.passengers # [&#x27;C&#x27;, &#x27;D&#x27;]team# [&#x27;C&#x27;, &#x27;D&#x27;]\n\nA、B从bus下车后，team的成员名单竟然也变了！  \nBus 类中__init__方法中把 self.passengers 变成 passengers 的别名，而实例化bus后把self.passengers是传给__init__方法的实参的别名team。在 self.passengers 上调用 .remove() 和 .append() 方法其实会修改传给构造方法的那个列表。\n这里的问题是: 校车Bus 为传给构造方法的列表创建了别名。正确的做法是，校车自己只维护乘客列表。修正的方法：在 __init__ 中，传入 passengers 参数时，应该把参数值的副本赋值给 self.passengers， 比如使用list(passengers)。另外，此时传给 passengers 参数的值可以是元组或任何其他可迭代对象，例如set 对象，甚至数据库查询结果，因为 list 构造方法接受任何可迭代对象。自己创建并管理列表可以确保支持所需的 .remove() 和 .append() 操作，这样 .pick() 和 .drop() 方法才能正常运作。\n小结：除非当前方法确实想修改通过参数传入的对象，否则在类中直接把参数赋值给实例变量之前，一定要三思，因为这样会为参数对象创建 别名 。如果不确定，那就创建副本。\n\n9. del和垃圾回收对象绝不会自行销毁；然而，无法得到对象时，可能会被当作垃圾回收。\ndel 语句删除名称，而不是对象。del 命令可能会导致对象被当作垃圾回收，但是仅当删除的变量保存的是对象的最后一个引用，或者无法得到对象时。重新绑定也可能会导致对象的引用数量归零，导致对象被销毁。\n有个__del__特殊方法，但是它不会销毁实例，不应该在代码中调用。即将销毁实例时，Python 解释器会调用 __del__ 方法，给实例最后的机会，释放外部资源。\n在 CPython 中，垃圾回收使用的主要算法是引用计数。实际上，每个对象都会统计有多少引用指向自己。当引用计数归零时，对象立即就被销毁：CPython 会在对象上调用 __del__方法（如果定义了），然后释放分配给对象的内存。CPython 2.0 增加了分代垃圾回收算法，用于检测引用循环中涉及的对象组——如果一组对象之间全是相互引用，即使再出色的引用方式也会导致组中的对象不可获取。Python 的其他实现有更复杂的垃圾回收程序，而且不依赖引用计数，这意味着，对象的引用数量为零时可能不会立即调用__del__方法。\n示例：使用 weakref.finalize 注册一个回调函数，在销毁对象时调用，来演示对象生命结束的情形。\nimport weakrefs1 = &#123;1,2,3&#125;s2 = s1    \t# s1和s2是别名，指向同一个集合&#123;1, 2, 3&#125;def bye():   # 这个函数一定不能是要销毁的对象的绑定方法，否则会有一个指向对象的引用。    print(&#x27;bye~&#x27;)  # 在 s1 引用的对象上注册 bye 回调    ender = weakref.finalize(s1, bye)  ender.alive# Truedel s1ender.alive  # del 不删除对象，而是删除对象的引用。# Trues2 = &#x27;new s2&#x27;# bye~# 重新绑定最后一个引用 s2，让 &#123;1, 2, 3&#125; 无法获取。对象被销毁了# 调用了 bye 回调，ender.alive 的值变成了 False。\n\n\n10. 弱引用正是因为有引用，对象才会在内存中存在。当对象的引用数量归零后，垃圾回收程序会把对象销毁。但是，有时需要引用对象，而不让对象存在的时间超过所需时间。这经常用在缓存中。\n弱引用不会增加对象的引用数量。引用的目标对象称为所指对象（referent）。因此我们说，弱引用不会妨碍所指对象被当作垃圾回收。\n弱引用在缓存应用中很有用，因为我们不想仅因为被缓存引用着而始终保存缓存对象。\nWeakValueDictionary简介：WeakValueDictionary 类实现的是一种可变映射，里面的值是对象的弱引用。被引用的对象在程序中的其他地方被当作垃圾回收后，对应的键会自动从 WeakValueDictionary 中删除。因此，WeakValueDictionary 经常用于缓存。\nimport weakrefclass Cheese():    def __init__(self, kind):        self.kind = kind    def __repr__(self):        return f&#x27;Chess-&#123;self.kind&#125;&#x27;stock = weakref.WeakValueDictionary()  # stock 是 WeakValueDictionary 实例。catalog = [Cheese(&#x27;Leicester&#x27;), Cheese(&#x27;Tilsit&#x27;), Cheese(&#x27;Brie&#x27;), Cheese(&#x27;Parmesan&#x27;)]for cheese in catalog:    stock[cheese.kind] = cheese  # stock把奶酪的名称映射到catalog中Cheese实例的弱引用上del catalogprint(sorted(stock.keys()))   # [&#x27;Parmesan&#x27;]del cheeseprint(sorted(stock.keys()))   # []\n\n删除 catalog 之后，stock 中的大多数奶酪都不见了，这是 WeakValueDictionary 的预期行为。\nfor cheese in catalog，临时变量cheese引用了对象，这可能会导致该变量的存在时间比预期长。通常，这对局部变量来说不是问题，因为它们在函数返回时会被销毁。但是在示例中，for 循环中的变量 cheese 是全局变量，除非显式删除，否则不会消失。\n\n11. 弱引用的局限不是每个 Python 对象都可以作为弱引用的目标（或称所指对象）。基本的 list 和 dict 实例不能作为所指对象，但是它们的子类可以轻松地解决这个问题：\nli = range(10)ref = weakref.ref(li)Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-15-740a7eb0b541&gt;&quot;, line 1, in &lt;module&gt;    ref = weakref.ref(li)TypeError: cannot create weak reference to &#x27;range&#x27; object  class Mylist(list):    passmyli = Mylist(range(10))myref = weakref.ref(myli)\n\nset 实例可以作为所指对象，因此上面的那个示例才使用 set 实例。用户定义的类型也没问题，这就解释了为什么使用那个简单的 Cheese 类。但是，int 和 tuple 实例不能作为弱引用的目标，甚至它们的子类也不行。\n\n12. Python对不可变类型施加的把戏通过前面的学习，我知道对于列表，如列表li，li[:]会创建一个副本，而list(li)返回一个对象的引用。\nli = [1,2,3]li2 = li[:]  # 创建副本li is li2# Falseli3 = list(li)  # 创建副本li3 is li# Falseli4 = li li4 is li# True\n\n对元组 t ，t[:] 不创建副本，而是返回同一个对象的引用。此外，tuple(t) 获得的也是同一个元组的引用。\nt = (1,2,3)t2 = t[:]t2 is t# Truet3 = tuple(t)t3 is t# Truet4 = t t4 is t# True\n\nstr、bytes 和 frozenset 实例也有这种行为。注意，frozenset 实例不是序列，因此不能使用 fs[:]（fs 是一个 frozenset 实例），但是fs.copy() 具有相同的效果：它会欺骗你，返回同一个对象的引用，而不是创建一个副本。\n字符串字面量可能会创建共享的对象：\nt = (1,2,3)t2 = (1,2,3)t2 is t# Falsel = [1,2,3]l2 = [1,2,3]l2 is l# Falses = &#x27;abc&#x27;s1 = &#x27;abc&#x27;s1 is s# True\n\n共享字符串字面量是一种优化措施，称为驻留（interning）。CPython 还会在小的整数上使用这个优化措施，防止重复创建“热门”数字，如 0、—1 和 42。注意，CPython 不会驻留所有字符串和整数，驻留的条件是实现细节，而且没有文档说明。\n千万不要依赖字符串或整数的驻留！比较字符串或整数是否相等时，应该使用 &#x3D;&#x3D;，而不是 is。驻留是 Python 解释器内部使用的一个特性。\n\n13. 小结\n每个 Python 对象都有标识、类型和值。只有对象的值会不时变化。\n\n如果两个变量指代的 不可变对象  具有相同的值（a &#x3D;&#x3D; b 为 True），实际上它们指代的是副本还是同一个对象的别名基本没什么关系，因为不可变对象的值不会变。但有一个例外：不可变的集合，如 元组  和 frozenset ：如果不可变集合保存的是可变元素的引用，那么可变元素的值发生变化后，不可变集合也会随之改变。实际上，这种情况不是很常见。不可变集合不变的是所含对象的标识。\n\n变量保存的是引用，这一点对 Python 编程有很多实际的影响。\n\n简单的赋值不创建副本。\n对 +&#x3D; 或 *&#x3D; 所做的增量赋值来说，如果左边的变量绑定的是不可变对象，会创建新对象；如果是可变对象，会就地修改。\n为现有的变量赋予新值，不会修改之前绑定的变量。这叫重新绑定：现在变量绑定了其他对象。如果变量是之前那个对象的最后一个引用，对象会被当作垃圾回收。\n函数的参数以别名的形式传递，这意味着，函数可能会修改通过参数传入的可变对象。这一行为无法避免，除非在本地创建副本，或者使用不可变对象（例如，传入元组，而不传入列表）。\n使用可变类型作为函数参数的默认值有危险，因为如果就地修改了参数，默认值也就变了，这会影响以后使用默认值的调用。\n\n\n在 CPython 中，对象的引用数量归零后，对象会被立即销毁。如果除了循环引用之外没有其他引用，两个对象都会被销毁。某些情况下，可能需要保存对象的引用，但不留存对象本身。例如，有一个类想要记录所有实例。这个需求可以使用弱引用实现，这是一种低层机制，是 weakref 模块中 WeakValueDictionary、WeakKeyDictionary 和 WeakSet 等有用的集合类，以及 finalize 函数的底层支持。\n\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：把函数视作对象之一等函数","url":"/posts/2019/11/24/21030/","content":"1. 一等函数Python 中，函数是一等对象。编程语言理论家把“一等对象”定义为满足下述条件的程序实体： \n\n在运行时创建\n能赋值给变量或数据结构中的元素 \n能作为参数传给函数 \n能作为函数的返回结果\n\n在 Python 中，整数、字符串和字典都是一等对象。函数也可以作为一等对象。\ndef factorial(n):    &quot;&quot;&quot;    阶乘    :param n: num     :return: num!    &quot;&quot;&quot;    return 1 if n &lt; 1 else n * factorial(n-1)  factorial.__doc__Out[2]: &#x27;\\n    阶乘\\n    :param n: num \\n    :return: num!\\n    &#x27;factorial(30)Out[3]: 265252859812191058636308480000000type(factorial)Out[4]: function\n\n这是一个控制台会话，def factorial(n):是在“运行时”创建一个函数。__doc__ 是函数对象众多属性中的一个。  factorial 是 function 类的实例。\n函数对象的“一等”本性:我们可以把 factorial 函数赋值给变量 fact，然后通过变量名调用。我们还能把它作为参数传给 map 函数。map 函数返回一个可迭代对象，里面的元素是把第一个参数（一个函数）应用到第二个参数（一个可迭代对象，这里 是 range(11)）中各个元素上得到的结果。\n# 通过别的名称使用函数，再把函数作为参数传递fact = factorialfact(5)Out[5]: 120type(fact)Out[6]: function  map(fact, range(5))Out[7]: &lt;map at 0x212ba2663c8&gt;list(map(fact, range(5)))Out[8]: [1, 1, 2, 6, 24]\n\n有了一等函数，就可以使用函数式风格编程。函数式编程的特点之一是使用高阶函数。\n\n2. 高阶函数接受函数为参数，或者把函数作为结果返回的函数是高阶函数（higher-order function）。在函数式编程范式中，最为人熟知的高阶函数有 map、filter、reduce。\n此外，内置函数 sorted 也是：可选的 key 参数用于提供一个函数，它会应用到各个元素上进行排序。\ndef reverse(word):     return word[::-1] fruits = [&#x27;strawberry&#x27;, &#x27;fig&#x27;, &#x27;apple&#x27;, &#x27;cherry&#x27;, &#x27;raspberry&#x27;, &#x27;banana&#x27;]sorted(fruits, key=reverse)Out[16]: [&#x27;banana&#x27;, &#x27;apple&#x27;, &#x27;fig&#x27;, &#x27;raspberry&#x27;, &#x27;strawberry&#x27;, &#x27;cherry&#x27;]\n\nmap、filter和reduce的现代替代品：\nmap 和 filter 还是内置函数，但是由于引入了列表推导和生成器表达式，它们变得没那么重要了。列表推导或生成器表达式具有 map 和 filter 两个函数的功能，而且更易于阅读。\n# Python3 中，map 和 filter 返回生成器（一种迭代器），因此现在它们的直接替代品是生成器表达式list(map(fact,range(6)))Out[17]: [1, 1, 2, 6, 24, 120][fact(n) for n in range(6)]   # 使用列表推导执行相同的操作。Out[18]: [1, 1, 2, 6, 24, 120]  list(map(fact, filter(lambda n:n%2, range(6))))Out[19]: [1, 6, 120][fact(n) for n in range(6) if n%2]  # 列表推导式，取代map、filter，并避免了lambda 表达式Out[20]: [1, 6, 120]\n\n# 在 Python2中，reduce 是内置函数，但是在 Python3 中放到 functools 模块里了。# 这个函数最常用于求和，自2003年发布的 Python2.3开始，最好使用内置的sum函数。# 在可读性和性能方面，这是一项重大改善.from functools import reducefrom operator import addreduce(add, range(6))Out[25]: 15\n\nsum 和 reduce 的通用思想是把某个操作连续应用到序列的元素上，累计之前的结果，把一系列值归约成一个值。all 和 any 也是内置的归约函数。\nall(iterable):  如果 iterable 的每个元素都是真值，返回 True；all([]) 返回 True。 有0即为假\nany(iterable) : 只要 iterable 中有元素是真值，就返回 True；any([]) 返回 False。 有1即为真\nPython 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;copyright&quot;, &quot;credits&quot; or &quot;license()&quot; for more information.&gt;&gt;&gt; all([1,0])False&gt;&gt;&gt; all([1])True&gt;&gt;&gt; all([])True&gt;&gt;&gt; any([1,0])True&gt;&gt;&gt; any([0])False&gt;&gt;&gt; any([])False\n\n\n3. 可调用对象除了用户定义的函数，调用运算符（即 ()）还可以应用到其他对象上。如果想判断对象能否调用，可以使用内置的 callable() 函数。Python 数据模型文档列出了 7 种可调用对象。\n\n用户定义的函数 \n使用 def 语句或 lambda 表达式创建。\n\n内置函数\n使用 C 语言（CPython）实现的函数，如 len 或 time.strftime。\n\n内置方法 \n使用 C 语言实现的方法，如 dict.get。\n\n方法 \n在类的定义体中定义的函数。 \n\n类 \n调用类时会运行类的 __new__ 方法创建一个实例，然后运行__init__方法，初始化实例，最后把实例返回给调用方。因为 Python 没有 new 运算符，所以调用类相当于调用函数。（通常，调用类会创建那个类的实例，不过覆盖 __new__ 方法的话，也可能出现 其他行为。）\n\n类的实例 \n如果类定义了__call__方法，那么它的实例可以作为函数调用。\n\n生成器函数 \n使用 yield 关键字的函数或方法。调用生成器函数返回的是生成器对象。\n\n\nPython 中有各种各样可调用的类型，因此判断对象能否调用，最安全的方法是使用内置的 callable() 函数： \n&gt;&gt;&gt; [callable(item) for item in [str, abs, 100]][True, True, False]\n\n\n\n4. 用户可调用的类型不仅 Python 函数是真正的对象，任何 Python 对象都可以表现得像函数。为此，只需实现实例方法 __call__。\nimport randomclass BingoCase(object):    def __init__(self, items):        self._items = list(items)        random.shuffle(self._items)    def pickitem(self):        try:            return self._items.pop()        except IndexError as e:            raise LookupError(&#x27;pick from empty BingoCase&#x27;)    def __call__(self, *args, **kwargs):  # bingo.pickitem()的快捷方式为bingo()        return self.pickitem()bingo = BingoCase([1, 2, 3, 3, 4, 5])print(bingo.pickitem())print(bingo())print(callable(bingo))\n\n实现__call__方法的类是创建函数类对象的简便方式，此时必须在内部维护一个状态，让它在调用之间可用，例如 BingoCage 中的剩余元素。装饰器就是这样，有时要在多次调用之间“记住”某些事（例如备忘memoization），即缓存消耗大的计算结果，供后面使用。\n创建保有内部状态的函数，还有一种截然不同的方式——闭包。\n\n5. 函数注解Python3提供了一种句法，用于为函数声明中的参数和返回值附加元数据。\ndef clip(text: str, max_len: &#x27;int &gt; 0&#x27; = 8) -&gt; str:  # 有注解的函数声明    &quot;&quot;&quot;    在max_len前面或后面的第一个空格处截断文本    &quot;&quot;&quot;    end = None    space_before = space_after = &#x27;&#x27;    if len(text) &gt; max_len:        space_before = text.rfind(&#x27; &#x27;, 0, max_len)        print(space_before)        if space_before &gt;= 0:            end = space_before        else:            space_after = text.rfind(&#x27; &#x27;, max_len)            print(space_after)            if space_after &gt;= 0:                end = space_after    if end is None:  # 没找到空格        end = len(text)    return text[:end].rstrip()print(clip(&quot;1adsfd2sdfjkl 3dsfa 4jskldf&quot;))print(clip.__annotations__)&#x27;&#x27;&#x27;1adsfd2sdfjkl 3dsfa&#123;&#x27;text&#x27;: &lt;class &#x27;str&#x27;&gt;, &#x27;max_len&#x27;: &#x27;int &gt; 0&#x27;, &#x27;return&#x27;: &lt;class &#x27;str&#x27;&gt;&#125;&#x27;&#x27;&#x27;\n\n函数声明中的各个参数可以在 : 之后增加注解表达式。如果参数有默认值，注解放在参数名和 &#x3D; 号之间。如果想注解返回值，在 ) 和函数声明末尾的 : 之间添加 -&gt; 和一个表达式。那个表达式可以是任何类型。注解中最常用的类型是类（如 str 或 int）和字符串（如’int &gt; 0’）。在示例中，max_len 参数的注解用的是字符串。\n注解不会做任何处理，只是存储在函数的 __annotations__ 属性（一个字典）中。\nPython 对注解所做的唯一的事情是，把它们存储在函数的 __annotations__ 属性里。仅此而已，Python 不做检查、不做强制、不做验证，什么操作都不做。换句话说，注解对Python 解释器没有任何意义。注解只是元数据，可以供 IDE、框架和装饰器等工具使用。\n\n6. 支持函数式编程的包operator模块\noperator 模块为多个算术运算符提供了对应的函数，从而避免编写 lambda a, b: a*b 这种平凡的匿名函数。\nfrom functools import reducedef func(n):\t    return reduce(lambda a, b:a*b, range(1,n+1))func(4)Out[2]: 24  from operator import muldef fact(n):    return reduce(mul, range(1,n+1))fact(4)Out[3]: 24\n\noperator 模块中还有一类函数，能替代从序列中取出元素或读取对象属性的 lambda 表达式：因此，itemgetter 和 attrgetter 其实会自行构建函数。\nitemgetter 使用 [] 运算符，因此它不仅支持序列，还支持映射和任何实现 __getitem__ 方法的类。itemgetter 的常见用途：根据元组的某个字段给元组列表排序\nmetro_data = [   (&#x27;Tokyo&#x27;, &#x27;JP&#x27;, 36.933, (35.689722, 139.691667)),   (&#x27;Delhi NCR&#x27;, &#x27;IN&#x27;, 21.935, (28.613889, 77.208889)),   (&#x27;Mexico City&#x27;, &#x27;MX&#x27;, 20.142, (19.433333, -99.133333)),   (&#x27;New York-Newark&#x27;, &#x27;US&#x27;, 20.104, (40.808611, -74.020386)),   (&#x27;Sao Paulo&#x27;, &#x27;BR&#x27;, 19.649, (-23.547778, -46.635833)), ]from operator import itemgetterfor city in sorted(metro_data, key=itemgetter(1)):    print(city)    # 如果把多个参数传给 itemgetter，它构建的函数会返回提取的值构成的元组：names = itemgetter(0, 1)for city in metro_data:    print(names(city))&quot;&quot;&quot;(&#x27;Tokyo&#x27;, &#x27;JP&#x27;)(&#x27;Delhi NCR&#x27;, &#x27;IN&#x27;)(&#x27;Mexico City&#x27;, &#x27;MX&#x27;)(&#x27;New York-Newark&#x27;, &#x27;US&#x27;)(&#x27;Sao Paulo&#x27;, &#x27;BR&#x27;)&quot;&quot;&quot;\n\nattrgetter 与 itemgetter 作用类似，它创建的函数根据名称提取对象的属性。如果把多个属性名传给 attrgetter，它也会返回提取的值构成的元组。此外，如果参数名中包含 .（点号），attrgetter 会深入嵌套对象，获取指定的属性。这些行为如下例所示，这个控制台会话不短，因为我们要构建一个嵌套结构，这样才能展示attrgetter 如何处理包含点号的属性名。\nfrom collections import namedtuple metro_data = [ (&#x27;Tokyo&#x27;, &#x27;JP&#x27;, 36.933, (35.689722, 139.691667)), (&#x27;Delhi NCR&#x27;, &#x27;IN&#x27;, 21.935, (28.613889, 77.208889)), (&#x27;Mexico City&#x27;, &#x27;MX&#x27;, 20.142, (19.433333, -99.133333)), (&#x27;New York-Newark&#x27;, &#x27;US&#x27;, 20.104, (40.808611, -74.020386)), (&#x27;Sao Paulo&#x27;, &#x27;BR&#x27;, 19.649, (-23.547778, -46.635833)), ]LatLong = namedtuple(&#x27;LatLong&#x27;, &#x27;lat long&#x27;) Metropolis = namedtuple(&#x27;Metropolis&#x27;, &#x27;name cc pop coord&#x27;) metro_areas = [Metropolis(name, cc, pop, LatLong(lat, long)) for name, cc, pop, (lat, long) in metro_data]metro_areas[0]Out[3]: Metropolis(name=&#x27;Tokyo&#x27;, cc=&#x27;JP&#x27;, pop=36.933, coord=LatLong(lat=35.689722, long=139.691667))metro_areas[0].coord.latOut[4]: 35.689722  from operator import attrgettername_lat = attrgetter(&#x27;name&#x27;, &#x27;coord.lat&#x27;)  # 定义一个 attrgetter，获取 name 属性和嵌套的 coord.lat 属性for city in sorted(metro_areas, key=attrgetter(&#x27;coord.lat&#x27;)): # 使用 attrgetter，按照纬度排序城市列表。    print(name_lat(city))     (&#x27;Sao Paulo&#x27;, -23.547778)(&#x27;Mexico City&#x27;, 19.433333)(&#x27;Delhi NCR&#x27;, 28.613889)(&#x27;Tokyo&#x27;, 35.689722)(&#x27;New York-Newark&#x27;, 40.808611)\n\n operator 模块中定义的部分函数（省略了以 _ 开头的名称，因为它们基本上是实现细节）:\n[name for name in dir(operator) if not name.startswith(&#x27;_&#x27;)] [&#x27;abs&#x27;, &#x27;add&#x27;, &#x27;and_&#x27;, &#x27;attrgetter&#x27;, &#x27;concat&#x27;, &#x27;contains&#x27;, &#x27;countOf&#x27;, &#x27;delitem&#x27;, &#x27;eq&#x27;, &#x27;floordiv&#x27;, &#x27;ge&#x27;, &#x27;getitem&#x27;, &#x27;gt&#x27;, &#x27;iadd&#x27;, &#x27;iand&#x27;, &#x27;iconcat&#x27;, &#x27;ifloordiv&#x27;, &#x27;ilshift&#x27;, &#x27;imatmul&#x27;, &#x27;imod&#x27;, &#x27;imul&#x27;, &#x27;index&#x27;, &#x27;indexOf&#x27;, &#x27;inv&#x27;, &#x27;invert&#x27;, &#x27;ior&#x27;, &#x27;ipow&#x27;, &#x27;irshift&#x27;, &#x27;is_&#x27;, &#x27;is_not&#x27;, &#x27;isub&#x27;, &#x27;itemgetter&#x27;, &#x27;itruediv&#x27;, &#x27;ixor&#x27;, &#x27;le&#x27;, &#x27;length_hint&#x27;, &#x27;lshift&#x27;, &#x27;lt&#x27;, &#x27;matmul&#x27;, &#x27;methodcaller&#x27;, &#x27;mod&#x27;, &#x27;mul&#x27;, &#x27;ne&#x27;, &#x27;neg&#x27;, &#x27;not_&#x27;, &#x27;or_&#x27;, &#x27;pos&#x27;, &#x27;pow&#x27;, &#x27;rshift&#x27;, &#x27;setitem&#x27;, &#x27;sub&#x27;, &#x27;truediv&#x27;, &#x27;truth&#x27;, &#x27;xor&#x27;]\n\nmethodcaller 它的作用与 attrgetter和 itemgetter 类似，它会自行创建函数。methodcaller 创建的函数会在对象上调用参数指定的方法。\nfrom operator import methodcallers = &quot;abcd efg&quot;upcase = methodcaller(&#x27;upper&#x27;)upcase(s)Out[16]: &#x27;ABCD EFG&#x27;  replace_case = methodcaller(&#x27;replace&#x27;,&#x27; &#x27;,&#x27;-&#x27;)replace_case(s)Out[18]: &#x27;abcd-efg&#x27;\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：数据模型","url":"/posts/2019/11/02/33468/","content":"Python风格的纸牌import collectionsCard = collections.namedtuple(&#x27;Card&#x27;, [&#x27;rank&#x27;, &#x27;suit&#x27;])class FrenchDeck:    ranks = [str(n) for n in range(2, 11)] + list(&#x27;JQKA&#x27;)    suits = &#x27;spades diamonds clubs hearts&#x27;.split()  # 黑桃 方块 梅花 红心    def __init__(self):        self._cards = [Card(rank, suit) for suit in self.suits                       \t\t\t\t\t\t\t\t\tfor rank in self.ranks]    def __len__(self):        return len(self._cards)    def __getitem__(self, position):        return self._cards[position]deck = FrenchDeck()len(deck)\t\t\t\tOut[2]: 52\t\t   # len()的使用是使用 __len__ 函数deck[0]Out[3]: CardName(rank=&#x27;2&#x27;, suit=&#x27;spades&#x27;)deck[-1]\t\t\t\t # 抽取特定序号的元素，如最后一个deck[-1]，由__getitem__提供Out[4]: CardName(rank=&#x27;A&#x27;, suit=&#x27;hearts&#x27;)\n\n# 使用Python内置的随机函数random.choice() 获取一张随机牌from random import choicechoice(deck)Out[5]: CardName(rank=&#x27;8&#x27;, suit=&#x27;clubs&#x27;)choice(deck)Out[6]: CardName(rank=&#x27;K&#x27;, suit=&#x27;hearts&#x27;)\n\n# 可迭代for item in deck:    print(item)# 反向迭代for item in deck:    print(item)# in 运算符Card(rank=&#x27;2&#x27;, suit=&#x27;spades&#x27;) in deck# Out[7]: TrueCard(rank=&#x27;2&#x27;, suit=&#x27;opades&#x27;) in deck# Out[8]: False\n\n# 排序：先看点数，再比较花色# 点数：2最小，A最大； 花色：黑桃&gt;红桃&gt;方块&gt;梅花  --&gt; 梅花2最小，为0，黑桃A最大，为52suit_values =dict(spades=3, hearts=2, diamonds=1, clubs=0)def spades_high(card):    rank_value = FrenchDeck.ranks.index(card.rank)   # 考虑到有字母，比较大小用下标    return rank_value * len(suit_values) + suit_values[card.suit]for card in sorted(deck,key=spades_high):    print(card)\n\nnametuple 用以构建只有少数属性但是没有方法的对象，比如数据库条目。上面是利用其获取一个纸牌对象。\n# 举例：import collectionsCard = collections.namedtuple(&#x27;CardName&#x27;, [&#x27;rank&#x27;, &#x27;suit&#x27;])mycard = Card(&#x27;r1&#x27;,&#x27;s1&#x27;)mycardOut[1]: CardName(rank=&#x27;r1&#x27;, suit=&#x27;s1&#x27;)\n\n虽然FrenchDeck隐式地继承了object类，但功能却不是继承而来的。我们通过数据模型和一些合成来实现这些功能。通过实现__len__和__getitem__这两个特殊方法，FrenchDeck就跟一个Python自有的序列数据类型一样，可以体现出Python的核心语言特性（例如迭代和切片）。同时这个类还可以用于标准库中诸如random.choice、reversed和sorted这些函数。另外，对合成的运用使得__len__和__getitem__的具体实现可以代理给self._cards这个Python列表（即list对象）。\n\n字符串表现形式Python 有一个内置的函数叫 repr，它能把一个对象用字符串的形式表达出来以便辨认，这就是“字符串表示形式”。repr 就是通过 __repr__ 这个特殊方法来得到一个对象的字符串表示形式的。如果没有实现 __repr__，当我们在控制台里打印一个向量的实例时，得到的字符串可能会是&lt;__main__.Vector at 0x186edbb5eb8&gt;。\nv2 = Vector(1,2)v2Out[2]: Vector: 1,2# 如果没有实现 __repr__v2 = Vector(1,2)v2Out[3]: &lt;__main__.Vector at 0x186edbb5eb8&gt;\n\n__repr__ 和 __str__ 的区别在于，前者方便我们调试和记录日志，后者是在 str() 函数被使用，或是在用 print 函数打印一个对象的时候才被调用的，并且它返回的字符串对终端用户更友好。\n如果只想实现这两个特殊方法中的一个，__repr__ 是更好的选择，因为如果一个对象没有__str__函数，而 Python 又需要调用它的时候，解释器会用__repr__作为替代。\n\n特殊方法from math import hypotclass Vector(object):    def __init__(self, x=0, y=0):        self.x = x        self.y = y    def __repr__(self):     # 把对象用字符串的形式表达出来        return f&#x27;Vector: &#123;self.x&#125;,&#123;self.y&#125;&#x27;    def __add__(self, other):        x = self.x + other.x        y = self.y + other.y        return Vector(x, y)    def __abs__(self):        return hypot(self.x, self.y)    def __bool__(self):        # return bool(self.__abs__())        return bool(abs(self))    # def __bool__(self):    #     return bool(self.x or self.y)  # 更高效的bool实现方式    def __mul__(self, scalar):        return Vector(self.x * scalar, self.y * scalar)v1 = Vector(1, 2)v2 = Vector(2, 3)&#x27;&#x27;&#x27;通过 __add__ 和 __mul__，示例为向量类带来了 + 和 * 这两个算术运算符。值得注意的是，这两个方法的返回值都是新创建的向量对象，被操作的两个向量（self 或 other）还是原封不动，代码里只是读取了它们的值而已。中缀运算符的基本原则就是不改变操作对象，而是产出一个新的值。&#x27;&#x27;&#x27;\n\n\n\n跟运算符无关的特殊方法:\n字符串 &#x2F; 字节序列表示形式 __repr__、__str__、__format__、__bytes__ \n数值转换 __abs__、__bool__、__complex__、__int__、__float__、__hash__、__index__ \n集合模拟 __len__、__getitem__、__setitem__、__delitem__、__contains__ \n迭代枚举__iter__、__reversed__、__next__\n可调用模拟__call__\n上下文管理 __enter__、__exit__ \n实例创建和销毁__new__、__init__、__del__\n属性管理__getattr__、__getattribute__、__setattr__、__delattr__、__dir__\n属性描述符__get__、__set__、__delete__\n跟类相关的服务 __prepare__、__instancecheck__、__subclasscheck__\n跟运算符相关的特殊方法:\n一元运算符__neg__ -、__pos__ +、__abs__ abs()\n众多比较运算符__lt__ &lt;、 __le__ &lt;=、 __eq__ ==、 __ne__ !=、 __gt__ &gt;、 __ge__ &gt;=\n算术运算符__add__ +、__sub__ -、__mul__ *、__truediv__  /、__floordiv__ //、__mod__ %、__divmod__ divmod()、__pow__ ** 或 pow()、__round__ round()\n反向算术运算符__radd__、__rsub__、__rmul__、__rtruediv__、__rfloordiv__、__rmod__、 __rdivmod__、__rpow__\n增量赋值算术运算符 __iadd__、__isub__、__imul__、__itruediv__、__ifloordiv__、__imod__、 __ipow__ \n位运算符__invert__ ~、__lshift__ &lt;&lt;、__rshift__ &gt;&gt;、__and__ &amp;、__or__ |、__xor__ ^\n反向位运算符__rlshift__、__rrshift__、__rand__、__rxor__、__ror__\n增量赋值位运算符 __ilshift__、__irshift__、__iand__、__ixor__、__ior__\n通过实现特殊方法，自定义数据类型可以表现得跟内置类型一样，从而让我们写出更具表达力的代码——或者说，更具 Python 风格的代码。\n\n列表推导、生成器表达式symbols = &#x27;$¢£¥€¤&#x27;codes = [ord(i) for i in symbols]  # 列表推导式codesOut[2]: [36, 162, 163, 165, 8364, 164]\t # 列表推导、生成器表达式，有自己的局部作用域，就像函数似的# 表达式内部的变量和赋值只在局部起作用，表达式的上下文里的同名变量可以被正常应用。i = 1codes = [ord(i) for i in symbols]\t iOut[3]: 1  codes = (ord(i) for i in symbols)codesOut[4]: &lt;generator object &lt;genexpr&gt; at 0x00000186EDB45048&gt;tuple(codes)Out[5]: (36, 162, 163, 165, 8364, 164)# 如果生成器表达式是一个函数调用过程中的唯一参数，则不需要额外的括号将表达式包含。tuple(ord(s) for s in symbols)\tOut[6]: (36, 162, 163, 165, 8364, 164)# array的构造方法需要两个参数，因此括号是必须的。  import arrayarray.array(&#x27;I&#x27;, (ord(s) for s in symbols))Out[7]: array(&#x27;I&#x27;, [36, 162, 163, 165, 8364, 164])\n\n笛卡尔积：\nXs = [1, 2, 3]Ys = [&#x27;a&#x27;, &#x27;b&#x27;]cartesian_product = [(x, y) for x in Xs for y in Ys ]cartesian_productOut[2]: [(1, &#x27;a&#x27;), (1, &#x27;b&#x27;), (2, &#x27;a&#x27;), (2, &#x27;b&#x27;), (3, &#x27;a&#x27;), (3, &#x27;b&#x27;)]  # 类似于：for x in Xs:  # 推导式中写前面的，在for循环中相当于在外层  for y in Ys:    print((x, y))\n\n\n\n\n切片如果把切片放在赋值语句的左边，或把它作为 del 操作的对象，我们就可以对序列进行嫁接、切除或就地修改操作。如果赋值的对象是一个切片，那么赋值语句的右侧必须是个可迭代对象。即便只有单独一个值，也要把它转换成可迭代的序列。\nl = list(range(10))lOut[64]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  l[2:5]Out[65]: [2, 3, 4]del l[5:7]lOut[67]: [0, 1, 2, 3, 4, 7, 8, 9]    l[3::2] = [11, 22]Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-68-369e6569c21e&gt;&quot;, line 1, in &lt;module&gt;    l[3::2] = [11, 22]ValueError: attempt to assign sequence of size 2 to extended slice of size 3l[3::2] = [11, 22, 33]lOut[70]: [0, 1, 2, 11, 4, 22, 8, 33]    l[2:5] = 100Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-71-da8b10461280&gt;&quot;, line 1, in &lt;module&gt;    l[2:5] = 100TypeError: can only assign an iterable    l[2:5] = [100]lOut[73]: [0, 1, 100, 22, 8, 33]\n\n嵌套列表的创建要小心：\n如果在 a * n 这个语句中，序列 a 里的元素是对其他可变对象的引用的话，结果可能会出乎意料\nboard = [[&#x27;&#x27;]*3 for i in range(3)]boardOut[78]: [[&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]]board[0][1] = 1boardOut[81]: [[&#x27;&#x27;, 1, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]]  board = [[&#x27;&#x27;]*3]*3boardOut[83]: [[&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]]board[0][1] = 1boardOut[86]: [[&#x27;&#x27;, 1, &#x27;&#x27;], [&#x27;&#x27;, 1, &#x27;&#x27;], [&#x27;&#x27;, 1, &#x27;&#x27;]]\n\n同理：\nboard = []for i in range(3):    row = [&#x27;&#x27;]*3\t\t# id(row) 地址不同    board.append(row)    board[0][1] = 1boardOut[96]: [[&#x27;&#x27;, 1, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]]  row = [&#x27;&#x27;]*3board = []for i in range(3):    board.append(row)  # 每次循环的是同一个row    boardOut[90]: [[&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], [&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]]board[0][1] = 1boardOut[92]: [[&#x27;&#x27;, 1, &#x27;&#x27;], [&#x27;&#x27;, 1, &#x27;&#x27;], [&#x27;&#x27;, 1, &#x27;&#x27;]]\n\n\n\n\n序列的增量赋值增量赋值运算符 +&#x3D; 和 *&#x3D; 的表现取决于它们的第一个操作对象。\n+&#x3D; 背后的特殊方法是 __iadd__（用于“就地加法”）。但是如果一个类没有实现这个方法的 话，Python 会退一步调用 __add__。\n可变序列一般都实现了 __iadd__ 方法，因此 +&#x3D; 是就地加法。但是如果 a 没有实现__iadd__的话，a +&#x3D; b 这个表达式的效果就变得跟 a &#x3D; a + b 一样了：首先 计算 a + b，得到一个新的对象，然后赋值给 a。也就是说，在这个表达式中，变量名会不会被关联到新的对象，完全取决于这个类型有没有实现 __iadd__ 这个方法。\nli = [1,2,3]id(li)Out[2]: 1679025343496li *= 2liOut[3]: [1, 2, 3, 1, 2, 3]id(li)Out[4]: 1679025343496tu = (1,2,3)id(tu)Out[5]: 1679025314120tu *= 2tuOut[6]: (1, 2, 3, 1, 2, 3)id(tu)Out[7]: 1679025046824\n\n对不可变序列进行重复拼接操作的话，效率会很低，因为每次都有一个新对象，而解释器需要把对象中的元素先复制到新的对象里，然后再追加新的元素。\n\n关于 +&#x3D; 的谜题tul = (1,2,[1,2])tul[2] += [3,4]Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-115-3108c6568ca3&gt;&quot;, line 1, in &lt;module&gt;    tul[2] += [3,4]TypeError: &#x27;tuple&#x27; object does not support item assignmenttulOut[116]: (1, 2, [1, 2, 3, 4])\n\nimport disdis.dis(&#x27;tul[2] += [3,4]&#x27;)  1           0 LOAD_NAME                0 (tul)              2 LOAD_CONST               0 (2)              4 DUP_TOP_TWO              6 BINARY_SUBSCR              8 LOAD_CONST               1 (3)             10 LOAD_CONST               2 (4)             12 BUILD_LIST               2             14 INPLACE_ADD             16 ROT_THREE             18 STORE_SUBSCR             20 LOAD_CONST               3 (None)             22 RETURN_VALUE\n\n教训：\n\n不要把可变对象放在元组（不可变对象）中。\n增量赋值不是一个原子操作。以上例子虽然抛出异常，但是完成了操作。\n查看Python字节码有助于了解代码背后的运行机制。\n\n\n数组 array\n如果我们需要一个只包含数字的列表，那么 array.array 比 list 更高效。数组支持所有跟可变序列有关的操作，包括 .pop、.insert 和 .extend。另外，数组还提供从文件读取和存入文件的更快的方法，如 .frombytes 和 .tofile。\nPython 数组跟 C 语言数组一样精简。创建数组需要一个类型码，这个类型码用来表示在 底层的 C 语言应该存放怎样的数据类型。比如 b 类型码代表的是有符号的字符（signed  char），因此 array(‘b’) 创建出的数组就只能存放一个字节大小的整数，范围从 -128 到 127，这样在序列很大的时候，我们能节省很多空间。而且 Python 不会允许你在数组里存 放除指定类型之外的数据。\nfrom array import arrayfrom random import randomfloats_array = array(&#x27;d&#x27;, (random() for i in range(10 ** 7)))  # 双精度浮点数组，类型码:dprint(floats_array[0])f = open(&#x27;floats.bin&#x27;, &#x27;wb&#x27;)floats_array.tofile(f)  # 把数组存入一个二进制文件中f.close()floats_array2 = array(&#x27;d&#x27;)  # 新建一个双精度浮点空数组f = open(&#x27;floats.bin&#x27;, &#x27;rb&#x27;)  floats_array2.fromfile(f, 10 ** 7)  # 把10**7个浮点数从二进制文件中读取出来f.close()print(floats_array2[0])print(floats_array == floats_array2)  # 检查两个数组是否相同\n\n array模块定义了一种对象类型，可以紧凑地表示基本类型值的数组：字符、整数、浮点数等。 数组属于序列类型，其行为与列表非常相似，不同之处在于其中存储的对象类型是受限的。 类型在对象创建时使用单个字符的 类型码来指定。 \n\n双向队列及其他利用 .append 和 .pop 方法，我们可以把列表当作栈或者队列来用（比如，把 .append 和 .pop(0) 合起来用，就能模拟栈的“先进先出”的特点）。但是删除列表的第一个元素（抑或是在第一个元素之前添加一个元素）之类的操作是很耗时的，因为这些操作会牵扯到移动列表里的所有元素。\n双向队列实现了大部分列表所拥有的方法，也有一些额外的符合自身设计的方法，比如说 popleft 和 rotate。但是为了实现这些方法，双向队列也付出了一些代价，从队列中间删除元素的操作会慢一些，因为它只对在头尾的操作进行了优化。\nappend 和 popleft 都是原子操作，也就说是 deque 可以在多线程程序中安全地当作先进先出的栈使用，而使用者不需要担心资源锁的问题。\ncollections.deque 类（双向队列）是一个线程安全、可以快速从两端添加或者删除元素的 数据类型。而且如果想要有一种数据类型来存放“最近用到的几个元素”，deque 也是一个很好的选择。这是因为在新建一个双向队列的时候，你可以指定这个队列的大小，如果这个队列满员了，还可以从反向端删除过期的元素，然后在尾端添加新的元素。\nfrom collections import deque# maxlen是一个可选参数，表示可容纳元素的数量，一旦设定不能修改dq = deque(range(10), maxlen=10) dqOut[4]: deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])# 队列的旋转操作接受一个参数 n，当 n &gt; 0 时，队列的最右边的 n 个元素会被移动到队列的左边。# 当 n &lt; 0 时，最左边的 n 个元素会被移动到右边。dq.rotate(3)dqOut[6]: deque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6])dq.rotate(-3)dqOut[8]: deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])  dq.appendleft(-1)dqOut[10]: deque([-1, 0, 1, 2, 3, 4, 5, 6, 7, 8])dq.append(-2)dqOut[12]: deque([0, 1, 2, 3, 4, 5, 6, 7, 8, -2])# 当试图对一个已满（len(d) == d.maxlen）的队列做尾部添加操作的时候，它头部的元素会被删除掉。dq.extend([11,22])dqOut[14]: deque([2, 3, 4, 5, 6, 7, 8, -2, 11, 22])# 在队列做头部添加操作的时候，它尾部的元素会被删除掉。dq.extendleft([-11,-22])dqOut[16]: deque([-22, -11, 2, 3, 4, 5, 6, 7, 8, -2])\n\n列表和双向队列的方法（不包括由对象实现的方法）:\n\n除了 deque 之外，还有些其他的 Python 标准库也有对队列的实现：\nqueue \n提供了同步（线程安全）类 Queue、LifoQueue 和 PriorityQueue，不同的线程可以利用 这些数据类型来交换信息。这三个类的构造方法都有一个可选参数 maxsize，它接收正整数作为输入值，用来限定队列的大小。但是在满员的时候，这些类不会扔掉旧的元素来腾出位置。相反，如果队列满了，它就会被锁住，直到另外的线程移除了某个元素而腾出了位置。这一特性让这些类很适合用来控制活跃线程的数量。 \nmultiprocessing \n这个包实现了自己的 Queue，它跟 queue.Queue 类似，是设计给进程间通信用的。同时 还有一个专门的 multiprocessing.JoinableQueue 类型，可以让任务管理变得更方便。 \nasyncio \nPython 3.4 新提供的包，里面有 Queue、LifoQueue、PriorityQueue 和 JoinableQueue，这些类受到 queue 和 multiprocessing 模块的影响，但是为异步编程里的任务管理提供了专门的便利。 \nheapq \n列的实现：\nqueue \n提供了同步（线程安全）类 Queue、LifoQueue 和 PriorityQueue，不同的线程可以利用 这些数据类型来交换信息。这三个类的构造方法都有一个可选参数 maxsize，它接收正整数作为输入值，用来限定队列的大小。但是在满员的时候，这些类不会扔掉旧的元素来腾出位置。相反，如果队列满了，它就会被锁住，直到另外的线程移除了某个元素而腾出了位置。这一特性让这些类很适合用来控制活跃线程的数量。 \nmultiprocessing \n这个包实现了自己的 Queue，它跟 queue.Queue 类似，是设计给进程间通信用的。同时 还有一个专门的 multiprocessing.JoinableQueue 类型，可以让任务管理变得更方便。 \nasyncio \nPython 3.4 新提供的包，里面有 Queue、LifoQueue、PriorityQueue 和 JoinableQueue，这些类受到 queue 和 multiprocessing 模块的影响，但是为异步编程里的任务管理提供了专门的便利。 \nheapq \n跟上面三个模块不同的是，heapq 没有队列类，而是提供了 heappush 和 heappop 方法，让用户可以把可变序列当作堆队列或者优先队列来使用。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：集合","url":"/posts/2019/11/09/14734/","content":"集合的本质是许多唯一对象的聚集。因此，集合可以用于去重。\n列表、字典、集合等不可散列的对象是不能用来作为集合的元素的，不可变的对象如字符串、元组等可散列才可以。\nset([1,2,3,[4,5]])Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-3-97f17f7a499c&gt;&quot;, line 1, in &lt;module&gt;    set([1,2,3,[4,5]])TypeError: unhashable type: &#x27;list&#x27;    set([1,2,3,&#123;&#x27;4&#x27;:5&#125;])Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-5-eae42bf28a0e&gt;&quot;, line 1, in &lt;module&gt;    set([1,2,3,&#123;&#x27;4&#x27;:5&#125;])TypeError: unhashable type: &#x27;dict&#x27;    set([1,2,3,&#123;1,2,3&#125;])Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-12-435ddc9ed94f&gt;&quot;, line 1, in &lt;module&gt;    set([1,2,3,&#123;1,2,3&#125;])TypeError: unhashable type: &#x27;set&#x27;    set([1,2,3,(4,5)])Out[4]: &#123;(4, 5), 1, 2, 3&#125;  set([1,2,&quot;123&quot;])Out[5]: &#123;1, &#x27;123&#x27;, 2&#125;  item = frozenset([1,2,3])set([1,2,3,item])Out[11]: &#123;1, 2, 3, frozenset(&#123;1, 2, 3&#125;)&#125;\n\nli = [1,2,3,4,4]set(li)Out[6]: &#123;1, 2, 3, 4&#125;\n\n集合中的元素必须是可散列的，set 类型本身是不可散列的，但是 frozenset 可以。因此可以创建一个包含不同 frozenset 的 set。 \n除了保证唯一性，集合还实现了很多基础的中缀运算符 。给定两个集合 a 和 b，a | b 返回的是它们的合集，a &amp; b 得到的是交集，而 a - b 得到的是差集。合理地利用这些操作，不仅能够让代码的行数变少，还能减少 Python 程序的运行时间。这样做同时也是为了让代码更易读，从而更容易判断程序的正确性，因为利用这些运算符可以省去不必要的循环和逻辑操作。\n集合字面量：\n除空集之外，集合的字面量——{1}、{1, 2}，等等——看起来跟它的数学形式一模一样。如果是空集，那么必须写成 set() 的形式。如果要创建一个空集，你必须用不带任何参数的构造方法 set()。如果只是写成 {} 的形式，跟以前一样，你创建的其实是个空字典。\n集合的推导：\nfrom unicodedata import names = &#123;chr(i) for i in range(32, 256) if &#x27;SIGN&#x27; in name(chr(i), &#x27;&#x27;)&#125;s&#123;&#x27;#&#x27;, &#x27;$&#x27;, &#x27;%&#x27;, &#x27;+&#x27;, &#x27;&lt;&#x27;, &#x27;=&#x27;, &#x27;&gt;&#x27;, &#x27;¢&#x27;, &#x27;£&#x27;, &#x27;¤&#x27;, &#x27;¥&#x27;, &#x27;§&#x27;, &#x27;©&#x27;, &#x27;¬&#x27;, &#x27;®&#x27;, &#x27;°&#x27;, &#x27;±&#x27;, &#x27;µ&#x27;, &#x27;¶&#x27;, &#x27;×&#x27;, &#x27;÷&#x27;&#125;\n\n\n集合的数学运算：\n\n\n\n数学符号\n运算符\n方法\n描述\n\n\n\nS ∩ Z\ns &amp; z\ns.__and__(z) \ns和z的交集\n\n\n\nz &amp; s\ns.__rand__(z) \n反向 &amp; 操作\n\n\n\n\ns.intersection(it, …)\n把可迭代的 it 和其他所有参数转化为集合，然后求它们与 s 的交集\n\n\n\ns &amp;&#x3D; z\ns.__iand__(z)\n把 s 更新为 s 和 z 的交集\n\n\n\n\ns.intersection_update(it, …)\n把可迭代的 it 和其他所有参数转化为集合，然后求得它们与 s 的交集，然后把 s 更新成这个交集\n\n\nS ∪ Z\n&#96;s\nz&#96;\ns.__or__(z) \n\n\n\n&#96;z\ns&#96;\ns.__ror__(z) \n\n\n\n\ns.union(it, …)\n把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的并集\n\n\n\n&#96;s\n&#x3D; z&#96;\ns.__ior__(z)\n\n\n\n\ns.update(it, …)\n把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的并集，并把 s 更新成这个并集\n\n\nS \\ Z\ns - z\ns.__sub__(z)\ns 和 z 的差集，或者叫作相对补集\n\n\n\nz - s\ns.__rsub__(z)\n- 的反向操作\n\n\n\n\ns.difference(it, …)\n把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的差集\n\n\n\ns -&#x3D; z\ns.__isub__(z)\n把 s 更新为它与 z 的差集\n\n\n\n\ns.difference_update(it, …)\n把可迭代的 it 和其他所有参数转化为集合，求它们和 s 的差集，然后把 s 更新成这个差集\n\n\n\n\ns.symmetric_difference(it)\n求 s 和 set(it) 的对称差集\n\n\nS ∆ Z\ns ^ z\ns.__xor__(z)\n求 s 和 z 的对称差集\n\n\n\nz ^ s\ns.__rxor__(z)\n^ 的反向操作\n\n\n\n\ns.symmetric_difference_update(it, …)\n把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的对称差集，最后把 s 更新成该结果\n\n\n\nz ^&#x3D; s\ns.__ixor__(z)\n把 s 更新成它与 z 的对称差集\n\n\n\n集合的比较运算：\n\n\n\n数学符号\n运算符\n方法\n描述\n\n\n\n\n\ns.isdisjoint(z)\n查看 s 和 z 是否不相交（没有共同元素）\n\n\ne ∈ S\ne in s\ns.__contains__(e)\n元素 e 是否属于 s\n\n\nS ⊆ Z\ns &lt;&#x3D; z\ns.__le__(z)\ns 是否为 z 的子集\n\n\n\n\ns.issubset(it)\n把可迭代的 it 转化为集合，然后查看 s 是否为它的子集\n\n\nS ⊂ Z\ns &lt; z\ns.__lt__(z)\ns 是否为 z 的真子集\n\n\nS ⊇ Z\ns &gt;&#x3D; z\ns.__ge__(z)\ns 是否为 z 的父集\n\n\n\n\ns.issuperset(it)\n把可迭代的 it 转化为集合，然后查看 s 是否为它的父集，然后查看 s 是否为它的父集\n\n\nS ⊃ Z\ns &gt; z\ns.__gt__(z)\ns 是否为 z 的真父集\n\n\n\n散列表其实是一个稀疏数组（总是有空白元素的数组称为稀疏数组）。在一般的数据结构教材中，散列表里的单元通常叫作表元（bucket）。在 dict 的散列表当中，每个键值对都占用一个表元，每个表元都有两个部分，一个是对键的引用，另一个是对值的引用。因为所有表元的大小一致，所以可以通过偏移量来读取某个表元。\n因为 Python 会设法保证大概还有三分之一的表元是空的，所以在快要达到这个阈值的时候，原有的散列表会被复制到一个更大的空间里面。 如果要把一个对象放入散列表，那么首先要计算这个元素键的散列值。Python 中可以用hash() 方法来做这件事情。\n由于字典使用了散列表，而散列表又必须是稀疏的，这导致它在空间上的效率低下。如果需要存放数量巨大的记录，那么放在由元组或是具名元组构成的列表中会是比较好的选择；最好不要根据 JSON 的风格，用由字典组成的列表来存放这些记录。用元组取代字典就能节省空间的原因有两个：其一是避免了散列表所耗费的空间，其二是无需把记录中字段的名字在每个元素里都存一遍。\nset的实现以及导致的结果：\nset 和 frozenset 的实现也依赖散列表，但在它们的散列表里存放的只有元素的引用（就像在字典里只存放键而没有相应的值）。在 set 加入到 Python 之前，都是把字典加上无意义的值当作集合来用的。\n\n字典和散列表的几个特点，对集合来说几乎都是适用的：\n\n集合里的元素必须是可散列的。 \n\n集合很消耗内存。 \n\n可以很高效地判断元素是否存在于某个集合。 \n\n元素的次序取决于被添加到集合里的次序。 \n\n往集合里添加元素，可能会改变集合里已有元素的次序。\n\n\ndict 和 set 背后的散列表效率很高，对它的了解越深入，就越能理解为什么被保存的元素会呈现出不同的顺序，以及已有的元素顺序会发生变化的原因。同时，速度是以牺牲空间为代价而换来的。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"编写高质量代码：Pythonic","url":"/posts/2019/09/21/20490/","content":"Rome was not built in one day， coding will not advance vigorously with one effort.\n从量变到智变的飞跃，需要从多方面一点一滴的积累，比如语言层面的使用技巧、常见注意事项、编程风格等。\n# 快排# 使用极简代码完成，且易读易理解def quickSort(array):    less, more = [], []    if len(array) &lt;= 1:        return array    middle = array.pop()    for i in array:        if i &lt; middle:            less.append(i)        else:            more.append(i)    return quickSort(less) + [middle] + quickSort(more)testArray = [2,1,6,3,9,8]print(quickSort(testArray))\n\n# 交换两数# 不像C语言需要找中间变量来传递a, b = b, a\n\n# 迭代器for i in onelist:\tdo_something(i)\n\n# 安全地关闭文件：withwith open(onepath, &#x27;r&#x27;) as f:\tdo_something(f)\n\n# slicealist = [1,2,3,4]newlist = alist[::-1] # 倒序\n\n# 字符串格式化print(&quot;newlist %s&quot; % newlist)# newlist [4, 3, 2, 1]print(&quot;newlist &#123;0&#125;, &#123;1&#125;&quot;.format(alist, newlist))# newlist [1, 2, 3, 4], [4, 3, 2, 1]print(f&quot;newlist:&#123;newlist&#125;&quot;)  # 建议使用f# &#x27;newlist:[4, 3, 2, 1]&#x27;\n\n包和模块的命名采用小写、单数形式，且短小包通常仅作为命名空间，如只包含空 __init__.py 文件\n\n\n\nPythonic的代码1. 避免劣化代码\n避免只用大小写区分不同的对象\n避免使用容易引起混淆的名称\n重复使用存在于上下文中的变量名来表示不同的类型\n使用内建名称来表示其他含义变量\n使用类似于element、list、dict、tuple等来作为变量名\n使用o（容易与0混淆），l（容易与数字1混淆）作为变量名\n\n\n不要怕变量名过长\n考虑代码的易读和理解，变量名需要长一些\n\n\n\n2. 深入认识python\n全面掌握python提供的特性：语言特性和库特性，参考官方手册Language Reference 和Library Reference。\n紧跟Python的迭代，学习新知识、新用法等。\n深入学习公认的比较pythonic的代码，比如Flask、gevent、requests等\n\n\nPEP8：代码布局、注释、命名规范。\nPylint、Google Python Style Guide、Pychecker、Pyflakes\n\n\n\n理解Python与C语言的不同1.缩进 vs {}\nC、C++、Java等用花括号{}来分隔代码。Python使用严格的代码缩进，空格和Tab不能混用。\n2.’’ vs “”\nC中单引号和双引号有着严格的区别，单引号表示一个字符，对应编译器所采用的字符集中的一个整数值，例如’a’与97对应。双引号表示字符串，默认以’\\0’结尾。\n在Python中单引号和双引号没有明显的区别，仅在输入字符串内容不同时，存在微小差异。\n3.三元操作符\n三元操作符是if…else…的简写方法，语法形式C？X:Y，表示满足满足条件C时取值X否则取值。\n4.switch…case\nPython中没有switch…case分支语句\nswitch(n)&#123;  case 0:    printf(&quot;zero \\n&quot;);    break;  case 1:    printf(&quot;one \\n&quot;);  default:    printf(&quot;other value \\n&quot;);    break;&#125;\n\nif n == 0:  print(&quot;zero&quot;)elif n == 1:  print(&quot;one&quot;)else:  print(&quot;other value&quot;)  # 或者使用跳转表实现def func(n):  return &#123;0:&quot;zero&quot;, 1:&quot;one&quot;&#125;.get(n, &quot;other value&quot;)\n\n\n\n适当、必要的注释Python的注释：块注释、行注释、文档注释（docstring）\n\n使用块或行注释，仅仅注释那些复杂的操作、算法、别人难以理解的技巧、不熟悉的业务\n注释和代码隔开一定的距离，可以使用PEP8规范格式化代码\n给外部可访问的函数和方法添加文档注释。\n注释描述方法的功能，对入参、返回值以及可能的异常说明\n\n\n文件头部推荐使用copyright声明、模块描述，添加作者信息及时间\n注释和代码不能重复，注释是用来解释代码的功能、原因、思路的\n用于调试的代码等不需要的代码不应该注释，而是应该删除\n\n适当空行优雅代码布局布局清晰、整洁、优雅的代码能够让阅读者比较愉悦。\n\n在一组代码表达完一个完整的思路后，应该用空白进行间隔\n函数与函数之间、导入声明与变量赋值之间等，无关的代码块之间最好用空行隔开\n\n\n避免过长的代码行，Pycharm：Ctrl+Alt++L格式化\n逗号前不要用空格\n\n函数编写的原则函数的作用：最大化的代码重用、最小化的代码冗余；编写函数追求：提高程序的健壮性、增强可读性、减少维护成本。\n\n函数设计要尽量短小，嵌套层次浅\n避免过长的函数体，在一个屏幕下就能看完整\nif、elif、for、while嵌套不超过3层\n\n\n函数声明应该合理、简单、易于使用\n函数名的见名知意\n参数设计简洁明了，入参个数不宜过多\n\n\n函数参数设计应该考虑向下兼容\n添加默认参数，适应函数调用接口的变化\n\n\n一个函数只做一件事，尽量避免函数语句粒度的一致性\n一个功能可以分解成多个小任务、函数\n\n\n\n常量集中到一个文件中Python实际内建命名空间支持一小部分常量：True、False、None等，没有提供定义常量的直接方式。在Python中一般这样使用常量：\n\n通过命风格表示该变量为常量：大写，一种约定俗成的风格\n自定义的类实现常量功能：\n命名全部为大写\n值一旦绑定就不能修改，否则抛出异常\n\n\n\n# constant.pyclass Constant(object):    class ConstError(TypeError):pass    class ConstCaseError(ConstError):pass    def __setattr__(self, key, value):        if key in self.__dict__:            raise self.ConstError(f&quot;Cant&#x27;t change constant &#123;key&#125;&quot;)        if not key.isupper():            raise self.ConstCaseError(f&quot;constant &#123;key&#125; is not all uppercase&quot;)        self.__dict__[key] = valueimport syssys.modules[__name__] = Constant# 定义好类后，在其他脚本中使用只要导入上面这个模块就行# other.pyimport constant  # 导入定义常量类的模块constant.MYNAME = &quot;justme&quot;\n\n使用 sys.modules[__name__] 可以获取一个模块对象&lt;module &#39;__main__&#39;&gt;，并可以通过该对象获取模块的属性，这里使用了sys.modules向系统字典中注入了一个Constant对象，从而实现了在执行import constant时实际获取了一个Constant实例的功能。\t\nsys.modules[__name__] = Constant 将系统已加载的模块列表中的 constant 替换为了 Constant，即一个Constant实例。\n备注：sys.modules 是存放已经缓存的模块，值为dict类型sys.path  搜索路径，值为list类型if __name__= __main__ 是python的程序入口，如果直接执行该 .py 文件，那么执行后面的代码，如果作为模块导入，则不执行后面的代码\n来源：《编写高质量代码：改善Python程序的91个建议》\n","categories":["技术","Python"],"tags":["Python"]},{"title":"编写高质量代码：Python中的内部机制（下）","url":"/posts/2019/10/20/9934/","content":"Rome was not built in one day， coding will not advance vigorously with one effort.\nPython对象协议可以这样比方：在Python中我需要调用你的某个方法，你正好有这个方法。\n举例：如果有占位符%s，那么按照字符串转换的协议，Python会自动去调用相应对象的__str__()方法。\nclass Obj(object):    def __str__(self):        return &#x27;called __str__&#x27;     obj = Obj()print(obj)  # called __str__\n\n除了__str__()方法，其他__repr__()、__init__、__floate__、__nonezero__等，统称为类型转换协议。\n其他协议：\n\n用于比较大小的协议__cmp__()方法：当两者相等时返回0，当self&lt;other时返回负值，反之返回正值。Python又有__eq__()、__lt__()、__gt__()等来实现相等、不等、小于和大于的判定，这就是Python对&#x3D;&#x3D;、!&#x3D;、&lt;、&gt;等操作符的进行重载的支撑机制。\n\n数值类型相关的协议\n\n数值运算符：__add__、__sub__、__mul__、__div__、__pow__\n位运算符：__lshift__、__rshift__、__and__、__or__、__xor__、__invert__\n运算赋值符：__iadd__、__isub__、__imul__、__idiv__、__ipow__\n其他：__pos__ - 正、__neg__ - 负、__abs__ - 绝对值\n\n\n容器类型协议\n\npython中内置了len函数，通过__len__完成\n\n__getitem__、__setitem__、__delitem__对应读、写和删除\n\n__reversed__对内置函数reversed支持\n\n对成员关系的判断符in和not in的支持：__contained__\n\n\n\n可调用对象协议可调用对象即类似函数对象，能够让类实例表现得像函数一样，这样就可以让每一个函数调用都有所不同。\nclass Functor(object):    def __init__(self, content):        self._content = content    def __call__(self, *args, **kwargs):        print(f&#x27;do something &#123;self._content&#125;&#x27;)func = Functor(&quot;a1&quot;)func2 = Functor(&quot;a2&quot;)func()   # do something a1func2()\t # do something a2\n\n与可调用对象差不多的，还有一个可哈希对象，它是用过__hash__()方法来支持hash()这个内置函数的，在创建自己的类型时非常有用，因为只有支持可哈希协议的类型才能作为dict的键类型（不过只要继承自object的新式类默认就支持了）。\n\n上下文管理器协议，也就是对with语句的支持。协议通过__enter__、__exit__两个方法来实现对资源的清理，确保资源无论在什么情况下都会被正常清理。\n\n\n\n迭代器协议\n实现了一个__iter__()方法，返回一个迭代器\n\n实现next()方法，返回当前元素，并指向下一个元素的位置，如果当前元素已无元素，则抛出StopIteration异常。\n\n\nmylist = range(2)next(mylist)Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-10-bae65c1f3ff5&gt;&quot;, line 1, in &lt;module&gt;    next(mylist)TypeError: &#x27;range&#x27; object is not an iterator  myiter = mylist.__iter__()myiterOut[2]: &lt;range_iterator at 0x208ddf3b3f0&gt;next(myiter)Out[3]: 0next(myiter)Out[4]: 1next(myiter)Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-15-ce4a7df7b15f&gt;&quot;, line 1, in &lt;module&gt;    next(myiter)StopIteration\n\n其实for语句就是福获取容器的迭代器、调用迭代器的next()方法以及对StopIteration进行处理等流程进行封装的语法糖（类似的还有in、not in)。\nmylist = range(3)myiter = iter(mylist)while True:    try:        print(next(myiter))    except StopIteration:        break\n\n使用容器的优点：\nclass Fib(object):    def __init__(self):        self.a, self.b = 0, 1    def __iter__(self):  # 使得&#x27;Fib&#x27; object is iterable        return self    def __next__(self):        self.a, self.b = self.b, self.a + self.b        return self.afor i, j in enumerate(Fib()):    print(j)    if i &gt; 10:        break        # 传统使用容器储存数列def traditional(n):    reslist = []    a, b = 0, 1    count = 0    while count &lt; n:        reslist.append(b)        a, b = b, a + b        count += 1    return reslistprint(traditional(10))\n\n与直接使用容器的代码相比，它仅使用两个变量，显而易见更省内存，并在一些应用场合更省CPU计算资源，所以在编写代码中应当多多使用迭代器协议，避免劣化代码。\n\n生成器如果一个函数使用了yield语句，那么它就是一个生成器函数。\n当调用生成器函数时，返回一个迭代器，不过迭代器是以生成器对象的形式出现的。\ndef fib(n):    a, b = 0, 1    count = 0    while count &lt; n:        yield b        a, b = b, a + b        count += 1print(list(fib(5)))print(dir(fib(5)))# [&#x27;__class__&#x27;, &#x27;__del__&#x27;, &#x27;__delattr__&#x27;, &#x27;__dir__&#x27;, &#x27;__doc__&#x27;, &#x27;__eq__&#x27;, &#x27;__format__&#x27;, &#x27;__ge__&#x27;, &#x27;__getattribute__&#x27;, &#x27;__gt__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__init_subclass__&#x27;, &#x27;__iter__&#x27;, &#x27;__le__&#x27;, &#x27;__lt__&#x27;, &#x27;__name__&#x27;, &#x27;__ne__&#x27;, &#x27;__new__&#x27;, &#x27;__next__&#x27;, &#x27;__qualname__&#x27;, &#x27;__reduce__&#x27;, &#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;, &#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;, &#x27;__subclasshook__&#x27;, &#x27;close&#x27;, &#x27;gi_code&#x27;, &#x27;gi_frame&#x27;, &#x27;gi_running&#x27;, &#x27;gi_yieldfrom&#x27;, &#x27;send&#x27;, &#x27;throw&#x27;]\n\n相对传统使用容器储存数列，使用yield代码量减少。\n通过dir(fib(5))对象带有__iter__和__next__方法可以看出它是一个迭代器。\ndef echo(value):    print(&quot;**begin&quot;)    while True:        try:            value = yield value        except Exception as e:            print(e)        finally:            print(&quot;finish**&quot;)gen = echo(1)print(next(gen))  # print(gen.__next__())print(next(gen))print(gen.send(2))\n\n**begin1finish**Nonefinish**2finish**\n\n\n基于生成器的协程先看基于生产者消费者模型，对抢占式多线程编程实现和协程编程实现进行对比。\n伪代码：\n# 队列容器var q:= new queue# 消费者线程loop \tlock(q)\tget item from q\tunlock(q)\tif item\t\tuse this item\telse\t\tsleep# 消费者线程loop\tcreate some new item\tlock(q)\tadd the items to q\tunlock(q)\n\n可以看出，线程实现至少有两点缺点：\n\n对队列的操作需要有显式\\隐式（使用线程安全点的队列）的加锁操作\n消费者线程还要通过sleep把CPU资源实时地“谦让”给生产者线程使用，其中适时多久，基本上只能静态地使用经验值，效果往往不尽人意\n\n而使用协程可以解决这个问题，以下是基于协程的生产者消费模型实现（伪代码）：\n# 队列容器var q:= new queue# 生产者协程loop \twhile q is not full:\t\tcreate some new items\t\tadd the items to q\tyield to consume\t# 消费者协程loop \twhile q is not empty\t\tremove some items from q\t\tuse the items\tyield to produce\n\n\n对象的管理与垃圾回收Python并不需要用户自己来像C语言一样来管理内存，它具备垃圾回收机制。\nPython中内存管理方式：使用引用计数器（Reference counting）的方法来表示该对象当前有多少个引用。当其他对象引用该对象时，其引用计数会增加1，而删除一个对当前对象的引用，其引用计数会减1。只有当引用计数的值为0时该对象才会被垃圾收集器回收，因为它表示这个对象不再被其他对象引用，是个不可达对象。\n但是，其缺点是无法解决循环引用的问题，即两个对象相互引用。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"编写高质量代码：Python中的内部机制（上）","url":"/posts/2019/10/20/56015/","content":"Rome was not built in one day， coding will not advance vigorously with one effort.除了掌握Python本身的语法以及使用外，对其内部机制的探索可以更深入理解和掌握语言本身蕴含的思想和理念。\n理解built-ln objectsPython中一切皆对象：字符是对象、列表是对象、内建类型 (built-ln type）也是对象；用户定义的类型是对象，object是对象，type也是对象。新式类中，object是所有内建类型的基类，所以用户定义的类可以继承自object可以继承自内建类型。\nobject 和 type的关系很像鸡和蛋的关系，先有object还是先有type没法说，obejct和type是共生的关系，必须同时出现的。\n\n在面向对象体系里面，存在两种关系：\n\n父子关系，即继承关系，表现为子类继承于父类，如『蛇』类继承自『爬行动物』类，我们说『蛇是一种爬行动物』，英文说『snake is a kind of reptile』。在python里要查看一个类型的父类，可使用它的__bases__属性。\n类型实例关系，表现为某个类型的实例化，例如『萌萌是一条蛇』，英文说『萌萌 is an instance of snake』。在python里要查看一个实例的类型，可以使用它的__class__属性，或者使用type()函数。\n\n这两种关系使用下面这张图简单示意，继承关系使用实线从子到父连接，类型实例关系使用虚线从实例到类型连接：\n\n我们将使用一块白板来描述一下Python里面对象的关系，白板划分成三列。\n\n 先来看看type和object： 它们都是type的一个实例，表示它们都是类型对象。 \n&gt;&gt;&gt; object&lt;class &#x27;object&#x27;&gt;&gt;&gt;&gt; type&lt;class &#x27;type&#x27;&gt;&gt;&gt;&gt; type(object)&lt;class &#x27;type&#x27;&gt;&gt;&gt;&gt; type(type)&lt;class &#x27;type&#x27;&gt;\n\n 在Python的世界中，object是父子关系的顶端，所有的数据类型的父类都是它；type是类型实例关系的顶端，所有对象都是它的实例的。它们两个的关系可以这样描述：\nobject是一个type，object is and instance of type。即object是type的一个实例。isinstance(object, type) &#x3D;&#x3D; True\n&gt;&gt;&gt; object.__class__&lt;class &#x27;type&#x27;&gt;&gt;&gt;&gt; object.__bases__   # object 无父类，它是滴继承关系的顶端()\n\n type是一种object， type is kind of object。即type是object的子类。 \n&gt;&gt;&gt; type.__class__   # type的类型是自己&lt;class &#x27;type&#x27;&gt;&gt;&gt;&gt; type.__bases__ (&lt;class &#x27;object&#x27;&gt;,)\n\n在python里：\n要查看一个类型的父类，可使用它的__bases__属性；\n要查看一个实例的类型，可使用它的__class__属性，或者使用type()函数\n此时，白板上对象的关系如下图：\n\n引入list, dict, tuple 这些内置数据类型来看看：它们的父类都是object，类型都是type。 \ndef test(obj):    print(type(obj))          # &lt;class &#x27;type&#x27;&gt;    print(obj.__class__)\t\t\t# &lt;class &#x27;type&#x27;&gt;    print(obj.__bases__)\t\t\t# (&lt;class &#x27;object&#x27;&gt;,)    print(isinstance(obj,object))\t# True    print(isinstance(obj,type))\t  # Truetest(list)test(dict)test(tuple)\n\n实例化一个list后的结果：mylist &#x3D; [1, 2, 3] 它的类型是list，没有父类。\ndef test(obj):    print(type(obj))          # &lt;class &#x27;list&#x27;&gt;    print(obj.__class__)\t\t\t# &lt;class &#x27;list&#x27;&gt;    print(obj.__bases__)\t\t\t# AttributeError: &#x27;list&#x27; object has no attribute &#x27;__bases__&#x27;    print(isinstance(obj,object))\t# True    print(isinstance(obj,type))\t  # False    mylist = [1, 2, 3]test(mylist)\n\n把它们加到白板上去：\n\n白板上的虚线表示源是目标的实例，实线表示源是目标的子类。即: 左边的是右边的类型，上面的是下面的父亲。虚线是跨列产生关系，而实线只能在一列内产生关系。除了type和object两者外。 \n\n自定义一个类及实例化它的时候，和上面的对象们又是什么关系呢？ \nclass C():    pass    c = C()def test(obj):    print(type(obj))          # &lt;class &#x27;type&#x27;&gt;    print(obj.__class__)\t\t\t# &lt;class &#x27;type&#x27;&gt;    print(obj.__bases__)\t\t\t# (&lt;class &#x27;object&#x27;&gt;,)    print(isinstance(obj,object))\t# True    print(isinstance(obj,type))\t  # Truetest(C)def test(obj):    print(type(obj))          # &lt;class &#x27;__main__.C&#x27;&gt;    print(obj.__class__)\t\t\t# &lt;class &#x27;__main__.C&#x27;&gt;    print(obj.__bases__)\t\t\t# AttributeError: &#x27;C&#x27; object has no attribute &#x27;__bases__&#x27;  实例化的C类对象也是没有父类的属性的。    print(isinstance(obj,object))\t# True    print(isinstance(obj,type))\t  # Falsetest(c)\n\n再更新一下白板：白板上的第一列，目前只有type，我们先把这列的东西叫Type。白板上的第二列，它们既是第三列的类型，又是第一列的实例，我们把这列的对象叫TypeObject。白板上的第三列，它们是第二列类型的实例，而没有父类（__bases__）的，我们把它们叫Instance。\n\n 想要在第一列增加一个，要怎么做？要属于第一列的，必须是type的子类，那么我们只需要继承type来定义类就可以了： \nclass M(type):    passprint(M.__bases__)  # (&lt;class &#x27;type&#x27;&gt;,)print(M.__class__)\t# &lt;class &#x27;type&#x27;&gt;\n\n M类的类型和父类都是type。这个时候，我们可以把它归到第一列去。那么，要怎么样实例化M类型呢？实例化后它应该出现在那个列? 由于刚刚创建的是一个元类（MetaClass）！即类的类。如果你要实例化一个元类，那还是得定义一个类： \nclass TM(object, metaclass=M): # 造一个M是TM的metaclass，指定元类    passprint(TM.__class__)  # &lt;class &#x27;__main__.M&#x27;&gt;  # 这个类不再是type类型，而是M类型的。print(TM.__bases__)\t # (&lt;class &#x27;object&#x27;&gt;,)\n\n总结一下：第一列，元类列，type是所有元类的父亲。我们可以通过继承type来创建元类。第二列，TypeObject列，也称类列，object是所有类的父亲，大部份我们直接使用的数据类型都存在这个列的。第三列，实例列，实例是对象关系链的末端，不能再被子类化和实例化。\n补充一张知乎上的图：\n\n该部分来自知乎：Python 的 type 和 object 之间是怎么一种关系？\n\nmetaclass什么是元类：\n\n元类是关于类的类，是类的模板\n元类是用来控制如何创建类，正如类是创建对象的模板一样\n元类的实例为类，正如类的实例为对象\n\n类也是对象，一切皆对象。当使用关键字class时，Python解释器在执行时会创建一个对象（这里的对象是指类，而非类的对象）\ndef dynamic_class(name):    if name == &#x27;A&#x27;:        class A(object):            pass        return A    elif name == &#x27;B&#x27;:        class B(object):            pass        return BMyClass = dynamic_class(&quot;A&quot;)print(MyClass())  # &lt;__main__.dynamic_class.&lt;locals&gt;.A object at 0x000001EB066CA518&gt;print(MyClass)  # &lt;class &#x27;__main__.dynamic_class.&lt;locals&gt;.A&#x27;&gt;print(MyClass.__class__)  # &lt;class &#x27;type&#x27;&gt;print(MyClass().__class__)  # &lt;class &#x27;__main__.dynamic_class.&lt;locals&gt;.A&#x27;&gt;print(MyClass.__bases__)  # (&lt;class &#x27;object&#x27;&gt;,)\n\nMyClass的类型是type，MyClass()的类型是  &lt;class ‘__main__.dynamic_class..A’&gt;。\ntype还可以这样使用：\ntype(类名, 父类的元组（针对继承的情况，可以为空）, 包含属性的字典（名称和值）)\n\nA = type(&#x27;A&#x27;, (object,), &#123;&#x27;var_attr&#x27;:1&#125;)A.__class__Out[1]: typeA.__bases__Out[2]: (object,)A.var_attrOut[3]: 1    class B(A):    passBOut[4]: __main__.BB.__class__Out[5]: typeB.__bases__Out[6]: (__main__.A,)B.var_attrOut[7]: 1\n\ntype通过接受类的描述作为参数返回一个对象，这个对象可以被继承， 属性能够被访问，它实际是一个类，其创建由type控制，有type创建的对象的__class__类型为type。type是Python的一个内建元类，用来指导类的生成。除了用内建元类type，用户也可以通过继承type来自定义元类。\n\n__init__()不是构造方法class A(object):    def __new__(cls, *args, **kwargs):        print(cls, args, kwargs)        instance = object.__new__(cls)        print(instance)        # return instance    def __init__(self, *args, **kwargs):        self.a, self.b = args        print(self.a, self.b)a1 = A(1,2,var=3)print(a1.a)print(a1.b)\n\n&lt;class &#x27;__main__.A&#x27;&gt; (1, 2) &#123;&#x27;var&#x27;: 3&#125;Traceback (most recent call last):&lt;__main__.A object at 0x000002147F2BC320&gt;  File &quot;D:/keeplearning/myLearning/python/book1/test.py&quot;, line 13, in &lt;module&gt;    print(a1.a)AttributeError: &#x27;NoneType&#x27; object has no attribute &#x27;a&#x27;\n\n__init__()并不是真正意义上的构造方法，__init__()方法所做的工作是在类的对象创建好后进行变量的初始化。 __new__()方法才会真正的创建实例，是类的构造方法。\n这两个方法都是object 类中默认的方法， 继承自object的新式类，如果不覆盖这两个方法将会默认调用object中对应的方法。\n上面的程序抛出异常时因为__new__()方法中并没有显式返回对象，因此a1为None。将上面代码中的注释取消就可以返回显式对象了。\n关于__new__()和__init__()方法的定义：\n\nobject.__new__(cls[,args...]) ：cls代表类，args为参数列表\n\nobject.__init__(self[,args...]) ： self代表实例对象，args为参数列表\n\n__new__() 是静态方法，__init__() 是实例方法\n\n__new__() 方法一般需要返回类的对象，当返回类的对象时将会自动调用__init__()方法进行初始化，如果没有对象返回，则__init__()方法不会被调用；__init__()方法不需要显式返回，默认为None，强行写return会抛出TypeError\n\n当需要控制实例创建的时候可使用__new__() 方法，而控制实例初始化的时候使用__init__()方法\n\n一般情况下，不需要覆盖__new__()方法，但当子类继承自不可变类型，如str、int、tuple时，往往需要覆盖该方法\n\n当需要覆盖__new__()和__init__() 时，必须使得两个方法的参数保持一致，否则导致异常\nclass B(object):    def __new__(cls, a, b):        # return object.__new__(cls)        return super(B,cls).__new__(cls)    def __init__(self, a, b):         self.a = a        self.b = bb = B(1,2)# 如果new和init方法的入参不一致，pycharm中会有检查提示：# This inspection checks mutual compatibility of __new__ and __init__ signatures# 但是如果使用 *args 或者 **kwargs就避免此问题的出现。\n\n名字查找机制Python中所有变量名都是赋值的时候生成的，而对任何变量名的创建、查找或者改变都会在命名空间（namespace）中进行。变量名所在的命名空间直接决定了其能访问到的范围，即变量的作用域：局部作用域（local）、全局作用域（Global）、嵌套作用域（enclosing functions locals）以及内置作用域（Build-In）。\n\n局部作用域： 函数的每次调用都会创建一个新的本地作用域，拥有新的命名空间。因此函数内的变量名可以与函数外的其他变量相同，由于命名空间不同，并不会产生冲突。默认情况下，函数内部任意的赋值操作（包括&#x3D;语句，import语句，def语句，参数传递）所定义的变量名，如果没用global语句，则申明都为局部变量，即仅在该函数内可见。\n\n全局作用域：定义在Python模块文件中的变量名拥有全局作用域，需要注意的是这里的全局仅限单个文件，即在一个文件的顶层的变量名仅在这个文件内可见，并非所有文件，其他文件中想使用这些变量必须先导入文件对应的模块。当在函数之外给一个变量名赋值是在其全局作用域的情况下进行的。\n\n嵌套作用域：一般在多重函数嵌套的情况下才会考虑到。global语句仅针对全局变量，在嵌套作用域的情况下，如果想在嵌套的函数内修改外层函数定义的变量，即使使用global进行申明也达不到目的，其结果最终是在嵌套的函数所在的命名空间中创建了一个新的变量。\ndef outer():    var = 1    def inner():        global var        var = 2        print(f&#x27;inner var=&#123;var&#125;&#x27;)    inner()    print(f&#x27;outer var=&#123;var&#125;&#x27;)outer()# inner var=2# outer var=1\n\n内置作用域：通过一个标准库中名为__builtin__的模块来实现的\n\n\n在Python中，当访问一个变量时，查找顺序遵循变量解析机制LEGB法则，即依次搜索4个作用域：局部、嵌套、全局、内置作用域，并且在第一个找到的地方停止寻找，如果没有找到则会抛出异常。当存在多个同名变量的时候，操作生效的往往是搜索顺序在前的。\nPython的名字查找机制：\n\n在最内层的范围内找，一般就是函数内部，即在locals()里面找\n在模块内找，即在globals()里面找\n在外层找，即在内置模块中找，也就是在__builtin__中找\n\n描述符机制每个类都有一个__dict__ 属性，其中包含的是它的所有属性， 又称类属性。通过__dict__访问和使用 .是一样的。\nclass A(object):    a_attr = 1    def a_method(self):        passa = A()A.__dict__Out[1]: mappingproxy(&#123;&#x27;__module__&#x27;: &#x27;__main__&#x27;,              &#x27;a_attr&#x27;: 1,              &#x27;a_method&#x27;: &lt;function __main__.A.a_method(self)&gt;,              &#x27;__dict__&#x27;: &lt;attribute &#x27;__dict__&#x27; of &#x27;A&#x27; objects&gt;,              &#x27;__weakref__&#x27;: &lt;attribute &#x27;__weakref__&#x27; of &#x27;A&#x27; objects&gt;,              &#x27;__doc__&#x27;: None&#125;)A.a_attrOut[2]: 1A.__dict__[&#x27;a_attr&#x27;]Out[3]: 1              A.a_methodOut[4]: &lt;function __main__.A.a_method(self)&gt;A.__dict__[&#x27;a_method&#x27;]Out[5]: &lt;function __main__.A.a_method(self)&gt;\n\n每一个实例也有响应的属性 表（__dict__)，成为实例属性。通过实例访问一个属性时，首先尝试在实例属性中找，如果找不到，则会到类属性中查找。\n通过. 操作符访问一个属性时，如果访问的是实例属性，与直接通过__dict__属性获取响应的元素是一样的。\n使用更为安全的propertyproperty 是用来实现属性可管理性的built-In数据类型，一种实现了__get__()和__set__()方法的类，也可以根据需要定义个性化的property。\n实质是一种特殊的数据描述符（如果一个对象同时定义了__get__()和__set__()方法，则称为数据描述符；如果仅定义了__get__()方法，则称为非数据描述符）。和普通描述符的区别在于：普通描述符提供的是一种较为低级的控制属性访问的机制，而property是它的高级应用，它以标准库的形式提供描述符的实现：\nproperty(fget=None, fset=None, fdel=None, doc=None) -&gt; property attribute\n\n常见使用形式一：\nclass A(object):    def __init__(self):        self._var = 0    def get_var(self):        return self._var    def set_var(self, value):        self._var = value    def del_var(self):        del self._var    var = property(get_var, set_var, del_var, &quot;A property&quot;)a = A()\n\na.__dict__Out[3]: &#123;&#x27;_var&#x27;: 0&#125;a.varOut[4]: 0a.var = 1a.varOut[6]: 1del a.vara.__dict__Out[8]: &#123;&#125;\n\n常见使用形式二：\nclass B(object):    _var = None    def __init__(self):        self._var = None    @property    def var(self):        return self._var    @var.setter    def var(self, value):        self._var = value    @var.deleter    def var(self):        del self._var\n\nproperty的优势：\n\n代码更加简洁，可读性强。 比 obj.var +&#x3D; 1 比 obj.set_var(obj.get_var() +1)更加简洁易读。\n\n更好的管理属性的访问。property将对属性的访问直接转换为对对应的get、set等函数的调用，属性能够更好地被控制和管理。常见的场景有：设置校验（检查某个地址、数据是否合法）、对某个属性进行二次计算后再返回用户、计算某个依赖于其他属性的属性。\nclass Date(object):    def __init__(self, dateString):        self._date = dateString    def get_data(self):        return self._date    def set_data(self, dataString):        year, month, day = dataString.split(&#x27;-&#x27;)        if not (0 &lt;= int(year) &lt;= 3000 and 0 &lt;= int(month) &lt;= 12 and 0 &lt;= int(day) &lt;= 31):            assert 0, f&#x27;&#123;dataString&#125; is invalid&#x27;        self._date = dataString    date = property(get_data, set_data)date = Date(&#x27;2019-10-1&#x27;)print(date.date)date.date = &#x27;4000-10-1&#x27;print(date.date)\n\n创建一个property实际上就是将其属性的访问与特定的函数关联起来，相对于标准属性的访问，其工作原理如图所示，property相当于一个分发器，对某个属性的访问并不直接操作具体的对象，而对标准属性的访问没有中间这一层，直接访问存储属性的对象。\n\n代码可维护性更好。property对属性进行再封装， 以类似接口的形式呈现给用户，以统一的语法来访问属性，当具体实现需要改变的时候（如改变某个内部变量，或赋值或取值的计算方式改变），访问的方式依旧可以保留一致。\n\n控制属性访问权限，提高数据安全性\n\n\n由于property是特殊的类，那么就可以被继承，因此用户可以根据需要定义property。\ndef update_meta(self, other):    self.__name__ = other.__name__    self.__doc__ = other.__doc__    self.__dict__.update(other.__dict__)    return selfclass MyProperty(property):    # def __new__(cls, *args, **kwargs):    def __new__(cls, fget=None, fset=None, fdel=None, doc=None):  # 构造函数__new__重新定义了fget()、fset()、fdel()方法        if fget is not None:            def __get__(obj, objtype=None, name=fget.__name__):                fget = getattr(obj, name)                print(f&#x27;fget:&#123;fget.__name__&#125;&#x27;)  # fget:get                print(f&#x27;&#123;obj&#125;,&#123;obj.__dict__&#125;&#x27;)  # &lt;__main__.A object at 0x0000029346BAB400&gt;,&#123;&#x27;_x&#x27;: 1&#125;                return fget()            fget = update_meta(__get__, fget)        if fset is not None:            def __set__(obj, value, name=fset.__name__):                fset = getattr(obj, name)                return fset(value)            fset = update_meta(__set__, fset)        if fdel is not None:            def __delete__(obj, name=fdel.__name__):                fdel = getattr(obj,name)                return fdel()            fdel = update_meta(__delete__, fdel)        return property(fget, fset, fdel, doc)  # 最后返回对象实际还是property实例class A(object):    def get(self):        return self._x    def set(self, x):        self._x = x    def delete(self):        del self._x    x = MyProperty(get,set,delete)a = A()print(a.__dict__)a.x = 1print(a.x)del a.xprint(a.__dict__)\n","categories":["技术","Python"],"tags":["Python"]},{"title":"编写高质量代码：Python中的常见库","url":"/posts/2019/10/06/12508/","content":"Rome was not built in one day， coding will not advance vigorously with one effort.\n字符串的基本用法Python遇到未闭合的小括号时会自动将多行代码拼接为一行，把相邻的两个字符串变量拼接在一起。\ns = (&#x27;I &#x27;     &#x27;am &#x27;     &#x27;coding &#x27;     &#x27;step by step&#x27;)sOut[7]: &#x27;I am coding step by step&#x27;\n\n# 字符串的方法（偏僻的方法用到时再去搜索学一下）&#x27;capitalize&#x27;, &#x27;casefold&#x27;, &#x27;center&#x27;, &#x27;count&#x27;, &#x27;encode&#x27;, &#x27;endswith&#x27;, &#x27;expandtabs&#x27;, &#x27;find&#x27;, &#x27;format&#x27;, &#x27;format_map&#x27;, &#x27;index&#x27;, &#x27;isalnum&#x27;, &#x27;isalpha&#x27;, &#x27;isdecimal&#x27;, &#x27;isdigit&#x27;, &#x27;isidentifier&#x27;, &#x27;islower&#x27;, &#x27;isnumeric&#x27;, &#x27;isprintable&#x27;, &#x27;isspace&#x27;, &#x27;istitle&#x27;, &#x27;isupper&#x27;, &#x27;join&#x27;, &#x27;ljust&#x27;, &#x27;lower&#x27;, &#x27;lstrip&#x27;, &#x27;maketrans&#x27;, &#x27;partition&#x27;, &#x27;replace&#x27;, &#x27;rfind&#x27;, &#x27;rindex&#x27;, &#x27;rjust&#x27;, &#x27;rpartition&#x27;, &#x27;rsplit&#x27;, &#x27;rstrip&#x27;, &#x27;split&#x27;, &#x27;splitlines&#x27;, &#x27;startswith&#x27;, &#x27;strip&#x27;, &#x27;swapcase&#x27;, &#x27;title&#x27;, &#x27;translate&#x27;, &#x27;upper&#x27;, &#x27;zfill&#x27;\n\n\n\nsort() 和sorted()sorted(iterable[, cmp[, key[, reverse]]])s.sort([cmp[, key[, reverse]]])\n\n\ncmp为用户定义的任何比较函数，函数的参数为两个可比较的元素（来自iterable），函数根据第一个参数与第二个参数的关系依次返回 -1、0或者+1（第一个参数小于第二个参数则返回负数）。cmp默认为None。\nkey是带一个参数的函数，用来为每个元素提取比较值，默认为None（即直接比较每个元素）\nreverse表示排序结果是否反转\n\nsorted()作用于任意可迭代的对象，而sort()一般作用于列表。\nsorted()函数返回一个排序后的列表，原有列表保持不变；而sort()函数会直接修改原有列表，函数返回为None。\nsorted 的使用：\n\n对字典排序\n\nConsolefrom operator import itemgetter# 对字典排序bookowner = &#123;&#x27;Bob&#x27;:&#x27;2&#x27;,&#x27;Caly&#x27;:&#x27;1&#x27;,&#x27;Amy&#x27;:&#x27;3&#x27;&#125;ret_sorted = sorted(bookowner.items(),key=itemgetter(1))ret_sortedOut[1]: [(&#x27;Caly&#x27;, &#x27;1&#x27;), (&#x27;Bob&#x27;, &#x27;2&#x27;), (&#x27;Amy&#x27;, &#x27;3&#x27;)]  ret_sorted = sorted(bookowner.items(),key=itemgetter(0))ret_sortedOut[2]: [(&#x27;Amy&#x27;, &#x27;3&#x27;), (&#x27;Bob&#x27;, &#x27;2&#x27;), (&#x27;Caly&#x27;, &#x27;1&#x27;)]\n\n\n多维list排序\n\ninfo = [[&#x27;Bob&#x27;, 95, &#x27;A&#x27;], [&#x27;Caly&#x27;, 86, &#x27;C&#x27;], [&#x27;justin&#x27;, 82, &#x27;A&#x27;], [&#x27;Amy&#x27;, 86, &#x27;D&#x27;]]sorted(info, key=itemgetter(2, 1))# Out[3]: [[&#x27;justin&#x27;, 82, &#x27;A&#x27;], [&#x27;Bob&#x27;, 95, &#x27;A&#x27;], [&#x27;Caly&#x27;, 86, &#x27;C&#x27;], [&#x27;Amy&#x27;, 86, &#x27;D&#x27;]]\n\n\n字典中混合list排序\n\nmydict = &#123;    &#x27;Bob&#x27;: [&#x27;M&#x27;, 7],    &#x27;Caly&#x27;: [&#x27;E&#x27;, 2],    &#x27;Justin&#x27;: [&#x27;P&#x27;, 3],    &#x27;Amy&#x27;: [&#x27;C&#x27;, 6]&#125;sorted(mydict.items(), key=lambda elem: itemgetter(1)(elem[1]))\n\n\nlist中混合字典排序\n\nratelist = [    &#123;&#x27;name&#x27;:&#x27;Bob&#x27;,&#x27;win&#x27;:10,&#x27;loss&#x27;:3,&#x27;rate&#x27;:75&#125;,    &#123;&#x27;name&#x27;:&#x27;David&#x27;,&#x27;win&#x27;:3,&#x27;loss&#x27;:5,&#x27;rate&#x27;:57&#125;,    &#123;&#x27;name&#x27;:&#x27;Carol&#x27;,&#x27;win&#x27;:4,&#x27;loss&#x27;:5,&#x27;rate&#x27;:57&#125;,    &#123;&#x27;name&#x27;:&#x27;Patty&#x27;,&#x27;win&#x27;:9,&#x27;loss&#x27;:3,&#x27;rate&#x27;:71&#125;,]sorted(ratelist,key=itemgetter(&#x27;rate&#x27;,&#x27;name&#x27;))# Out[62]: # [&#123;&#x27;name&#x27;: &#x27;Carol&#x27;, &#x27;win&#x27;: 4, &#x27;loss&#x27;: 5, &#x27;rate&#x27;: 57&#125;,#  &#123;&#x27;name&#x27;: &#x27;David&#x27;, &#x27;win&#x27;: 3, &#x27;loss&#x27;: 5, &#x27;rate&#x27;: 57&#125;,#  &#123;&#x27;name&#x27;: &#x27;Patty&#x27;, &#x27;win&#x27;: 9, &#x27;loss&#x27;: 3, &#x27;rate&#x27;: 71&#125;,#  &#123;&#x27;name&#x27;: &#x27;Bob&#x27;, &#x27;win&#x27;: 10, &#x27;loss&#x27;: 3, &#x27;rate&#x27;: 75&#125;]\n\n\n\nCounter# 统计次数# 1、使用dictdata = [&#x27;a&#x27;, &#x27;2&#x27;, &#x27;c&#x27;, 1, 2, &#x27;a&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, 0, 1]count_dict = dict()for ele in data:    if ele in count_dict:        count_dict[ele] +=1    else:        count_dict[ele] = 1# count_dict# Out[1]: &#123;&#x27;a&#x27;: 3, &#x27;2&#x27;: 1, &#x27;c&#x27;: 2, 1: 2, 2: 1, &#x27;b&#x27;: 1, 0: 1&#125;# 2、使用defaultdictfrom collections import defaultdictcount_default = defaultdict(int)for ele in data:    count_default[ele] +=1# count_default# Out[2]: defaultdict(int, &#123;&#x27;a&#x27;: 3, &#x27;2&#x27;: 1, &#x27;c&#x27;: 2, 1: 2, 2: 1, &#x27;b&#x27;: 1, 0: 1&#125;)# 3、使用set和listcount_set = set(data)count_list = []for ele in count_set:    count_list.append((ele, data.count(ele)))# count_list# Out[3]: [(0, 1), (1, 2), (&#x27;2&#x27;, 1), (2, 1), (&#x27;c&#x27;, 2), (&#x27;b&#x27;, 1), (&#x27;a&#x27;, 3)]# 4、更加优雅、简介的方式：使用collection.Counter# Counter类属于字典类的子类，是一个容器对象，主要用来统计散列对象# 支持集合操作+-&amp;|，其中&amp;|分别返回两个Counter对象元素的最小值和最大值from collections import Counter# 三种方式初始化：可迭代对象、关键字参数、字典Counter(&#x27;success&#x27;)      # Counter(&#123;&#x27;s&#x27;: 3, &#x27;u&#x27;: 1, &#x27;c&#x27;: 2, &#x27;e&#x27;: 1&#125;)Counter(a=1, b=2, c=3)      # Counter(&#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3&#125;)Counter(&#123;&#x27;a&#x27;: &#x27;2&#x27;, &#x27;c&#x27;: 1, 2: &#x27;a&#x27;&#125;)  # Out[8]: Counter(&#123;&#x27;a&#x27;: &#x27;2&#x27;, &#x27;c&#x27;: 1, 2: &#x27;a&#x27;&#125;)\n\n# 使用element()方法来获取Counter中的key值data = [&#x27;a&#x27;, &#x27;2&#x27;, &#x27;c&#x27;, 1, 2, &#x27;a&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, 0, 1]list(Counter(data).elements())# Out[10]: [&#x27;a&#x27;, &#x27;a&#x27;, &#x27;a&#x27;, &#x27;2&#x27;, &#x27;c&#x27;, &#x27;c&#x27;, 1, 1, 2, &#x27;b&#x27;, 0]# 使用most_common()方法找出前n个出现频率最高的元素、对应次数Counter(data).most_common(2)# Out[12]: [(&#x27;a&#x27;, 3), (&#x27;c&#x27;, 2)]# 当访问的元素不存在时，默认返回0，而不是抛出异常(Counter(data)[&#x27;y&#x27;])# Out[13]: 0# updata()方法用于被统计对象元素的更新，原有Counter计数器对象和新增元素的统计数值相加而不是直接替换它们c = Counter(&#x27;success&#x27;)# c# Out[15]: Counter(&#123;&#x27;s&#x27;: 3, &#x27;u&#x27;: 1, &#x27;c&#x27;: 2, &#x27;e&#x27;: 1&#125;)c.update(&#x27;successfully&#x27;)# c# Out[17]: Counter(&#123;&#x27;s&#x27;: 6, &#x27;u&#x27;: 3, &#x27;c&#x27;: 4, &#x27;e&#x27;: 2, &#x27;f&#x27;: 1, &#x27;l&#x27;: 2, &#x27;y&#x27;: 1&#125;)# subtract()用于实现计数器对象中元素统计值相减，输入和输出的统计值允许为0或者为负数c.subtract(&#x27;successfully&#x27;)# c# Out[19]: Counter(&#123;&#x27;s&#x27;: 3, &#x27;u&#x27;: 1, &#x27;c&#x27;: 2, &#x27;e&#x27;: 1, &#x27;f&#x27;: 0, &#x27;l&#x27;: 0, &#x27;y&#x27;: 0&#125;)\n\n\n\nConfigParser配置文件的意义在于用户不需要修改代码，就可以改变应用的行为。\ngetboolean()函数，根据一定的规则将配置项的值转换为布尔值。\n[section1]option1=0\n\n当调用getboolean(‘section1’,’option1’)) 时，返回False，除了0之外，no、false、off都会被转义为False，对应的1、yes、true、on都会被转义为True，其他值都会导致抛出ValueError异常。\n配置项的查找规则，在ConfigParser支持的配置文件格式里，有一个[DEFAULT]节点，当读取的配置项不在指定的节点里时，ConfigParser将会到[DEFAULT]节点中区找。\n[section1]option1=false[section2][DEFAULT]in_default = &#x27;an option value in default&#x27;\n\nimport configparserconf = configparser.ConfigParser()conf.read(&#x27;example.conf&#x27;)print(conf.getboolean(&#x27;section1&#x27;,&#x27;option1&#x27;))  # Falseprint(conf.get(&#x27;section2&#x27;,&#x27;in_default&#x27;))    # &#x27;an option value in default&#x27;\n\n配置项值的查找规则：\n\n若找不到节点名，就抛出NoSectionError；\n若给定的配置项出现在get()方法的vars参数中，则返回vars参数中的值；\n若在指定的节点中含有给定的配置项，则返回其值；\n若在[DEFAULT]中有指定的配置项，则返回其值；\n若在构造函数的default参数中有指定的配置项，则返回其值；\n抛出NoOptionError；\n\nConfigParser支持字符串格式化的语法：\nexample_str = &#x27;%(protocol)s://%(server)s:%(port)s/&#x27; % &#123;&#x27;protocol&#x27;:&#x27;http&#x27;,&#x27;server&#x27;:&#x27;example.com&#x27;,&#x27;port&#x27;:1080,&#125;# http://example.com:1080/\n\n[DEFAULT]conn_str = %(dbn)s://%(user)s:%(pw)s@%(host)s:%(port)s/%(db)sdbn = mysqluser = roothost = localhostport = 3306[db1]user = zyppw = pppdb = example[db2]host = 192.168.0.110pw = wwwdb =example\n\nimport configparserconf = configparser.ConfigParser()conf.read(&#x27;example.conf&#x27;)print(conf.get(&#x27;db1&#x27;,&#x27;conn_str&#x27;))print(conf.get(&#x27;db2&#x27;,&#x27;conn_str&#x27;))# mysql://zyp:ppp@localhost:3306/example# mysql://root:www@192.168.0.110:3306/example\n\n\n\npickle序列化是把内存中的数据结构在不丢失其身份和类型信息的情况下转成对象的文本或二进制的过程。对象序列化后的形式经过饭序列化能恢复为原有对象。Python中有很多支持序列化的模块，如pickle、json、marshal、shelve。\npickle是最通用的序列化模块，还有用C语言实现的cPickle，拥有这更好的性能。\npickle最主要的两个函数：dump()、load()，用于对象的序列化和反序列化。\n\npickle.dump(obj, file[,protocol])：序列化数据到一个文件描述符（一个打开的文件、套接字等）。参数obj表示需要序列化的对象，包括布尔、数字、字符串、字节数组、None、列表、元组、字典、集合等基本数据类型，还可以处理循环，递归引用对象、类、函数以及类的实例等。参数file支持write()方法的文件句柄，可以为真实的文件，也可以是StringIO对象。protocol为序列化使用的协议版本，0表示ASCII协议（默认为0），所序列化的对象使用可打印的ASCII码表示；1表示老式的二进制协议；2表示2.3版本引入的新二进制协议，比以前的高效。\nload(file)：表示把文件中的对象恢复为原来的对象（反序列化）\n\nimport pickledata = &#123;&#x27;Bob&#x27;: &#x27;2&#x27;, &#x27;Caly&#x27;: &#x27;1&#x27;, &#x27;Amy&#x27;: &#x27;3&#x27;&#125;file_name = &#x27;test_pickle.txt&#x27;with open(file_name,&#x27;wb&#x27;) as fp:    pickle.dump(data, fp)with open(file_name,&#x27;rb&#x27;) as fp:    res = pickle.load(fp)    print(res)\n\npickle的特点：\n\n接口简单，容易使用，通过dump和load可以轻松实现序列化和反序列化\n\npickle的存储格式具有通用性，能被不同平台的Python解析器共享：Linux下序列化的格式文件可在Windows的Python解析器中反序列化，兼容性好\n\n支持的数据类型广泛: 数字、布尔值、字符串，只包含可序列化对象的元组、字典、列表等，非嵌套的函数、类以及通过类的__dict__或者__getstate__可以返回序列化对象的实例等\n\npickle模块是可扩展的。pickle模块是可以扩展的。对于实例对象，pickle在还原对象的时候一般是不调用__init__()函数的，如果要调用__init__()进行初始化，对于古典类可以在类定义中提供__getinitargs__()函数，并返回一个元组，当进行unpickle的时候，Python就会自动调用__init__()，并把__getinitargs__()中返回的元组作为参数传递给__init__()，而对于新式类，可以提供__getnewargs__()来提供对象生成时候的参数，在unpickle的时候以Class.__new__(Class, *arg)的方\n式创建对象。对于不可序列化的对象，如sockets、文件句柄、数据库连接等，也可以通过实现pickle协议来解决这些局限，主要是通过特殊方法__getstate__()和__setstate__()来返回实例在被pickle时的状态，见如下示例：\n\n\nimport pickleclass TextReader():    def __init__(self, filename):        self.filename = filename        self.file = open(self.filename)  # 打开文件的句柄        self.position = self.file.tell()    def readline(self):        line = self.file.readline()        self.position = self.file.tell()        if not line:            return None        if line.endswith(&#x27;\\n&#x27;):            line = line[:-1]        return f&quot;&#123;self.position&#125;&quot;, line    def __getstate__(self):  # 记录文件被pickle时的状态        print(&quot;in __getstate__&quot;)        state = self.__dict__.copy()  # 获取被pickle时的字典信息        del state[&#x27;file&#x27;]        return state    def __setstate__(self, state):  # 设置反序列化后的状态        print(&quot;in __setstate__&quot;)        self.__dict__.update(state)        file = open(self.filename)        self.file = filereader = TextReader(&quot;test.py&quot;)print(reader.readline())print(reader.readline())print(&quot;---&quot;)s = pickle.dumps(reader)  # 在dumps时会默认调用__getstate__new_reader = pickle.loads(s)  # 在loads时会默认调用__setstate__print(&quot;***&quot;)print(new_reader.readline())print(new_reader.readline())\n\n\n能够自动维护对象间的引用，如果一个对象上存在多个引用，pickle后不会改变对象间的引用，并且能够自动处理循环和递归。\n\nimport picklea = [1,2]b = ab.append(3)p = pickle.dumps((a,b))a1, b1 = pickle.loads(p)a1Out[1]: [1, 2, 3]b1Out[2]: [1, 2, 3]a1.append(4)b1Out[3]: [1, 2, 3, 4]  # 反序列化对a1对象的修改仍然会影响到b1\n\npickle的使用也存在以下限制：\n\n不能保证操作的原子性\n存在安全性问题\npickle协议是Python特定的，不同语言之间的兼容性难以保障\n\njsonjson是一种轻量级数据交换格式，基于JavaScript的一个子集，可读性和互操作性较强，易于解析和使用。json和pickle类似，使用dump&#x2F;dumps来序列化，load&#x2F;loads来反序列化。\njson的两大数据结构：名称&#x2F;值对的集合、值的有序列表。\ntraceback 获取栈信息tracebac模块可以在发生异常时展示出现场信息，输出完整的栈信息，包括调用顺序、异常发生的语句、错误类型。\ntraceback.print_exc()方法打印出的信息包括3部分：错误类型(IndexError)、错误对应的值(list index out of range)、具体的trace信息，包括文件名、具体的行号、函数名以及对应的源代码。常用的几个方法：\n\ntraceback.print_exception(type, value, traceback[, limit[, file]])，根据limit的设置打印栈信息，file为None时定位到sys.stderr，否则写入文件；type、value、traceback这3个参数对应的值可以从sys.exc_info()中获取\ntraceback.print_exc([limit[, file]])，为print_exception()函数的缩写，不需要传入type、value、traceback\ntraceback.format_exc([limit])，与print_exc类似，区别在于返回形式为字符串\ntraceback.extract_stack([file, [, [limit]]])，从当前栈帧中提取trace信息\n\nthreadingPython为多线程编提供了模块：thread、threading。\n\nthread模块提供了多线程底层支持模块，以敌机原始的方式来处理和控制线程，使用较为复杂\nthreading模块基于thread进行包装，将线程的操作对象化，在语言层面提供了丰富的特性\n\n一般Python多线程支持两种方式来创建线程：一种是通过继承Thread类，重写它的run()方法；另一种是创建一个threading.Thread对象，在它的初始化函数(__init__)中将可调用对象作为参数传入。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"编写高质量代码：Python中的常见语法","url":"/posts/2019/09/29/25728/","content":"Rome was not built in one day， coding will not advance vigorously with one effort.\n有节制地使用from… import语句\n尽量优先使用import a形式，如访问B需要使用a.B的形式\n有节制的使用from a import B， 可以直接访问B\n无节制使用可能会导致：命名空间的冲突、循环嵌套导入\n\n\n最好不使用from a import * ，这会导致污染命名空间，且无法清楚得知导入了哪些对象\n\nPython的import机制：在初始化环境的时候会预先加载一批内建模块到内存中，这些模块相关信息被存放在sys.modules中，可以通过sys.modules.items()查看。\n加载一个模块时，解释器实际要做以下操作：\n\n在sys.modules中进行搜索看该模块是否已经存在， 如果存在则将其导入到当前局部命名空间，加载结束；\n如果在sys.modules中没有找到对应模块的名称，则为需要导入的模块创建一个字典对象，并将该对象信息插入到sys.modules中；\n加载前确认是否需要对模块对应的文件进行编译，如果需要则先进行编译；\n执行动态加载，在当前模块的命名空间中执行编译后的字节码，并将其中所有的对象放入模块对应的字典中；\n\n# test_module.pya = 1b = &#x27;b&#x27;print(&quot;this is test_module.py&quot;)# other.pydir()# [&#x27;__annotations__&#x27;, &#x27;__builtins__&#x27;, &#x27;__cached__&#x27;, &#x27;__doc__&#x27;, &#x27;__file__&#x27;, &#x27;__loader__&#x27;, &#x27;__name__&#x27;, &#x27;__package__&#x27;, &#x27;__spec__&#x27;]import sysimport test_moduledir()# [&#x27;__annotations__&#x27;, &#x27;__builtins__&#x27;, &#x27;__cached__&#x27;, &#x27;__doc__&#x27;, &#x27;__file__&#x27;, &#x27;__loader__&#x27;, &#x27;__name__&#x27;, &#x27;__package__&#x27;, &#x27;__spec__&#x27;, &#x27;sys&#x27;, &#x27;test_module&#x27;]# from test_module import a  # 将 a 加入到sys.module中assert &#x27;test_module&#x27; in sys.modules.keys()assert id(test_module) == id(sys.modules[&#x27;test_module&#x27;])dir(test_module)# [&#x27;__builtins__&#x27;, &#x27;__cached__&#x27;, &#x27;__doc__&#x27;, &#x27;__file__&#x27;, &#x27;__loader__&#x27;, &#x27;__name__&#x27;, &#x27;__package__&#x27;, &#x27;__spec__&#x27;, &#x27;a&#x27;, &#x27;b&#x27;]\n\n从以上结果看，对于用户定义的模块，import机制会创建一个新的module将其加入到当前的局部命名空间中，与此同时，sys.modules也会加入了该模块的相关信息。\n脚本文件所在的目录中的__pycache__中多了一个test_module.cpython-36.pyc文件，该文件为解释器生成的模块相对应的字节码，从import之后的输出“this is test_module.py“可以看出模块同时被执行，而a和b被写入test_module所对应的字典信息中。\n优先使用absolute importabsolute import 可读性和出现问题后可跟踪性更好，而使用relative import可能会导致命名冲突、语义含糊。\n连接字符串优先使用jointry…except…finally…无论try中是否有异常抛出，finally语句总会被执行。\ntry块中发生异常的时候，如果在except语句中找不到对应的异常处理，异常将会被临时保存起来，当finally语句中产生了新的异常、或执行了return、或break语句那么临时保存的异常将被丢失，从而导致异常被屏蔽。\n另外不推荐在finally中使用return语句进行返回，这种处理方式不仅会带来误解，可能还会导致严重的错误。\ndef test_finally(n):    try:        if n &lt;= 0:            raise ValueError(&#x27;data is negative&#x27;)        else:            return n    except ValueError as e:        print(e)    finally:        return -1print(test_finally(0))  # -1print(test_finally(2))  # -1\n\n\n\n优先使用列表生成式\n使用列表生成式更为直观清晰、代码更加简洁。\n列表生成式的效率更高\n\n举例：\nwords = [&#x27;  a&#x27;, &#x27;awk&#x27;, &#x27;backup&#x27;, &#x27;Advance&#x27;, &#x27;Street&#x27;]new_words = []for word in words:    if word.strip().istitle():        new_words.append(word)print(new_words)# 列表生成式new_words2 = [word for word in words if word.strip().istitle()]print(new_words2)import randomxlist = [random.randint(0, 10) for i in range(3)]ylist = [random.randint(-10, 0) for i in range(3)]point = [(x, y) for x, y in zip(xlist, ylist)]# [(5, -8), (6, -3), (1, -10)]\n\n\n\n函数传参既不是传值也不是传引用Python函数参数传对象，或者说是传对象的引用。\n\n函数参数在传递的过程中将整个对象传入，对可变对象的修改在函数内外都可见，调用者和被调用者之间共享这个对象；\n对于是不可变对象的参数，并不能真正被改变，是通过生成一个新对象后赋值来实现改变。我的理解是：一个是实参，一个是形参；\n\n# 两个例子：# 1、作为不可变对象：参数传值def test_invarible(var):    print(var, id(var))    var += 1    print(var, id(var))var = 1print(var, id(var))test_invarible(var)print(var, id(var))# 1 1380754528# 1 1380754528# 2 1380754560# 1 1380754528# 如果是引用，函数中var的id应该是不变的，且最后的var打印应该为2。# var是不可变对象，可以这么理解：外部的var=1是实参，test_invarible入参var是形参，函数中的形参改变了，var重新申请了内存地址，不影响实参# 2、作为可变对象：参数引用def test_varibale(varlist):    print(varlist, id(varlist))    varlist.append(&quot;func&quot;)    print(varlist, id(varlist))originlist = [1, 2, 3]test_varibale(originlist)print(originlist, id(originlist))# [1, 2, 3] 1486999385800# [1, 2, 3, &#x27;func&#x27;] 1486999385800# [1, 2, 3, &#x27;func&#x27;] 1486999385800# 如果是传值，且最后的originlist打印应该为最初的[1, 2, 3]。# originlist是可变对象，函数内外使用同一片内存地址，只要不重新给它分配内存地址，originlist的id是不变的（这里的append是在varlist对象上做的改变，没有重新开辟内存地址）\n\n小结：id到底变不变，一看参数是否为可变对象，二看是否重新开辟内存地址\ndef function_param(origin_list):    new_list = origin_list  # new_list和origin_list引用同一个内存地址    print(origin_list, id(origin_list))    print(new_list, id(new_list))    # new_list = [0, 0, 0]  # case1：给new_list重新分配内存地址，id改变    new_list.append(&#x27;a&#x27;)  # case2：在new_list对象上更改，内存地址不变，id不变    print(new_list, id(new_list))origin_list = [1, 2, 3]function_param(origin_list)print(origin_list, id(origin_list))&#x27;&#x27;&#x27;new_list = [0, 0, 0]时[1, 2, 3] 1990045687496[1, 2, 3] 1990045687496[0, 0, 0] 1990045619720[1, 2, 3] 1990045687496&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;new_list.append(&#x27;a&#x27;)时[1, 2, 3] 2733052026568[1, 2, 3] 2733052026568[1, 2, 3, &#x27;a&#x27;] 2733052026568[1, 2, 3, &#x27;a&#x27;] 2733052026568&#x27;&#x27;&#x27;\n\n\n\n Python中的赋值  VS  C&#x2F;C++中的赋值：背后的内存地址分配\na = 1b = ab = 2\n\nC&#x2F;C++：\n\n执行b=a时，在内存中申请一块内存并将a的值复制到该内存中\n执行b=2时，将b对应的值从原来的1修改为2\n\nPython：\n\nPython中的赋值不是复制，b=a使b与a引用同一个对象，而b=2是将b指向对象2\n\n\n警惕默认参数潜在的问题可变对象不能作为默认参数传递\ndef test_default(paramlist=[]):    paramlist.append(&#x27;a&#x27;)    return paramlist  test_default()Out[5]: [&#x27;a&#x27;]test_default.__defaults__Out[6]: ([&#x27;a&#x27;],)  test_default()Out[7]: [&#x27;a&#x27;, &#x27;a&#x27;]test_default.__defaults__Out[8]: ([&#x27;a&#x27;, &#x27;a&#x27;],)\n\ndef 在Python中是一个可执行的语句，当解释器执行 def 时，默认参数也会被计算，并存在函数的__defaults__属性中。\n如果 不想让默认参数所指向的对象在所有的函数调用中被共享，而是在函数调用的过程中动态生成，可以在定义时使用None对象作为占位符。\ndef test_default(paramlist=None):    if paramlist is None:        paramlist = []    paramlist.append(&#x27;a&#x27;)    return paramlist\n\n\n\n一个问题：假设某个函数需要传入当时系统的时间并做一些处理，下面两种哪种正确？\nimport timedef test(when = time.time):    print(when())def test2(when = time.time()):    print(when)&#x27;&#x27;&#x27;我的理解是第一种正确。第二种在解释器执行def时就计算了when的值，这并不是代码中调用该函数的时间，更不可能是函数内存某个时刻调用的时间，不符合需求。&#x27;&#x27;&#x27;\n\nimport timedef test1(when = time.time):    print(when())def test2(when = time.time):    time.sleep(3)  # 加入延时3秒    print(when())def test3(when = time.time()):    print(when)test1()test2()test3()# 1569592866.623606# 1569592869.6237614# 1569592866.623606# 由结果可知，test2虽然比test3早调用，但是test2的when比test3的大# 另外，test3和test1的when相等，# 说明test3函数的when在解释器执行def时就计算了time.time()的值。\n\n\n\n不定长参数的使用*args 实现可变列表，**kwargs接受字典的关键字参数列表\n可变长参数的使用场景：\n\n为函数添加一个装饰器\n\ndef decorate(func):    def originfunc(*args, **kwargs):        print(&quot;decorate&quot;)        return func(*args, **kwargs)    return originfunc@decoratedef test(var,var2=1):    print(var)    print(var2)\n\n\n参数的数量不确定，可以考虑使用可变长参数\n实现函数的多态或者在继承情况下子类需要调用父类的某些方法\n\nstr() 和 repr()的区别对于不同类型的输入，对比两者的差异：\n\n两者的面向的对象不同：str()主要是面向用户，其目的是可读性，返回形式为用户友好性和可读性都较强的字符串类型。而repr()面向的是python解释器、程序员，返回值为Python解释器内部的含义，常作为debug用。\n在解释器中直接输入a时默认调用repr(）函数，而print(a)是调用str()函数\nrepr()返回值一般可以用eval()函数来还原对象：obj &#x3D;&#x3D; eval(repr(obj))\n两个方法分别调用内建的__str__ 、__repr__方法，一般来说在类中都应该定义__repr__方法，而__str__方法是可选的，若没有定义__str__方法，默认使用__repr__\n\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"编写高质量代码：Python中的惯用法","url":"/posts/2019/09/22/37783/","content":"Rome was not built in one day， coding will not advance vigorously with one effort.\n利用Assert发现问题assert 主要是为调试使用，方便检查程序的异常和不恰当的值。\n__debug__的值为True。\n\n断言不要滥用，应该使用在正常逻辑不可到达之处、正常情况下总是为真的场合\n能使用python的异常处理，就可以不使用断言\n函数调用后，需要确认返回值是否合理时可以使用断言\n当条件是业务逻辑继续下去的先决条件时可以使用断言\n\n数据值交换不推荐使用中间变量import disdef swap1():    a = 1    b = 2    a, b = b, a    &gt;&gt;&gt;dis.dis(swap1)  2           0 LOAD_CONST               1 (1)              2 STORE_FAST               0 (a)  3           4 LOAD_CONST               2 (2)              6 STORE_FAST               1 (b)  4           8 LOAD_FAST                1 (b)             10 LOAD_FAST                0 (a)             12 ROT_TWO             14 STORE_FAST               0 (a)             16 STORE_FAST               1 (b)             18 LOAD_CONST               0 (None)             20 RETURN_VALUE\n\ndef swap2():    a = 11    b = 22    temp = a    a = b    b = temp    &gt;&gt;&gt;dis.dis(swap2)  2           0 LOAD_CONST               1 (11)              2 STORE_FAST               0 (a)  3           4 LOAD_CONST               2 (22)              6 STORE_FAST               1 (b)  4           8 LOAD_FAST                0 (a)             10 STORE_FAST               2 (temp)  5          12 LOAD_FAST                1 (b)             14 STORE_FAST               0 (a)  6          16 LOAD_FAST                2 (temp)             18 STORE_FAST               1 (b)             20 LOAD_CONST               0 (None)             22 RETURN_VALUE\n\nPython中的字节码是一种类似汇编指令的中间语言，但是一个字节码指令并不是对应一个机器指令。\nswap1中的a, b = b, a对应着代码块的12-16行（2个LOAD_FAST, 2个STORE_FAST, 1个ROT_TWO），而swap2中第4-6行对应着13-18行（3个LOAD_FAST，3个STORE_FAST），ROT_TWO的主要作用是交换两个栈的最顶层元素，它比执行一个LOAD_FAST+STORE_FAST快。\n充分利用Lazy evaluation特性\n避免不必要的计算，带来性能上的提升\n\n条件表达式，如if x and y， 在x为False情况，或者if x or y，在x为True的情况下，y都是不计算的\n对于and条件表达式，应该将值为False可能性高的变量写前面；对于or条件表达式，将值为True可能性高的写前面\n\n\n节省空间，使得无限循环的数据结构变成可能\n\n生成器表达式：每次需要计算时才通过yield产生所需要的元素\n\ndef fib():    a, b = 0, 1    while True:        yield a        a, b = b, a + b\n\n不推荐使用type来检查类型作为动态语言的强类型脚本语言，Python中的变量在定义时并不会指明具体的类型，Python解释器在运行时自动进行类型检查并根据需要进行隐式类型转换， 在出错时通过抛出异常来处理。\nclass UserInt(int):  # 继承int    def __init__(self, var=0):        # self._var = int(var)        super(UserInt, self).__init__()        self._var = int(var)    def __add__(self, other):        if isinstance(other, UserInt):            return UserInt(self._var + other._var)        return self._var + other    def __iadd__(self, other):        raise NotImplementedError(&quot;not support operation&quot;)    def __str__(self):        return str(self._var)    def __repr__(self):        return f&quot;Interger &#123;self._var&#125;&quot;user1 = UserInt()user2 = UserInt(2)user3 = UserInt(&#x27;3&#x27;)print(user1, user2, user3)  # 0 2 3print(user1 + user2)  # 2print(user3 + 12)  # 15type_user1 = type(user1)  # &lt;class &#x27;__main__.UserInt&#x27;&gt;type_int = type(int)  # &lt;class &#x27;type&#x27;&gt;if type_user1 is type_int: # False    print(True)else:    print(False)    print(UserInt, type(UserInt))  # &lt;class &#x27;__main__.UserInt&#x27;&gt; &lt;class &#x27;type&#x27;&gt;print(UserInt(), type(UserInt()))  # 0 &lt;class &#x27;__main__.UserInt&#x27;&gt;print(user1, type(user1))  # 0 &lt;class &#x27;__main__.UserInt&#x27;&gt;print(int, type(int))  # &lt;class &#x27;int&#x27;&gt; &lt;class &#x27;type&#x27;&gt;\n\n虽然UserInt继承于int，但是type()并不认为user1是int类型，显然是不合理的。基于内建类型扩展的用户定义类型，type函数并不能准确的返回结果。\n推荐使用 isinstance()函数:\nif isinstance(user1, type(UserInt())):  # True    print(True)else:    print(False)if isinstance(user1, int):  # True    print(True)else:    print(False)\n\n\n\n使用enumerate()获取序列的索引和值小需求：对某一序列进行迭代并获取序列中的元素进行处理\nfor i, ele in enumerate(list_):    print(f&quot;i:&#123;i&#125;, element:&#123;ele&#125;&quot;)# 推荐 enumerate(sequence,start=0)# sequence可以是任何可迭代对象，函数返回本质上是一个迭代器，可用next()获取下一个迭代元素enu = enumerate(list_)next(enu)  # (0, 1)# enumerate内部实现原理def mock_enumerate(sequence, start=0):    n = start    for ele in sequence:        yield n, ele        n += 1# 实现自己的enumerate()函数:反序列def reverse_enumerate(sequence, start=0):    n = -1    for ele in reversed(sequence):        yield len(sequence)+n, ele        n -= 1# 对于字典的迭代，enumerate()并不适合，而是应该使用方法items()mydict = &#123;1:&#x27;aa&#x27;,2:&#x27;bb&#x27;&#125;for key,value in mydict.items():\n\n\n\nis 和 &#x3D;&#x3D; 的适用场景两个对象相等应该用 &#x3D;&#x3D; \n\n\n\n操作符\n意义\n\n\n\nis\nobject identity\n\n\n&#x3D;&#x3D;\nequal\n\n\nis的作用是用来检验对象的标识符是否一致，也就是比较两个对象在内存中是否拥有同一块内存空间，它并不适合用来判断两个字符串是否相等。x is y 仅当x和y是同一个对象的时候才返回True，基本相当于id(x) &#x3D; id(y)。而&#x3D;&#x3D;是用来检验两个对象的值是否相等的，调用的是内部的__eq__方法， a == b相当于 a.__eq__(b) ，==是可以被重载的，而is不能被重载。\n另外Python中的string interning（字符串驻留）机制得处理较小的字符串和较长字符串有所不同。对于较小的字符串，为了提高系统性能会保留其值的一个副本，当创建新的字符串时直接指向该副本即可。所以有时有的对象有着相同的内容，但是标识符却不相同，用&#x3D;&#x3D;判断为True，用is判断为False。\nshort_a = &#x27;aa&#x27;short_b = &#x27;aa&#x27;id(short_a), id(short_b)Out[1: (2899755577672, 2899755577672)short_a == short_bOut[3]: Trueshort_a is short_bOut[5]: True        long_b = &quot;just test long string&quot;long_a = &quot;just test long string&quot;id(long_a), id(long_b)Out[2]: (2899904998112, 2899906473896)  long_a == long_bOut[4]: True  long_a is long_bOut[6]: False\n\n来源：《编写高质量代码：改善Python程序的91个建议》\n","categories":["技术","Python"],"tags":["Python"]},{"title":"自动化测试脚本编写小结","url":"/posts/2019/09/14/37423/","content":"1. 注释\n业务代码必须要写好注释。变量的命名也需要考虑规范，尽量和业务名相关，这样也算是一种注释，让人看得清楚。\n纯逻辑代码注明该块代码的作用是什么，入参、返回值的注释。一头(入参)、一尾(返回值)、一大概(功能)，让他人拿到就能用，不用想怎么实现的，应用为先。\n\n2. 代码抽取、封装\n使用两次及以上的代码块，即可考虑封装成函数，抽取复用的代码，提出入参为变量。\n涉及到对某个字段或者特定数据等进行多种操作时，考虑写成类的形式。\n某业务的操作涉及的数据和逻辑功能较多且复杂，考虑将业务操作和数据分离。\n\n3. 业务相关\n写代码前一定要考虑好业务需求，评估需要实现的业务；理清业务之间的关系，业务中也分轻重，并不是所有的业务都是需要立即去实现的。\n使用思维导图梳理业务，将业务走一遍，再思考每一步怎么用代码实现。\n磨刀不误砍柴工，明确需求、思路更重要，代码只是实现的手段。\n\n4. 结果校验\n写测试脚本，校验是必不可少的一环，有的字段配置下发后，是否成功未知，测试未知，需要通过重新获取来验证，常常使用assert来判断。\n结果数据的展示，使用 f 语法来展示数据（比%s、.foramt()更清晰），在pytest+Allure 中使用allure.attach(数据，’描述信息’)\n\n5. 调试\n遇到bug，重复运行两遍不如debug一遍，调试最能发现问题所在。\n调试技巧需要不断地提升，提高调试的能力。\n\n6. 提交代码\n提交代码前先自己检查一遍，将调试的代码删除，比如使用main函数调试的代码，将没用到的变量、导包、无用的注释删除， 再使用 Ctrl+Alt+L 将代码格式化后符合PEP8规范。\n每次提交的信息，都应该简明扼要地描述当前提交的代码。\n每天记得更新项目代码，避免在开发新的脚本过程中落后master太多，也便于提交代码时合入、减少冲突。\n\n7. 及时总结\n每写一项业务、一个脚本，及时记录自己在其中遇到的问题，有哪些教训可以总结哪些东西。\n有的业务只有在用自动化覆盖时才去了解，一旦了解后就记录该块的业务知识、注意点，业务这种东西一旦学习了，以后就只要花很少时间就能拿起来。\n\n8. 向同事学习\n同事写的代码总有值得学习的地方，学他人之长，补己之短。\n对于别人写的不好的地方，思考是否有优化的空间。\n刚开始可以学习模仿别人写代码，慢慢地试着优化代码。\n\n","categories":["技术","工作小结"],"tags":["总结"]},{"title":"面试题，如何检验自己写的代码质量高低","url":"/posts/2019/03/05/4769/","content":"有人说: 代码永远会有BUG，没有最好只有更好。高效是程序员必须作到的事情，无错是程序员一生的追求。复用、分而治之、折衷是代码哲学的基本思想。模块化与面向对象是实现高效无错代码的方法。高效无错代码需要思想与实践的不断反复。\n代码水平高低，是看他的可维护性、可重用性、可扩展性、可读性，几十行代码，不太能全部提现，如果我得到了这份工作，我一定会在我每一行代码上体现我最好的水平。\n多注意以下几点，坚持这样写, 代码质量会越来越高的。\n\n多写注释 (多使用代码本身来注释)\n命名规范 (比如通过命名知道它的类型)\n多使用函数封装, 函数名体现功能, 保证函数单一的功能, 消灭大块的代码\n最小作用域, 方法&#x2F;属性&#x2F;局部变量的作用域的设定\n公共函数&#x2F;接口独立成模块(模块化), 降低耦合性\n便于测试代码\n结构清晰, 逻辑大体上看起来，是枝丫分明的树状结构（tree）\n代码的复用性高, 可扩展程度高 (对未来有预测会添加哪些需求)\n不断优化业务逻辑\n\n","categories":["技术","面试题"],"tags":["Python","面试题"]},{"title":"Django 前后端交互的断点调试(Pycharm & F12-Console)","url":"/posts/2020/06/21/59720/","content":"在 Django 的一个项目中，出现一个 bug ，借着这个问题，记录一下调试的过程。\n1. bug出现的场景在“新建接口集”时，输入正确格式的数据时，点击“确定”后，返回的数据有问题，与预期不符合。\n问题截图：\n\n2. 选择 debug 工具在前端的页面进行调试，F12打开浏览器开发者工具进行调试。\n说明：在 pycharm 中的 js 代码中添加断点不能 debug 进入。\n\n在 bug 出现的页面打开浏览器开发者工具（F12）：\n3. 前端post数据给后端首先，点击“新建接口集”（我是在这里出的 bug ），填写数据后点击“确定”后提交（可见问题截图）；\n接着后端就拿到了前端传来的数据：\n\n后端处理数据，主要是把前端的数据写入数据库，这一步操作没有问题。通常后端成功做了某操作，要给前端一个提示，问题就在这一步。于是往后走，马上就要到后端返回数据后出错的地方了，所以在后端给前端 response 前，在前端添加断点。\n4. 在前端添加断点\n前一步点击collections.js后，就来到了这里，然后根据业务，因为我是新建接口集，找到这片代码的位置，在可能出现的地方添加断点。\n\n5. 后端返回response回到后端代码中，添加断点后，才能让后端给前端返回 response，否则来不及添加断点程序就跑完了。\n\n执行下一步让 JsonResponse 把数据返回给前端，让前端渲染展示出成功的结果提示。可以看到，后端传给前端数据的流程，停在了断点处：\n\n6. 利用console调试因为传到前端的数据比较长，在调试时没有全部展示出来，可以在 console 界面中打印：\n\n可以发现问题所在：传到前端的数据，其中的 errno 的值不等于 ‘’0”，所以无法进入前端成功创建的语句分支中，而是进入了 else 分支，那么我需要结束此次调试然后重新改代码、填写数据来调试嘛？\n不需要，因为还没有进入关键分支语句，我可以通过 console 来修改后端传来的数据，然后验证正确的数据传入以后、前端代码的执行流程。\n\n发现 bug 根源在于后端传给前端的数据中 errno 的值不是 “0” 的问题，如果直接下一步可以肯定进入 else 语句，于是在上一步中在 console 中修改正确的数据后，再回到 Sources 中执行下一步。\n\n终于让数据有了走了正确的道路（前端代码终于走对了分支），于是界面的提示也就正确了。\n\n由于本次演示最后这张图不容易截取到， 所以试了好几次（那个测试数据也有略微的差异)。\n终于完成了本次的断点调试，说难不难。coding 过程中出现的大部分问题，通过添加断点来 debug 应该是最佳最有效率的方式了吧，感觉调试的技巧还有很多，慢慢积累学习。\n","categories":["技术","Django"],"tags":["Python","FixBug","Django"]},{"title":"Django mysql 版本报错","url":"/posts/2020/06/18/10318/","content":"场景：Django 项目中使用了0.9.3旧版本的 mysql 数据库，在生成 app 应用时报错。\n报错信息关键部分：\nmanage.py@api_testing &gt; startapp login......\tFile &quot;D:\\env_testing\\lib\\site-packages\\django\\db\\backends\\mysql\\base.py&quot;, line 36, in &lt;module&gt;    raise ImproperlyConfigured(&#x27;mysqlclient 1.3.13 or newer is required; you have %s.&#x27; % Database.__version__)django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.13 or newer is required; you have 0.9.3.\n\n比较好的解决办法(亲测可用)：找到引入 pymsql 的文件，然后添加版本信息，添加一行代码。改动前：\nimport pymysqlpymysql.install_as_MySQLdb()\n改动后：\nimport pymysqlpymysql.version_info = (1, 3, 13, &quot;final&quot;, 0) # 解决mysql版本问题报错而添加的代码pymysql.install_as_MySQLdb()\n\n原因：\n\nWhy do I know you are using pymysql? Because 0.9.3 is just the latest version of pymysql.\nWhy use pymysql instead of mysqlclient for the project? Because it is easier to install. pymysql does not depend on system libraries, while mysqlclient relies on a series of system libraries such as libmysqlclient-dev.\nWhy is mysqlclient difficult to install and Django still uses it by default? Because mysqlclient is faster and performs better. So if your project has high performance requirements, I suggest you remove the compatible code above and install mysqlclient in your project. If you need help during the installation of mysqlclient, please refer to this link: How to install Python MySQLdb module using pip?, and ensure libssl-dev has been installed before pip install mysqlclient.\n\n其他方法：参考 stack overflow 上的其他建议。\nps：我特意先使用 google 搜索该问题，第一条搜索结果就可以解决该问题，而且还很简单；然后我去百度同样搜索，发现很多方法比较复杂，也没有用，治标不治本，还浪费时间。\n","categories":["技术","Django"],"tags":["FixBug","Django"]},{"title":"Django 接口管理平台中遇到的 bug","url":"/posts/2020/06/26/24791/","content":"最近又练习了一个基于 django 的小项目，在此过程中也遇到一些小问题，最后通过查找资料和debug等办法解决了，同时也将一些感觉比较好的bug记录了一下。\n\n1. 虚拟环境最好在命令行中创建虚拟环境，如果用 pycharm 可能不不小心将本地的 Python 环境作为基础添加进去。\nD:\\&gt;pythonPython 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; quit()D:\\&gt;python -m venv env_testingD:\\&gt;D:\\&gt;cd env_testing/ScriptsD:\\env_testing\\Scripts&gt;activate.bat(env_testing) D:\\env_testing\\Scripts&gt;\n\n\n2. django 项目之始迁移文件发现在通过 python manage.py runserver 启动服务后，访问 127.0.0.1:8000\n但是无法访问 admin 的页面，报错如下：\n......File &quot;D:\\env_testing\\lib\\site-packages\\django\\db\\backends\\sqlite3\\base.py&quot;, line 383, in execute    return Database.Cursor.execute(self, query, params)django.db.utils.OperationalError: no such table: django_session[17/Jun/2020 01:08:13] &quot;GET /admin/ HTTP/1.1&quot; 500 198090\n\n需要迁移数据库：\n(env_testing) D:\\django_learning\\api_testing&gt;python manage.py migrateOperations to perform:  Apply all migrations: admin, auth, contenttypes, sessionsRunning migrations:  Applying contenttypes.0001_initial... OK  Applying auth.0001_initial... OK  Applying admin.0001_initial... OK  Applying admin.0002_logentry_remove_auto_add... OK  Applying admin.0003_logentry_add_action_flag_choices... OK  Applying contenttypes.0002_remove_content_type_name... OK  Applying auth.0002_alter_permission_name_max_length... OK  Applying auth.0003_alter_user_email_max_length... OK  Applying auth.0004_alter_user_username_opts... OK  Applying auth.0005_alter_user_last_login_null... OK  Applying auth.0006_require_contenttypes_0002... OK  Applying auth.0007_alter_validators_add_error_messages... OK  Applying auth.0008_alter_user_username_max_length... OK  Applying auth.0009_alter_user_last_name_max_length... OK  Applying auth.0010_alter_group_name_max_length... OK  Applying auth.0011_update_proxy_permissions... OK  Applying sessions.0001_initial... OK\n\n接着就可以访问 admin 了。\n\n3. mysqlclient errormanage.py@api_testing &gt; startapp login............\tFile &quot;D:\\env_testing\\lib\\site-packages\\django\\db\\backends\\mysql\\base.py&quot;, line 36, in &lt;module&gt;    raise ImproperlyConfigured(&#x27;mysqlclient 1.3.13 or newer is required; you have %s.&#x27; % Database.__version__)django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.13 or newer is required; you have 0.9.3.\n\n比较好的解决办法(亲测可用)：找到引入 pymsql 的文件，然后添加版本信息，只需要一行代码。\nimport pymysqlpymysql.version_info = (1, 3, 13, &quot;final&quot;, 0) # 解决mysql版本问题报错而添加的代码pymysql.install_as_MySQLdb()\n\n原因：\n\nWhy do I know you are using pymysql? Because 0.9.3 is just the latest version of pymysql.\nWhy use pymysql instead of mysqlclient for the project? Because it is easier to install. pymysql does not depend on system libraries, while mysqlclient relies on a series of system libraries such as libmysqlclient-dev.\nWhy is mysqlclient difficult to install and Django still uses it by default? Because mysqlclient is faster and performs better. So if your project has high performance requirements, I suggest you remove the compatible code above and install mysqlclient in your project. If you need help during the installation of mysqlclient, please refer to this link: How to install Python MySQLdb module using pip?, and ensure libssl-dev has been installed before pip install mysqlclient.\n\n其他方法：参考 stack overflow 上的其他建议。\n\n4. 运行时在 mysql 的 operations.py 中报错(env_testing) D:\\django_learning\\api_testing&gt;python manage.py runserver\t......\tFile &quot;D:\\env_testing\\lib\\site-packages\\django\\db\\backends\\mysql\\features.py&quot;, line 82, in is_sql_auto_is_null_enabled    cursor.execute(&#x27;SELECT @@SQL_AUTO_IS_NULL&#x27;)  File &quot;D:\\env_testing\\lib\\site-packages\\django\\db\\backends\\utils.py&quot;, line 103, in execute    sql = self.db.ops.last_executed_query(self.cursor, sql, params)\tFile &quot;D:\\env_testing\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py&quot;, line 146, in last_executed_query    query = query.decode(errors=&#x27;replace&#x27;)AttributeError: &#x27;str&#x27; object has no attribute &#x27;decode&#x27;\n\n处理办法：Go to django folder, then go to this path:  django\\db\\backends\\mysql\nthen go to operations.py and find query = query.decode(errors=&#39;replace&#39;). Remove the line and put query = errors=&#39;replace&#39;\ndef last_executed_query(self, cursor, sql, params):    # With MySQLdb, cursor objects have an (undocumented) &quot;_executed&quot;    # attribute where the exact query sent to the database is saved.    # See MySQLdb/cursors.py in the source distribution.    query = getattr(cursor, &#x27;_executed&#x27;, None)    if query is not None:        # query = query.decode(errors=&#x27;replace&#x27;)  # zhuyuping modify        query = errors = &#x27;replace&#x27;  # zhuyuping add    return query\n\n\n5. 映射html出问题，函数不存在NoReverseMatch at /register/Reverse for &#x27;login&#x27; not found. &#x27;login&#x27; is not a valid view function or pattern name.\n\ntemplates\\login\\register.html:\n&lt;div class=&quot;margin-top20 text-center&quot;&gt;    已经有账号了? &lt;a href=&#123;% url &#x27;login&#x27; %&#125;&gt;登录&lt;/a&gt;&lt;/div&gt;\n\nlogin\\urls.py:\napp_name = &#x27;login&#x27;urlpatterns = [    path(&#x27;&#x27;, views.LoginView.as_view(), name=&#x27;login&#x27;),    path(&#x27;forgot/&#x27;, views.ForgotView.as_view(), name=&#x27;forgot&#x27;),    path(&#x27;register/&#x27;, views.RegisterView.as_view(), name=&#x27;register&#x27;),    path(&#x27;reset/&#x27;, views.ResetView.as_view(), name=&#x27;reset&#x27;),]\n\n需要指定app，所以修改为：\n&lt;div class=&quot;margin-top20 text-center&quot;&gt;    已经有账号了? &lt;a href=&#123;% url &#x27;login:login&#x27; %&#125;&gt;登录&lt;/a&gt;&lt;/div&gt;\n\n同理，还有类似的写法也都是报这个错误。\n\n6. register页面注册成功后跳转到login页面，但是url还是registerclass RegisterView(View):    def get(self, request):        return render(request, &#x27;login/register.html&#x27;)    def post(self, request):        user_register_form = RegisterForm(data=request.POST)        if user_register_form.is_valid():            username = user_register_form.cleaned_data.get(&#x27;username&#x27;)            password = user_register_form.cleaned_data.get(&#x27;password&#x27;)            email = user_register_form.cleaned_data.get(&#x27;email&#x27;)            if not request.POST.get(&#x27;aggree&#x27;):                return translate2json(errno=ResCode.AGGREE, errmsg=error_map[ResCode.AGGREE])            new_user = User.objects.create(username=username, password=password, email=email)            new_user.save()            return render(request, &#x27;login/index.html&#x27;)        else:            return HttpResponse(&quot;注册输入有误，请重新输入~&quot;)\n\n在注册页面，注册一个用户：\n\n提交注册数据后，跳转到登录页面：\n\n如果直接填写信息登录，会出现错误，原因是当前网页的 url 并不是真正的登录（login）页面，所以提交的数据不能通过本应该是 login 的路由来发出 get 请求。仔细看页面的路由，依然是 register。\n此时填写正确的注册过的用户数据，会返回注册过程的一些数据。(由于刚刚在注册页面注册了信息，数据被写入数据库，然后再在当前的假登录【实际还是注册的页面】进行登录，就相当于用原来的数据重新注册一次，当然这样是不允许的，在后端代码中就防止该行为出现而抛出异常。)\n解决办法：使用 redirect 来重定向到真正的登录页面。\n# return render(request, &#x27;login/index.html&#x27;)return redirect(&#x27;login:login&#x27;)\n\n从该定位该 bug 以及解决可知，以后凡是涉及页面跳转的，不仅要考虑前端页面，还有考虑跳转后的路由 url 是否与页面匹配，防止出现类似的问题。\n\n同样的，在登录页面进行登录后进入首页，但是路由 url 并没有改变，刷新 url 后又回到了登录界面，显然是不合理的。\n涉及的相关代码：\nclass LoginView(View):    def get(self, request):        return render(request, &#x27;login/index.html&#x27;)    def post(self, request):        try:            post_data = request.POST            if not post_data:                return translate2json(errno=ResCode.PARAMERR, errmsg=&quot;参数为空，请输入&quot;)            user_key = [&quot;email&quot;, &quot;password&quot;, &quot;remember&quot;]            data_dict = &#123;&#125;            for key in user_key:                data_dict[key] = post_data.get(key)        except Exception as e:            logging.info(&quot;错误信息：\\n&#123;&#125;&quot;.format(e))            return translate2json(errno=ResCode.UNKOWNERR, errmsg=error_map[ResCode.UNKOWNERR])        login_form = LoginForm(data=data_dict, request=request)        if login_form.is_valid():            return render(request, &#x27;home/index.html&#x27;)  # 问题原因\n\n将 render 改为重定向：\n# login\\views.pyif login_form.is_valid():    # return render(request, &#x27;home/index.html&#x27;)    return redirect(reverse(&#x27;index&#x27;)) \n\n# apiwork\\urls.pyurlpatterns = [    path(&#x27;index/&#x27;, views.ApiView.as_view(), name=&#x27;index&#x27;)]\n\n# apiwork\\views.pyclass ApiView(View):    def get(self, request):        return render(request, &#x27;home/index.html&#x27;)\n\n\n7. as_view()路由中调用视图函数 as_view 函数后面需要加括号。\nurlpatterns = [    path(&#x27;index/&#x27;, views.ApiView.as_view, name=&#x27;index&#x27;)]\n\nview.py是这样的：\nclass ApiView(View):    def get(self, request):        return render(request, &#x27;home/index.html&#x27;)\n\n当前端发起 request 请求时，会报这样的错误：\nTypeError at &#x2F;apiwork&#x2F;index&#x2F;\nas_view() takes 1 positional argument but 2 were given\n\n\n\n\nRequest Method:\nGET\n\n\n\nRequest URL:\nhttp://127.0.0.1:8000/apiwork/index/\n\n\nDjango Version:\n2.2\n\n\nException Type:\nTypeError\n\n\nException Value:\nas_view() takes 1 positional argument but 2 were given\n\n\nurlpatterns = [    path(&#x27;index/&#x27;, views.ApiView.as_view(), name=&#x27;index&#x27;)]\n\n\n8. 小结通过这个小小的项目的学习练习，也发现自己在前端知识方面存在很多不懂的地方，需要好好弥补一下。不过由于现在练习的两个项目都是前后端不分离，这已经是落后的潮流了，以后的趋势是前后端分离，所以准备学一下目前大火的 Vue，正好也有一个前后端分离的项目可以用来练习。\n很多模型以及设计方面的东西还是不太理解的，只是照葫芦画瓢，不过相比以前刚刚接触 django 来说，已经是进步很多了。有些 bug 的处理没有很好地办法，有的可以通过删库后重新迁移文件来解决，但是实际场景中肯定是不可以这样做的，也就是说很多 bug 的解决没有找到本质的原因、没有用最佳的方法解决，需要慢慢练习、向他人学习。\n从一个 django 项目的练习中，可以发现哪些东西都要恶补，记录一下，加入到后续的学习计划中。\n\nHTTP \n数据库\ndjango 的官方文档\n前端，Vue\n\n","categories":["技术","Django"],"tags":["Python","FixBug","Django"]},{"title":"Django 博客项目中遇到的 bug","url":"/posts/2020/06/16/34544/","content":"1. 配置路由：includeurlpatterns = [    path(&#x27;admin/&#x27;, admin.site.urls),    path(&#x27;article/&#x27;, include(&#x27;article.urls&#x27;, namespace=&#x27;article&#x27;)),    path(&#x27;userprofile/&#x27;, include(&#x27;userprofile.urls&#x27;, namespace=&#x27;userprofile&#x27;)),]\n\n错误写法：path(&#39;userprofile/&#39;, include(&#39;userprofile.urls&#39;), namespace=&#39;userprofile&#39;),，_path() 中多了个参数，namespace 应该在 include 中。\n报错： \n  File &quot;D:\\django_learning\\blog_project\\blog_project\\urls.py&quot;, line 22, in &lt;module&gt;    path(&#x27;userprofile/&#x27;, include(&#x27;userprofile.urls&#x27;), namespace=&#x27;userprofile&#x27;),TypeError: _path() got an unexpected keyword argument &#x27;namespace&#x27;\n\n\n2. forms 表单类字段 fieldsfrom django import formsfrom django.contrib.auth.models import Userclass UserRegisterForm(forms.ModelForm):  # 对数据库进行操作的表单应继承forms.ModelForm    # 复写 User 的密码    password = forms.CharField()    password2 = forms.CharField()    class Meta:        model = User        field = (&#x27;username&#x27;, &#x27;email&#x27;)\n\nDjango项目中某 app 的 forms.py 段代码如上，执行时报错如下：\n  File &quot;D:\\django_learning\\blog_project\\userprofile\\urls.py&quot;, line 8, in &lt;module&gt;    from userprofile import views  File &quot;D:\\django_learning\\blog_project\\userprofile\\views.py&quot;, line 5, in &lt;module&gt;    from userprofile.forms import UserLoginForm, UserRegisterForm  File &quot;D:\\django_learning\\blog_project\\userprofile\\forms.py&quot;, line 17, in &lt;module&gt;    class UserRegisterForm(forms.ModelForm):  # 对数据库进行操作的表单应继承forms.ModelForm  File &quot;D:\\env\\lib\\site-packages\\django\\forms\\models.py&quot;, line 243, in __new__    &quot;needs updating.&quot; % namedjango.core.exceptions.ImproperlyConfigured: Creating a ModelForm without either the &#x27;fields&#x27; attribute or the &#x27;exclude&#x27; attribute is prohibited; form UserRegisterForm needs updating.\n\n在 stackoverflow 上找到有类似的报错，排在前面的几个解决方法：\nclass ArticleForm(forms.ModelForm):    class Meta:        model = Article         fields = &#x27;__all__&#x27; # Or a list of the fields that you want to include in your form\n\n意思是 需要将 fields 的字段改为 __all__，或者在你的 form 中想去 include 的字段，这里我就是想要 username 和 email 。\n或者：使用 exclude  = () \nclass ArticleForm(forms.ModelForm):    class Meta:        model = Article        exclude = ()\n\n我尝试了两种，只有后面这种可以解决，第一种使用 __all__ 依旧报错，什么原因呢？不明白，最后才发现我写的 field 是单数，应该是 fields ，好吧，知道了。\n\n3. 拓展 User 后，不删除原有数据登录会失败from django.db import modelsfrom django.contrib.auth.models import Userfrom django.db.models.signals import post_savefrom django.dispatch import receiver# Create your models here.# 当 userprofile 这个 app 没有改动 model 时不用迁移数据。# 用户拓展信息class Profile(models.Model):    # 与 User 模型构成一对一的关系    # 每个Profile模型对应唯一的一个User模型，形成了对User的外接扩展    user = models.OneToOneField(User, on_delete=models.CASCADE, related_name=&#x27;profile&#x27;)    phone = models.CharField(max_length=20, blank=True)    avatar = models.ImageField(upload_to=&#x27;avatar/%Y%m%d/&#x27;, blank=True)    bio = models.TextField(max_length=500, blank=True)    def __str__(self):        return f&#x27;user &#123;self.user.username&#125;&#x27;# 信号接收函数，每当新建 User 实例时自动调用@receiver(post_save, sender=User)def create_user_profile(sender, instance, created, **kwargs):    if created:        Profile.objects.create(user=instance)# 信号接收函数，每当更新 User 实例时自动调用@receiver(post_save, sender=User)def save_user_profile(sender, instance, **kwargs):    instance.profile.save()\n\n每个Profile模型对应唯一的一个User模型，形成了对User的外接扩展，因此你可以在Profile添加任何想要的字段。这种方法的好处是不需要对User进行任何改动，从而拥有完全自定义的数据表。\n迁移好数据后，如果试图登录用户，会得到报错。这是因为之前创建的User数据都没有对应的Profile模型，违背了现有的模型。一种解决办法就是干脆删除旧的数据，因此就需要用到Django的shell命令。\n输入下面两行指令就可以轻松删除User数据库：\n(env) D:\\django_learning\\blog_project&gt;python manage.py shellPython 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.(InteractiveConsole)&gt;&gt;&gt; from django.contrib.auth.models import User&gt;&gt;&gt; User.objects.all()&lt;QuerySet [&lt;User: zhuyuping&gt;, &lt;User: taijialan&gt;, &lt;User: zyp&gt;]&gt;&gt;&gt;&gt; User.objects.all().delete()(17, &#123;&#x27;admin.LogEntry&#x27;: 9, &#x27;auth.User_groups&#x27;: 0, &#x27;auth.User_user_permissions&#x27;: 0, &#x27;article.ArticlePost&#x27;:5, &#x27;userprofile.Profile&#x27;: 0, &#x27;auth.User&#x27;: 3&#125;)\n\n因为前面写的article模型中，与User的外键也采用了models.CASCADE级联删除模式，因此随着User的删除，相关的文章也一并删除了。\n输入exit()退出shell，输入指令python manage.py createsuperuser，重新创建管理员账户。\n\n4. Profile.objects.get(user_id&#x3D;id).exists() 出错报错提示：{AttributeError}’Profile’ object has no attribute ‘exists’，’Profile’ object 只有我写的一些特殊具体的属性，没有exists属性或方法。\n通过 dir(Profile.objects.filter(user_id=id))，可以证明通过 filter 可以产生 exists 属性。\n\n5. 被包含的子路由模块需要添加app_name属性# blog_project/urls.pyurlpatterns = [    path(&#x27;admin/&#x27;, admin.site.urls),    path(&#x27;article/&#x27;, include(&#x27;article.urls&#x27;, namespace=&#x27;article&#x27;)),    path(&#x27;userprofile/&#x27;, include(&#x27;userprofile.urls&#x27;, namespace=&#x27;userprofile&#x27;)),    path(&#x27;password-reset/&#x27;, include(&#x27;password_reset.urls&#x27;)),    path(&#x27;comment/&#x27;, include(&#x27;comment.urls&#x27;, namespace=&#x27;comment&#x27;)), # 报错位置]\n\n  File &quot;D:\\django_learning\\blog_project\\blog_project\\urls.py&quot;, line 26, in &lt;module&gt;    path(&#x27;comment/&#x27;, include(&#x27;comment.urls&#x27;, namespace=&#x27;comment&#x27;)),  File &quot;D:\\env\\lib\\site-packages\\django\\urls\\conf.py&quot;, line 39, in include    &#x27;Specifying a namespace in include() without providing an app_name &#x27;django.core.exceptions.ImproperlyConfigured: Specifying a namespace in include() without providing an app_name is not supported. Set the app_name attribute in the included module, or pass a 2-tuple containing the list of patterns and app_name instead.\n\n在新增 comment 评论的模型时，通过 python manage.py startapp comment新建一个评论的app，然后在 setting 中的 INSTALLED_APPS 列表添加 ‘comment’，在主路由中配置子路由，接着编写 comment 的模型类，写完后需要迁移数据库，执行 python manage.py makemigrations， 这时候出现上面这个报错。\n报错信息是指，在 include() 中没有提供给一个支持的 app_name，需要在被包含的子模块（这里是 comment 目录下的 urls.py 模块）中设置 app_name 属性。\n具体原因是在 comment 的 urls.py 文件中没有写该 app_name &#x3D; ‘comment’， 以及配置 urlpatterns。\n# comment/urls.pyapp_name = &#x27;comment&#x27;urlpatterns = []\n\n再次执行迁移：\n(env) D:\\django_learning\\blog_project&gt;python manage.py makemigrationsMigrations for &#x27;comment&#x27;:  comment\\migrations\\0001_initial.py    - Create model Comment\n\n\n6. 使用F12检查没有展示的元素模板中已经写好前端的展示，视图函数也给前端传参了，但是实际就是没有显示。\n\n通过F12查看元素，可以发现该标签中没有内容，应该是没有从视图中获取到标签、或者获取到后经过前端操作后没有拿到该有的标签。\n自然地，先检查视图函数有没有给前端模板传递对象，然后回到该页面的 html 代码中检查，发现是 html 中的变量 articles 写错了。\n&#123;% for article in articles %&#125;\t\t\t&#123;% for tag in articles.tags.all %&#125;           &lt;a href=&quot;#&quot; class=&quot;badge badge-secondary&quot;&gt;&#123;&#123; tag &#125;&#125;&lt;/a&gt;       &#123;% endfor %&#125;\n\n\n7. A server error occurred. Please contact the administrator.修改 django 文件：D:\\env\\Lib\\site-packages\\django\\views\\debug.py，在打开文件时使用 utf-8，这样修改后，可以在页面看到具体的报错，而不只是一串“A server error occurred. Please contact the administrator.”。\ndef get_traceback_html(self):    &quot;&quot;&quot;Return HTML version of debug 500 HTTP error page.&quot;&quot;&quot;    with Path(CURRENT_DIR, &#x27;templates&#x27;, &#x27;technical_500.html&#x27;).open(encoding=&#x27;utf-8&#x27;) as fh:        t = DEBUG_ENGINE.from_string(fh.read())    c = Context(self.get_traceback_data(), use_l10n=False)    return t.render(c)\n\nno such column 报错：删库解决。。。重新生成迁移文件、创建数据。\n\n8. 部署以前还买了阿里云服务器，后来就没有续费了。现在在本地的 Ubuntu 上部署测试。\n\n修改 Django 的配置文件\n# my_blog/settings.py# 关闭调试模式DEBUG = False# 允许的服务器ALLOWED_HOSTS = [&#x27;*&#x27;]# 静态文件收集目录STATIC_ROOT = os.path.join(BASE_DIR, &#x27;collected_static&#x27;)\n\n虚拟环境一般是需要在服务器上重新生成的\n安装包：\nsudo apt-get updatesudo apt-get upgradesudo apt-get install python3sudo apt-get install python3-pipsudo apt-get install gitsudo pip3 install virtualenv\n\n从远程库中拉取项目代码：\ngit clone https://gitee.com/zypdominate/django_learning.git\n\ncd 进入项目中，生成虚拟环境，并激活：\nvirtualenv --python=python3.6 envsource env/bin/activate\n\n安装库、收集静态资源、数据迁移了：\npip3 install -r requirements.txt python manage.py collectstaticpython3 manage.py migrate\n\n代码部署基本就完成了，接下来配置 Nginx \n安装 nginx：\nsudo apt-get install nginx\n\n启动 nginx，查看安装的 nginx 是否正常：\nsudo service nginx start\n\n打开浏览器，输入你的服务器公网 IP 地址（可在Ubuntu上试用）查看效果。\n接着，重新写 Nginx 的配置文件。进入 /etc/nginx/sites-available 目录，这里是定义 Nginx 可用配置 的地方。输入指令 sudo vi dusaiphoto.com 创建配置文件，以下是已经配置好的：\nzyp@zyp-virtual-machine:/etc/nginx/sites-available$ lsdefault  my_blog  siteszyp@zyp-virtual-machine:/etc/nginx/sites-available$ cat my_blog server &#123;  charset utf-8;  listen 80;  server_name 192.168.171.128;  # 暂时是我本地的Ubuntu的ip地址  location /static &#123;    root /home/zyp/sites/django_learning/blog_project/collected_static;  &#125;    location /media &#123;    root /home/zyp/sites/django_learning/blog_project/media;  &#125;  location / &#123;    proxy_set_header Host $host;    proxy_pass http://unix:/tmp/192.168.171.128.socket;  &#125;&#125;\n\n写的只是 Nginx 的可用配置，所以还需要把这个配置文件链接到在用配置上去：\nsudo ln -s /etc/nginx/sites-available/my_blog  /etc/nginx/sites-enabled\n\nzyp@zyp-virtual-machine:/etc/nginx/sites-available$ lsdefault  my_blog  siteszyp@zyp-virtual-machine:/etc/nginx/sites-available$ sudo ln -s /etc/nginx/sites-available/my_blog  /etc/nginx/sites-enabled...zyp@zyp-virtual-machine:/etc/nginx/sites-enabled$ lsmy_blog  sites\n\n至此 Nginx 就配置好了，接下来搞定 Gunicorn:\n\n安装 Gunicorn\n重启 Nginx 服务\n启动 Gunicorn\n\n先回到项目所在的目录，并且进入虚拟环境，然后输入：\n(myenv) zyp@zyp-virtual-machine:~/sites/django_learning/blog_project$ pip3 install gunicorn(myenv) zyp@zyp-virtual-machine:~/sites/django_learning/blog_project$ sudo service nginx reload(myenv) zyp@zyp-virtual-machine:~/sites/django_learning/blog_project$ gunicorn --bind unix:/tmp/192.168.171.128.socket blog_project.wsgi:application\n\n也可以用 sudo service nginx restart，区别是 reload 只重载配置文件，restart 重启整个服务。\n最后打开浏览器，访问服务器查看效果。\n\n\n\n9. css、js等没有加载出来本地调试好工程后，服务起来后在浏览器上测试也是正常的，但是一部署后就发现浏览器中没有加载css、js等，只有单纯的html格式，经过查看 nginx 的日志发现了问题：没有所需要的文件。\n\n怎么会没有该文件呢？于是查看了 nginx 的配置文件：\nserver &#123;  charset utf-8;  listen 80;  server_name 192.168.171.128;  # 暂时是我本地的Ubuntu的ip地址  location /static &#123;    root /home/zyp/sites/django_blog_tutorial/collected_static;  &#125;    location /media &#123;    root /home/zyp/sites/django_blog_tutorial/media;  &#125;  location / &#123;    proxy_set_header Host $host;    proxy_pass http://unix:/tmp/192.168.171.128.socket;  &#125;&#125;\n\n然后查看工程中 collected_static 目录下，发现没有 static 目录，所需要的 css、js文件都直接在 collected_static 目录下，也就是少了中间件一层 static。可以推理是在执行 python manage.py collectstatic 后出现的问题，排查发现在 settings.py 文件中的静态文件收集目录的路径有误：\n# 静态文件收集目录STATIC_ROOT = os.path.join(BASE_DIR, &#x27;collected_static&#x27;)\n\n添加 static 后就可以展示 css、js等了：\n# 静态文件收集目录STATIC_ROOT = os.path.join(BASE_DIR, &#x27;collected_static/static&#x27;)\n\n同理，media 目录中存放的资源在页面中加载不出来，也是路径的问题。其实这边可以修改工程中的 settings.py 文件，也可以更改 nginx 中的配置文件。\n最后，终于改好了：\n\n","categories":["技术","Django"],"tags":["Python","FixBug","Django"]},{"title":"Docker 中安装 Elasticsearch + Kibana + Filebeat","url":"/posts/2020/10/15/6122/","content":"在 Docker 中安装 Elasticsearch + Kibana + Filebeat在 CentOS上安装 Docker Engine先更新一下 yum 软件源的缓存，安装依赖包\nsudo yum updatesudo yum install -y yum-utils device-mapper-persistent-data lvm2\n\n添加国内下载源\nsudo yum-config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo\n\n安装比较稳定的版本 Docker CE \nsudo yum makecache fastsudo yum install docker-ce\n\n配置开机启动，并启动 Docker CE ：\nsudo systemctl enable dockersudo systemctl start docker\n\n测试是否正确安装了 Docker Engine:\ndocker run hello-world\n\n建立 docker 组，将当前用户加入 docker 组：\nsudo groupadd dockersudo usermod -aG docker $USER\n\n再次执行 docker run hello-world 测试是否可以执行。\n安装 Docker-Compose在线安装，下载一个 Docker-Compose\nsudo curl -L &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose\n\n给文件执行权限\nsudo chmod +x /usr/local/bin/docker-compose\n\n创建指向 /usr/bin 的链接\nsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n\n查看版本\ndocker-compose --version\n\n安装 Elasticsearch在 Docker-hub 中搜索 Elasticsearch 版本\ndocker search Elasticsearch\n\n安装 Elasticsearch 7.2 的版本\ndocker pull docker.elastic.co/elasticsearch/elasticsearch:7.2.0\n\n安装完成后，执行 docker images 或者 docker image ls\n[root@bogon /]# docker imagesREPOSITORY                      TAG         IMAGE ID        CREATED         SIZEhello-world                     latest      bf756fb1ae65    9 months ago    13.3kBdocker.elastic.co/elasticsearch/elasticsearch   7.2.0       0efa6a3de177    15 months ago    861MB\n\nDocker + Elasticsearch + Kibana + Filebeat 实例我的 test_docker 文件夹，目录层级\n[root@bogon test_docker]# tree.├── docker-compose.yaml└── filebeat    ├── conf    │   └── filebeat.yml    ├── data    │   ├── meta.json    │   └── registry    │       └── filebeat    │           ├── data.json    │           └── meta.json    └── logs6 directories, 5 files\n\n新建一个 docker-compose.yml 文件\nversion: &#x27;2.2&#x27;services:  cerebro:    image: lmenezes/cerebro:0.8.3    container_name: cerebro    ports:      - &quot;9000:9000&quot;    command:      - -Dhosts.0.host=http://elasticsearch:9200  kibana:    image: docker.elastic.co/kibana/kibana:7.1.0    container_name: kibana7    environment:      - I18N_LOCALE=zh-CN      - XPACK_GRAPH_ENABLED=true      - TIMELION_ENABLED=true      - XPACK_MONITORING_COLLECTION_ENABLED=&quot;true&quot;    ports:      - &quot;5601:5601&quot;  elasticsearch:    image: docker.elastic.co/elasticsearch/elasticsearch:7.1.0    container_name: es7_01    environment:      - cluster.name=zhuyuping      - node.name=es7_01      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;      - discovery.seed_hosts=es7_01      - cluster.initial_master_nodes=es7_01 #,es7_02      - path.data:/data/elasticsearch      - path.logs:/data/log/elasticsearch    ulimits:      memlock:        soft: -1        hard: -1    volumes:      - es7data1:/usr/share/elasticsearch/data    ports:      - 9200:9200  filebeat:    container_name: filebeat    hostname: filebeat    image: docker.elastic.co/beats/filebeat:7.1.1    restart: always    user: root    links:  # 需要链接es，不然存在报错      - es7_01    volumes:      - ./filebeat/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml      # 映射到容器中[作为数据源]      - ./filebeat/logs:/usr/share/filebeat/logs      - ./filebeat/data:/usr/share/filebeat/datavolumes:  es7data1:    driver: local  es7data2:    driver: local#elasticsearch2:#image: docker.elastic.co/elasticsearch/elasticsearch:7.1.0#container_name: es7_02#environment:  #- cluster.name=zhuyuping  #- node.name=es7_02  #- bootstrap.memory_lock=true  #- &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;  #- discovery.seed_hosts=es7_01  #- cluster.initial_master_nodes=es7_01,es7_02#ulimits:  #memlock:    #soft: -1    #hard: -1#volumes:  #- es7data2:/usr/share/elasticsearch/data\n\n关于 filebeat.yml 的配置\n# 日志输入配置filebeat.inputs:- type: log  enabled: true  paths:  # 需要收集的日志所在的位置，可使用通配符进行配置  - /var/log/*.log  #- /data/fxqalog/*.txtoutput.elasticsearch:  #hosts: [&#x27;10.103.131.242:9200&#x27;]  hosts: [&quot;es7_01:9200&quot;]    #定义的es的url，之前名字取为es7_01，需要保持一致，不能使用localhost  #日志输出配置(采用 logstash 收集日志，5044为logstash端口)#output.logstash:  #hosts: [&quot;10.103.131.242:5044&quot;]  #hosts: [&quot;es7_01:5044&quot;]\n\n启动容器\n[root@bogon test_docker]# docker-compose up\n\n# 一些docker 命令# 启动、停止容器docker-compose updocker-compose down# 停止容器并且移除数据docker-compose down -vdocker ps -a  # 正在运行的容器docker container ls  # 存在的容器# 停止、启动、杀死、重启一个容器$docker stop Name/ID  $docker start Name/ID  $docker kill Name/ID  $docker restart name/ID# 删除 image (例如删除REPOSITORY为prima/filebeat的image)$docker images$docker rmi prima/filebeat# 删除单个容器$docker rm Name/ID# 删除所有容器$docker rm `docker ps -a -q` \n\n接着通过浏览器查看 Elasticsearch、Kibana 服务\n\n配置 Kibana 索引\n浏览器中打开 http://10.103.131.242:5601/\n在 索引模式 中输入 filebeat 后，下面会有匹配到索引，然后点击下一步，选择 时间筛选字段名称，最后点击创建索引模式。查看现有的索引：http://10.103.131.242:9200/_cat/indices?v\n\n当前 health 状态是 green，如果一开始是 yellow，则需要查看索引的配置信息，修改分片数：目前我只是一台机器，所以设置成0，然后再刷新后就变绿了。\n\n\n遇到的问题及解决\nAnother app is currently holding the yum lock; waiting for it to exit…\n\n执行yum报错error: rpmdb: BDB0113 Thread&#x2F;process 23226 failed: BDB1507 Thread died in Berkeley D\n\nyum的卸载与重新安装\n\nwindows Elasticsearch启动报此处不应有Files\\elascsearch-7.8.0\\jdk解决办法一\n\nKibana报错Failed to create Beat meta file: open &#x2F;usr&#x2F;share&#x2F;filebeat&#x2F;data&#x2F;meta.json.new: permission denied\n\n浏览器界面提示 Kibana server is not ready yet\n执行 docker-compose up 后，在浏览器上查看 Kibana 服务，发现提示 Kibana server is not ready yet。\n通过 docker ps 查看，只启动了 cerebro 和 kibana，elasticsearch 没启动成功\n\n在 /etc/sysctl.conf 中增加配置 vm.max_map_count=262144，保存后执行 sysctl -p ，重新再启动服务就ok了\n\n\nwindows 下启动 logstash 报错 Unrecognized VM option &#39;UseConcMarkSweepGC&#39;\n根据类似的错误，将 logstash 的 config 目录下的 jvm.options 文件中的以下3行注释掉：\n## -XX:+UseConcMarkSweepGC## -XX:CMSInitiatingOccupancyFraction=75## -XX:+UseCMSInitiatingOccupancyOnly\n\nERROR：filebeat 连接不了 elasticsearch\n报错：Failed to connect to backoff(elasticsearch(http://localhost:9200)):Get http://localhost:9200:dail tcp 127.0.0.1:9200:connect:connection refused，后面一行又尝试 reconnect 了7次都失败了\n\n原因：在 filebeat.yml 中配置的问题，将 hosts: [&quot;localhost:9200&quot;] 改为 hosts: [&quot;es7_01:9200&quot;]，其中 es7_01 是我在 docker-compose.yml 中 elasticsearch 的配置 container_name: es7_01，地址需要保持一致。\n这个问题找了很久，在网上一直没有找到 docker 下部署的出现这个问题的资料，最后在相关群里问人才解决。连接成功的结果：\n\n\n\n\n学习记录\nDocker容器进入的4种方式\n其中最便捷的一种：\n[root@bogon test_docker]# docker psCONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS              PORTS                              NAMESa313438333f4        docker.elastic.co/elasticsearch/elasticsearch:7.1.0   &quot;/usr/local/bin/dock…&quot;   4 hours ago         Up 41 minutes       0.0.0.0:9200-&gt;9200/tcp, 9300/tcp   es7_01ece44e259317        lmenezes/cerebro:0.8.3                                &quot;/opt/cerebro/bin/ce…&quot;   4 hours ago         Up 41 minutes       0.0.0.0:9000-&gt;9000/tcp             cerebrod85ff4c04999        docker.elastic.co/beats/filebeat:7.1.1                &quot;/usr/local/bin/dock…&quot;   4 hours ago         Up 41 minutes                                          filebeat6b9f47643a7a        docker.elastic.co/kibana/kibana:7.1.0                 &quot;/usr/local/bin/kiba…&quot;   4 hours ago         Up 41 minutes       0.0.0.0:5601-&gt;5601/tcp             kibana7[root@bogon test_docker]# docker exec -it a313438333f4 /bin/bash\n\nelasticsearch.yml 配置项详解\nbin ：脚本文件，包括 ES 启动 &amp; 安装插件等等config ： elasticsearch.yml（ES 配置文件）、jvm.options（JVM 配置文件）、日志配置文件等等JDK ： 内置的 JDK，JAVA_VERSION=“12.0.1“lib ： 类库logs ： 日志文件modules ： ES 所有模块，包括 X-pack 等plugins ： ES 已经安装的插件。默认没有插件data ： ES 启动的时候，会有该目录，用来存储文档数据。该目录可以设置\n\n\n参考资料\nInstall Docker Engine on CentOS\nInstall Docker Compose\nInstall Elasticsearch with Docker\nInstall Kibana with Docker\n在Docker容器中运行Elasticsearch, Kibana和Cerebro\nElasticsearch Reference\n\n","categories":["技术","Elasticsearch"],"tags":["elasticsearch","docker"]},{"title":"Git：分支merge主线代码","url":"/posts/2020/01/11/11785/","content":"工作协作开发某个模块或者功能特性时，一般都是从主线master创建分支，然后将该分支拉取到本地进行开发，该模块开发完成后，再将此分支合并到远程主分支。如果是特殊分支可以保留成一条单独的分支（不合入主线）来维护。\n但是我们经常会遇到一些问题，比如我们都是整个团队协作开发，等到编码完成、review结束，需要将该分支合并到远程分支的时候，远程分支（不可避免地有其他同事对其有代码提交）已经有很多次提交（commit)了，自己的分支已经落后主分支很多版本，切换回主分支的时候就不在最新commit上，即没有最新的代码。\n如果是自己编码的分支提交上去和主线没有冲突还好，直接合入主线就行，若有冲突就本地处理本分支的冲突再合入；但如果编码周期长，需要经常更新主线代码，拉取同事最近提交到主线的代码，那么必须将主线最新代码合入我现在开发的分支中。\n\n下面结合Gitlab，在此基础上小结一下：\n对于一个具体的开发任务\n1. 创建议题一般先创建一个议题（Issue）：\n2.创建合并请求再创建一个合并请求（Create merge request），分支名可以自己修改，如 test_dev\n3. 本地检出分支然后在本地拉取远程最新的(刚刚创建的)分支, 并检出该分支：\ngit fetch origingit checkout -b test_dev  origin/test_dev\n4.编码 &amp; review接下来就可以在本地的该分支上编码了。编码完成后，提交到该分支，review后再将该分支合并到远程主分支。\n5. merge 主线中间可能存在的问题，在合并到远程分支时，比如这里的test_dev已经落后主分支很多次提交了，为了避免合不进去，需要先解决冲突等。在开发过程中经常将主线master（test_dev是从源分支master上拉取的）最新代码合入当前的分支 test_dev。\n\n查看当前分支：git branch ，确保当前处于开发的分支上\n查看本地是否有test_dev分支的源分支：git branch，如果本地有主线，则先切换到主线分支：git checkout master，再更新本地的主线代码: git pull ；\n如果本地没有test_dev的源分支，就拉取远程库中所有的分支：git fetch origin，然后检出主线代码： git checkout master ；\n前两步使得本地有主线代码，且是最新的，然后切换到原来我们开发的分支上：git checkout test_dev，最后将 master 主线代码 合入test_dev分支： git merge master ；\n如果有冲突就在本地处理，处理完后，此时的该分支已经不落后源分支master了；\n将开发的代码提交到 test_dev ： git add .，git commit -m xxx，git push ；git add .，git commit -m xxx，git push ；\nreview后流程结束后，将test_dev分支合入源分支，若没有留该分支的必要就删除该test_dev分支。\n\n","categories":["技术","Git"],"tags":["Git"]},{"title":"Linux网络管理","url":"/posts/2020/08/23/63252/","content":"网络状态查看\nifconfig\neth0 第一块网卡（网络接口）\n这里我的是Ubuntu虚拟机，第一个网络接口是 eth0 \nroot@zyp-virtual-machine:/# ifconfigeth0      Link encap:以太网  硬件地址 00:0c:29:cb:3d:56            inet 地址:192.168.171.129  广播:192.168.171.255  掩码:255.255.255.0          inet6 地址: fe80::20c:29ff:fecb:3d56/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  跃点数:1          接收数据包:40109 错误:0 丢弃:0 过载:0 帧数:0          发送数据包:44089 错误:0 丢弃:0 过载:0 载波:0          碰撞:0 发送队列长度:1000           接收字节:4456689 (4.4 MB)  发送字节:10033944 (10.0 MB)lo        Link encap:本地环回            inet 地址:127.0.0.1  掩码:255.0.0.0          inet6 地址: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  跃点数:1          接收数据包:1446 错误:0 丢弃:0 过载:0 帧数:0          发送数据包:1446 错误:0 丢弃:0 过载:0 载波:0          碰撞:0 发送队列长度:1000           接收字节:112637 (112.6 KB)  发送字节:112637 (112.6 KB)\n\n第一网络接口的其他名称：\n\neno1 板载网卡\nens33  PCI-E 网卡\nenp0s3 无法获取物理信息的PCI-E网卡\n\n\n网络接口命令修改（网卡名称固定之后，方便编写多主机批量控制脚本）\n\n网卡命名规则受 biosdevname 和 net.ifnames 两个参数影响\n\n编辑 &#x2F;etc&#x2F;default&#x2F;grub 文件， 增加 biosdevname&#x3D;0 net.ifnames&#x3D;0\nGRUB_CMDLINE_LINUX=&quot;biosdevname=0 net.ifnames=0&quot;\n\n更新 grub： 执行命令 update-grub或者grub-mkconfig -o /boot/grub/grub.dfg\n\n编辑 &#x2F;etc&#x2F;network&#x2F;interfaces文件，这边是动态配置：\nauto eth0iface eth0 inet dhcp\n\n重启 reboot\n\n\n\n\nbiosdevname\nnet.ifnames\n网卡名\n\n\n\n默认\n0\n1\nens33\n\n\n组合1\n1\n0\nem1\n\n\n组合2\n0\n0\neth0\n\n\n\n\n\nmii-tool eth0  查看网卡物理连接情况\nroot@zyp-virtual-machine:/# mii-tool eth0eth0: negotiated 1000baseT-FD flow-control, link ok\n\nroute  查看网关\n\nroute -n\n\n\n\n网络配置\n网卡配置\n\nifconfig &lt;接口&gt; &lt;IP地址&gt; [netmask 子网掩码] 设置 IP 地址\nifconfig eth0 192.168.171.126\nifconfig eth0 192.168.171.126 netmask 255.255.255.0\n\n\nifup &lt;接口&gt;  网卡启用\nifup eth0\n\n\nifdown &lt;接口&gt;   网卡关闭\nifdown eth0\n\n\nservice networking restart 重启网络配置\n\n\nip 命令\n\nip addr ls \nifconfig\n\n\nip link set dev eth0 up\nifup eth0\n\n\nip addr add xxx.0.0.1/24 dev eth1\nifconfig eth1 xxx.0.0.1 netmask 255.255.255.0\n\n\nip route add xxx.0.0.1/24 via 192.168.0.1\nroute add -net xxx.0.0.0 netmask 255.255.255.0 gw 192.168.0.1\n\n\n\n\n\n路由命令添加、删除网关\n\nroute -n 查看网关\n\nroute add default gw &lt;网关ip&gt; \n\nroute add -host &lt;指定ip&gt; gw &lt;网关ip&gt;\n例如route add -host 192.168.171.11 gw 192.168.171.1\n\nroute add -net &lt;指定网段&gt; netmask &lt;子网掩码&gt; gw &lt;网关ip&gt;\n例如route add -net 192.168.0.0 netmask 255.255.255.0 gw 192.168.171.11\n\n删除时将 add 改为 del\n\n\n网络故障管理\n我当前的 Ubuntu 路由状态：\nroot@zyp-virtual-machine:/# route -n内核 IP 路由表目标            网关            子网掩码        标志  跃点   引用  使用 接口0.0.0.0         192.168.171.2   0.0.0.0         UG    0      0        0 eth0169.254.0.0     0.0.0.0         255.255.0.0     U     1000   0        0 eth0192.168.171.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0\n\nping  查看当前主机和目标主机是否畅通\n\ntrackroute  追踪路由、服务器的每一跳\nroot@zyp-virtual-machine:/# traceroute -w 1 www.baidu.comtraceroute to www.baidu.com (182.61.200.7), 30 hops max, 60 byte packets 1  192.168.171.2 (192.168.171.2)  0.370 ms  0.204 ms  0.577 ms 2  * * *  (中间的主机如果不支持traceroute，以*的方式展示)\n\nmtr  看是否有数据包丢失\n\nnslookup  查看域名对应的 ip \nroot@zyp-virtual-machine:/# nslookup www.baidu.comServer:\t\t114.114.114.114   这里可以看出是通过哪个DNS服务器来进行的域名解析Address:\t114.114.114.114#53Non-authoritative answer:www.baidu.com\tcanonical name = www.a.shifen.com.Name:\twww.a.shifen.comAddress: 182.61.200.7Name:\twww.a.shifen.comAddress: 182.61.200.6\n\ntelnet\n畅通：\nroot@zyp-virtual-machine:/# telnet www.baid.com 80Trying 47.254.33.193...Connected to www.baid.com.Escape character is &#x27;^]&#x27;.   \n\n端口不可达：\nroot@zyp-virtual-machine:/# telnet www.baid.com 890Trying 47.254.33.193...telnet: Unable to connect to remote host: Connection refused\n\ntcpdump\n\nport xx  指定端口 \n抓取 任意的网卡、80端口的数据包\n tcpdump -i any -n port 80\n\nhost xxx.xxx.xxx.xxx  指定主机地址 \n抓取 host 为192.168.171.129、端口为80 的数据\ntcpdump -i any -n host 192.168.171.129 and port 80\n\n-w filename  将抓包数据保存到一个文件里\ntcpdump -i any -n host 192.168.171.1 -w fileb\n\n\n\nnetstat\nnetstat -ntpl  查看服务器监听地址\n-n 显示ip地址、不显示域名\n-t 以TCP协议截取想要显示的内容\n-p 进程\n-l  表示tcp的一个状态LISTEN\nroot@zyp-virtual-machine:/home/zyp/tmp# netstat -ntpl激活Internet连接 (仅服务器)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      1394/mysqld     tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      1401/redis-server 1tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      1419/nginx -g daemotcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1400/sshd       tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      2094/cupsd      tcp        0      0 127.0.0.1:6010          0.0.0.0:*               LISTEN      6915/8          tcp        0      0 127.0.0.1:6011          0.0.0.0:*               LISTEN      7113/9          tcp6       0      0 :::21                   :::*                    LISTEN      1365/vsftpd     tcp6       0      0 :::22                   :::*                    LISTEN      1400/sshd       tcp6       0      0 ::1:631                 :::*                    LISTEN      2094/cupsd      tcp6       0      0 ::1:6010                :::*                    LISTEN      6915/8          tcp6       0      0 ::1:6011                :::*                    LISTN      7113/9 \n\nss \nss -ntpl 使用方法和 netstat -npl 相似。\n\n\n常用网络配置文件网络服务管理程序分为两种：SysV、systemd\n\nservice network status|start|stop|restart\n\nchkconfig -list network  如果不支持，使用 systemctl\nroot@zyp-virtual-machine:/# systemctl list-unit-files|grep networksystemd-networkd-resolvconf-update.path    static  dbus-org.freedesktop.network1.service      disablednetwork-manager.service                    enabled networking.service                         enabled systemd-networkd-resolvconf-update.service static  systemd-networkd-wait-online.service       disabledsystemd-networkd.service                   disabledsystemd-networkd.socket                    disablednetwork-online.target                      static  network-pre.target                         static  network.target                             static \n\n\n\nsystemctl list-unit-files NetworkManager.service\nroot@zyp-virtual-machine:/# systemctl list-unit-files NetworkManager.serviceUNIT FILE              STATE  NetworkManager.service enabled\n\nsystemctl start|stop|reload|restart NetworkManager\n\nsystemctl enabled|disable NetworkManger\n\nsystemctl list-units 查看活跃的单元\n\nsystemctl status xxx  查看某个xxx服务的状态\n\nsystemctl list-unit-files|grep enabled 查看已启动的服务列表\n\nsystemctl --failed 查看启动失败的服务列表\n\n\n","categories":["技术","Network"],"tags":["network"]},{"title":"翻译PEP8中学习 -- Style Guide for Python Code","url":"/posts/2019/03/18/56849/","content":"官方原文:PEP8 Style Guide for Python Code\nIntroductionThis document gives coding conventions for the Python code comprising the standard library in the main Python distribution. Please see the companion informational PEP describing style guidelines for the C code in the C implementation of Python.本文档给出了包含主python发行版中标准库的python代码的编码约定。请参见公司信息PEP描述的用C实现的python中的C代码中的风格指南。\nThis document and PEP 257 (Doc string Conventions) were adapted from Guido’s original Python Style Guide essay, with some additions from Barry’s style guide.这篇文档和PEP 257 (约定文档) 改编自Guido最初的python代码风格指南文章, 并从Barry的风格指南总添加了一些内容.\nMany projects have their own coding style guidelines. In the event of any conflicts, such project-specific guides take precedence for that project.许多项目有他们自己的代码风格指南. 如果发生任何的冲突, 这样一些具体明确的指南就可以优先于他们的项目.\nA Foolish Consistency is the Hobgoblin of Little Minds愚蠢的一致性是弱智的妖精。\nOne of Guido’s key insights is that code is read much more often than it is written. The guidelines provided here are intended to improve the readability of code and make it consistent across the wide spectrum of Python code. As PEP 20 says, “Readability counts”.Guido关键的洞见之一就是代码的阅读频率远高于编写频率. 这里提供的指导方针旨在提高代码的可读性, 使得它可以在各种各样的python代码中保持一致. 正如PEP 20 说的, “可读性很重要”.\nA style guide is about consistency. Consistency with this style guide is important. Consistency within a project is more important.Consistency within one module or function is the most important.样式指南是关于一致性的. 和样本指南一致是很重要的. 在一个项目中, 一致性就显得更加重要了. 在一个模块或者函数中, 一致性是最重要的.\nHowever, know when to be inconsistent – sometimes style guide recommendations just aren’t applicable. When in doubt, use your best judgment. Look at other examples and decide what looks best. And don’t hesitate to ask!然而, 知道何时变得不一致 – 有时样式指南推荐方法是不适用的.  当存在疑惑时, 使用你最佳的判断力. 看一下其他例子然后决定哪种看上去最好. 不要犹豫问别人问题.\nIn particular: do not break backwards compatibility just to comply with this PEP!特别的: 不要仅仅为了遵守和这个PEP规范保持一致, 而破坏向后的兼容性.\nSome other good reasons to ignore a particular guideline:一些其他可以忽略特殊规范的好的理由:\n\nWhen applying the guideline would make the code less readable, even for someone who is used to reading code that follows this PEP. (当使用这个规范会导致代码可读性下降时, 甚至对于习惯于阅读遵守这PEP规范的人也是如此)\nTo be consistent with surrounding code that also breaks it (maybe for historic reasons) – although this is also an opportunity to clean up someone else’s mess (in true XP style).  (为了和周围代码保持一致有时也会打破这个规则(可能是历史原因), 尽管这是一个可以用来清理别人代码混乱的机会(正真的XP风格))\nBecause the code in question predates the introduction of the guideline and there is no other reason to be modifying that code. (因为所讨论的代码早于 准则的引入, 并且没有其他理由修改代码)\nWhen the code needs to remain compatible with older versions of Python that don’t support the feature recommended by the style guide. (当代码需要和老版本的python代码保持兼容性, 而老版本的代码不支持由样式指导推荐的特性)\n\nCode Lay-out代码布局\nIndentationUse 4 spaces per indentation level.  (每个缩进级别使用4个空格)\nContinuation lines should align wrapped elements either vertically using Python’s implicit line joining inside parentheses, brackets and braces, or using a hanging indent. When using a hanging indent the following should be considered: there should be no arguments on the first line and further indentation should be used to clearly distinguish itself as a continuation line.续行应使用 python的隐式行连接圆括号,括号,花括号, 或者使用一个悬挂缩进来对齐被包装的元素.  当使用一个悬挂时应该考虑一下内容: 这里起始行应没有参数, 应使用进一步的缩进将其作为一个续行而进行清楚地区分.\n# Yes:# Aligned with opening delimiter (分隔符).foo = long_function_name(var_one, var_two,                         var_three, var_four)# Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.def long_function_name(        var_one, var_two, var_three,        var_four):    print(var_one)# Hanging indents should add a level.foo = long_function_name(    var_one, var_two,    var_three, var_four)# No:# Arguments on first line forbidden when not using vertical alignment.foo = long_function_name(var_one, var_two,    var_three, var_four)# Further indentation required as indentation is not distinguishable.def long_function_name(    var_one, var_two, var_three,    var_four):    print(var_one)\n\nThe 4-space rule is optional for continuation lines. (4个空格的规范对于 续行 来说也是可选的)\n# Hanging indents *may* be indented to other than 4 spaces.foo = long_function_name(  var_one, var_two,  var_three, var_four)\n\nWhen the conditional part of an if-statement is long enough to require that it be written across multiple lines, it’s worth noting that the combination of a two character keyword (i.e. if), plus a single space, plus an opening parenthesis creates a natural 4-space indent for the subsequent lines of the multi line conditional.   This can produce a visual conflict with the indented suite of code nested inside the if-statement, which would also naturally be indented to 4 spaces. This PEP takes no explicit position on how (or whether) to further visually distinguish such conditional lines from the nested suite inside the if-statement. Acceptable options in this situation include, but are not limited to:当条件语句部分的 if 语句足够长, 以至于需要跨行写, 值得注意的是: 两个字符的关键字(例如if), 加上一个空格, 加上一个左括号, 会为了后续行的多行条件语句, 创造一个自然的4个空格的缩进.  这可能会与 嵌套在if语句中的缩进的代码集产生视觉冲突,  而这同样会自然地缩进4空格.  PEP规范没有明确的立场关于如何(或者是否)进一步在视觉上区分这种条件行 与嵌套在里面的if语句. 这种情况下可接受的选项包括, 但是并不限于:\n# No extra indentation.if (this_is_one_thing and    that_is_another_thing):    do_something()# Add a comment, which will provide some distinction in editors# supporting syntax highlighting.if (this_is_one_thing and    that_is_another_thing):    # Since both conditions are true, we can frobnicate.    do_something()# Add some extra indentation on the conditional continuation line.if (this_is_one_thing        and that_is_another_thing):    do_something()\n\n(Also see the discussion of whether to break before or after binary operators below.)（参见下面关于是否在二元运算符之前或之后中断的讨论。）\nmy_list = [    1, 2, 3,    4, 5, 6,    ]result = some_function_that_takes_arguments(    &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;,    &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;,    )\n\nor it may be lined up under the first character of the line that starts the multi line construct, as in:或者在开始多行结构的时, 它可以排列在行的第一个字符下面, 例如:\nmy_list = [    1, 2, 3,    4, 5, 6,]result = some_function_that_takes_arguments(    &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;,    &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;,)\n\nTabs or Spaces?Spaces are the preferred indentation method.空格是首选的缩进方法.\nTabs should be used solely to remain consistent with code that is already indented with tabs.Tabs 应该只能用在已经使用制表符来缩进的代码中, 以保持一致.\nPython 3 disallows mixing the use of tabs and spaces for indentation.python 3 不允许混用tabs和空格来缩进.\nPython 2 code indented with a mixture of tabs and spaces should be converted to using spaces exclusively.python 2 代码使用tabs和空格的混合来作为缩进, 应该被转换为单独使用空格.\nWhen invoking the Python 2 command line interpreter with the -t option, it issues warnings about code that illegally mixes tabs and spaces. When using -tt these warnings become errors. These options are highly recommended!当使用-t 选项调用python 2 命令行解释器时, 它会发出警告: 非法混合tabs和空格的代码. 当使用 -tt 这样事, 警告会变成错误. 这些选项值得强烈推荐!\nMaximum Line LengthLimit all lines to a maximum of 79 characters.对所有行来说, 最大容纳79字符.\nFor flowing long blocks of text with fewer structural restrictions (doc strings or comments), the line length should be limited to 72 characters.对于结构限制较少的长文本块（doc strings或注释），行长度应限制为72个字符。\nLimiting the required editor window width makes it possible to have several files open side-by-side, and works well when using code review tools that present the two versions in adjacent columns.限制所需要的编辑窗口宽度, 可以使多个文件并排打开, 而且在使用相邻列中显示不同版本的代码检查工作时更好.\nThe default wrapping in most tools disrupts the visual structure of the code, making it more difficult to understand. The limits are chosen to avoid wrapping in editors with the window width set to 80, even if the tool places a marker glyph in the final column when wrapping lines. Some web based tools may not offer dynamic line wrapping at all.大多数工具中默认包装会破坏代码的视觉结构,  使得更加难以理解. 选择这个限制是为了避免在窗口宽度设置为80的编辑器中换行,  即使当在换行时工具会在最后一列放置一个glyph标志.  一些基于工具的web, 可能根本不会提供动态换行.\nSome teams strongly prefer a longer line length. For code maintained exclusively or primarily by a team that can reach agreement on this issue, it is okay to increase the line length limit up to 99 characters, provided that comments and doc strings are still wrapped at 72 characters.一些团队强烈希望有一个更长的行长度. 对于专门维护或者主要由团队维护的代码, 可以对此达成统一见解. 延长行的最大长度限制至99字符是可以的, 前提是评论和doc string仍然需要限制在72字符以内.\nThe Python standard library is conservative and requires limiting lines to 79 characters (and doc strings&#x2F;comments to 72).python 标准库是保守的, 要求限制行数至79字符( doc string&#x2F;comment 至72)\nThe preferred way of wrapping long lines is by using Python’s implied line continuation inside parentheses, brackets and braces. Long lines can be broken over multiple lines by wrapping expressions in parentheses. These should be used in preference to using a backslash for line continuation.包装长的行的首选方法是在圆括号&#x2F;括号&#x2F;大括号内使用python的隐含行继续符, 长行可以通过将表达式括在括号中, 实现在多行上打断长行. 这些应该优先使用反斜杠作为行继续符.\nBackslashes may still be appropriate at times. For example, long, multiple with-statements cannot use implicit continuation, so backslashes are acceptable:反斜杠有时候仍然是一个恰当的方法. 例如, 长的&#x2F;多重的with语句, 不能使用隐式延续,  因此可以接受反斜杠.\nwith open(&#x27;/path/to/some/file/you/want/to/read&#x27;) as file_1, \\     open(&#x27;/path/to/some/file/being/written&#x27;, &#x27;w&#x27;) as file_2:    file_2.write(file_1.read())# 卧槽, 还可以这样写, 涨知识了\n\nAnother such case is with assert statements.另一个相似的例子是  assert 断言 语句.\nMake sure to indent the continued line appropriately.确保适当地缩进连续行.\nShould a Line Break Before or After a Binary Operator?在二元运算符之前还是之后换行？\nFor decades the recommended style was to break after binary operators. But this can hurt readability in two ways: the operators tend to get scattered across different columns on the screen, and each operator is moved away from its operand and onto the previous line. Here, the eye has to do extra work to tell which items are added and which are subtracted:数十年来推荐的风格是在二元运算符后面进行中断. 但是有两种方式会损害可读性: 运算符往往分散在屏幕的不同列中,  并且每个运算符都会从其操作数移到前一行. 在这里, 眼睛不得不做额外的工作来区分哪些项目是增加的, 哪些项目是减去的:\n# No: operators sit far away from their operandsincome = (gross_wages +          taxable_interest +          (dividends - qualified_dividends) -          ira_deduction -          student_loan_interest)\n\nTo solve this readability problem, mathematicians and their publishers follow the opposite convention. Donald Knuth explains the traditional rule in his Computers and Typesetting series: “Although formulas within a paragraph always break after binary operations and relations, displayed formulas always break before binary operations” .为了解决这个可读性问题, 数学家和他们的出版商遵循了相反的惯例. Donald Knuth 在他的计算机和排版系列中解释了传统的规则: 尽管一个段落中的公式总是在二进制运算和关系之后中断, 但显示的公式总是在二进制运算之前中断.\nFollowing the tradition from mathematics usually results in more readable code:遵循数学的传统通常会导致一些更加易读的代码:\n# Yes: easy to match operators with operandsincome = (gross_wages          + taxable_interest          + (dividends - qualified_dividends)          - ira_deduction          - student_loan_interest)\n\nIn Python code, it is permissible to break before or after a binary operator, as long as the convention is consistent locally. For new code Knuth’s style is suggested.在python代码中, 在二元运算符前后中断都是允许的, 只要在本地的约定一致. 对于新的代码, 建议使用Knuth式.\nBlank LinesSurround top-level function and class definitions with two blank lines.用两个空行来围绕顶级函数和类的定义.\nMethod definitions inside a class are surrounded by a single blank line.在一个类中的方法定义, 是通过一个空白行来围绕的.\nExtra blank lines may be used (sparingly) to separate groups of related functions. Blank lines may be omitted between a bunch of related one-liners (e.g. a set of dummy implementations).可以使用额外的空行(保守地,节约地)来分隔相关函数组. 在一组相关的一行程序(例如一组虚拟实现) 之间可以省略空行.\nUse blank lines in functions, sparingly, to indicate logical sections.在函数中尽量使用空行可以表示逻辑部分.\nPython accepts the control-L (i.e. ^L) form feed  character as whitespace; Many tools treat these characters as page separators, so you may use them to separate pages of related sections of your file. Note, some editors and web-based code viewers may not recognize control-L as a form feed and will show another glyph in its place.python接受 control-L 表单提要字符作为空白. 一些工具把这些字符当做是页分隔符, 所以你可以使用它们来分隔文件的相关部分的页面. 注意, 一些编辑器和基于web的代码查看器可能不能识别control-L作为表单提要, 将会在该处用另一种glyph来标志.\nSource File EncodingCode in the core Python distribution should always use UTF-8 (or ASCII in Python 2).在核心python发布版本中的代码, 应该始终使用UTF-8(在python2中使用ASCII).\nFiles using ASCII (in Python 2) or UTF-8 (in Python 3) should not have an encoding declaration.在python 2中使用ASCII或者在python 3中使用UTF-8的文件, 不应该有编码声明.\nIn the standard library, non-default encodings should be used only for test purposes or when a comment or doc string needs to mention an author name that contains non-ASCII characters; otherwise, using \\x, \\u, \\U, or \\N escapes is the preferred way to include non-ASCII data in string literals.在标准库中, 非默认的编码应该只用来测试目的或者当注释&#x2F;doc string 中有涉及包含非ASCII字符的作者名时使用. 否则, 使用\\x, \\u或者\\N 转义 是在字符串文本中来包含非ASCII数据的首选方法.\nFor Python 3.0 and beyond, the following policy is prescribed for the standard library (see PEP 3131): All identifiers in the Python standard library MUST use ASCII-only identifiers, and SHOULD use English words wherever feasible (in many cases, abbreviations and technical terms are used which aren’t English). In addition, string literals and comments must also be in ASCII. The only exceptions are (a) test cases testing the non-ASCII features, and (b) names of authors. Authors whose names are not based on the Latin alphabet (latin-1, ISO&#x2F;IEC 8859-1 character set) MUST provide a transliteration of their names in this character set.对于python 3.0 以及更高版本, 标准库规定了以下策略(看PEP 3131) : 在python 官方库中所有的标识符都必须使用仅ASCII标识符, 并且应在可行的情况下使用英文单词(在一些案例中, 缩写和技术词条不是英文的). 除此以外, 字符串文本和注释必须使用ASCII. 唯一的例外是测试非ASCII特性和作者名的测试用例. 名称不基于拉丁字母（拉丁-1，ISO&#x2F;IEC 8859-1字符集）的作者必须在此字符集中提供其名称的音译。\nOpen source projects with a global audience are encouraged to adopt a similar policy.鼓励那些拥有全球受众的开源项目来采用类似的策略.\nImportsImports should usually be on separate lines:\nYes: import os     import sysNo:  import sys, os\n\nIt’s okay to say this though:\nfrom subprocess import Popen, PIPE\n\nImports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants.Imports 总是放在文件的顶部, 在模块注释和doc string 的后面, 在模块的全局变量和常量的前面.\nImports should be grouped in the following order:imports 应该以下面顺序来分组:\n\nStandard library imports.标准库的导入.\nRelated third party imports.相关三方库的导入.                            \nLocal application&#x2F;library specific imports.局部应用程序&#x2F;特定库的导入.\n\nYou should put a blank line between each group of imports.你应该将在每个导入的组之间添加空行.\nAbsolute imports are recommended, as they are usually more readable and tend to be better behaved (or at least give better error messages) if the import system is incorrectly configured (such as when a directory inside a package ends up on sys.path):建议使用绝对导入,  如果导入系统没有正确地配置(正如当包中的目录以 sys.path 结尾时) , 绝对导入通常更具可读性, 而且往往表现更好(至少给出更好的错误提示信息) ,\nimport mypkg.siblingfrom mypkg import siblingfrom mypkg.sibling import example\n\nHowever, explicit relative imports are an acceptable alternative to absolute imports, especially when dealing with complex package layouts where using absolute imports would be unnecessarily verbose:然而, 显式相对导入对于绝对导入是一个可接受的选择, 尤其是当处理复杂的包布局时, 使用了绝对导入将不必要地冗长.\nfrom . import siblingfrom .sibling import example\n\nStandard library code should avoid complex package layouts and always use absolute imports.标准库代码应该避免复杂的包布局, 应始终使用绝对导入.\nImplicit relative imports should never be used and have been removed in Python 3.隐式相对导入应该从不使用, 而且已经被python 3 移除了.\nWhen importing a class from a class-containing module, it’s usually okay to spell this:当从一个包含类的模块中导入一个类时, 通常可以这样写:\nfrom myclass import MyClassfrom foo.bar.yourclass import YourClass\n\nIf this spelling causes local name clashes, then spell them explicitly:如果这个拼写会导致本地名字冲突, 则显式拼写.\nimport myclassimport foo.bar.yourclass# and use &quot;myclass.MyClass&quot; and &quot;foo.bar.yourclass.YourClass&quot;.\n\nWild card imports (from &lt;module&gt; import *) should be avoided, as they make it unclear which names are present in the name space, confusing both readers and many automated tools. There is one defensible use case for a wild card import, which is to republish an internal interface as part of a public API (for example, overwriting a pure Python implementation of an interface with the definitions from an optional accelerator module and exactly which definitions will be overwritten isn’t known in advance).应避免使用通配符号导入( from  import * ) . 因为这样会使名称空间中存在哪些名称变得不清楚, 会让读者和自动化工具困惑.  通配符有一种可防御的用例, 即将内部的接口重新发布为公共API的一部分(例如, 重写一个可选择的加速器模块中定义的, 用纯粹的python实现的内部接口 , 确切的说哪些定义会被重写不能提前知道)\nWhen republishing names this way, the guidelines below regarding public and internal interfaces still apply.当用这种方式重新发布名字时,  下面关于公共和外部的接口的指导原则仍然适合.\nModule Level Dunder NamesModule level “dunders” (i.e. names with two leading and two trailing underscores) such as __all__, __author__, __version__, etc. should be placed after the module doc string but before any import statements except from __future__ imports. Python mandates that future-imports must appear in the module before any other code except doc strings:模块级”dunders”( 即 名字带有两个前导和两个尾随下划线的名称), 例如__ all __ ,__ author __ , __ version __ 等, 应放在doc string 模块后面, 但是除了 from __ future __ imports 之外的任何导入语句的前面.  python要求将来的导入必须出现在模块中除了doc strings 之外的任何代码之前.\n&quot;&quot;&quot;This is the example module.This module does stuff.&quot;&quot;&quot;from __future__ import barry_as_FLUFL__all__ = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]__version__ = &#x27;0.1&#x27;__author__ = &#x27;Cardinal Biggles&#x27;import osimport sys\n\n\n\nString QuotesIn Python, single-quoted strings and double-quoted strings are the same. This PEP does not make a recommendation for this. Pick a rule and stick to it. When a string contains single or double quote characters, however, use the other one to avoid backslashes in the string. It improves readability.在python中, 单引号字符串和双引号字符串是一样的. PEP规范没有提出建议. 选择一条规则并且坚持下去. 当一个字符串包含一个单引号或者双引号字符时, 当一个字符串包含单引号或者双引号时, 请使用另一种字符避免字符串中出现反斜杠.\nFor triple-quoted strings, always use double quote characters to be consistent with the doc string convention in PEP 257.对于三引号字符串, 始终使用双引号字符以符合PEP 257中的doc string约定.\nWhitespace in Expressions and StatementsPet Peeves宠物的烦恼\nAvoid extraneous whitespace in the following situations:以下情况, 避免出现外来空白:\n\nImmediately inside parentheses, brackets or braces.括号内的括号或者括号的开始.\n\nYes: spam(ham[1], &#123;eggs: 2&#125;)No:  spam( ham[ 1 ], &#123; eggs: 2 &#125; )\n\n\nBetween a trailing comma and a following close parenthesis.在尾随逗号和后面的右括号之间.\n\nYes: foo = (0,)No:  bar = (0, )\n\n\nImmediately before a comma, semicolon, or colon:紧跟在逗号&#x2F;分号&#x2F;冒号之前:\n\nYes: if x == 4: print x, y; x, y = y, xNo:  if x == 4 : print x , y ; x , y = y , x\n\n\nHowever, in a slice the colon acts like a binary operator, and should have equal amounts on either side (treating it as the operator with the lowest priority). In an extended slice, both colons must have the same amount of spacing applied. Exception: when a slice parameter is omitted, the space is omitted.然而, 在一个切片中, 冒号就像一个二元操作符, 并且应该在每一侧具有相等的数量(将其视为优先级最低的运算符). 在扩展切片中, 两个冒号必须有相同数量的间距. 例外: 当一个切片参数被省略时, 空格被省略.\n\n# Yes: ham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:]ham[lower:upper], ham[lower:upper:], ham[lower::step]ham[lower+offset : upper+offset]ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)]ham[lower + offset : upper + offset]# No:ham[lower + offset:upper + offset]ham[1: 9], ham[1 :9], ham[1:9 :3]ham[lower : : upper]ham[ : upper]\n\n\nImmediately before the open parenthesis that starts the argument list of a function call:在开始函数调用的参数列表的左括号之前:\n\nYes: spam(1)No:  spam (1)\n\n\nImmediately before the open parenthesis that starts an indexing or slicing:在开始索引或者切片的左括号之前:\n\nYes: dct[&#x27;key&#x27;] = lst[index]No:  dct [&#x27;key&#x27;] = lst [index]\n\n\nMore than one space around an assignment (or other) operator to align it with another.多个空格围绕在一个分配(或者其他)运算符周围, 使得它和其他运算符对齐.\n\n# Yes:x = 1y = 2long_variable = 3# No:x             = 1y             = 2long_variable = 3\n\nOther RecommendationsAvoid trailing whitespace anywhere. Because it’s usually invisible, it can be confusing: e.g. a backslash followed by a space and a newline does not count as a line continuation marker. Some editors don’t preserve it and many projects (like C Python itself) have pre-commit hooks that reject it.避免在任何地方尾随空白. 因为它通常是不可见的, 所以可能会让人困惑: 例如, 反斜杠后面跟着空白, 换行符不算作行继续标记. 有些编辑器不保存它, 许多项目(例如C python本身) 都有预提交钩子来拒绝它.\nAlways surround these binary operators with a single space on either side: assignment (=), augmented assignment (+=, -= etc.), comparisons (==, &lt;, &gt;, !=, &lt;&gt;, &lt;=, &gt;=, in, not in, is, is not), Booleans (and, or, not).\n始终在这些二元运算符两边用一个空格包围:  赋值(&#x3D;), 増广赋值(+&#x3D;, -&#x3D; 等), 比较(&#x3D;、&lt;、&gt;、！&#x3D;，&lt;&gt;，&lt;&#x3D;，&gt;&#x3D;，in，not in，is，is not），布尔值（and，or，not）\n# Yes:i = i + 1submitted += 1x = x*2 - 1hypot2 = x*x + y*yc = (a+b) * (a-b)# No:i=i+1submitted +=1x = x * 2 - 1hypot2 = x * x + y * yc = (a + b) * (a - b)\n\nFunction annotations should use the normal rules for colons and always have spaces around the -&gt; arrow if present. (See Function Annotations below for more about function annotations.)函数注释应该使用冒号的常规规则, 并且如果存在的话, 在-&gt;箭头周围总是有空格.  (有关函数注释的详细信息，请参见下面的函数注释。）\n# Yesdef munge(input: AnyStr): ...def munge() -&gt; AnyStr: ...  # Nodef munge(input:AnyStr): ...def munge()-&gt;PosInt: ...\n\nDon’t use spaces around the = sign when used to indicate a keyword argument, or when used to indicate a default value for an unannotated  function parameter.当用于指示关键字参数, 或用于指示未标记函数参数的默认值时, 不要在&#x3D; 号周围使用空格.\n# Yes:def complex(real, imag=0.0):    return magic(r=real, i=imag)# No:def complex(real, imag = 0.0):    return magic(r = real, i = imag)\n\nWhen combining an argument annotation with a default value, however, do use spaces around the = sign:当将参数批注与默认值组合时, 请在&#x3D; 符号周围使用空格:\n# Yes:def munge(sep: AnyStr = None): ...def munge(input: AnyStr, sep: AnyStr = None, limit=1000): ...# No:def munge(input: AnyStr=None): ...def munge(input: AnyStr, limit = 1000): ...\n\nCompound statements (multiple statements on the same line) are generally discouraged.复合语句(多重声明在同一行) 一般是不鼓励的.\n# Yes:if foo == &#x27;blah&#x27;:    do_blah_thing()do_one()do_two()do_three()# No:if foo == &#x27;blah&#x27;: do_blah_thing()do_one(); do_two(); do_three()\n\nWhile sometimes it’s okay to put an if&#x2F;for&#x2F;while with a small body on the same line, never do this for multi-clause statements. Also avoid folding such long lines!尽管有时可以把一个 if&#x2F;for&#x2F;while 和一个小的主体放在同一行, 但是不要这样用于复合语句.  同样避免折叠这么长的行.\n# rather notif foo == &#x27;blah&#x27;: do_blah_thing()for x in lst: total += xwhile t &lt; 10: t = delay()# Definitely not:if foo == &#x27;blah&#x27;: do_blah_thing()else: do_non_blah_thing()try: something()finally: cleanup()do_one(); do_two(); do_three(long, argument,                             list, like, this)if foo == &#x27;blah&#x27;: one(); two(); three()\n\n\n\nWhen to Use Trailing CommasTrailing commas are usually optional, except they are mandatory when making a tuple of one element (and in Python 2 they have semantics for the print statement). For clarity, it is recommended to surround the latter in (technically redundant) parentheses.尾随逗号通常是可选的, 除非他们在构成一个元素的元组时是强制的(在python 2 中, 它们具有print语句的语义). 为了清楚起见, 建议将后者括在(技术上的冗余)括号中.\n# Yes:FILES = (&#x27;setup.cfg&#x27;,)# ok, but confusing:FILES = &#x27;setup.cfg&#x27;,\n\nWhen trailing commas are redundant, they are often helpful when a version control system is used, when a list of values, arguments or imported items is expected to be extended over time. The pattern is to put each value (etc.) on a line by itself, always adding a trailing comma, and add the close parenthesis&#x2F;bracket&#x2F;brace on the next line. However it does not make sense to have a trailing comma on the same line as the closing delimiter (except in the above case of singleton tuples).当尾随逗号是冗余时, 当使用一个版本控制系统时,  在一系列值,参数或者导入项的列表随着时间的推移而扩展时, 尾随逗号通常是有用的. 模式是将每个值(等)单独放在一行上, 始终添加一个尾随逗号, 并在下一行添加右括号&#x2F;括号&#x2F;大括号. 但是, 在结束分隔符的同一行使用尾随逗号是没有意义的(上面的单例元组除外)\n# Yes:FILES = [    &#x27;setup.cfg&#x27;,    &#x27;tox.ini&#x27;,    ]initialize(FILES,           error=True,           )# No:FILES = [&#x27;setup.cfg&#x27;, &#x27;tox.ini&#x27;,]initialize(FILES, error=True,)\n\n\n\nCommentsComments that contradict the code are worse than no comments. Always make a priority of keeping the comments up-to-date when the code changes!与代码冲突的注释比没有注释还糟糕. 当代码更改时, 始终保持优先更新注释.\nComments should be complete sentences. The first word should be capitalized, unless it is an identifier that begins with a lower case letter (never alter the case of identifiers!).注释应该是完整的句子. 第一个单词应该大写, 除非它是一个以小写字母开始的标识符(不要更改标识符).\nBlock comments generally consist of one or more paragraphs built out of complete sentences, with each sentence ending in a period.注释块一般由一个或者多个完整句子构成的段落组成,每个句子以句点结尾.\nYou should use two spaces after a sentence-ending period in multi- sentence comments, except after the final sentence.在多句评论中, 句末句点后应使用两个空格,  最后一句除外.\nWhen writing English, follow Strunk and White.当你写英语的时候，跟着斯特伦克和怀特.\nPython coders from non-English speaking countries: please write your comments in English, unless you are 120% sure that the code will never be read by people who don’t speak your language.对于母语非英语的python 程序员: 请用英文写评论, 除非你有120%的把握确信这些代码以后绝不会被那些不会自己语言的人读到.\nBlock CommentsBlock comments generally apply to some (or all) code that follows them, and are indented to the same level as that code. Each line of a block comment starts with a # and a single space (unless it is indented text inside the comment).块注释一般适用于一些(或者所有)遵循他们并且在缩进方面是一个级别的代码. 块注释的每行评论都说以一个# 和一个空格开始(除非是在注释中缩进的文本)\nParagraphs inside a block comment are separated by a line containing a single #.块注释内的段落由包含单个# 的行分隔.\nInline CommentsUse inline comments sparingly.谨慎使用内联注释.\nAn inline comment is a comment on the same line as a statement. Inline comments should be separated by at least two spaces from the statement. They should start with a # and a single space.一个内联注释是与语句在同一行上的注释. 内联注释和语句应该至少有两个空格隔开. 他们应该以一个# 和一个空格开始.\nInline comments are unnecessary and in fact distracting if they state the obvious. Don’t do this:内联注释是不必要地, 事实上, 如果它们声明了明显的内容, 则会分散注意力. 不要这样:\nx = x + 1                 # Increment x# But sometimes, this is useful:x = x + 1                 # Compensate for border\n\nDocumentation StringsConventions for writing good documentation strings (a.k.a. “doc strings”) are immortalized in PEP 257.编写好文档字符串的约定(也称为”doc string”) 在PEP 257 中永久化.\nWrite doc strings for all public modules, functions, classes, and methods. Doc strings are not necessary for non-public methods, but you should have a comment that describes what the method does. This comment should appear after the def line.为了所有公共模块,函数,类和方法编写doc string. Doc string 不一定是为了非公共方法, 但是应该用一个注释来描述该方法的作用是什么. 这个注释应该出现在def行的后面.\nPEP 257 describes good doc string conventions. Note that most importantly, the &quot;&quot;&quot; that ends a multi line doc string should be on a line by itself:PEP 257 描述了好的doc string 公约.  注意到最重要的是,  结束多行doc string 的””” 本身应该在一行上:\n&quot;&quot;&quot;Return a foobangOptional plotz says to frobnicate the bizbaz first.&quot;&quot;&quot;\n\nFor one liner doc strings, please keep the closing &quot;&quot;&quot; on the same line.对于一行文档字符串, 请将结束符””” 保持在同一行.\nNaming ConventionsThe naming conventions of Python’s library are a bit of a mess, so we’ll never get this completely consistent – nevertheless, here are the currently recommended naming standards. New modules and packages (including third party frameworks) should be written to these standards, but where an existing library has a different style, internal consistency is preferred.python 库的命名的约定有点混乱, 所以我们永远不能达成一致—- 然而, 这里是当前推荐的命名标准. 新的模块和包(包括三方框架) 应该按照这些标准来写, 但是当已经存在的库有不同的样式时, 更倾向于内部的一致性.\nOverriding Principle压倒性原则\nNames that are visible to the user as public parts of the API should follow conventions that reflect usage rather than implementation.作为API的公共部分, 名字对于用户是可见的,  应该遵守反应语法而不是实现的约定.\nDescriptive: Naming StylesThere are a lot of different naming styles. It helps to be able to recognize what naming style is being used, independently from what they are used for.这里有许多不同的命名样式. 它可以帮助人能够识别出正在使用的命名样式, 独立于它们的用途.\nThe following naming styles are commonly distinguished:以下命名样式通常是可区分的:\n\nb (single lowercase letter)   \nB (single uppercase letter)\nlowercase\nlower_case_with_underscores    (小写字母带下划线)\nUPPERCASE\nUPPER_CASE_WITH_UNDERSCORES\nCapitalizedWords (or CapWords, or CamelCase – so named because of the bumpy look of its letters). This is also sometimes known as StudlyCaps.  (凹凸不平的样子)Note: When using acronyms in CapWords, capitalize all the letters of the acronym. Thus HTTPServerError is better than HttpServerError.注意: 在使用首字母缩略词时,  将首字母缩略词的所有字母大写. \nmixedCase (differs from CapitalizedWords by initial lowercase character!)\nCapitalized_Words_With_Underscores (ugly!)  (带下划线的大写单词)\n\nThere’s also the style of using a short unique prefix to group related names together. This is not used much in Python, but it is mentioned for completeness. For example, the os.stat() function returns a tuple whose items traditionally have names like st_mode, st_size, st_mtime and so on. (This is done to emphasize the correspondence with the fields of the POSIX system call struct, which helps programmers familiar with that.)有时也会使用短的 唯一 的前缀来将相关的命名组合在一起. 这在python中虽然不经常用, 但是为了完整起见, 本文提到了这一点. 例如, os.stat() 函数返回一个元组, 它的项传统上由像st_mode, st_mtime, st_size等命名. (这是用来强调和POSIX系统调用结构字段的对应关系, 它可以帮助编程人员熟悉它)\nIn addition, the following special forms using leading or trailing underscores are recognized (these can generally be combined with any case convention):此外, 还可以识别以下使用了前导或尾随下划线的特殊表单(这些一般能够和任意约定案例结合):\n\n_single_leading_underscore: weak “internal use” indicator. E.g. from M import * does not import objects whose names start with an underscore._single_leading_underscore: 弱”内部使用”指标. 例如, 从 from M import * 不导入那些以下划线开头的对象.\n\nsingle_trailing_underscore_: used by convention to avoid conflicts with Python keyword, e.g.single_trailing_underscore_:  约定用来避免和python关键字冲突:\nTkinter.Toplevel(master, class_=&#x27;ClassName&#x27;)   # class_\n\n__double_leading_underscore: when naming a class attribute, invokes name mangling (inside class FooBar, __boo becomes _FooBar__boo; see below).__ double_leading_underscore: 当命名一个类属性时,  调用 名称管理.\n\n__double_leading_and_trailing_underscore__: “magic” objects or attributes that live in user-controlled namespaces. E.g. __init__, __import__ or __file__. Never invent such names; only use them as documented.双&#x2F;前导&#x2F;尾随&#x2F;下划线:  存在于用户控制的命名空间中的”magic” 对象或者属性.\n\n\nPrescriptive: Naming Conventions说明性: 命名约定\nNames to AvoidNever use the characters ‘l’ (lowercase letter el), ‘O’ (uppercase letter oh), or ‘I’ (uppercase letter eye) as single character variable names.不要使用字符”l” (小写字母l) , “O”(大写字母O), 或者”I” (大写字母) 作为单个字符变量名.\nIn some fonts, these characters are indistinguishable from the numerals one and zero. When tempted to use ‘l’, use ‘L’ instead.在一些字体中, 这些字符和其他数字和0分不清. 当试图使用”l” 时, 请使用”L”.\nASCII CompatibilityIdentifiers used in the standard library must be ASCII compatible as described in the policy section of PEP 3131标识符在标准库中使用必须是与ASCII码兼容的, 入PEP 的策略部分所述.\nPackage and Module NamesModules should have short, all-lowercase names. Underscores can be used in the module name if it improves readability. Python packages should also have short, all-lowercase names, although the use of underscores is discouraged.模块应该是简短的, 都是小写的名称.  如果下划线可以提高可读性,  可以在模块名称中使用下划线.  尽管不鼓励使用下划线, python包应该也有简短的,都是小写的命名.\nClass NamesClass names should normally use the CapWords convention.类名通常应该使用首字母大写的约定.\nThe naming convention for functions may be used instead in cases where the interface is documented and used primarily as a callable.对于函数的命名约定,可用于记录接口并当做主要的调用接口情况.\nNote that there is a separate convention for builtin names: most builtin names are single words (or two words run together), with the CapWords convention used only for exception names and builtin constants.注意: 对于内置的命名有一个单独的约定: 大多数内置的命名是单一的单词(或者两个单词在一起), 以大写字母开始的约定只用在异常命名和内置的常量.\nType Variable NamesNames of type variables introduced in PEP 484 should normally use CapWords preferring short names: T, AnyStr, Num. It is recommended to add suffixes _co or _contra to the variables used to declare covariant or contravariant behavior correspondingly:PEP 484 中引入的不同种类的名称 通常应该使用以大写字母开头优先于短的名称: T, AnyStr, Num建议添加 _co 或者 _contra 的 后缀到变量中, 用来相应地声明协变的或者逆变的行为.\nfrom typing import TypeVarVT_co = TypeVar(&#x27;VT_co&#x27;, covariant=True)KT_contra = TypeVar(&#x27;KT_contra&#x27;, contravariant=True)\n\nException NamesBecause exceptions should be classes, the class naming convention applies here. However, you should use the suffix “Error” on your exception names (if the exception actually is an error).由于异常应该是类, 所以类的命名约定也同样适合这里. 然而, 你应该在你的异常名称中使用”Error”作为后缀(如果异常事实上是一个错误).\nGlobal Variable Names(Let’s hope that these variables are meant for use inside one module only.) The conventions are about the same as those for functions.(希望这些变量仅仅意味着在一个模块中使用.) 这些约定和对于函数的约定是大致相同的. \nModules that are designed for use via from M import * should use the __all__ mechanism to prevent exporting globals, or use the older convention of prefixing such globals with an underscore (which you might want to do to indicate these globals are “module non-public”).为了使用 from M import * 而设计的模块, 应该使用 __ all __ 机制来避免导出全局变量, 或使用较旧的惯例, 在这些全局变量前面加下划线 (可能想表示这些全局变量是”非公共的模块”).\nFunction and Variable NamesFunction names should be lowercase, with words separated by underscores as necessary to improve readability.函数名称应该是小写的, 通过下划线来分隔单词来提高可读性是有必要的.\nVariable names follow the same convention as function names.变量名称和函数名称一样遵守相同的公约.\nmixedCase is allowed only in contexts where that’s already the prevailing style (e.g. threading.py), to retain backwards compatibility.混合的例子 只有在那些已经流行的样式中的上下文中才能被允许(比如threading.py) , 为的是保留向后的兼容性.\nFunction and Method ArgumentsAlways use self for the first argument to instance methods.始终把 self 作为实例方法的第一个参数.\nAlways use cls for the first argument to class methods.始终把 cls 作为类方法的第一个参数.\nIf a function argument’s name clashes with a reserved keyword, it is generally better to append a single trailing underscore rather than use an abbreviation or spelling corruption. Thus class_ is better than clss. (Perhaps better is to avoid such clashes by using a synonym.)如果一个函数的参数名和一个保留的关键字冲突了, 通常更好的做法是附加一个单独的尾随下划线, 而不是用一个缩写或者拼写错误. 因此, class_ 相对于clss 更好. (最好是使用同义词避免这样的错误.).\nMethod Names and Instance VariablesUse the function naming rules: lowercase with words separated by underscores as necessary to improve readability.使用函数命名的规则: 根据需要用下划线分隔的小写单词.\nUse one leading underscore only for non-public methods and instance variables.使用一个下划线开头仅仅是为了非公共的方法和实例变量.\nTo avoid name clashes with subclasses, use two leading underscores to invoke Python’s name mangling rules.为了避免名称和子类名称冲突, 使用两个前导下划线可以调用python的命名管理规定.\nPython mangles these names with the class name: if class Foo has an attribute named __a, it cannot be accessed by Foo.__a. (An insistent user could still gain access by calling Foo._Foo__a.) Generally, double leading underscores should be used only to avoid name conflicts with attributes in classes designed to be subclassed.python用类名来管理这些名称: 如果Foo类有一个名称为 __a 的属性, 它不能通过 Foo.__a 来访问.(一个坚持的用户仍然能够通过调用  Foo._Foo__a来访问) 一般来说, 双前导下划线仅应为了避免与 设计成子类的类的属性 产生冲突.\nNote: there is some controversy about the use of __names (see below).注意: 关于 __names 的用法有一些争议(如下):\nConstantsConstants are usually defined on a module level and written in all capital letters with underscores separating words. Examples include MAX_OVERFLOW and TOTAL.常量通常在模块级定义, 使用一些下划线分隔的单词, 所有的大写字母书写. 例如  MAX_OVERFLOW and TOTAL.\nDesigning for Inheritance为了继承而设计\nAlways decide whether a class’s methods and instance variables (collectively: “attributes”) should be public or non-public. If in doubt, choose non-public; it’s easier to make it public later than to make a public attribute non-public.始终决定一个类方法和实例变量(统称为: “attributes”) 是否应该是公共的还是非公共的. 如果有疑问, 选择非公共的; 相比较将公共属性设置为非公共的,  稍后将其变成公共的更容易.\nPublic attributes are those that you expect unrelated clients of your class to use, with your commitment to avoid backwards incompatible changes. Non-public attributes are those that are not intended to be used by third parties; you make no guarantees that non-public attributes won’t change or even be removed.公共属性是那些你希望类中使用的不相关的clients的属性, 并且你承诺避免向后不兼容的变更. 非公共的属性是那些不打算由第三方使用的属性.  你不能保证非公共属性将不会更改或者甚至被移除.\nWe don’t use the term “private” here, since no attribute is really private in Python (without a generally unnecessary amount of work).我们这里不使用”private”词条, 因为在python中没有正真私有的属性( 没有通常不必要地工作量).\nAnother category of attributes are those that are part of the “subclass API” (often called “protected” in other languages). Some classes are designed to be inherited from, either to extend or modify aspects of the class’s behavior. When designing such a class, take care to make explicit decisions about which attributes are public, which are part of the subclass API, and which are truly only to be used by your base class.另一类别属性是属于”子类API” ( 在其他语言中经常被称作”protected”). 一些类设计成继承自 类行为的扩展或者修改的层面.  当设计这样的类时, 要注意明确地决定: 哪些属性时公共的, 哪些是subclass API的部分, 哪些只是被基类使用的.\nWith this in mind, here are the Pythonic guidelines:考虑到这一点, 下面是pythonic 指南:\n\nPublic attributes should have no leading underscores.公共属性应该没有前导下划线\n\nIf your public attribute name collides with a reserved keyword, append a single trailing underscore to your attribute name. This is preferable to an abbreviation or corrupted spelling. (However, notwithstanding this rule, ‘cls’ is the preferred spelling for any variable or argument which is known to be a class, especially the first argument to a class method.)如果你的公共属性名和一个保留的关键字冲突了, 在你的属性名后添加一个尾随下划线. 这比缩写或者拼写错误更可取. ( 但是, 尽管有这条规则的,  对于已知为类的任何变量或者参数, 尤其是作为一个类方法的第一个参数, “cls” 是首选拼写. )Note 1: See the argument name recommendation above for class methods.注意1: 对于类方法参看上面的参数命名建议.\n\nFor simple public data attributes, it is best to expose just the attribute name, without complicated accessor&#x2F;mutator methods. Keep in mind that Python provides an easy path to future enhancement, should you find that a simple data attribute needs to grow functional behavior. In that case, use properties to hide functional implementation behind simple data attribute access syntax.对于简单的公共的数据属性, 最好只公开属性名, 而不使用复杂的访问器&#x2F;装换器方法. 如果你发现一个简单的数据属性需要增长函数行为, 那么python对未来的加强提供了一个简单的途径, . 在那种情况下, 可以使用属性来隐藏 在简单数据属性访问语法背后的函数的实现.\nNote 1: Properties only work on new-style classes.注意1: 属性仅适用于新式类.\nNote 2: Try to keep the functional behavior side-effect free, although side-effects such as caching are generally fine.注意2: 尽量保持函数行为的副作用是免费的, 尽管缓存这样的副作用一般是较好的.\nNote 3: Avoid using properties for computationally expensive operations; the attribute notation makes the caller believe that access is (relatively) cheap.注意3:  避免在计算代价高昂的操作中使用属性;  属性表示法使得调用者相信访问(相对) 低廉.\n\nIf your class is intended to be subclassed, and you have attributes that you do not want subclasses to use, consider naming them with double leading underscores and no trailing underscores. This invokes Python’s name mangling algorithm, where the name of the class is mangled into the attribute name. This helps avoid attribute name collisions should subclasses inadvertently contain attributes with the same name.如果你的类是打算被子类化, 而且你有一些不希望子类使用拥有的属性,  那么考虑用双前导下划线和无尾随下划线来命名他们.  这会调用Python的命名管理算法, 其中类的名称被管理为属性名 . 这有助于避免属性名冲突, 如果子类无意中包含有相同名称的属性.\nNote 1: Note that only the simple class name is used in the mangled name, so if a subclass chooses both the same class name and attribute name, you can still get name collisions.注意1: 注意只有简单的类名可以在名称管理中被使用, 所以如果一个子类选择既有相同的类名,又有属性名, 那么你可以仍然会导致冲突.\nNote 2: Name mangling can make certain uses, such as debugging and __getattr__(), less convenient. However the name mangling algorithm is well documented and easy to perform manually.注意2: 命名管理可以使得某些用途不是很方便, 例如调试和  __getattr__(). 然而, 命名管理算法可以有很好的文档记录并且容易手动实现.\n\n\nPublic and Internal InterfacesAny backwards compatibility guarantees apply only to public interfaces. Accordingly, it is important that users be able to clearly distinguish between public and internal interfaces.任何向后兼容性的保证适用于 仅面向公共接口的. 因此,  用户必须能够清楚地区分公共和内部接口.\nDocumented interfaces are considered public, unless the documentation explicitly declares them to be provisional or internal interfaces exempt from the usual backwards compatibility guarantees. All undocumented interfaces should be assumed to be internal.文件化的接口被视为公共接口, 除非文件明确声明它们是**临时(暂定的)**接口或者内部接口, 不在通常的向后兼容性保证之内. 所有的未记录的接口都应该设计成内部接口.\nTo better support introspection, modules should explicitly declare the names in their public API using the __all__ attribute. Setting __all__ to an empty list indicates that the module has no public API.为了更好的支持自省, 模块应该使用__all__属性在其公共API中显式声明名称. 设置 __all__  为一个空列表预示着模块没有公共的API.\nEven with __all__ set appropriately, internal interfaces (packages, modules, classes, functions, attributes or other names) should still be prefixed with a single leading underscore.即使对 __all__ 进行了适当地设置, 内部接口(包,模块, 类, 函数, 属性或者其他名称) 应该依然用一个单独的前导下划线来作为前缀.\nAn interface is also considered internal if any containing namespace (package, module or class) is considered internal.如果任何包含命名空间(包,模块或者类) 是内部的, 则也将接口视为内部的.\nImported names should always be considered an implementation detail. Other modules must not rely on indirect access to such imported names unless they are an explicitly documented part of the containing module’s API, such as os.path or a package’s __init__ module that exposes functionality from submodules.导入名称应该永远视为一个实现细节. 其他模块必须不依赖于间接地访问这些类导入的名称, 除非他们是一个包含模块的API的明确记录部分, 例如os.path 或者包的 __init__ 模块, 该模块公开子模块的功能.\nProgramming Recommendations\nCode should be written in a way that does not disadvantage other implementations of Python (PyPy, Jython, IronPython, Cython, Psyco, and such).代码的编写方式不应影响其他Python实现.\nFor example, do not rely on CPython’s efficient implementation of in-place string concatenation for statements in the form a += b or a = a + b. This optimization is fragile even in CPython (it only works for some types) and isn’t present at all in implementations that don’t use refcounting. In performance sensitive parts of the library, the &#39;&#39;.join() form should be used instead. This will ensure that concatenation occurs in linear time across various implementations.\n例如，不要依赖cpython对形式为a+&#x3D;b或a&#x3D;a+b的语句的就地字符串连接的有效实现。即使在cpython中，这种优化也是脆弱的（它只对于某些类型起作用），并且在不使用refcounting的情况下根本无法实现。在库的性能敏感部分中，应改用 &#39;&#39;.join() 形式。这将确保在不同实现之间以线性时间发生连接。\n\nComparisons to singletons like None should always be done with is or is not, never the equality operators.像None这样的单例比较应该始终用is或者is not, 而不是使用 equality 运算符.\nAlso, beware of writing if x when you really mean if x is not None – e.g. when testing whether a variable or argument that defaults to None was set to some other value. The other value might have a type (such as a container) that could be false in a boolean context!同时, 当你真正想表达 if x is not None 时应该意识 if x 的书写 . – 例如, 当你测试一个的默认值为None的变量或者参数是否被设置为其他值时.  另一个值的类型(例如一个容纳) 可能在布尔上下文中是错误的.\n\nUse is not operator rather than not ... is. While both expressions are functionally identical, the former is more readable and preferred.使用 is not 运算符, 而不是 not … is . 尽管这两个表达式在功能上是相同的 ,  但是前者比后者更加具有可读性更加受欢迎.\n# Yes:if foo is not None:# No:if not foo is None:\n\nWhen implementing ordering operations with rich comparisons, it is best to implement all six operations (__eq__, __ne__, __lt__, __le__, __gt__, __ge__) rather than relying on other code to only exercise a particular comparison.在执行具有丰富的比较来实现排序操作时, 最好执行所有的六个操作(__eq__, __ne__, __lt__, __le__, __gt__, __ge__) , 而不是依赖其他代码仅仅运算一个特殊的比较.\nTo minimize the effort involved, the functools.total_ordering() decorator provides a tool to generate missing comparison methods.为了最小化所涉及的工作,  functools.total_ordering()装饰器提供了一个工具可以用来生成所缺的比较的方法.\nPEP 207 indicates that reflexivity rules are assumed by Python. Thus, the interpreter may swap y &gt; x with x &lt; y, y &gt;= x with x &lt;= y, and may swap the arguments of x == y and x != y. The sort() and min() operations are guaranteed to use the &lt; operator and the max() function uses the &gt; operator. However, it is best to implement all six operations so that confusion doesn’t arise in other contexts.PEP207表示反射性规则由python假定。因此，解释器可以用x&lt;y交换y&gt;x，用x&lt;&#x3D;y交换y&gt;&#x3D;x，可以用x&#x3D;y和x交换参数 x!&#x3D;y .  Sort（）和Min（）操作保证使用&lt;运算符，Max（）函数使用&gt;运算符。但是，最好实现这六个操作，这样在其他上下文中就不会出现混淆。\n\nAlways use a def statement instead of an assignment statement that binds a lambda expression directly to an identifier.始终使用一个def 语句, 而不是将lambda表达式直接 绑到标识符的赋值语句.\n# Yes:def f(x): return 2*x# No:f = lambda x: 2*x\n\nThe first form means that the name of the resulting function object is specifically ‘f’ instead of the generic ‘‘. This is more useful for tracebacks and string representations in general. The use of the assignment statement eliminates the sole benefit a lambda expression can offer over an explicit def statement (i.e. that it can be embedded inside a larger expression)第一个表单意思是结果函数对象的名称是一个特定的f 而不是一般的lambda. 这对于一般的回溯和字符串表示更有用. 使用赋值语句消除了lambda表达式相对于显式def语句所能提供的唯一好处( 即它可以嵌入到更大的表达式中).\n\nDerive exceptions from Exception rather than BaseException. Direct inheritance from BaseException is reserved for exceptions where catching them is almost always the wrong thing to do.从Exception而不是BaseException派生异常.直接从BaseException继承是为异常保留的, 在异常中捕获它们几乎总是错误的.\nDesign exception hierarchies based on the distinctions that code catching the exceptions is likely to need, rather than the locations where the exceptions are raised. Aim to answer the question “What went wrong?” programmatically, rather than only stating that “A problem occurred” (see PEP 3151 for an example of this lesson being learned for the builtin exception hierarchy)设计异常层次结构基于可能需要的代码捕获异常的差异, 而不是异常抛出的位置. 为了从编程角度回答”哪里出了问题”, 而不是仅仅陈述”一个问题发生了”(参看PEP 3151 中的一个示例, 关于从内置异常层次中学习到的课程)\nClass naming conventions apply here, although you should add the suffix “Error” to your exception classes if the exception is an error. Non-error exceptions that are used for non-local flow control or other forms of signaling need no special suffix.类命名约定也适合这里, 尽管当异常是一个错误的时候, 你应该在你的异常类后面添加”Error”的后缀.  用作非本地流控制或者其他形式的信令的非错误异常 不需要特殊后缀.\n\nUse exception chaining appropriately. In Python 3, “raise X from Y” should be used to indicate explicit replacement without losing the original traceback.恰当地使用异常链接. 在python3 中, “从Y中抛出X异常” 应该用来指示显式替换, 而不会丢失原始的回溯.\nWhen deliberately replacing an inner exception (using “raise X” in Python 2 or “raise X from None” in Python 3.3+), ensure that relevant details are transferred to the new exception (such as preserving the attribute name when converting KeyError to AttributeError, or embedding the text of the original exception in the new exception message).当故意替换一个内部异常(在Python2 中使用”raise X” 或者在Python3.3+ 中使用”raise X from None”), 确保相关的细节被传输到新的异常(例如将关键字转换为属性错误时保留属性名, 或者在新异常信息中嵌入原始异常文本)\n\nWhen raising an exception in Python 2, use raise ValueError(&#39;message&#39;) instead of the older form raise ValueError, &#39;message&#39;.在python2中抛出异常, 请使用raise ValueError(&#39;message&#39;), 而不是老的形式raise ValueError, &#39;message&#39;.\nThe latter form is not legal Python 3 syntax.后一种形式不是合法的python3语法.\nThe paren-using form also means that when the exception arguments are long or include string formatting, you don’t need to use line continuation characters thanks to the containing parentheses.当异常参数很长或者包含字符串格式的时候,   paren-using意味着由于包含括号, 不需要使用续行字符.\n\nWhen catching exceptions, mention specific exceptions whenever possible instead of using a bare except:clause:当捕获异常时, 尽可能提及特定的异常, 无论何时不要使用一个裸露的异常: 字句.\ntry:    import platform_specific_moduleexcept ImportError:    platform_specific_module = None\n\nA bare except: clause will catch SystemExit and KeyboardInterrupt exceptions, making it harder to interrupt a program with Control-C, and can disguise other problems. If you want to catch all exceptions that signal program errors, use except Exception: (bare except is equivalent to except BaseException:).裸露的异常: 字句将会捕获SystemExit和 KeyboardInterrupt异常, 使得很难使用Ctrl+C来中断程序, 而且会掩盖其他问题.  如果想要捕获所有表示程序错误的异常, 请使用except Exception:( 裸露的异常等同于 except BaseException:)\nA good rule of thumb is to limit use of bare ‘except’ clauses to two cases:一个好的经验法则是将”例外”语句的使用限制在两种情况下:\n\nIf the exception handler will be printing out or logging the traceback; at least the user will be aware that an error has occurred.如果异常处理器将打印输出或者日志记录到回溯, 至少使用者会意识到发生错误了.\nIf the code needs to do some cleanup work, but then lets the exception propagate upwards with raise.try...finally can be a better way to handle this case.如果代码需要做一些清理工作,  那么让异常随着raise.try...finally传播可能是处理该案例的一个更好方法.\n\n\nWhen binding caught exceptions to a name, prefer the explicit name binding syntax added in Python 2.6:当将捕获的异常和一个名词绑定一起时, 首选python2.6中添加的显式名称绑定语法:\ntry:    process_data()except Exception as exc:    raise DataProcessingFailedError(str(exc))\n\nThis is the only syntax supported in Python 3, and avoids the ambiguity problems associated with the older comma-based syntax.这是在Python3中仅支持的语法, 避免了 与旧的基于逗号语法的语法相关联的模糊性问题.\n\nWhen catching operating system errors, prefer the explicit exception hierarchy introduced in Python 3.3 over introspection of errno values.当捕获操作系统错误时, 优先选择Python3.3 中引入的显式异常层次结构, 而不是对errno值进行自省.\n\nAdditionally, for all try&#x2F;except clauses, limit the try clause to the absolute minimum amount of code necessary. Again, this avoids masking bugs.另外, 对于所有的try&#x2F;except 语句, 请将try字句限制为所需的绝对最小代码量. 而且, 这会避免隐藏的bugs.\n# Yes:try:    value = collection[key]except KeyError:    return key_not_found(key)else:    return handle_value(value)# No:try:    # Too broad!    return handle_value(collection[key])except KeyError:    # Will also catch KeyError raised by handle_value()    return key_not_found(key)\n\nWhen a resource is local to a particular section of code, use a with statement to ensure it is cleaned up promptly and reliably after use. A try&#x2F;finally statement is also acceptable.当资源位于特定代码段的本地时 , 使用 with 语句确保在使用后能够及时可靠得清理资源. try&#x2F;finally 语句也是可以接受的. \n\nContext managers should be invoked through separate functions or methods whenever they do something other than acquire and release resources.当上下文管理器执行除了获取和发布资源以外的其他操作时, 应该通过单独的函数或者模块来调用它们. \n# Yes:with conn.begin_transaction():    do_stuff_in_transaction(conn)# No:with conn:    do_stuff_in_transaction(conn)\n\nThe latter example doesn’t provide any information to indicate that the __enter__ and __exit__ methods are doing something other than closing the connection after a transaction. Being explicit is important in this case.后者示例没有提供任何的信息来提示 __enter__ and __exit__ 方法做了什么, 而不是在事务后关闭了连接.在案例中保持明确是很重要的.\n\nBe consistent in return statements. Either all return statements in a function should return an expression, or none of them should. If any return statement returns an expression, any return statements where no value is returned should explicitly state this as return None, and an explicit return statement should be present at the end of the function (if reachable).在返回语句中保持一致.  要么函数中的return语句都应该返回一个表达式, 要么不反悔表达式. 如果任何return返回一个表达式,  任何没有返回值的return语句都应该显式得声明为返回None ,而且显式return语句应该出现在函数的末尾(如果可以到达的话).\n# Yes:def foo(x):    if x &gt;= 0:        return math.sqrt(x)    else:        return Nonedef bar(x):    if x &lt; 0:        return None    return math.sqrt(x)# No:def foo(x):    if x &gt;= 0:        return math.sqrt(x)def bar(x):    if x &lt; 0:        return    return math.sqrt(x)\n\nUse string methods instead of the string module.使用字符串方法而不是字符串模块.\nString methods are always much faster and share the same API with unicode strings. Override this rule if backwards compatibility with Pythons older than 2.0 is required.字符串方法始终更快一些,而且与unicode字符串共享相同的API.  如果需要向后兼容性大于2.0的Python, 则重写该规则.\n\nUse &#39;&#39;.startswith() and &#39;&#39;.endswith() instead of string slicing to check for prefixes or suffixes.使用&#39;&#39;.startswith() and &#39;&#39;.endswith()  取代字符串切片可以检查前缀和后缀.\nstartswith() and endswith() are cleaner and less error prone:startswith() and endswith() 更加干净也更不容易出错.\nYes: if foo.startswith(&#x27;bar&#x27;):No:  if foo[:3] == &#x27;bar&#x27;:\n\nObject type comparisons should always use isinstance() instead of comparing types directly.对象类型的比较应该始终使用 isinstance(), 而不是直接比较类型.\nYes: if isinstance(obj, int):No:  if type(obj) is type(1):\n\nWhen checking if an object is a string, keep in mind that it might be a unicode string too! In Python 2, str and unicode have a common base class, basestring, so you can do:当检查一个对象是否是字符串时, 记住它可能是一个unicode的字符串! 在Python2中, str和unicode 有相同的基类,基础字符串, 所以你可以这样做:\nif isinstance(obj, basestring):\n\nNote that in Python 3, unicode and basestring no longer exist (there is only str) and a bytes object is no longer a kind of string (it is a sequence of integers instead).注意在Python3中, unicode 和 basestring 不再存在(仅有str) 以及一个bytes 对象不再是一种string类型( 它是一个整数序列).\n\nFor sequences, (strings, lists, tuples), use the fact that empty sequences are false.例如, (strings, lists, tuples) , 使用空序列为假的事实.\nYes: if not seq:     if seq:No:  if len(seq):     if not len(seq):\n\nDon’t write string literals that rely on significant trailing whitespace. Such trailing whitespace is visually indistinguishable and some editors (or more recently, reindent.py) will trim them.不要依赖 大量的 尾随空格来写字符串文本. 这样的尾随空格在视觉上是不可区分的, 而且一些编辑器(或者最近的reindent.py)会对其进行修剪.\n\nDon’t compare boolean values to True or False using ==.不要使用 &#x3D;&#x3D; 将布尔值与True或False来比较.\nYes:   if greeting:No:    if greeting == True:Worse: if greeting is True:\n\nFunction AnnotationsWith the acceptance of PEP 484, the style rules for function annotations are changing.随着对PEP 484 的接受, 对于函数注释的样式规则正在改变.\n\nIn order to be forward compatible, function annotations in Python 3 code should preferably use PEP 484 syntax. (There are some formatting recommendations for annotations in the previous section.)为了向前的兼容性, Python3中的函数注释应该首选使用PEP 484 语法. (在前面部分中, 对于注释有一些格式上的建议).\n\nThe experimentation with annotation styles that was recommended previously in this PEP is no longer encouraged.在这个PEP中以前被推荐使用的注释样式实验,  已经不再被鼓励了.\n\nHowever, outside the stdlib, experiments within the rules of PEP 484 are now encouraged. For example, marking up a large third party library or application with PEP 484 style type annotations, reviewing how easy it was to add those annotations, and observing whether their presence increases code understandability.然而, 除了标准库之外, 现在正鼓励在PEP 484之内实验. 例如, 用PEP484 样式类型的注释标记大的三方库或者应用程序, 评审增加这些注释的容易程度, 观察他们的存在是否是增加代码的可理解度.\n\nThe Python standard library should be conservative in adopting such annotations, but their use is allowed for new code and for big refactorings.Python标准库应该对于采用这样的注释是保守地, 但是对于新的代码和为了大的重构来说是被允许的.\n\nFor code that wants to make a different use of function annotations it is recommended to put a comment of the form:对于想不同地使用函数注释的代码, 建议放置表单注释:\n# type: ignore\n\nnear the top of the file; this tells type checker to ignore all annotations. (More fine-grained ways of disabling complaints from type checkers can be found in PEP 484)\n在文件顶部的附近; 这告诉种类检查器来忽略所有的注释. (在PEP 484中, 可以找到禁用类型检查程序投诉的更精细的方法。)\n\nLike linters, type checkers are optional,  separate tools. Python interpreters by default should not issue any messages due to type checking and should not alter their behavior based on annotations.像线头一样, 类型检查器是可选的, 独立的工具. 默认的Python编译器不应该任何由于类型检查而声明消息, 也不应该基于注释更改它们的行为.\n\nUsers who don’t want to use type checkers are free to ignore them. However, it is expected that users of third party library packages may want to run type checkers over those packages. For this purpose PEP 484 recommends the use of stub files: .pyi files that are read by the type checker in preference of the corresponding .py files. Stub files can be distributed with a library, or separately (with the library author’s permission) through the typeshed repo.\n不想使用类型检查器的用户可以随意忽略它们. 但是, 第三方库包的用户可能想要在这些包中运行类检查器. 为了这个目的, PEP484 建议使用存根文件: .pyi文件, 这些文件是由类型检查器读取, 而不是相应的.py文件. 存根文件可以与库一起分发, 或者通过排版报告单独分发(经过作者许可).\n\nFor code that needs to be backwards compatible, type annotations can be added in the form of comments. See the relevant section of PEP 484.对于需要向后兼容的代码, 类型注释可以以评论的形式添加.\n\n\nVariable AnnotationsPEP 526 introduced variable annotations. The style recommendations for them are similar to those on function annotations described above:PEP 526 引入了变量注释. 它们的样式建议与以上对函数注释的描述有相似之处:\n\nAnnotations for module level variables, class and instance variables, and local variables should have a single space after the colon.对于模块级别变量, 类, 实例变量, 以及局部变量的注释, 应该在冒号后面有一个单独的空格. \n\nThere should be no space before the colon.在冒号之前应该没有空格.\n\nIf an assignment has a right hand side, then the equality sign should have exactly one space on both sides.如果一个赋值有一个右手边, 那么等号两边应该正好有一个空格.\n# Yes:code: intclass Point:    coords: Tuple[int, int]    label: str = &#x27;&lt;unknown&gt;&#x27;      # No:code:int  # No space after coloncode : int  # Space before colonclass Test:    result: int=0  # No spaces around equality sign\n\nAlthough the PEP 526 is accepted for Python 3.6, the variable annotation syntax is the preferred syntax for stub files on all versions of Python (see PEP 484 for details).尽管在Python3.6中接受了 PEP 526 , 但是对于所有版本的Python来说, 变量注释是Python上根存文件的首选语法.\n\n\nfootnotes:\nHanging indentation is a type-setting style where all the lines in a paragraph are indented except the first line. In the context of Python, the term is used to describe a style where the opening parenthesis of a parenthesized statement is the last non-whitespace character of the line, with subsequent lines being indented until the closing parenthesis.悬挂缩进是一种类型设置样式，除第一行外，段落中的所有行都缩进。在python上下文中，该术语用于描述一种样式，其中带括号语句的左括号是行的最后一个非空白字符，随后的行缩进到右括号。\n","categories":["技术","编程规范"],"tags":["Python","翻译"]},{"title":"MySQL 初识","url":"/posts/2020/04/26/11242/","content":"关系型数据库\n支持复杂的SQL语句的查询\n支持事物(一系列操作的集合。也可理解为集合中的一系列操作协作完成事务)\n\n非关系型数据库\nNOSQL  不需要经过SQL层的处理  性能高\n可扩展性  因为是键值对的形式  所以水平扩展非常的容易\n\n使用管理员身份：net  start  mysql57MySQL57 服务正在启动 .MySQL57 服务已经启动成功。\n\n一、进入到数据库-h  host   主机名-u  user 用户名-p  password 密码\nmysql -h localhost -u root -p-&gt;密码mysql -uroot -p-&gt;密码\n\nroot超级管理员  可以创建和管理其他的用户root用户不可以远程登录\n\n二、对于库的操作CREATE \t创建\nDROP\t删除\nALTER  \t修改\nSHOW   \t展示\n(1) 查看所有的数据库show databases;\n(2) 创建数据库create database 库名;\ncreate database if not exists 库名;  防止创建同名的库出现错误\n(3) 查看创库语句show create database 库名\n(4) 使用数据库(进入到当前的库中)use 库名\n(5) 查看当前所在的数据库select database();\n(6) 数据库的删除drop database 库名;\ndrop database if exists 库名;   删除数据库如果该库存在 防止报错\n(7) 创建数据库并设置字符集 create database 库名 character set utf8;\n(8) 创建数据库 并设置字符集alter database hzpython1803 character set 字符集;\n\n三、对于表的操作1. 查看所有的表show tables;\n2. 创建表mysql&gt; create table if not exists fs(    -&gt; id int unsigned primary key auto_increment,    -&gt; username varchar(20),    -&gt; sex tinyint,    -&gt; age tinyint unsigned,    -&gt; info varchar(100)    -&gt; );\n\n3. 查看表结构desc 表名   : descend降序\n+----------+---------------------+------+-----+---------+----------------+| Field    | Type                | Null | Key | Default | Extra          |+----------+---------------------+------+-----+---------+----------------+| id       | int(10) unsigned    | NO   | PRI | NULL    | auto_increment || username | varchar(20)         | YES  |     | NULL    |                || sex      | tinyint(4)          | YES  |     | NULL    |                || age      | tinyint(3) unsigned | YES  |     | NULL    |                || info     | varchar(100)        | YES  |     | NULL    |                |+----------+---------------------+------+-----+---------+----------------+\n\n4. 删除表中的某个字段alter table fs drop 字段名;\n5. 删除表drop table if exists 表名; 删除表如果该表存在\n\n四、MySQL表的创建字段类型\n(1) 整形\n\n\n类型\n大小\n范围\n无符号范围\n用途\n\n\n\ntinyint\n1字节\n-128,127\n0，255\n小整数值\n\n\nsmallint\n2字节\n-32768,32767\n0，65535\n大整数值\n\n\nint\n4字节\n2-&gt;10位置\n4… 10 位的\n大整数值\n\n\nfloat(m,n)\n4个字节\n\n\n单精度浮点型\n\n\ndouble(m,n)\n8个字节\n\n\n双精度浮点型\n\n\ndecimal(m,n)\n根据存储的值\n\n\n小数据值（更加精准）\n\n\n浮点数中的m代表当前存储的长度  n代表小数的位数   m-n代表整数的位数  超出则报错\n整形后面的数字的意义：\n整形后面给定数字 并不是限定当前存储值的长度  并没有任何的意义 除非配合可选参数 zerofill 零填充 才有意义\n字符串类型后面给定的长度 则是限制当前存储数据的长度\n整形默认长度会比本身长度大1，因为是符号位\n\n(2) 字符串类型\n\n\n类型\n大小\n用途\n\n\n\nchar\n0-255\n存储定长字符串\n\n\nvarchar\n0-255\n存储不定长度字符串\n\n\ntext\n0-65535\n长文本数据\n\n\nblob\n0-65535\n存储二进制的长文本数据\n\n\nenum(‘w’,’m’)\n65535个成员\n枚举：只能选取括号中的某一个值进行存储\n\n\nset(‘w’,’m’)\n64个成员\n集合：可以选择多个成员\n\n\n\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\nid\nint(11)\nYES\nNULL\n\n\n\n\nnum\nsmallint(6)\nYES\nNULL\n\n\n\n\nage\ntinyint(4)\nYES\nNULL\n\n\n\n\nfmoney\nfloat(6,4)\nYES\nNULL\n\n\n\n\ndmoney\ndecimal(6,2)\nYES\nNULL\n\n\n\n\nint、smallint、tinyint 后面搜加一位:符号位 \nchar和varchar的相同和不同点 ：\nchar 和 varchar 的存储长度都为0-255\nchar 的执行效率高于 varchar\nvarchar 要比 char 更节省存储空间\n当 char 存储的值达不到指定的长度时 则使用空来占位\n\nenum和set区别\nenum只能选择其中的一个值\nset可以选择多个值 多个值使用逗号来隔开\n\ncreate table mystring(....)select * from mystring该语句为查询表或视图中的所有字段，* 表示所有字段\n\n(3) 时间和日期\n\n\n类型\n大小\n范围\n格式\n用途\n\n\n\ndate\n3\n1000-01-01 - 9999-12-31\nYYYY-MM-DD\n日期\n\n\ntime\n3\n-838:59:59&#x2F;838:59:59\nHH:MM:SS\n时间值或持续时间\n\n\nyear\n1\n1901&#x2F;2155\nYYYY\n年分值\n\n\ndatetime\n8\n1000-01-01 00:00:00 &#x2F;9999-12-31 23:59:59\nYYYY-MM-DD HH:MM:SS\n存储时间和日期\n\n\n五、字段约束1. unsigned 无符号  正数只能用于数值类型，不允许出现负数，存储长度会扩大一倍\n2. zerofill    零填充只能用于数值类型，当指定的位数不足的时候，零填充\n3. default   默认值如果当前字段没有传值，则值为默认值（不设定默认值  默认为null）\n4. null 和 not null默认为null，当不插入值则插入的为null，当设置当前字段为 not null 的时候，则该字段必须传值\n5. comment   设置当前字段的说明6. auto_increment  自增\n六、注意\nSQL 语句以分号作为结束\n\nSQL命令 不区分大小写\n\n数据库的切换使用use\n\n\\c 撤销当前命令\n\n\\G 竖着查看\n\n当遇到在终端中 不管怎样输入命令都不执行 name 查看一下左侧 是否为-&gt;\n\n在Windows下 不区分库,表名的大小写  但是在Ubuntu下区分\n\n退出数据库的几种方式\n\\q exit  quit\n\n\n","categories":["技术","数据库","MySQL"],"tags":["MySQL"]},{"title":"Python 调用 OCR","url":"/posts/2020/08/09/49677/","content":"报错场景最近是在练习一个Selenium的测试项目，其中有一个测试用例需要验证码登录，用到了OCR识别，但是我安装了 pytesseract 后，执行程序依然报错，提示：\nTraceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\pytesseract\\pytesseract.py&quot;, line 238, in run_tesseract    proc = subprocess.Popen(cmd_args, **subprocess_args())  File &quot;D:\\Python3.6.0\\lib\\subprocess.py&quot;, line 707, in __init__    restore_signals, start_new_session)  File &quot;D:\\Python3.6.0\\lib\\subprocess.py&quot;, line 990, in _execute_child    startupinfo)FileNotFoundError: [WinError 2] 系统找不到指定的文件。During handling of the above exception, another exception occurred:Traceback (most recent call last):  ......  File &quot;D:\\Python3.6.0\\lib\\site-packages\\pytesseract\\pytesseract.py&quot;, line 242, in run_tesseract    raise TesseractNotFoundError()pytesseract.pytesseract.TesseractNotFoundError: tesseract is not installed or it&#x27;s not in your PATH\n\n搜索资料网上搜索了一些资料，解决方法都大同小异，只是有一步骤没理解，浪费了一些时间。都说是去 https://github.com/tesseract-ocr/tesseract/wiki 下载安装，千篇一律，点进去后是github上的源码，下载压缩包后，并没有可以直接下载 .exe 可执行文件，也就无法按照很多指导中写的进行后续操作了。\n其实是需要再进入其他链接找的，我把这种方法放后面了，先说以下这种方法。\n下载方式1（老版本）正确的可以直接下载 tesseract.exe 可执行文件地址（windows64）：\nhttps://digi.bib.uni-mannheim.de/tesseract/\n点击下载文件后，在本地可以看到这样一个文件（可以自己选exe，不一定相同），双击该文件安装。\n安装过程中，它会让你选择可识别的语言，如果需要识别汉字，需要勾选 Chinese，也可以全选，但是没必要。勾选安装语言组件后，就不用自己单去下载语言包了，很方便。接着，需要选择安装路径，我默认安装在 C:\\Program Files\\Tesseract-OCR，这个路径很重要，以后要用到。\n\n下载方式（新版本）通过 GitHub - tesseract-ocr&#x2F;tesseract: Tesseract Open Source OCR Engine (main repository)，进入 Home · UB-Mannheim&#x2F;tesseract Wiki · GitHub，可以看到最新的下载版本。\n\n修改配置方式1（不推荐）修改源码，找到 pytesseract.py 文件，修改 tessseract_cmd = 我的ocr程序安装路径，例如 r&#39;C:\\Program Files\\Tesseract-OCR\\tesseract.exe&#39;。\n方式2在用到的时候，配置路径\npytesseract.pytesseract.tesseract_cmd = r&#x27;C:\\Program Files\\Tesseract-OCR\\tesseract.exe&#x27;image = Image.open(picture_new_path)text = pytesseract.image_to_string(image, lang=&#x27;eng&#x27;, config=&quot;--psm 6&quot;)\n或者\ntesseract_executable = r&#x27;C:\\Program Files\\Tesseract-OCR\\tesseract.exe&#x27;output_file = os.path.join(os.path.dirname(picture_path), &#x27;output&#x27;)subprocess.run([tesseract_executable, picture_new_path, output_file, &quot;-l&quot;, &quot;eng&quot;], check=True)with open(output_file + &quot;.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) as result_file:    text = result_file.read()    print(&quot;OCR result:&quot;, text)\n\n\nMac 平台在 Mac 上，使用官网推荐的方式安装：\nbrew install tesseract\nThe tesseract directory can then be found using brew info tesseract, e.g. \n/usr/local/Cellar/tesseract/5.3.2/bin/tesseract\ndemo:\nimport pytesseractfrom PIL import Image# 可以写一个函数 crop_picture 将原图裁剪一下，只保留想要识别文本的部分，这样识别更加准确一些。def crop_picture(picture_path, crop_box: list):    &quot;&quot;&quot;    crap picture with crop_box    :param picture_path: picture to be crapped    :param crop_box: crop region, eg: [100, 200, 300, 350]    :return: path of crapped picture    &quot;&quot;&quot;    dirname = os.path.dirname(picture_path)    basename = os.path.basename(picture_path)    new_basename = &#x27;&#x27;.join([basename.split(&#x27;.&#x27;)[0], &#x27;_new.&#x27;, basename.split(&#x27;.&#x27;)[1]])    picture_origin = Image.open(picture_path)    picture_origin_size = picture_origin.size    if crop_box[2] is None:        crop_box[2] = picture_origin_size[0]    if crop_box[3] is None:        crop_box[3] = picture_origin_size[1]    picture_new = picture_origin.crop(tuple(crop_box))    picture_new_path = os.path.join(dirname, new_basename)    picture_new.save(picture_new_path)    return picture_new_pathdef get_text_from_picture(picture_path):    &quot;&quot;&quot;    get text from picture    :param picture_path: picture to be crapped    :param crop_box: crop region, eg: [100, 200, 300, 350]    :return: text    &quot;&quot;&quot;    pytesseract.pytesseract.tesseract_cmd = r&#x27;/usr/local/Cellar/tesseract/5.3.2/bin/tesseract&#x27;    picture_new_path = crop_picture(picture_path, crop_box=[585, 360, None, 800])    image = Image.open(picture_new_path)    text = pytesseract.image_to_string(image, lang=&#x27;eng&#x27;)    return text\n\n\n","categories":["技术","Python"],"tags":["Python","FixBug"]},{"title":"MySQL 基本操作","url":"/posts/2020/04/27/4800/","content":"一、null的注意事项\nnull意味着没有值 或者 未知值\n可以测试某个值是否为null  is null\n不能对null进行算数运算  \n所有和null进行运算的都为null\n\n\n二、mysql的索引\n主键索引 primary key\n唯一索引  unique\n常规索引  index\n全文索引 fulltext\n\nPRI主键约束；  UNI唯一约束；  MUL可以重复。 \n(1)  主键索引主键索引是数据库中最常见的索引类型， 主要确定数据表里数据记录的位置，给字段添加 primary key 来确定索引值\n注意： \n\n每个表中 只能有一个主键索引\n\n每个表中最好有一个主键索引 并不是必须的\n\n主键索引可以有很多的候选项 （auto_increment，not null）\n\n当表中的数据 被删除以后 auto_increment 依然记录着下一个数据插入的行号值  \n\ntruncate 表名   清空表  并将自增归位    —–&gt; truncate myindex;\nalter table 表名 auto_increment=1\n\n\n\n实例\nmysql&gt; create table myindex(    -&gt; id int unsigned primary key auto_increment not null    -&gt; );\n\n(2) 唯一索引唯一索引和主键索引 都一样，不能插入重复的值；不同的是 主键一个表只能存在一个，唯一索引可以存在多个\n实例\nmysql&gt; create table myunique(    -&gt; username varchar(20) unique not null    -&gt; );\n\n(3) 常规索引常规索引 只作为提高数据的查询效率来使用的 \n缺点：\n\n提高了查询效率 但是降低了增删改的效率\n索引文件 占用磁盘空间\n\n数据库文件存放的位置\nwindwos:  C:\\ProgramData\\MySQL\\MySQL Server 5.7\\Data\\performance_schema\nubuntu: &#x2F;var&#x2F;lib&#x2F;mysql\n(4) 全文索引fulltext\nalter table 表名  add fulltext  索引名称(索引字段)\n创建表并添加索引的完整写法\nmysql&gt; create table user(-&gt; id int unsigned primary key auto_increment not null,-&gt; username varchar(20) unique,-&gt; age tinyint,-&gt; index(age)-&gt; #unique(username)-&gt; );#给索引添加索引名称mysql&gt; create table user2(    -&gt; username varchar(20),    -&gt; age tinyint,    -&gt; unique myname(username),    -&gt; index aindex(age)    -&gt; );\n例子的创建表\nmysql&gt; create table test(    -&gt; id int unsigned primary key auto_increment not null,    -&gt; username varchar(50) not null,    -&gt; userpass varchar(50) not null,    -&gt; telno varchar(20) not null,    -&gt; sex enum(&#x27;w&#x27;,&#x27;m&#x27;) not null default &#x27;m&#x27;,    -&gt; birthday date not null default &#x27;0000-00-00&#x27;,    -&gt; index(username),    -&gt; index(userpass),    -&gt; unique(telno)    -&gt; );\n\n\n三、表的存储类型MyISAM 和 InnoDB\n修改类型\nalter table 表名 engine=表存储类型;\nMyISAM和InnoDB的区别\nMyISAM表的存储文件为3个，InnoDB为2个\nMyISAM不支持事物 innodb支持\nMyISAM不支持外键  innodb支持\nMyISAM表的查询效率高于innodb，但是innodb的安全性高于MyISAM\n\n(1) MyISAM的文件说明\nfrm文件 存储当前表结构的文件\n在innodb和MyISAM中都存在\n\nMYD：即MY DATA   存储表数据的文件\n\nMYI：即 MY INDEX   存储表索引的文件\n\n\n(2) InnoDB的文件说明\nfrm文件 存储当前表结构的文件\n在innodb和MyISAM中都存在\n\nibd   存储表数据和索引\n\n\n(3) innodb事物处理操作\n将当前表文件存储类型改为 innodbalter table 表名 engine=innodb;\n\n查看当前表的提交类型select  @@autocommit\n如果值为1 则为自动提交\n\n改为手动提交（开启事物）set autocommit=0\n\n事物开始begin;\n\n执行各种SQL语句\n提交或者回滚\ncommit work;\nrollback work;\n\n\n\n注意：\n事物是针对库中表的数据来操作的  并不是针对你当前的库 如果库被干掉了，那就一切都不存在。\nmysql&gt; show tables;+--------------------+| Tables_in_practice |+--------------------+| user               || user2              |+--------------------+2 rows in set (0.00 sec)mysql&gt; select @@autocommit;+--------------+| @@autocommit |+--------------+|            1 |+--------------+1 row in set (0.00 sec)mysql&gt; set autocommit=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; select @@autocommit;+--------------+| @@autocommit |+--------------+|            0 |+--------------+1 row in set (0.00 sec)mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;Empty set (0.00 sec)mysql&gt; desc user;+----------+------------------+------+-----+---------+----------------+| Field    | Type             | Null | Key | Default | Extra          |+----------+------------------+------+-----+---------+----------------+| id       | int(10) unsigned | NO   | PRI | NULL    | auto_increment || username | varchar(20)      | YES  | UNI | NULL    |                || age      | tinyint(4)       | YES  | MUL | NULL    |                |+----------+------------------+------+-----+---------+----------------+3 rows in set (0.00 sec)mysql&gt; insert into user values(null, &#x27;张三&#x27;, 20);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 |+----+----------+------+1 row in set (0.00 sec)mysql&gt; commit work;Query OK, 0 rows affected (0.00 sec)mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into user values(null, &#x27;李四&#x27;, 21);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 ||  2 | 李四     |   21 |+----+----------+------+2 rows in set (0.00 sec)mysql&gt; rollback work;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 |+----+----------+------+1 row in set (0.00 sec)mysql&gt; show create table user \\G*************************** 1. row ***************************       Table: userCreate Table: CREATE TABLE `user` (  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  `username` varchar(20) DEFAULT NULL,  `age` tinyint(4) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `username` (`username`),  KEY `age` (`age`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf81 row in set (0.00 sec)\n\n这里的auto-increment变成3了！说明有数据来过，但是又没有保留下来。\nmysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into user values(null, &#x27;王武&#x27;, 22);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 ||  3 | 王武     |   22 |+----+----------+------+2 rows in set (0.00 sec)mysql&gt; \\q   # 退出ByeC:\\Users\\zyp&gt;mysql -uroot -p  # 重启mysqlEnter password: ****Welcome to the MySQL monitor.mysql&gt; use practice;Database changedmysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 |+----+----------+------+1 row in set (0.01 sec)mysql&gt; show create table user\\G;*************************** 1. row ***************************       Table: userCreate Table: CREATE TABLE `user` (  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  `username` varchar(20) DEFAULT NULL,  `age` tinyint(4) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `username` (`username`),  KEY `age` (`age`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf81 row in set (0.00 sec)\n\n\n四、更改表结构mysql&gt; use practice;Database changedmysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 ||  4 | 赵柳     |   23 |+----+----------+------+2 rows in set (0.00 sec)\n\n1. 给当前的表添加一个新的字段    addalter table user add sex enum(&#x27;w&#x27;,&#x27;m&#x27;) default &#x27;w&#x27;;\n\nmysql&gt; alter table user add sex enum(&#x27;w&#x27;,&#x27;m&#x27;) default &#x27;w&#x27;;Query OK, 0 rows affected (0.15 sec)Records: 0  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----+----------+------+------+| id | username | age  | sex  |+----+----------+------+------+|  1 | 张三     |   20 | w    ||  4 | 赵柳     |   23 | w    |+----+----------+------+------+2 rows in set (0.00 sec)\n\n2. 删除一个字段dropalter table user drop sex/id /info/age/money....\n\nmysql&gt; alter table user drop sex;Query OK, 0 rows affected (0.12 sec)Records: 0  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----+----------+------+| id | username | age  |+----+----------+------+|  1 | 张三     |   20 ||  4 | 赵柳     |   23 |+----+----------+------+2 rows in set (0.00 sec)\n\n3. 添加新字段在第一位   firstalter table user add info varchar(100) default &#x27;个人说明&#x27; first;\n\nmysql&gt; alter table user add info varchar(100) default &#x27;个人说明&#x27; first;Query OK, 0 rows affected (0.12 sec)Records: 0  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+------+| info     | id | username | age  |+----------+----+----------+------+| 个人说明 |  1 | 张三     |   20 || 个人说明 |  4 | 赵柳     |   23 |+----------+----+----------+------+2 rows in set (0.00 sec)\n\n\n添加新字段在某个字段的后面  after\n\nalter table user add backinfo varchar(100) default &#x27;备注&#x27; after age;\n\nmysql&gt; alter table user add backinfo varchar(100) default &#x27;备注&#x27; after age;Query OK, 0 rows affected (0.12 sec)Records: 0  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+------+----------+| info     | id | username | age  | backinfo |+----------+----+----------+------+----------+| 个人说明 |  1 | 张三     |   20 | 备注     || 个人说明 |  4 | 赵柳     |   23 | 备注     |+----------+----+----------+------+----------+2 rows in set (0.00 sec)\n\n4. 更改字段名称并更改字段顺序   changemysql&gt; alter table user change age money decimal(6,2);Query OK, 2 rows affected (0.13 sec)Records: 2  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+-------+----------+| info     | id | username | money | backinfo |+----------+----+----------+-------+----------+| 个人说明 |  1 | 张三     | 20.00 | 备注     || 个人说明 |  4 | 赵柳     | 23.00 | 备注     |+----------+----+----------+-------+----------+2 rows in set (0.01 sec)\n\nmysql&gt; alter table user change money age tinyint;Query OK, 2 rows affected (0.11 sec)Records: 2  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+------+----------+| info     | id | username | age  | backinfo |+----------+----+----------+------+----------+| 个人说明 |  1 | 张三     |   20 | 备注     || 个人说明 |  4 | 赵柳     |   23 | 备注     |+----------+----+----------+------+----------+2 rows in set (0.01 sec)mysql&gt; alter table user change age money decimal(6,2) after backinfo;Query OK, 2 rows affected (0.12 sec)Records: 2  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 |+----------+----+----------+----------+-------+2 rows in set (0.01 sec)\n\n5. 更改字段类型  modifymysql&gt; alter table user modify username char(11);Query OK, 2 rows affected (0.12 sec)Records: 2  Duplicates: 0  Warnings: 0mysql&gt; desc user;+----------+------------------+------+-----+----------+----------------+| Field    | Type             | Null | Key | Default  | Extra          |+----------+------------------+------+-----+----------+----------------+| info     | varchar(100)     | YES  |     | 个人说明 |                || id       | int(10) unsigned | NO   | PRI | NULL     | auto_increment || username | char(11)         | YES  | UNI | NULL     |                || backinfo | varchar(100)     | YES  |     | 备注     |                || money    | decimal(6,2)     | YES  | MUL | NULL     |                |+----------+------------------+------+-----+----------+----------------+5 rows in set (0.01 sec)\n\n6. 添加字段索引alter table user add index(username);  # 添加常规索引\n\nalter table user add unique(username);  # 添加唯一索引\n\nalter table user add index infoindex(info);  # 添加索引并添加索引名\n\n7. 删除索引alter table user drop key username;\n\n8. 创建一个表b和表a一样create table copy_user like user;\n\n9. 查看所有的索引show index from 表名;\nmysql&gt; show index from user;+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name   | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| user  |          0 | PRIMARY    |            1 | id          | A         |           2 |     NULL | NULL   |      | BTREE      |         |               || user  |          0 | username_3 |            1 | username    | A         |           2 |     NULL | NULL   | YES  | BTREE      |         |               || user  |          1 | age        |            1 | money       | A         |           2 |     NULL | NULL   | YES  | BTREE      |         |               || user  |          1 | username_2 |            1 | username    | A         |           2 |     NULL | NULL   | YES  | BTREE      |         |               || user  |          1 | infoindex  |            1 | info        | A         |           1 |     NULL | NULL   | YES  | BTREE      |         |               |+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+5 rows in set (0.00 sec)\n\n10. 更改字段的字符集alter database  xxx_ku  character set utf8;\n\nalter table  xxx(user)  character set utf8;\n\nalter table  xxx(user)  modify username varchar(20) character set utf8;\n\n\n五、INSERT 数据的添加mysql&gt; desc user;+----------+------------------+------+-----+----------+----------------+| Field    | Type             | Null | Key | Default  | Extra          |+----------+------------------+------+-----+----------+----------------+| info     | varchar(100)     | YES  | MUL | 个人说明 |                || id       | int(10) unsigned | NO   | PRI | NULL     | auto_increment || username | char(11)         | YES  | UNI | NULL     |                || backinfo | varchar(100)     | YES  |     | 备注     |                || money    | decimal(6,2)     | YES  | MUL | NULL     |                |+----------+------------------+------+-----+----------+----------------+5 rows in set (0.00 sec)\n\n1. 指定字段名称添加数据insert into user(username, money) values(&#39;王五&#39;, 24);\nmysql&gt; insert into user(username, money) values(&#x27;王五&#x27;, 24);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王五     | 备注     | 24.00 |+----------+----+----------+----------+-------+4 rows in set (0.00 sec)\n\n需要注意：如果有字段不为空且没有默认值 那么必须插入值\n2. 不指定字段添加值（需要将所有字段都插入值）insert into user values(&#39;个人说明&#39;, null, &#39;钱强&#39;,&#39;备注&#39;, 25);\nmysql&gt; insert into user values(&#x27;个人说明&#x27;, null, &#x27;钱强&#x27;,&#x27;备注&#x27;, 25);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王五     | 备注     | 24.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 |+----------+----+----------+----------+-------+5 rows in set (0.00 sec\n\n3. 指定字段添加多个值insert into user(username, money) values(&#39;诸葛&#39;,26),(&#39;孔明&#39;,27);\nmysql&gt; insert into user(username, money) values(&#x27;诸葛&#x27;,26),(&#x27;孔明&#x27;,27);Query OK, 2 rows affected (0.00 sec)Records: 2  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王五     | 备注     | 24.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 || 个人说明 |  9 | 诸葛     | 备注     | 26.00 || 个人说明 | 10 | 孔明     | 备注     | 27.00 |+----------+----+----------+----------+-------+7 rows in set (0.00 sec)\n\n4. 不指定字段添加多个值insert into user values(&#39;个人说明&#39;,null,&#39;欧阳&#39;,&#39;备注&#39;,28),(&#39;个人说明&#39;,null,&#39;夏丹&#39;,&#39;备注&#39;,29);\nmysql&gt; insert into user values(&#x27;个人说明&#x27;,null,&#x27;欧阳&#x27;,&#x27;备注&#x27;,28),(&#x27;个人说明&#x27;,null,&#x27;夏丹&#x27;,&#x27;备注&#x27;,29);Query OK, 2 rows affected (0.00 sec)Records: 2  Duplicates: 0  Warnings: 0mysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王五     | 备注     | 24.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 || 个人说明 |  9 | 诸葛     | 备注     | 26.00 || 个人说明 | 10 | 孔明     | 备注     | 27.00 || 个人说明 | 11 | 欧阳     | 备注     | 28.00 || 个人说明 | 12 | 夏丹     | 备注     | 29.00 |+----------+----+----------+----------+-------+9 rows in set (0.00 sec)\n\n让字段可以重复，去掉key\nalter table user drop key username;\n5. 改字段中的某个信息：updateupdate user set username=&#39;王二&#39; where id=7;\nmysql&gt; update user set username=&#x27;王二&#x27; where id=7;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王二     | 备注     | 24.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 || 个人说明 |  9 | 诸葛     | 备注     | 26.00 || 个人说明 | 10 | 孔明     | 备注     | 27.00 || 个人说明 | 11 | 欧阳     | 备注     | 28.00 || 个人说明 | 12 | 夏丹     | 备注     | 29.00 |+----------+----+----------+----------+-------+9 rows in set (0.00 sec)\n\n\n六、SELECT 数据的查询1. 不指定字段查询（查询所有字段）select * from 表名;\nmysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王二     | 备注     | 24.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 || 个人说明 |  9 | 诸葛     | 备注     | 26.00 || 个人说明 | 10 | 孔明     | 备注     | 27.00 || 个人说明 | 11 | 欧阳     | 备注     | 28.00 || 个人说明 | 12 | 夏丹     | 备注     | 29.00 |+----------+----+----------+----------+-------+9 rows in set (0.00 sec)\n\n2. 指定字段查询select 字段名1,字段名2...  from 表名;\nmysql&gt; select username from user;+----------+| username |+----------+| 夏丹     || 孔明     || 张三     || 李斯     || 欧阳     || 王二     || 诸葛     || 赵柳     || 钱强     |+----------+9 rows in set (0.00 sec)\n\n3. 查询字段并运算select id+money from user;\nmysql&gt; select id + money from user;+------------+| id + money |+------------+|      21.00 ||      27.10 ||      27.00 ||      31.00 ||      33.00 ||      35.00 ||      37.00 ||      39.00 ||      41.00 |+------------+9 rows in set (0.00 sec)\n\n4. 起别名select username as name from 表名;\nselect username name from 表名;\n\n七、where 条件(1) 比较运算符\n&gt;\n&lt;\n&gt;&#x3D;\n&lt;&#x3D;\n!&#x3D;&#x2F;&lt;&gt;\n&#x3D;\n\n(2) 逻辑运算符\n逻辑与 and\nselect * from user where username=&#39;苍老师&#39; and age&lt;=30;\n两侧为真才为真\n\n逻辑或 or\nselect * from user where username=&#39;苍老师&#39; or age&lt;=30;\n只要满足一个就为真\n\nand 和 or 一起使用\nselect * from user where id=1 or (age=18 and sex=&#39;w&#39;);\n\n在…内 in\nselect * from user where id in(1,3,5,6,7);   \nselect * from user where id=1 or id=2 or id=6; \n\n不在…内 not  in\nselect * from user where id not in(1,3,5,6,7);    \nselect * from user where id!=1 and id!=2 and id!=6; \n\n在…范围内 between … and …\nselect * from user where age between 20 and 33; &#96;\nselect * from user where age&gt;=20 and age&lt;=33;\n\n不在…范围内 not between … and …\nselect * from user where age not between 20 and 33; \n\n\n(3) order by  排序\n默认升序  asc\n select * from user order by age;\n select * from user order by age asc;\n\n降序  desc\nselect * from user order by age desc;\n\n\n(4) is  is not\nis not\n select * from user where username is not null;\n\nis\n select * from user where username is null;\n\n\n(5) limitlimit num   直接取出num条数据\nselect * from user order by age desc limit 1;  # 取出年龄最大的一条数据\nlimit x,num  从 x 的位置开始，取出 num 条数据\nmysql&gt; select * from user;+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  1 | 张三     | 备注     | 20.00 || 个人说明 |  4 | 赵柳     | 备注     | 23.00 || 个人说明 |  6 | 李斯     | 备注     | 21.10 || 个人说明 |  7 | 王二     | 备注     | 24.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 || 个人说明 |  9 | 诸葛     | 备注     | 26.00 || 个人说明 | 10 | 孔明     | 备注     | 27.00 || 个人说明 | 11 | 欧阳     | 备注     | 28.00 || 个人说明 | 12 | 夏丹     | 备注     | 29.00 |+----------+----+----------+----------+-------+9 rows in set (0.00 sec)mysql&gt; select * from user order by money desc limit 3;  # 取出money最多的3个+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 | 12 | 夏丹     | 备注     | 29.00 || 个人说明 | 11 | 欧阳     | 备注     | 28.00 || 个人说明 | 10 | 孔明     | 备注     | 27.00 |+----------+----+----------+----------+-------+3 rows in set (0.00 sec)mysql&gt; select * from user order by money desc limit 3, 2;  # 从3个位置开始，取出2个钱多的+----------+----+----------+----------+-------+| info     | id | username | backinfo | money |+----------+----+----------+----------+-------+| 个人说明 |  9 | 诸葛     | 备注     | 26.00 || 个人说明 |  8 | 钱强     | 备注     | 25.00 |+----------+----+----------+----------+-------+2 rows in set (0.00 sec)\n\n注意：\n如果是从头取出num条数据  limit num  &#x3D;&#x3D;  limit 0,num\n分页计算：求分页取值的偏移量：（nowPage-1）* everyPage\n(6) 模糊查询  like\n包含查询\nlike ‘%字符%’\n\n以某个字符开头的查询\nlike ‘字符%’\n\n以某个字符结尾的查询\nlike  ‘%字符’\n\n\n\n八、聚合函数1. 最大值max()   \nselect max(age) from user;\nmysql&gt; select max(money) from user;+------------+| max(money) |+------------+|      29.00 |+------------+1 row in set (0.00 sec)\n\n2. 最小值min()\nselect min(age) from user;\nmysql&gt; select min(id) from user;+---------+| min(id) |+---------+|       1 |+---------+1 row in set (0.00 sec)\n\n3. 统计count()\nselect count(*) from user\nmysql&gt; select count(*) from user;+----------+| count(*) |+----------+|        9 |+----------+1 row in set (0.00 sec)\n\n4. 平均值avg()\nselect avg(age) from user;\nmysql&gt; select avg(money) from user;+------------+| avg(money) |+------------+|  24.788889 |+------------+1 row in set (0.00 sec)\n\n5. 求和sum()\nselect sum(age) from user;\nmysql&gt; select sum(money) from user;+------------+| sum(money) |+------------+|     223.10 |+------------+1 row in set (0.00 sec)\n\n\n九、group by 分组查询男女分别多少人\nselect sex,count(*) from user group by sex;\n统计每个年龄段分别多少人\nselect age,count(*) from user group by age;\n统计每个年龄段的男女分别有多少人\nselect sex,age,count(*) from user group by sex,age;\ngroub by  having   其中的having相当于where\n查询每个年龄段人数大于1人的数据\nselect age,count(*) as count from user group by age having count&gt;1;\n查询每个年龄段人数大于1人的数据 并且年龄小于40\nselect age,count(*) as count from user group by age having count&gt;1 and age&lt;40;\n查询每个年龄段人数大于1人的数据 并且年龄为10,20,30\nselect age,count(*) as count from user group by age having age in(18,20,30);\n\n十、delete 删除delete from 表名 [where…]\n注意： where 应该加 如果没有where条件删除所有数据\n实例: delete from user where username=&#39;xxx&#39;;\n\n十一、update 修改update 表名 set 字段名&#x3D;字段值,[字段名&#x3D;字段值…[where…..]] \n注意： 不要忘记where条件  否则修改全部\n实例： update user set sex=&#39;m&#39; where age in(18,20);\n\n十二、多表联查关联条件\n外键\n(1) 隐式内连接select * from user,goods where user.id=goods.uidselect user.username,user.age,goods.goodsname from user,goods where user.id=goods.uid\n起别名\nselect u.username,g.goodsname from user u,goods g where u.id=g.uid\n(2) 显示内连接 inner join  onselect * from user INNER JOIN goods ON user.id=goods.uid and goods.uid=1\nselect u.username,g.goodsname from user u INNER JOIN goods g ON u.id=g.uid and g.uid=1\n注意： 隐式内连接和显示内连接其实是同一个查询  会将关联的数据全部查询出来\n(3) 左链接  left join  onselect u.username,g.goodsname from user u LEFT JOIN goods g ON u.id=g.uid\n注意： 左链接会将左表作为主表 右表为辅表 会将主表所有数据查询出来 辅表没有关联的数据使用null来占\n","categories":["技术","数据库","MySQL"],"tags":["MySQL"]},{"title":"Python代码执行顺序","url":"/posts/2020/04/08/25924/","content":"模块导入时和运行时比较Python程序员会区分“导入时”和“运行时”，不过这两个术语没有严格的定义，而且二者之间存在着灰色地带。\n在导入时，解释器会从上到下一次性解析完 .py 模块的源码，然后生成用于执行的字节码。如果句法有错误，就在此时报告。\n如果本地的 __pycache__ 文件夹中有最新的 .pyc 文件，解释器会跳过上述步骤，因为已经有运行所需的字节码了。\n\n编译肯定是导入时的活动，不过那个时期还会做些其他事，因为Python中的语句几乎都是可执行的，也就是说语句可能会运行用户代码，修改用户程序的状态。\n尤其是 import 语句，它不只是声明，在进程中首次导入模块时，还会运行所导入模块中的全部顶层代码——以后导入相同的模块则使用缓存，只做名称绑定。那些顶层代码可以做任何事，包括通常在“运行时”做的事，例如连接数据库。\n因此，“导入时”与“运行时”之间的界线是模糊的：import语句可以触发任何“运行时”行为。\n\n导入时会“运行全部顶层代码”，但是“顶层代码”会经过一些加工。导入模块时，解释器会执行顶层的def语句，可是这么做有什么作用呢？\n解释器会编译函数的定义体（首次导入模块时），把函数对象绑定到对应的全局名称上，但是显然解释器不会执行函数的定义体。通常这意味着解释器在导入时定义顶层函数，但是仅当在运行时调用函数时才会执行函数的定义体。\n对类来说，情况就不同了：在导入时，解释器会执行每个类的定义体，甚至会执行嵌套类的定义体。执行类定义体的结果是，定义了类的属性和方法，并构建了类对象。从这个意义上理解，类的定义体属于“顶层代码”，因为它在导入时运行。\n\n举例：理解代码执行顺序的练习强烈建议在代码中添加断点，debug一步一步地查看执行顺序。\n# evalsupport.pyprint(&#x27;&lt;[100]&gt; evalsupport module start&#x27;)def deco_alpha(cls):    print(&#x27;&lt;[200]&gt; deco_alpha&#x27;)    def inner_1(self):        print(&#x27;&lt;[300]&gt; deco_alpha:inner_1&#x27;)    cls.method_y = inner_1    return clsclass MetaAleph(type):    print(&#x27;&lt;[400]&gt; MetaAleph body&#x27;)    def __init__(cls, name, bases, dic):        print(&#x27;&lt;[500]&gt; MetaAleph.__init__&#x27;)        def inner_2(self):            print(&#x27;&lt;[600]&gt; MetaAleph.__init__:inner_2&#x27;)        cls.method_z = inner_2print(&#x27;&lt;[700]&gt; evalsupport module end&#x27;)\n\n# evaltime.pyfrom evalsupport import deco_alphaprint(&#x27;&lt;[1]&gt; evaltime module start&#x27;)class ClassOne():    print(&#x27;&lt;[2]&gt; ClassOne body&#x27;)    def __init__(self):        print(&#x27;&lt;[3]&gt; ClassOne.__init__&#x27;)    def __del__(self):        print(&#x27;&lt;[4]&gt; ClassOne.__del__&#x27;)    def method_x(self):        print(&#x27;&lt;[5]&gt; ClassOne.method_x&#x27;)    class ClassTwo(object):        print(&#x27;&lt;[6]&gt; ClassTwo body&#x27;)# 先计算被装饰的类ClassThree的定义体，然后运行装饰器函数。@deco_alphaclass ClassThree():    print(&#x27;&lt;[7]&gt; ClassThree body&#x27;)    def method_y(self):        print(&#x27;&lt;[8]&gt; ClassThree.method_y&#x27;)class ClassFour(ClassThree):    print(&#x27;&lt;[9]&gt; ClassFour body&#x27;)    def method_y(self):        print(&#x27;&lt;[10]&gt; ClassFour.method_y&#x27;)if __name__ == &#x27;__main__&#x27;:    print(&#x27;&lt;[11]&gt; ClassOne tests&#x27;, 30 * &#x27;.&#x27;)    one = ClassOne()    one.method_x()    print(&#x27;&lt;[12]&gt; ClassThree tests&#x27;, 30 * &#x27;.&#x27;)    three = ClassThree()    three.method_y()    print(&#x27;&lt;[13]&gt; ClassFour tests&#x27;, 30 * &#x27;.&#x27;)    four = ClassFour()    four.method_y()print(&#x27;&lt;[14]&gt; evaltime module end&#x27;)\n\n\n场景1 ：被当做模块导入到其他模块中evaltime.py 被当做模块导入到其他模块中\n&lt;[100]&gt; evalsupport module start&lt;[400]&gt; MetaAleph body&lt;[700]&gt; evalsupport module end&lt;[1]&gt; evaltime module start&lt;[2]&gt; ClassOne body&lt;[6]&gt; ClassTwo body&lt;[7]&gt; ClassThree body&lt;[200]&gt; deco_alpha&lt;[9]&gt; ClassFour body&lt;[14]&gt; evaltime module end\n\n导入evaltime模块时，其中的 evalsupport 模块中的所有顶层代码在导入模块时运行；解释器会编译 deco_alpha 函数，但是不会执行定义体；ClassThree 被装饰器 deco_alpha 修饰，先计算被装饰的类 ClassThree 的定义体，然后运行装饰器函数deco_alpha ；evaltime模块是导入的，因此不会运行 if __name__==&#39;__main__&#39;: 块。\n小结：\n\n这个场景由简单的 import evaltime 语句触发；\n解释器会执行所导入模块及其依赖（evalsupport）中的每个类定义体；\n解释器先计算类的定义体，然后调用依附在类上的装饰器函数，这是合理的行为，因为必须先构建类对象，装饰器才有类对象可处理；\n在这个场景中，只运行了一个用户定义的函数或方法——deco_alpha装饰器。\n\n\n场景2 ：直接运行模块运行evaltime.py\n&lt;[100]&gt; evalsupport module start&lt;[400]&gt; MetaAleph body&lt;[700]&gt; evalsupport module end&lt;[1]&gt; evaltime module start&lt;[2]&gt; ClassOne body&lt;[6]&gt; ClassTwo body&lt;[7]&gt; ClassThree body&lt;[200]&gt; deco_alpha&lt;[9]&gt; ClassFour body&lt;[11]&gt; ClassOne tests ..............................&lt;[3]&gt; ClassOne.__init__&lt;[5]&gt; ClassOne.method_x&lt;[12]&gt; ClassThree tests ..............................&lt;[300]&gt; deco_alpha:inner_1&lt;[13]&gt; ClassFour tests ..............................&lt;[10]&gt; ClassFour.method_y&lt;[14]&gt; evaltime module end&lt;[4]&gt; ClassOne.__del__\n\ndeco_alpha 装饰器修改了 ClassThree.method_y 方法，因此调用 three.method_y()时会运行 inner_1 函数的定义体。只有程序结束时，绑定在全局变量 one 上的 ClassOne 实例才会被垃圾回收程序回收。\n场景2主要想说明的是，类装饰器可能对子类没有影响。在示例中，把 ClassFour 定义为 ClassThree 的子类，ClassThree 类上依附的 @deco_alpha 装饰器把 method_y 方法替换掉了，但是这对 ClassFour 类根本没有影响。当然，如果 ClassFour.method_y 方法使用 super(...) 调用 ClassThree.method_y 方法，我们便会看到装饰器起作用，执行inner_1函数。\nclass ClassFour(ClassThree):    print(&#x27;&lt;[9]&gt; ClassFour body&#x27;)    def method_y(self):        print(&#x27;&lt;[10]&gt; ClassFour.method_y&#x27;)        super(ClassFour, self).method_y()\n\n&lt;[13]&gt; ClassFour tests ..............................&lt;[10]&gt; ClassFour.method_y&lt;[300]&gt; deco_alpha:inner_1  # 装饰器起作用了\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Selenium IDE 简介","url":"/posts/2020/08/02/17662/","content":"下载安装Selenium IDESelenium IDE 是 Selenium 提供的一个浏览器插件，支持 Chrome 和 Fixforx 浏览器。\n\n可以实现 Web 自动化测试的录制和回放\n可以自动生成自动化测试脚本\n\n在 Chrome 浏览器下载安装步骤：\n\n打开 Chrome –&gt; 更多工具 –&gt; 拓展程序，打开拓展程序管理界面\n点击左侧菜单栏，打开 Chrome 网上商店\n在输入框输入，Selenium IDE 进行搜索\n在搜索结果中选择 Selenium IDE\n点击工具 Se 图标打开 Selenium IDE\n\n\n基本用法Selenium IDE 的 UI 界面可以分为6个不同区域：\n\n菜单栏\n修改项目名称\n创建新项目\n打开新项目\n保存项目\n帮助信息\n\n工具栏功能\n运行所有测试\n运行单个测试\n调试命令\n控制执行速度\n开始录制\n停止录制\n\n地址栏地址栏是一个测试对象所在的 URL地址，它提供了一个下拉菜单，可以记住基本 URL 的所有曾经访问过的网站。\n测试用例窗口\n测试用例\n测试套件\n正在运行的用例\n用例列表\n创建测试套件\n创建测试用例\n\n测试脚本编辑器框\n命令：可以将命令视为在浏览器元素上执行的实际操作。例如：若要打开一个新URL，该命令是 open，若单击网页上的链接或按钮，则命令为click。\n\n目标：Target 指定必须再其上执行操作的 web 元素以及locator 属性。\n\n\n日志、引用窗格\n日志：日志窗格在执行期间显示运行时消息\n引用：引用窗格在编辑器中显示当前所选命令的完整详细信息\n\n实例：\n\n录制回放及导出脚本录制\n创建一个项目\n创建一个测试用例\n输入测试URL地址\n点击开始录制按钮进行录制\n手动进行需要的测试操作\n停止录制\n\n截图显示：\n\n\n\n\n\n回放\n点击回放按钮\n使用命令行脚本运行\n\n导出为脚本\n选择要导出的测试用例，或者测试套件\n选择 Export\n选择 pytest （或者想选择的方式）\n导出\n在命令行或编辑器运行导出的脚本代码\n\n注意：导出的脚本，不一定能成功的在编辑器中执行，更不用说在命令行执行了。由于一些版本不同、定位元素无法找到、代码中没有等待方式等原因，需要跑一遍报错的基础上进行调试一下。\n","categories":["技术","Selenium"],"tags":["Selenium"]},{"title":"Python 小技巧","url":"/posts/2020/06/10/6450/","content":"使用分隔符号的数字也可以计算，没想到吧，我用了两年多Python才发现。这样的数据看起来也更加清晰。不仅可以相加，减法、乘除都可以。\n# python3.6num1 = 10_000_000_000num2 = 10_000print(num1 + num2)print(f&#x27;&#123;num1+num2:,&#125;&#x27;)print(f&#x27;&#123;num1+num2:_&#125;&#x27;)&#x27;&#x27;&#x27;1000001000010,000,010,00010_000_010_000&#x27;&#x27;&#x27;\n\n一行代码处理简单的 if else\ncondition = Trueif condition:    x = 1else:    x = 0x = 1 if condition else 0\nfor … else… 也挺常用的\nfor i in range(10):    # do something    if i == 100:        print(&quot;i will break&quot;)        breakelse:    print(&quot;代码没有执行到循环中的break，遍历里所有元素&quot;)\n\ntry … else … \ncondition = 1try:    if condition:        ret = 1 / 0    print(&quot;这是准备前面没有报错才执行的代码&quot;)except Exception as e:    print(e)else:    print(&quot;没有异常，我就执行&quot;)&#x27;&#x27;&#x27;condition = 1 时输出:division by zerocondition = 0 时输出：这是准备前面没有报错才执行的代码没有异常，我就执行&#x27;&#x27;&#x27;\n\n\nfor 语句中使用 enumerate 来遍历\nnames = [&#x27;aa&#x27;, &#x27;bb&#x27;, &#x27;cc&#x27;]for index, name in enumerate(names):    print(index, name)&#x27;&#x27;&#x27;0 aa1 bb2 cc&#x27;&#x27;&#x27;names = [&#x27;aa&#x27;, &#x27;bb&#x27;, &#x27;cc&#x27;]ages = [10, 20, 30]regions = [&#x27;nanjing&#x27;, &#x27;hangzhou&#x27;, &#x27;shanghai&#x27;]for name, age, region in zip(names, ages, regions):    print(f&#x27;&#123;name&#125; is &#123;age&#125; from &#123;region&#125;&#x27;)&#x27;&#x27;&#x27;aa is 10 from nanjingbb is 20 from hangzhoucc is 30 from shanghai&#x27;&#x27;&#x27;\n\n为对象动态赋予属性\nclass Person():    passperson = Person()first_key = &#x27;name&#x27;first_value = &#x27;banana&#x27;setattr(person, first_key, first_value)print(person.name)  # bananaget_first_key = getattr(person, first_key)print(get_first_key)# banana\n\n升级一下：\nclass Person():    passperson = Person()person_info = &#123;&quot;first&quot;: &quot;Tom&quot;, &quot;last&quot;: &quot;Jenny&quot;&#125;for key, value in person_info.items():    setattr(person, key, value)print(person.first)  # Tomprint(person.last)  # Jenny\n\nclass Person(object):    def __init__(self, name, gender, **kwargs):        self.name = name        self.gender = gender        for k, v in kwargs.items():            # dict_items([(&#x27;age&#x27;, 25), (&#x27;love&#x27;, &#x27;reading&#x27;)])            setattr(self, k, v)p1 = Person(&quot;zyp&quot;, &#x27;male&#x27;, age=25, love=&quot;reading&quot;)# print(dir(p1))print(p1.age)print(p1.love)\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python：使用future并发下载图片","url":"/posts/2020/03/14/19948/","content":"网络普通下载图片为了高效处理网络I&#x2F;O，需要使用并发，因为网络有很高的延迟，所以为了不浪费CPU周期去等待，最好在收到网络响应之前做些其他的事。\n两个示例程序，从网上下载图片。第一个示例程序是依序下载的：下载完一个图，并将其保存在硬盘中之后，才请求下一个图像。另一个脚本是并发下载的：几乎同时请求所有图像，每下载完一个文件就保存一个文件，脚本使用concurrent.futures模块。\n在I&#x2F;O密集型应用中，如果代码写得正确，那么不管使用哪种并发策略（使用线程或asyncio包），吞吐量都比依序执行的代码高很多。\n这边我改了《流畅的Python》中的下载地址和对象：\nimport osimport sysimport timeimport requestsDOWNNLOAD_DIR = r&#x27;D:\\downloadimage&#x27;BASE_URL = &#x27;http://pic2.sc.chinaz.com/Files/pic/pic9/202002/&#x27;image_list = [&#x27;zzpic231&#x27; + str(i) + &#x27;_s.jpg&#x27; for i in range(10, 90)]def save_image(img, filename):    path = os.path.join(DOWNNLOAD_DIR, filename)    with open(path, &#x27;wb&#x27;) as fp:        fp.write(img)def get_image(suffix):    url = os.path.join(BASE_URL, suffix)    response = requests.get(url)    return response.contentdef show(text):    print(text,end=&#x27;\\n&#x27;)    sys.stdout.flush()def download_all(image_name_list):  # download_all是与并发实现比较的关键函数。    for image_name in image_name_list:        image = get_image(image_name)        save_image(image, image_name)        show(image)    return len(image_name_list)def main(download_task):    t0 = time.time()    count = download_task(image_list)    elapsed = time.time() - t0    msg = f&#x27;\\n download &#123;count&#125; images in &#123;elapsed&#125;s&#x27;    print(msg)if __name__ == &#x27;__main__&#x27;:    main(download_all)#  download 80 images in 4.6661295890808105s#  download 80 images in 5.478628873825073s#  download 80 images in 4.028514862060547s\n\n\n使用concurrent.futures模块实现并发下载concurrent.futures模块的主要特色是 ThreadPoolExecutor 和 ProcessPoolExecutor 类，这两个类实现的接口能分别在不同的线程或进程中执行可调用的对象。这两个类在内部维护着一个工作线程或进程池，以及要执行的任务队列。不过，这个接口抽象的层级很高，像下载图片这种简单的案例，无需关心任何实现细节。\n使用ThreadPoolExecutor.map方法，以最简单的方式实现并发下载：\n# a5_4_downloadimage2.pyfrom concurrent import futuresfrom a5_4_downloadimage import save_image, get_image, show, mainMAX_WORDERS = 20  # 设定ThreadPoolExecutor类最多使用几个线程：并发20个def download_single(image_name):    image = get_image(image_name)    save_image(image, image_name)    show(image)    return image_namedef download_multiple(image_name_list):    tasks = min(MAX_WORDERS, len(image_name_list))    with futures.ThreadPoolExecutor(tasks) as executor:        res = executor.map(download_single, sorted(image_name_list))    return len(list(res))if __name__ == &#x27;__main__&#x27;:    main(download_multiple)# download 80 images in 1.4081335067749023s# download 80 images in 1.561039924621582s# download 80 images in 1.393141746520996s\n\ndownload_multiple 函数中设定工作的线程数量：使用允许的最大（MAX_WORKERS）与要处理的数量之间较小的那个值，以免创建多余的线程；使用工作的线程数实例化ThreadPoolExecutor类；executor.__exit__  方法会调用 executor.shutdown(wait=True) 方法，它会在所有线程都执行完毕前阻塞线程；map方法的作用与内置的map函数类似，不过 download_single 函数会在多个线程中并发调用；map方法返回一个生成器，因此可以迭代，获取各个函数返回的值。最后返回获取的结果数量，如果有线程抛出异常，异常会在return语句处抛出，这与隐式调用 next() 函数从迭代器中获取相应的返回值一样。\ndownload_single 函数其实是前面例子中的 download_all 函数的 for 循环体。编写并发代码时经常这样重构：把依序执行的for循环体改成函数，以便并发调用。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Selenium 通识","url":"/posts/2020/08/02/47242/","content":"WebDriver运行原理执行 selenium 测试过程：\n\n工程师写的自动化测试代码：自动化测试代码发送请求给浏览器的驱动（Chrome驱动，FireFox驱动）\n浏览器驱动：解析自动化测试代码，解析后将其发送给浏览器\n浏览器：执行浏览器驱动发来的指令，完成工程师想要的操作\n\nSelenium WebDriver 如何与浏览器通信：\n\n对于每一条 selenium 脚本，对应一个 http 请求会被创建并且发送给浏览器的驱动；\n浏览器驱动中包含了一个 HTTP Server，接受 http 请求；\nHTTP Server 接受到请求后根据请求来具体控制浏览器；\n浏览器执行具体的测试步骤；\n浏览器将步骤执行结果返回给 HTTP Server；\nHTTP Server 将结果返回给 Selenium 脚本，如果是错误的 http 代码则会在控制台中看到报错信息；\n\n\nWebDriver的协议：\n\nWebDriver使用的协议是：JSON Wire protocol\n通信的数据格式是 json\n\n\n元素定位的8种方法import timefrom selenium import webdriverfrom selenium.webdriver.common.by import Byclass TestCase(object):    def __init__(self):        # from .chrome.webdriver import WebDriver as Chrome  # noqa        self.driver = webdriver.Chrome()        self.driver.get(&quot;http://www.baidu.com&quot;)        self.driver.maximize_window()        time.sleep(1)    def execute_click_su(self):        self.driver.find_element_by_id(&#x27;su&#x27;).click()        time.sleep(3)    def quit_driver(self):        self.driver.quit()\n\n最常用的是使用 id 来定位：\n# id 定位元素def test_id(self):    element = self.driver.find_element_by_id(&#x27;kw&#x27;)    element.send_keys(&#x27;selenium&#x27;)    print(type(element))    self.execute_click_su()\n\n元素名定位：\n# name 定位def test_name(self):    # find_element_by_name 可能找到多个name元素，返回第一个    element = self.driver.find_element_by_name(&#x27;wd&#x27;)    element.send_keys(&#x27;selenium&#x27;)    self.execute_click_su()\n\n链接文本定位：\n# 链接文本定位def test_linktext(self):    self.test_id()    self.driver.find_element_by_link_text(&quot;百度首页&quot;).click()    time.sleep(3)    # 部分链接定位def test_partial_linktext(self):    self.test_id()    self.driver.find_element_by_partial_link_text(&quot;首页&quot;).click()    time.sleep(3)\n\nxpath 定位\n# xpath 定位def test_xpath(self):    # self.driver.find_element_by_xpath(&quot;//*[@id=&#x27;kw&#x27;]&quot;).send_keys(&quot;github&quot;)    self.driver.find_element_by_xpath(&quot;//input[@id=&#x27;kw&#x27;]&quot;).send_keys(&quot;github&quot;)    self.execute_click_su()    time.sleep(3)\n\ntag 标签定位\n# tag 标签名称定位def test_tag(self):    element = self.driver.find_elements_by_tag_name(&#x27;input&#x27;)    for i in range(17):        try:            element[i].send_keys(&#x27;git&#x27;)            self.execute_click_su()            time.sleep(3)        except Exception as e:            print(e)    print(element)    # time.sleep(10)\n\ncss selector 定位\n# css selector 定位def test_css_selector(self):    self.driver.find_element_by_css_selector(&#x27;#kw&#x27;).send_keys(&#x27;github&#x27;)    self.execute_click_su()    time.sleep(3)\n\n类名定位\n# 类名定位def test_class_name(self):    self.driver.find_element_by_class_name(&#x27;s_ipt&#x27;).send_keys(&#x27;github&#x27;)    self.execute_click_su()    time.sleep(3)\n\n通用的指定定位方式来定位\n# 指定定位方式，可选def test_all(self):    self.driver.find_element(By.ID, value=&#x27;kw&#x27;).send_keys(&#x27;git&#x27;)    self.execute_click_su()    time.sleep(3)\n\n运行：\nif __name__ == &#x27;__main__&#x27;:    case = TestCase()    # 8种元素定位方法：    case.test_id()    case.test_name()    case.test_linktext()    case.test_partial_linktext()    case.test_xpath()    case.test_tag()    case.test_css_selector()    case.test_class_name()    case.test_all()    case.quit_driver()\n\n封装写法：\nimport timefrom selenium import webdriverfrom selenium.webdriver.common.by import Bydef get_element(driver, *loc):    element = driver.find_element(*loc)    return elementif __name__ == &#x27;__main__&#x27;:    driver = webdriver.Chrome()    driver.get(&quot;http://www.baidu.com&quot;)    loc1 = (By.ID, &#x27;kw&#x27;)    # loc2 = (By.ID, &#x27;su&#x27;)    get_element(driver, *loc1).send_keys(&quot;pornhub&quot;)    get_element(driver, By.ID, &#x27;su&#x27;).click()    time.sleep(3)    driver.quit()\n\n\nSelenium WebDriver 属性\n\n\n\n#\n属性\n属性描述\n\n\n\n1\ndriver.name\n浏览器名称\n\n\n2\ndriver.current_url\n当前url\n\n\n3\ndriver.title\n当前页面标题\n\n\n4\ndriver.page_source\n当前页面源码\n\n\n5\ndriver.current_window_handle\n窗口句柄\n\n\n6\ndriver.window_handles\n当前窗口所有句柄\n\n\n\nSelenium WebElementWebElement 属性使用 WebDriver 的 find 方法定位到元素后，会返回一个 WebElement 对象，该对象用来描述 web 页面上的一个元素。\nWebElement 常用属性：\n\n\n\n#\n属性\n属性描述\n\n\n\n1\nid\n标示\n\n\n2\nsize\n宽高\n\n\n3\nrect\n宽高和坐标\n\n\n4\ntag_name\n标签名称\n\n\n5\ntext\n文本内容\n\n\n示例：\nimport timefrom selenium import webdriverfrom selenium.webdriver.remote.webelement import WebElementclass TestCase(object):    def __init__(self):        self.driver = webdriver.Chrome()        self.driver.get(&quot;http://sahitest.com/demo/linkTest.htm&quot;)    def test_webelement_prop(self):        e = self.driver.find_element_by_id(&#x27;t1&#x27;)        # e1 = WebElement        print(type(e))if __name__ == &#x27;__main__&#x27;:    case = TestCase()    case.test_webelement_prop()\n\n通过 debug 查看：\n\n常用方法\n\n\n#\n方法\n方法描述\n\n\n\n1\nsend_keys()\n输入内容\n\n\n2\nclear()\n清空内容\n\n\n3\nclick()\n单击\n\n\n4\nget_attribute()\n获得属性值\n\n\n5\nis_selected()\n是否被选中\n\n\n6\nis_enabled()\n是否可用\n\n\n7\nis_displayed()\n是否显示\n\n\n8\nvalue_of_css_property()\ncss属性值\n\n\n示例：\ndef test_webElement_method(self):    e = self.driver.find_element_by_id(&#x27;t1&#x27;)    e.send_keys(&#x27;test selenium&#x27;)    time.sleep(2)    print(e.get_attribute(&#x27;type&#x27;))    print(e.get_attribute(&#x27;name&#x27;))    print(e.get_attribute(&#x27;value&#x27;))    print(e.value_of_css_property(&#x27;font&#x27;))    print(e.value_of_css_property(&#x27;color&#x27;))    time.sleep(2)    e.clear()def test_webElement_method2(self):    # id 为 t1 的元素是在 form 表单里，所以也可以先找到 form 表单，再去找 t1    form_ele = self.driver.find_element_by_xpath(&quot;//input[@id=&#x27;t1&#x27;]&quot;)    form_ele.find_element_by_id(&#x27;t1&#x27;).send_keys(&#x27;666&#x27;)\n\n方法截图：\n\n","categories":["技术","Selenium"],"tags":["Selenium"]},{"title":"Windows 安装 Elasticsearch、Kibana、Logstash","url":"/posts/2020/10/15/26094/","content":"Elasticsearch 安装与简单配置Windows 环境下载安装下载地址\n下载后安装到没有空格的路径下。比如：D:\\softwares\\elasticsearch-7.9.2\n启动方式：D:\\softwares\\elasticsearch-7.9.2\\bin&gt;elasticsearch\n启动后在浏览器中访问：\n![img](..&#x2F;..&#x2F;images&#x2F;2020&#x2F;es&#x2F;start elasticsearch.png)\n查看已安装的插件：D:\\softwares\\elasticsearch-7.9.2\\bin&gt;elasticsearch-plugin list\n安装 analysis-icu 插件：elasticsearch-plugin install analysis-icu，安装好后重新启动，然后查看：\n\n简单配置如何在开发机上运行多个 Elasticsearch 实例？\n在 bin 目录下，分别打开3个命令行窗口、各执行一条语句（windows下必须分别执行多个CMD 才能模拟多节点集群）：\n\nelasticsearch -E node.name&#x3D;node1 -E cluster.name&#x3D;geektime -E path.data&#x3D;node1_data -d\nelasticsearch -E node.name&#x3D;node2 -E cluster.name&#x3D;geektime -E path.data&#x3D;node2_data -d\nelasticsearch -E node.name&#x3D;node3 -E cluster.name&#x3D;geektime -E path.data&#x3D;node3_data -d\n\n查看集群中运行的节点：http://127.0.0.1:9200/_cat/nodes\n\n删除进程：ps | grep elasticsearch ，kill pid\n\nKibana 的安装Kibana 是基于 Elasticsearch 运行的，所以在启动 Kibana 前需要将 Elasticsearch 运行起来。\n下载地址(华为云)\n运行 Kibana：D:\\softwares\\kibana-7.8.0\\bin&gt;kibana\n启动后在浏览器中访问：http://localhost:5601\nKibana Console\n\nDev Tool\nSearch Profiler\nHelp + 一些快捷键\nCtrl + &#x2F; (查看API帮助文档)\nCtrl + I 代码收缩\n\n\n\nLogstash 安装下载地址\n启动：\nD:\\softwares\\logstash-7.8.0\\bin&gt;logstash -f logstash.conf\n\n查看索引：\nhttp://10.103.131.242:9200/_cat/indices?v\n\ndemo 地址\n注意点：logstash.conf 部分修改（windows和mac上不同：一般我们从windows系统中复制的路径都是\\斜杠的，但是配置文件中的路径需要的是&#x2F;斜杠的路径）：\ninput &#123;  file &#123;    path =&gt; [&quot;D:/Program Files/logstash-7.8.0/movielens/ml-latest-small/movies.csv&quot;]    start_position =&gt; beginning    sincedb_path =&gt; &quot;D:/Program Files/logstash-7.8.0/123&quot;  &#125;&#125;\n\nwindows下还有个小问题要注意：logstash 的安装目录不能有空格，不然运行会报错：找不到或无法加载主类。\n\n参考资料\n在Docker容器中运行Elasticsearch, Kibana和Cerebro\nElasticsearch Reference\n\n","categories":["技术","Elasticsearch"],"tags":["elasticsearch"]},{"title":"Selenium 常用操作汇总","url":"/posts/2020/08/02/23731/","content":"Selenium 操作 form 表单form 表单是常用的测试用例对象，大多数 web 应用程序都有这方面的功能。例如：用户登录、注册都会用到 form 表单。\nform 表单的流程：\n\n定位表单元素\n输入测试值\n判断表单元素属性\n获取表单元素属性\n提交表单进行验证\n\n实例：在本地使用了 file 协议加载本地文件，自定义一个 form 表单，使用 selenium 实现了表单的数据输入、提交。\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&quot;javascript:alert(&#x27;hello&#x27;)&quot;&gt;    username: &lt;input type=&quot;text&quot; name=&quot;username&quot; id=&quot;username&quot;&gt;&lt;br&gt;    password: &lt;input type=&quot;password&quot; name=&quot;password&quot; id=&quot;password&quot;&gt;&lt;br&gt;    submit&lt;input type=&quot;submit&quot; value=&quot;submit&quot; id=&quot;submit&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n\nimport osfrom time import sleepfrom selenium import webdriverfrom Selenium.utils.util import PROJECT_PATH  # 自定义的Selenium目录class TestCase(object):    def __init__(self):        self.path = os.path.join(PROJECT_PATH, &#x27;static&#x27;)        self.forms_file = &#x27;file:///&#x27; + self.path + &#x27;/demo2_3_forms.html&#x27;        self.driver = webdriver.Chrome()    def quit(self):        self.driver.quit()    def get_forms_file(self):        self.driver.get(self.forms_file)    def test_login(self):        self.get_forms_file()        username = self.driver.find_element_by_id(&#x27;username&#x27;)        username.send_keys(&#x27;admin&#x27;)        password = self.driver.find_element_by_id(&#x27;password&#x27;)        password.send_keys(&#x27;123456&#x27;)        print(username.get_attribute(&#x27;value&#x27;))        print(password.get_attribute(&#x27;value&#x27;))        sleep(2)        self.driver.find_element_by_id(&#x27;submit&#x27;).click()        sleep(1)        self.driver.switch_to.alert.accept()        sleep(1)        username.clear()        password.clear()        sleep(1)        self.quit()if __name__ == &#x27;__main__&#x27;:    case = TestCase()    # print(case.get_forms_file())    case.test_login()\n\n\nSelenium 操作 checkbox 和 radiobutton\nform 表单里常用 checkbox 和 radiobutton， checkbox 是多选框，radiobutton 是单选框；\n例如，一个注册表单收集用户爱好可以用 checkbox，输入性别可以用 radiobutton；\n\n关于 checkbox\n\n如果 checkbox 有 id 属性，可以直接通过 id 定位；若没有则通过 input 标签名称定位，然后通过 type 属性过滤；\n选择或反选 checkbox，使用 click() 方法；\n\n实例：\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&quot;javascript:alert(&#x27;test&#x27;)&quot;&gt;    swimming: &lt;input type=&quot;checkbox&quot; name=&quot;swimming&quot; value=&quot;swimming&quot;&gt;&lt;br&gt;    reading: &lt;input type=&quot;checkbox&quot; name=&quot;reading&quot; value=&quot;reading&quot;&gt;&lt;br&gt;    &lt;hr&gt;    gender: &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;male&quot;&gt;male &amp;nbsp    &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;female&quot;&gt;female &lt;br&gt;    login: &lt;input type=&quot;submit&quot; name=&quot;submit&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n\nimport osfrom time import sleepfrom selenium import webdriverfrom Selenium.utils.util import PROJECT_PATHclass TestCase(object):    def __init__(self):        self.path = os.path.join(PROJECT_PATH, &#x27;static&#x27;)        self.file = &#x27;file:///&#x27; + self.path + &#x27;/demo2_4_checkbox_radiobutton.html&#x27;        self.driver = webdriver.Chrome()    def get_path(self):        self.driver.get(self.file)    def quit(self):        self.driver.quit()    def test_checkbox(self):        self.get_path()        sleep(2)        checkbox1 = self.driver.find_element_by_name(&#x27;swimming&#x27;)        checkbox2 = self.driver.find_element_by_name(&#x27;reading&#x27;)        for ele in [checkbox1, checkbox2]:            if not ele.is_selected():                ele.click()                sleep(1)        self.quit()    def test_radiobutton(self):        self.get_path()        radios = self.driver.find_elements_by_name(&#x27;gender&#x27;)        for radio in radios:            radio.click()            sleep(1)        self.quit()if __name__ == &#x27;__main__&#x27;:    case = TestCase()    # case.test_checkbox()    case.test_radiobutton()\n\n\nSelenium 操作下拉列表处理下拉列表，需要用到工具栏 Select 。\n\n\n\n#\n方法&#x2F;属性\n方法&#x2F;属性描述\n\n\n\n1\nselect_by_value()\n根据值选择\n\n\n2\nselect_by_index()\n根据索引选择\n\n\n3\nselect_by_visible_text()\n根据文本选择\n\n\n4\ndeselect_by_value\n根据值反选\n\n\n5\ndeselect_by_index\n根据索引反选\n\n\n6\ndeselect_by_visible_text\n根据文本反选\n\n\n7\ndeselect_all\n反选所有\n\n\n8\noptions\n所有选项\n\n\n9\nall_selected_options\n所有选中选项\n\n\n10\nfirst_selected_option\n第一个选择选项\n\n\n实例：\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&quot;javascript:alert(&#x27;test select&#x27;)&quot;&gt;    &lt;label for=&quot;provise&quot;&gt;provide:&lt;/label&gt;    &lt;select name=&quot;provise&quot; id=&quot;provise&quot; multiple&gt;        &lt;option value=&quot;bj&quot;&gt;beijing&lt;/option&gt;        &lt;option value=&quot;hz&quot;&gt;hangzhou&lt;/option&gt;        &lt;option value=&quot;nj&quot;&gt;nanjing&lt;/option&gt;    &lt;/select&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n\nimport osfrom time import sleepfrom selenium import webdriverfrom selenium.webdriver.support.select import Selectfrom Selenium.utils.util import PROJECT_PATHclass TestCase(object):    def __init__(self):        self.path = os.path.join(PROJECT_PATH, &#x27;static&#x27;)        self.file = &#x27;file:///&#x27; + self.path + &#x27;/demo2_5_select.html&#x27;        self.driver = webdriver.Chrome()    def get_path(self):        self.driver.get(self.file)        sleep(2)    def quit(self):        self.driver.quit()    def test_select_by_value(self):        ele = self.driver.find_element_by_id(&#x27;provise&#x27;)        select_obj = Select(ele)        select_obj.select_by_value(&#x27;nj&#x27;)        sleep(1.5)        select_obj.select_by_value(&#x27;hz&#x27;)        sleep(1.5)    def test_select_by_index(self):        ele = self.driver.find_element_by_id(&#x27;provise&#x27;)        select_obj = Select(ele)        select_obj.select_by_index(2)        sleep(1.5)        select_obj.select_by_index(1)        sleep(1.5)        select_obj.select_by_index(0)        sleep(1.5)    def test_select_by_visible_text(self):        ele = self.driver.find_element_by_id(&#x27;provise&#x27;)        select_obj = Select(ele)        select_obj.select_by_visible_text(&#x27;beijing&#x27;)        sleep(1.5)        select_obj.select_by_visible_text(&#x27;nanjing&#x27;)        sleep(1.5)    def test_select_multiple(self):        ele = self.driver.find_element_by_id(&#x27;provise&#x27;)        select_obj = Select(ele)        for i in range(3):            select_obj.select_by_index(i)            sleep(1)        select_obj.deselect_all()        sleep(1)    def test_options(self):        ele = self.driver.find_element_by_id(&#x27;provise&#x27;)        select_obj = Select(ele)        for option in select_obj.options:            print(option)            print(option.text)if __name__ == &#x27;__main__&#x27;:    case = TestCase()    case.get_path()    # case.test_select_by_value()    # case.test_select_by_index()    # case.test_select_by_visible_text()    # case.test_select_multiple()    case.test_options()    case.quit()\n\n\nSelenium 处理弹框页面上的弹框有三种：\n\nalert：用来提示\nconfirm：用来确认\nprompt：输入内容\n\n\n\n\n#\n方法&#x2F;属性\n方法&#x2F;属性描述\n\n\n\n1\naccept()\n接受\n\n\n2\ndismiss()\n取消\n\n\n3\ntext\n显示的文本\n\n\n4\nsend_keys\n输入内容\n\n\n实例：\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;a href=&quot;javascript:alert(&#x27;提示框&#x27;)&quot; id=&quot;alert&quot;&gt;&lt;br&gt;    Alert&lt;/a&gt;&lt;a href=&quot;javascript:confirm(&#x27;确认框&#x27;)&quot; id=&quot;confirm&quot;&gt;&lt;br&gt;    Confirm&lt;/a&gt;&lt;a href=&quot;javascript:var inputvar = prompt(&#x27;请输入&#x27;);document.write(inputvar)&quot; id=&quot;prompt&quot;&gt;&lt;br&gt;    Prompt&lt;/a&gt;&lt;!--&lt;a href=&quot;javascript:prompt(&#x27;请输入&#x27;)&quot; id=&quot;prompt&quot;&gt;&lt;br&gt;--&gt;&lt;!--    Prompt--&gt;&lt;!--&lt;/a&gt;--&gt;&lt;/body&gt;&lt;/html&gt;\n\nimport osfrom selenium import webdriverfrom time import sleepfrom Selenium.utils.util import PROJECT_PATHclass TestCase(object):    def __init__(self):        self.path = os.path.join(PROJECT_PATH, &#x27;static&#x27;)        self.file = &#x27;file:///&#x27; + self.path + &#x27;/demo2_6_alert.html&#x27;        self.driver = webdriver.Chrome()    def get_path(self):        self.driver.get(self.file)        sleep(2)    def quit(self):        self.driver.quit()    def test_alert(self):        self.get_path()        ele = self.driver.find_element_by_id(&#x27;alert&#x27;)        ele.click()        alert_obj = self.driver.switch_to.alert  # 切换到alert        print(alert_obj.text)        sleep(1)        alert_obj.accept()        sleep(1)        self.quit()    def test_confirm(self):        self.get_path()        for i in range(2):            ele = self.driver.find_element_by_id(&#x27;confirm&#x27;)            ele.click()            alert_obj = self.driver.switch_to.alert            sleep(1)            if i == 0:                alert_obj.accept()  # 确认            else:                alert_obj.dismiss()  # 取消            sleep(1)        self.quit()    def test_prompt(self):        self.get_path()        ele = self.driver.find_element_by_id(&#x27;prompt&#x27;)        ele.click()        prompt_obj = self.driver.switch_to.alert        print(prompt_obj.text)        sleep(3)        # prompt_obj.send_keys(&#x27;100&#x27;)        prompt_obj.accept()        sleep(3)        self.quit()if __name__ == &#x27;__main__&#x27;:    case = TestCase()    # case.test_alert()    # case.test_confirm()    case.test_prompt()\n\n\nSelenium 三种等待方式在 UI 自动化测试中，必然会遇到测试环境不稳定的情况，网络延迟等，如果不做任何处理，代码会由于没有找到元素而报错。除此，有的页面会使用 ajax 异步加载机制，需要用到等待。\n常用的等待有三种：\n\ntime.sleep 固定等待\n在开发自动化测试框架过程中，忌讳使用Python自带模块time的sleep方法进行等待，虽然可以自定义时间，当时当网络条件好时，依旧会等待，导致整个项目的测试时间没有必要的延长。只是在脚本调试是推荐使用。\n\nimplicitly_wait 隐式等待\n设置了一个最长等待时间，如果在规定时间内网页加载完成，则执行下一步，否则一直会等待时间结束，然后执行下一步。这样的隐式等待会有问题，页面上的元素加载完毕后再加载 body 后面的 JavaScript，导致一直在等待页面加载结束。\n隐式等待对整个 driver 周期都起作用，在最开始设置一次就可以。不要当做笃定等待使用、到哪都使用。\n\nWebDriverWait 显式等待\nWebDriverWait 是 selenium 提供得到显示等待的模块，引入路径：\nfrom selenium.webdriver.support.wait import WebDriverWait\n\nWebDriverWait 参数：\n\n\n\n#\n参数\n参数说明\n\n\n\n1\ndriver\n传入 WebDriver 实例\n\n\n2\ntimeout\n超时时间，等待的最长时间\n\n\n3\npoll_frequency\n调用until或until_not中的方法的间隔时间，默认是0.5秒\n\n\n4\nignored_exceptions\n忽略的异常\n\n\n该模块中一共只要两种方法：until 和 until_not\n\n\n\n#\n参数\n参数说明\n\n\n\n1\nmethod\n在等待时间，每隔一段时间调用这个传入的方法，直到返回值不是False\n\n\n2\nmessage\n如果超时，抛出TimeoutException异常，将message传入异常\n\n\n\n\n实例：\nclass TestCase(object):    def __init__(self):        self.driver = webdriver.Chrome()        self.driver.get(&#x27;https://www.baidu.com&#x27;)    def test_sleep(self):        self.driver.find_element_by_id(&#x27;kw&#x27;).send_keys(&#x27;selenium&#x27;)        sleep(3)  # 线程阻塞 blocking wait        self.driver.find_element_by_id(&#x27;su&#x27;).click()        sleep(3)        self.driver.quit()    def test_implicitly(self):        self.driver.implicitly_wait(10)        self.driver.find_element_by_id(&#x27;kw&#x27;).send_keys(&#x27;selenium&#x27;)        self.driver.find_element_by_id(&#x27;su&#x27;).click()        self.driver.quit()    def test_wait(self):        # self, driver, timeout, poll_frequency=POLL_FREQUENCY, ignored_exceptions=None        wait = WebDriverWait(self.driver, 5, 0.5)        wait.until(EC.title_is(&#x27;百度一下，你就知道&#x27;))        self.driver.find_element_by_id(&#x27;kw&#x27;).send_keys(&#x27;selenium&#x27;)        self.driver.find_element_by_id(&#x27;su&#x27;).click()        self.driver.quit()if __name__ == &#x27;__main__&#x27;:    case = TestCase()    # case.test_sleep()    # case.test_implicitly()    case.test_wait()\n\n\nSelenium 等待条件\n\n\n#\n条件\n判断\n返回值\n\n\n\n1\ntitle_is\ntitle，是否出现\n布尔\n\n\n2\ntitle_contains\ntitle，是否包含某些子字符串\n布尔\n\n\n3\npresence_of_element_located\n某个元素是否被在dom树里，并不代表该元素一定可见\nWebElement\n\n\n4\nurl_contains\n当前url中包含子字符串\n布尔\n\n\n5\nurl_matches\n当前url匹配某表达式\n布尔\n\n\n6\nurl_to_be\nurl是否相同\n布尔\n\n\n7\nurl_changes\nurl不能准确匹配\n布尔\n\n\n8\nvisibility_of_element_located\n某个元素是否被在dom里并且可见，宽和高都大于0\nWebElement\n\n\n9\nvisibility_of\n元素是否可见，若可见就返回这个元素\nWebElement\n\n\n10\npresence_of_all_elements_located\n是否至少有1个元素存在dom树中\n列表\n\n\n11\nvisibility_of_any_elements_located\n至少有1个元素在页面中可见\n列表\n\n\n12\ntext_to_be_present_in_element\n指定元素中是否包含了预期的文本\n布尔\n\n\n13\ntext_to_be_present_in_element_value\n指定元素的属性值中是否包含了预期的文本\n布尔\n\n\n14\nframe_to_be_available_and_switch_to_it\n该frame是否可以switch进去，若是则切进去\n布尔\n\n\n15\ninvisibility_of_element_located\n某个元素是否存在于dom或不可见\n布尔\n\n\n16\nelement_to_be_clickable\n某个元素是否可见并且是enabled的，代表可点击\n布尔\n\n\n17\nstaleness_of\n等待某个元素从dom树中移除\n布尔\n\n\n18\nelement_to_be_selected\n某个元素是否被选中了，一般用在下拉列表\n布尔\n\n\n19\nelement_located_to_be_selected\n某个定位元素是否被选中了\n布尔\n\n\n20\nelement_selection_state_to_be\n某个元素的选中状态是否符合预期\n布尔\n\n\n21\nelement_located_selection_state_to_be\n某个元素的选中状态是否符合预期\n布尔\n\n\n22\nalert_is_present\n页面上是否存在alert\nalert\n\n\n\nSelenium 鼠标和键盘操作Selenium 中的鼠标和键盘时间被封装在 ActionChains 类中，正确的使用方法是：ActionChains(driver).click(btn).perform() ，下面是常用方法。\n\n\n\n#\n方法\n描述\n\n\n\n1\nperform\n执行链中的所有动作\n\n\n2\nreset_actions\n清空链中已经存储的所有动作\n\n\n3\nclick\n点击一个元素\n\n\n4\nclick_and_hold\n在一个元素上单击并保持\n\n\n5\ncontext_click\n在一个元素上右击\n\n\n6\ndouble_click\n双击一个元素\n\n\n7\ndrag_and_drop\n在一个元素上单击并拖动到另一个元素上再释放（拖拽）\n\n\n8\ndrag_and_drop_by_offset\n在一个元素上单击并拖动固定距离到另一个坐标点\n\n\n9\nkey_down\n键盘上按下某个键\n\n\n10\nkey_up\n键盘上释放某个键\n\n\n11\nmove_by_offset\n鼠标从当前位置移动到某个坐标\n\n\n12\nmove_to_element\n鼠标移动到某个元素\n\n\n13\nmove_to_element_with_offset\n移动到距某个元素（左上角坐标）多少距离的位置\n\n\n14\npause\n在一定时间内，暂停所有的输入\n\n\n15\nrelease\n在一个元素上释放鼠标左键\n\n\n16\nsend_keys\n发送数据到当前焦点的元素\n\n\n17\nsend_keys_to_element\n发送某个键到指定元素\n\n\n实例：\nfrom time import sleepfrom selenium import webdriverfrom selenium.webdriver import ActionChainsfrom selenium.webdriver.common.keys import Keysclass TestCase(object):    def __init__(self):        self.driver = webdriver.Chrome()        self.driver.maximize_window()    def test_mouse(self):        self.driver.get(&#x27;http://sahitest.com/demo/clicks.htm&#x27;)        # actionchains = ActionChains(self.driver)        # 不能使用一个实例化的ActionChains去执行多个操作，否则会下一次会执行前面累积的操作，需要reset        doubleclick_ele = self.driver.find_element_by_xpath(&#x27;/html/body/form/input[2]&#x27;)        ActionChains(self.driver).double_click(doubleclick_ele).perform()        click_ele = self.driver.find_element_by_xpath(&#x27;/html/body/form/input[3]&#x27;)        ActionChains(self.driver).click(click_ele).perform()        rightclick_ele = self.driver.find_element_by_xpath(&#x27;/html/body/form/input[4]&#x27;)        ActionChains(self.driver).context_click(rightclick_ele).perform()    def test_mouse_reset(self):        self.driver.get(&#x27;http://sahitest.com/demo/clicks.htm&#x27;)        actionchains = ActionChains(self.driver)        doubleclick_ele = self.driver.find_element_by_xpath(&#x27;/html/body/form/input[2]&#x27;)        actionchains.double_click(doubleclick_ele).perform()        actionchains.reset_actions()        click_ele = self.driver.find_element_by_xpath(&#x27;/html/body/form/input[3]&#x27;)        actionchains.click(click_ele).perform()        actionchains.reset_actions()        rightclick_ele = self.driver.find_element_by_xpath(&#x27;/html/body/form/input[4]&#x27;)        actionchains.context_click(rightclick_ele).perform()    def test_keys(self):        self.driver.get(&#x27;http://www.baidu.com&#x27;)        kw_ele = self.driver.find_element_by_id(&#x27;kw&#x27;)        kw_ele.send_keys(&#x27;selenium&#x27;)        kw_ele.send_keys(Keys.CONTROL, &#x27;a&#x27;)        sleep(1)        kw_ele.send_keys(Keys.CONTROL, &#x27;x&#x27;)        sleep(1)        kw_ele.send_keys(Keys.CONTROL, &#x27;v&#x27;)        config_ele = self.driver.find_element_by_name(&#x27;tj_settingicon&#x27;)        ActionChains(self.driver).move_to_element(config_ele).perform()        forcast_ele = self.driver.find_element_by_link_text(&#x27;关闭预测&#x27;)        ActionChains(self.driver).click(forcast_ele).perform()if __name__ == &#x27;__main__&#x27;:    case = TestCase()    # case.test_mouse()    # case.test_mouse_reset()    case.test_keys()\n\n\nSelenium 执行 JavaScript 脚本WebDriver 有两个方法来执行 JavaScript，分别是：\n\nexecute_script 同步执行\nexecute_async_script 异步执行\n\nfrom time import sleepfrom selenium import webdriverclass TestCase(object):    def __init__(self):        self.driver = webdriver.Chrome()        self.driver.get(&quot;http://www.baidu.com&quot;)        self.driver.maximize_window()    def test_js1(self):        # 通过js创建alert弹框        self.driver.execute_script(&#x27;alert(&quot;test_javascript&quot;)&#x27;)        sleep(1)        self.driver.switch_to.alert.accept()    def test_js2(self):        # 通过js获取页面标题        js_sentence = &#x27;return document.title&#x27;        title = self.driver.execute_script(js_sentence)        return title    def test_js3(self):        # 通过js修改样式        js_sentencce = &quot;var q = document.getElementById(&#x27;kw&#x27;); q.style.border=&#x27;2px solid red&#x27;&quot;        self.driver.execute_script(js_sentencce)    def test_js4(self):        # 通过js来拖动滚动条        self.driver.implicitly_wait(5)        self.driver.find_element_by_id(&#x27;kw&#x27;).send_keys(&#x27;python&#x27;)        self.driver.find_element_by_id(&#x27;su&#x27;).click()        sleep(1)        js_sentence = &quot;window.scrollTo(0, document.body.scrollHeight)&quot;        self.driver.execute_script(js_sentence)if __name__ == &#x27;__main__&#x27;:    case = TestCase()    # case.test_js1()    # print(case.test_js2())    # case.test_js3()    case.test_js4()\n\n\nSelenium 屏幕截图WebDriver 内置了一些在测试中捕获并保存的方法：\n\n\n\n#\n方法\n描述\n\n\n\n1\nsave_screenshot(filename)\n获取当前屏幕截图并保存为文件，filename为指定保存的路径或图片的文件名\n\n\n2\nget_screenshot_as_base64()\n获取当前屏幕截图base64编码字符串\n\n\n3\nget_screenshot_as_file(filename)\n获取当前的屏幕截图，使用完整的路径\n\n\n4\nget_screenshot_as_png()\n获取当前屏幕截图的二进制文件数据\n\n\n实例：\nimport osfrom time import sleep, strftime, localtime, timefrom selenium import webdriverfrom utils.util import PROJECT_PATHclass TestCase(object):    def __init__(self):        self.path = PROJECT_PATH        self.driver = webdriver.Chrome()        self.driver.get(&quot;http://www.baidu.com&quot;)        self.driver.maximize_window()    def test1(self):        self.driver.find_element_by_id(&#x27;kw&#x27;).send_keys(&#x27;截屏&#x27;)        self.driver.find_element_by_id(&#x27;su&#x27;).click()        sleep(1)        # self.driver.save_screenshot(&#x27;screenshot_baidu&#x27;)        str_time = strftime(&quot;%Y-%m-%d-%H-%M-%S&quot;, localtime(time()))        # file_name = str_time + &#x27;.png&#x27;        # self.driver.save_screenshot(file_name)        screenshot_dir = os.path.join(self.path, &#x27;screenshot&#x27;)        if not os.path.exists(screenshot_dir):            os.mkdir(screenshot_dir)        file_name = os.path.join(screenshot_dir, str_time + &#x27;.png&#x27;)        self.driver.save_screenshot(file_name)if __name__ == &#x27;__main__&#x27;:    case = TestCase()    case.test1()\n\n\nSelenium 定位 frame iframeframe 标签有 frameset、frame、iframe 三种，frameset 跟其他普通标签没有区别，不会影响到正常的定位，而 frame 与 iframe 对 Selenium 定位而言是一样的，Selenium 有一组方法对 frame 进行操作。\n\n\n\n#\n方法\n描述\n\n\n\n1\nswitch_to.frame(reference)\n切换frame，reference是传入的参数，用来定位frame，可以传入id，name，index以及selenium的WebElement对象\n\n\n2\nswitch_to.default_content()\n返回主文档\n\n\n3\nswitch_to.parent_frame()\n返回父文档\n\n\n实例：\nfrom time import sleepfrom selenium import webdriverclass TestCase(object):    def __init__(self):        self.driver = webdriver.Chrome()        self.driver.get(&quot;http://sahitest.com/demo/framesTest.htm&quot;)    def test_frame(self):        self.driver.implicitly_wait(10)        frame1_ele = self.driver.find_element_by_name(&#x27;top&#x27;)        self.driver.switch_to.frame(frame1_ele)        Link_Test = self.driver.find_element_by_xpath(&quot;/html/body/table/tbody/tr/td[1]/a[1]&quot;)        Link_Test.click()        self.driver.switch_to.default_content()        sleep(3)        frame2_ele = self.driver.find_element_by_xpath(&quot;/html/frameset/frame[2]&quot;)        self.driver.switch_to.frame(frame2_ele)        Link_Test2 = self.driver.find_element_by_xpath(&quot;/html/body/table/tbody/tr/td[1]/a[1]&quot;)        Link_Test2.click()if __name__ == &#x27;__main__&#x27;:    case = TestCase()    case.test_frame()\n\n","categories":["技术","Selenium"],"tags":["Selenium"]},{"title":"TypeError，自定义异常类","url":"/posts/2020/03/09/60844/","content":"写了一个demo异常类，没有继承BaseException类，提示报如下错误，很明显只要继承一下BaseException就可以了。TypeError: catching classes that do not inherit from BaseException is not allowed 捕获到一个没有继承BaseException的异常类（这是不被允许的）。\nException ignored in: &lt;generator object demo_exc_handling at 0x000001D06C66E200&gt;Traceback (most recent call last):  File &quot;a5_3_coroutine_exception.py&quot;, line 10, in demo_exc_handlingTypeError: catching classes that do not inherit from BaseException is not allowed\nclass DemoException():  # DemoException(BaseException) 为正确写法    &quot;&quot;&quot;demo异常类型&quot;&quot;&quot;    passdef demo_exc_handling():    print(&#x27;-&gt; coroutine started&#x27;)    while True:        try:            var = yield        except DemoException as e:            print(&#x27;*** DemoException handled. Continuing...&#x27;)        else:            print(&#x27;-&gt; coroutine received: &#123;!r&#125;&#x27;.format(var))    # raise RuntimeError(&#x27;This line should never run.&#x27;)cor_exc = demo_exc_handling()cor_exc.send(None)cor_exc.send(1)\n","categories":["技术","Python"],"tags":["Python","FixBug"]},{"title":"Useful Python Tricks","url":"/posts/2020/06/10/6697/","content":"使用分隔符号的数字也可以计算，而且看起来数据更加清晰。\n# python3.6&gt;&gt;&gt; num1 = 10_000_000_000&gt;&gt;&gt; num2 = 10_000&gt;&gt;&gt; num1 + num210000010000&gt;&gt;&gt; f&#x27;&#123;num1+num2:,&#125;&#x27;&#x27;10,000,010,000&#x27;&gt;&gt;&gt; f&#x27;&#123;num1+num2:_&#125;&#x27;&#x27;10_000_010_000&#x27;\n\n一行代码处理简单的 if else\ncondition = Trueif condition:    x = 1else:    x = 0x = 1 if condition else 0\n\nfor … else… 也挺常用的\nfor i in range(10):    # do something    if i == 100:        print(&quot;i will break&quot;)        breakelse:    print(&quot;代码没有执行到循环中的break&quot;)\n\ntry … else … \ncondition = 1try:    if condition:        ret = 1 / 0    print(&quot;这是准备前面没有报错才执行的代码&quot;)except Exception as e:    print(e)else:    print(&quot;没有异常，我就执行&quot;)&#x27;&#x27;&#x27;condition = 1 时输出:division by zerocondition = 0 时输出：这是准备前面没有报错才执行的代码没有异常，我就执行&#x27;&#x27;&#x27;\n\nfor 语句中使用 enumerate 来遍历\nnames = [&#x27;aa&#x27;, &#x27;bb&#x27;, &#x27;cc&#x27;]for index, name in enumerate(names):    print(index, name)&#x27;&#x27;&#x27;0 aa1 bb2 cc&#x27;&#x27;&#x27;names = [&#x27;aa&#x27;, &#x27;bb&#x27;, &#x27;cc&#x27;]ages = [10, 20, 30]regions = [&#x27;nanjing&#x27;, &#x27;hangzhou&#x27;, &#x27;shanghai&#x27;]for name, age, region in zip(names, ages, regions):    print(f&#x27;&#123;name&#125; is &#123;age&#125; from &#123;region&#125;&#x27;)&#x27;&#x27;&#x27;aa is 10 from nanjingbb is 20 from hangzhoucc is 30 from shanghai&#x27;&#x27;&#x27;\n\n为对象动态赋予属性：\nclass Person():    passperson = Person()first_key = &#x27;name&#x27;first_value = &#x27;banana&#x27;setattr(person, first_key, first_value)print(person.name)  # bananaget_first_key = getattr(person, first_key)print(get_first_key)# banana\n\n升级一下：\nclass Person():    passperson = Person()person_info = &#123;&quot;first&quot;: &quot;Tom&quot;, &quot;last&quot;: &quot;Jenny&quot;&#125;for key, value in person_info.items():    setattr(person, key, value)print(person.first)  # Tomprint(person.last)  # Jenny\n\nclass Person(object):    def __init__(self, name, gender, **kwargs):        self.name = name        self.gender = gender        for k, v in kwargs.items():            # dict_items([(&#x27;age&#x27;, 25), (&#x27;love&#x27;, &#x27;reading&#x27;)])            setattr(self, k, v)p1 = Person(&quot;zyp&quot;, &#x27;male&#x27;, age=25, love=&quot;reading&quot;)# print(dir(p1))print(p1.age)print(p1.love)\n\n","categories":["技术"],"tags":["Python","Tricks"]},{"title":"基于华三交换机，限制其他网段的IP访问","url":"/posts/2020/05/03/58377/","content":"有时工作需要，需要限制某些网段的IP访问。\n以下操作在telnet上进行，基于hc交换机。\n\n需要被限制范文的设备是连接在203.2.1.1的交换机上，首先需要连接交换机，telnet 连接 203.2.1.1 或者 203.1.1.1  密码 xxxxxx\nPassword:&lt;L3&gt;&lt;L3&gt;system-viewSystem View: return to User View with Ctrl+Z.[L3]\n\n查看ACL，当前测试使用的是203.1.2网段，对应的acl规则号是3512\n[L3]acl number 3512[L3-acl-adv-3512]\n\n查看3512下的所有rule规则\n[L3-acl-adv-3512]di this#acl number 3512 rule 1 permit ip source 203.2.1.66 0 rule 2 permit ip source 203.2.1.48 0 rule 3 permit ip source 203.2.1.18 0 rule 4 permit ip source 203.2.1.36 0 rule 5 permit ip source 203.2.1.46 0 rule 6 permit ip source 203.2.1.50 0 rule 7 permit ip source 203.2.1.47 0 rule 100 deny ip source 209.0.0.0 0.255.255.255 rule 101 deny ip source 203.2.0.0 0.0.255.255 rule 102 deny ip source 203.1.1.0 0.0.0.255 rule 103 deny ip source 203.1.7.0 0.0.0.255\n\nrule后面的数字表示优先级，数字越小优先级越高。所以如果需要在某被限制的网段中添加白名单，需要将白名单IP的rule优先级，设置地比当前限制网段的rule优先级高。\n拿  rule 1 permit ip source 203.2.1.66 0 来看，这里的IP地址后面的0是通配符掩码，0代表，0.0.0.0，意味着这只允许一个IP地址 203.2.1.66 访问，换成其他如 203.2.1.67 就不可以了；假如需要1-254 都可以访问，那么后面的通配符就要变成，0.0.0.255，即比如  rule 1 permit ip source 203.2.1.47 0.0.0.255，0代表精确匹配，255代表模糊匹配。\n\n退出当前状态\n[L3-acl-adv-3501]qu[L3]qu&lt;L3&gt;\n\n添加限制规则\nrule 100 deny ip source 209.0.0.0 0.255.255.255  # 限制209网段的所有设备访问203.2.1.x rule 101 deny ip source 203.2.0.0 0.0.255.255  # 限制203.2.x.x网段设备访问203.2.1.x rule 102 deny ip source 203.1.1.0 0.0.0.255  # 限制203.1.1.x网段设备访问203.2.1.x \n\n添加白名单\nrule 1 permit ip source 203.2.1.66 0  # 允许203.2.1.66地址访问203.2.1.x \n\n删除规则\nundo rule 1 # 删除规则1undo rule 100 # 删除规则100\n\n使用 undo rule n 来删除配置的规则，n为优先级数字。\n\n以下操作很少用：\n\n查看当前交换机中wlan的所有acl： di cur\n[L3]di cur# version 5.20, Release 1211P03# sysname L3# clock timezone GTS-8 add 08:00:00# ftp server enable# irf mac-address persistent timer irf auto-update enable undo irf link-delay# domain default enable system# ipv6 ipv6 unreachables enable# telnet server enable# acl logging frequence 1440# multicast routing-enable#               acl number 2501   # 这些就是想要查看的acl number#acl number 3000   acl number 3001acl number 3014acl number 3015acl number 3500 description For_Vlan3011 rule 1 permit ip source 203.2.1.101 0 rule 2 permit ip source 203.5.1.239 0 rule 3 permit ip source 203.2.1.245 0\n\n配置acl\n# 接着上一步，选取di cur后的打印信息中的部分interface Vlan-interface3014 description PktFlt outb for Filtering packets from outside Vlan3014 ipv6 address 2001:0:0:104::1/64 ip address 203.1.4.1 255.255.255.0 igmp enable pim sm packet-filter 3501 outbound   # 可以看到这个网段已经配置了acl规则，number为3501#interface Vlan-interface3015 ip address 203.1.5.1 255.255.255.0  # 可以看到这个网段没有配置acl规则  pim sm#                            # 准备给 203.1.5.1 255.255.255.0 配置acl      [L3]interface Vlan-interface3015[L3-Vlan-interface3015]packet-filter 3515 outbound  # 选择一个不存在的acl数字，这里面number=3515[L3-Vlan-interface3015]di this#interface Vlan-interface3015 ip address 203.1.5.1 255.255.255.0 pim sm packet-filter 3515 outbound#return[L3-Vlan-interface3015]\n\n","categories":["技术","Network"],"tags":["network"]},{"title":"含元类、类装饰器的Python代码执行顺序","url":"/posts/2020/04/11/25962/","content":"通过学习《流畅的Python》这本书的第21章：类元编程，我算是系统地理清了Python代码的执行顺序，现在看到该书作者的这几个举例，我才算是真正明白。下面这个 evaltime.py 脚本值得多看几遍，加深理解。\n元类基础知识元类是制造类的工厂，不过不是函数，而是类。\n根据Python对象模型，类是对象，因此类肯定是另外某个类的实例。默认情况下，Python中的类是type类的实例。也就是说，type是大多数内置的类和用户定义的类的元类：\n&gt;&gt;&gt; &#x27;spam&#x27;.__class__ &lt;class &#x27;str&#x27;&gt; &gt;&gt;&gt; str.__class__ &lt;class &#x27;type&#x27;&gt; &gt;&gt;&gt; LineItem.__class__&lt;class &#x27;type&#x27;&gt; &gt;&gt;&gt; type.__class__ &lt;class &#x27;type&#x27;&gt;&gt;&gt;&gt; object.__class__&lt;class &#x27;type&#x27;&gt;\n\n为了避免无限回溯，type是其自身的实例。\n没有说 str 或 LineItem 继承自type。而是说，str和LineItem是type的实例。这两个类是object的子类。\n\n两个示意图都是正确的。左边的示意图强调 str、type和LineItem是object的子类。右边的示意图则清楚地表明str、object和LineItem是type的实例，因为它们都是类\nobject类和type类之间的关系很独特：object是type的实例，而type是object的子类。这种关系很“神奇”，无法使用Python代码表述，因为定义其中一个之前另一个必须存在。type是自身的实例这一点也很神奇。\n除了type，标准库中还有一些别的元类，例如ABCMeta和Enum。如下述代码片段所示，collections.Iterable所属的类是abc.ABCMeta。Iterable是抽象类，而ABCMeta不是——不管怎样，Iterable是ABCMeta的实例：\n&gt;&gt;&gt; import collections &gt;&gt;&gt; collections.Iterable.__class__ &lt;class &#x27;abc.ABCMeta&#x27;&gt; &gt;&gt;&gt; import abc &gt;&gt;&gt; abc.ABCMeta.__class__ &lt;class &#x27;type&#x27;&gt; &gt;&gt;&gt; abc.ABCMeta.__mro__ (&lt;class &#x27;abc.ABCMeta&#x27;&gt;, &lt;class &#x27;type&#x27;&gt;, &lt;class &#x27;object&#x27;&gt;)\n\n向上追溯，ABCMeta最终所属的类也是type。所有类都直接或间接地是type的实例，不过只有元类同时也是type的子类。若想理解元类，一定要知道这种关系：元类（如ABCMeta）从type类继承了构建类的能力。\n\n所有类都是type的实例，但是元类还是type的子类，因此可以作为制造类的工厂。\n\n理解元类计算时间的demo其中demo中用到的代码：\n# evaltime_meta.pyfrom evalsupport import deco_alphafrom evalsupport import MetaAlephprint(&#x27;&lt;[1]&gt; evaltime_meta module start&#x27;)@deco_alphaclass ClassThree():    print(&#x27;&lt;[2]&gt; ClassThree body&#x27;)    def method_y(self):        print(&#x27;&lt;[3]&gt; ClassThree.method_y&#x27;)class ClassFour(ClassThree):    print(&#x27;&lt;[4]&gt; ClassFour body&#x27;)    def method_y(self):        print(&#x27;&lt;[5]&gt; ClassFour.method_y&#x27;)# ClassFive 是 MetaAleph 元类的实例class ClassFive(metaclass=MetaAleph):    print(&#x27;&lt;[6]&gt; ClassFive body&#x27;)    def __init__(self):        print(&#x27;&lt;[7]&gt; ClassFive.__init__&#x27;)    def method_z(self):        print(&#x27;&lt;[8]&gt; ClassFive.method_z&#x27;)class ClassSix(ClassFive):    print(&#x27;&lt;[9]&gt; ClassSix body&#x27;)    def method_z(self):        print(&#x27;&lt;[10]&gt; ClassSix.method_z&#x27;)if __name__ == &#x27;__main__&#x27;:    print(&#x27;&lt;[11]&gt; ClassThree tests&#x27;, 30 * &#x27;.&#x27;)    three = ClassThree()    three.method_y()    print(&#x27;&lt;[12]&gt; ClassFour tests&#x27;, 30 * &#x27;.&#x27;)    four = ClassFour()    four.method_y()    print(&#x27;&lt;[13]&gt; ClassFive tests&#x27;, 30 * &#x27;.&#x27;)    five = ClassFive()    five.method_z()    print(&#x27;&lt;[14]&gt; ClassSix tests&#x27;, 30 * &#x27;.&#x27;)    six = ClassSix()    six.method_z()print(&#x27;&lt;[15]&gt; evaltime_meta module end&#x27;)\n\n\n场景1：evaltime_meta.py 被当做模块导入：&lt;[100]&gt; evalsupport module start&lt;[400]&gt; MetaAleph body&lt;[700]&gt; evalsupport module end&lt;[1]&gt; evaltime_meta module start&lt;[2]&gt; ClassThree body&lt;[200]&gt; deco_alpha&lt;[4]&gt; ClassFour body&lt;[6]&gt; ClassFive body&lt;[500]&gt; MetaAleph.__init__  # 与场景1的关键区别是，创建ClassFive时调用了MetaAleph.__init__方法。&lt;[9]&gt; ClassSix body&lt;[500]&gt; MetaAleph.__init__  # 创建ClassFive的子类ClassSix时也调用了MetaAleph.__init__方法。&lt;[15]&gt; evaltime_meta module end\n\nfrom evalsupport import deco_alpha在导入 deco_alpha 时，会执行 evalsupport 的所有顶层代码，所以有了上面结果的前3个打印输出。\n编写元类时，通常会把self参数改成cls。例如，在上述元类的 __init__ 方法中，把第一个参数命名为cls能清楚地表明要构建的实例是类。__init__方法的定义体中定义了inner_2函数，然后将其绑定给cls.method_z。MetaAleph.__init__ 方法签名中的cls指代要创建的类（例如ClassFive）。而inner_2函数签名中的self最终是指代我们在创建的类的实例（例如ClassFive类的实例）。\n\n场景2：执行evaltime_meta.py：&lt;[100]&gt; evalsupport module start&lt;[400]&gt; MetaAleph body&lt;[700]&gt; evalsupport module end&lt;[1]&gt; evaltime_meta module start&lt;[2]&gt; ClassThree body  # class ClassThree():有被装饰器 deco_alpha 修饰，执行完类后会执行装饰器函数。&lt;[200]&gt; deco_alpha&lt;[4]&gt; ClassFour body   # class ClassFour(ClassThree): 执行时，虽然继承了被装饰的ClassThree，但是ClassFour不会继承装饰器函数，因此不会ClassFour执行后，不会执行装饰器函数。&lt;[6]&gt; ClassFive body   # class ClassFive(metaclass=MetaAleph):执行后，需要执行元类的init函数，完成实例化。&lt;[500]&gt; MetaAleph.__init__&lt;[9]&gt; ClassSix body    # class ClassSix(ClassFive):继承ClassFive，所以会继承元类，执行完ClassSix后执行元类。&lt;[500]&gt; MetaAleph.__init__&lt;[11]&gt; ClassThree tests ..............................&lt;[300]&gt; deco_alpha:inner_1   # ClassThree被装饰器修饰而更改了method_y函数。&lt;[12]&gt; ClassFour tests ..............................&lt;[5]&gt; ClassFour.method_y   # 虽ClassFour是ClassThree的子类，但是没有像ClassThree依附装饰器而更改了method_y函数。&lt;[13]&gt; ClassFive tests ..............................&lt;[7]&gt; ClassFive.__init__&lt;[600]&gt; MetaAleph.__init__:inner_2  # ClassFive是MetaAleph元类的实例，在MetaAleph的init函数中把method_z绑定为inner_2&lt;[14]&gt; ClassSix tests ..............................&lt;[7]&gt; ClassFive.__init__     # ClassSix继承了ClassFive，所以six=ClassSix()实例化会执行ClassFive的init函数&lt;[600]&gt; MetaAleph.__init__:inner_2  # 同理，作为父类的ClassFive是MetaAleph元类的实例，所以ClassSix也是。&lt;[15]&gt; evaltime_meta module end\n\n注意，ClassSix 类没有直接引用MetaAleph类，但是却受到了影响，因为它是ClassFive的子类，进而也是MetaAleph类的实例，所以由MetaAleph.__init__ 方法初始化。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 上下文管理器","url":"/posts/2020/03/07/33832/","content":"上下文管理器和with块上下文管理器对象存在的目的是管理 with 语句，就像迭代器的存在是为了管理 for 语句一样。\nwith 语句的目的是简化 try&#x2F;finally 模式。这种模式用于保证一段代码运行完毕后执行某项操作，即便那段代码由于异常、return 语句或 sys.exit() 调用而中止，也会执行指定的操作。finally 子句中的代码通常用于释放重要的资源，或者还原临时变更的状态。\n上下文管理器协议包含 __enter__ 和 __exit__ 两个方法。with 语句开始运行时，会在上下文管理器对象上调用 __enter__ 方法。with 语句运行结束后，会在上下文管理器对象上调用 __exit__  方法，以此扮演 finally 子句的角色。\nwith 语句会设置一个临时的上下文，交给上下文管理器对象控制，并且负责清理上下文。这么做能避免错误并减少样板代码，因此 API 更安全，而且更易于使用。除了自动关闭文件之外，with 块还有很多用途。\n最常见的例子是确保关闭文件对象：\nwith open(&quot;a5_3_with.py&quot;) as f:    content = f.read(100)print(f)  # fp 变量仍然可用# &lt;_io.TextIOWrapper name=&#x27;a5_3_with.py&#x27; mode=&#x27;r&#x27; encoding=&#x27;cp936&#x27;&gt;print(len(content))  # 100print(f.closed, f.encoding)# True cp936# f.read(10)  # ValueError: I/O operation on closed file.# 不能在 fp 上执行 I/O 操作，因为在 with 块的末尾，调用TextIOWrapper.__exit__方法把文件关闭了。\n\n执行 with 后面的表达式得到的结果是上下文管理器对象，不过，把值绑定到目标变量上（as 子句）是在上下文管理器对象上调用 __enter__ 方法的结果。\n不管控制流程以哪种方式退出 with 块，都会在上下文管理器对象上调用 __exit__ 方法，而不是在 __enter__ 方法返回的对象上调用。\nwith 语句的 as 子句是可选的。对 open 函数来说，必须加上 as 子句，以便获取文件的引用。不过，有些上下文管理器会返回 None，因为没什么有用的对象能提供给用户。\n\n上下文管理器与 __enter__ 方法返回的对象之间的区别：\nclass LookingGlass():    def __enter__(self):  # ❶        import sys        self.origin_write = sys.stdout.write  # ❷        sys.stdout.write = self.reverse_write  # ❸        return &quot;reversed word -&gt; drow desrever&quot;  # ❹    def reverse_write(self, context):  # ❺        self.origin_write(context[::-1])    def __exit__(self, exc_type, exc_val, exc_tb): # ❻        import sys  # ❼        sys.stdout.write = self.origin_write  # ❽        if exc_type is ZeroDivisionError:  # ❾            print(&quot;do not divide by zero&quot;)            return True  # ❿        # ⓫with LookingGlass() as look:    print(&quot;I&#x27;m looking sth.&quot;)    print(look)    # .hts gnikool m&#x27;I# reversed word&gt;-drow desrever\n\n\n❶除了self之外，Python调用__enter__方法时不传入其他参数。\n❷ 把原来的sys.stdout.write方法保存在一个实例属性中，供后面使用。\n❸ 为sys.stdout.write打猴子补丁，替换成自己编写的方法。\n❹ 返回’reversed word -&gt; drow desrever’字符串，这样才有内容存入目标变量look。\n❺ 这是用于取代sys.stdout.write的方法，把text参数的内容反转，然后调用原来的实现。\n❻ 如果一切正常，Python调用__exit__方法时传入的参数是None, None, None；如果抛出了异常，这三个参数是异常数据，如下所述。\n❼ 重复导入模块不会消耗很多资源，因为Python会缓存导入的模块。\n❽ 还原成原来的sys.stdout.write方法。\n❾ 如果有异常，而且是ZeroDivisionError类型，打印一个消息……\n❿ ……然后返回True，告诉解释器，异常已经处理了。\n⓫ 如果 __exit__ 方法返回None，或者True之外的值，with块中的任何异常都会向上冒泡。\n\n传给 __exit__ 方法的三个参数列举如下。\n\nexc_type：异常类（例如 ZeroDivisionError）；\n\nexc_value：异常实例，有时会有参数传给异常构造方法，例如错误消息，这些参数可以使用 exc_value.args 获取；\n\nexc_tb：traceback 对象；\n\n\n\n在 with 块之外使用 LookingGlass 类：\nmanager = LookingGlass()print(manager)content = manager.__enter__()print(&quot;12345&quot;)print(manager)print(content)&#x27;&#x27;&#x27;&lt;__main__.LookingGlass object at 0x0000019F7625D828&gt;54321&gt;828D5267F9100000x0 ta tcejbo ssalGgnikooL.__niam__&lt;reversed word &gt;- drow desrever&#x27;&#x27;&#x27;\n\n\ncontextlib模块中的实用工具@contextmanager 装饰器能减少创建上下文管理器的样板代码量，因为不用编写一个完整的类，定义 __enter__ 和 __exit__ 方法，而只需实现有一个 yield 语句的生成器，生成想让__enter__ 方法返回的值。\n在使用 @contextmanager 装饰的生成器中，yield 语句的作用是把函数的定义体分成两部分：yield 语句前面的所有代码在 with 块开始时（即解释器调用 __enter__ 方法时）执行，yield 语句后面的代码在 with 块结束时（即调用 __exit__ 方法时）执行。\nfrom contextlib import contextmanager@contextmanagerdef lookingmirror():    import sys    oringin_write = sys.stdout.write    def reverse_write(text):        # 定义自定义的 reverse_write 函数；在闭包中可以访问 original_write。        oringin_write(text[::-1])    sys.stdout.write = reverse_write    # 产出一个值，这个值会绑定到 with 语句中 as 子句的目标变量上。    # 执行 with 块中的代码时，这个函数会在这一点暂停。    msg = &#x27;&#x27;    try:        yield &quot;lookingmirror func&quot;    except ZeroDivisionError as e:        msg = e    finally:        # 控制权一旦跳出 with 块，继续执行 yield 语句之后的代码；        # 这里是恢复成原来的 sys.stdout.write 方法。        sys.stdout.write = oringin_write        if msg:            print(msg)with lookingmirror() as l:    print(l)    print(&quot;12345&quot;)    # cnuf rorrimgnikool# 54321\n\n其中，如果在 with 块中抛出了异常，Python 解释器会将其捕获，然后在 lookingmirror 函数的 yield 表达式里再次抛出。但是，如果那里没有处理错误的代码，lookingmirror 函数会中止，永远无法恢复成原来的 sys.stdout.write 方法，导致系统处于无效状态，所以使用try来处理异常。\n使用 @contextmanager 装饰器时，要把 yield 语句放在 try&#x2F;finally 语句中（或者放在 with 语句中），这是无法避免的，因为我们永远不知道上下文管理器的用户会在 with 块中做什么。\ncontextlib.contextmanager 装饰器会把函数包装成实现 __enter__ 和 __exit__ 方法的类，通过debug可以进入源码看到类 _GeneratorContextManager 。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python中常见的术语","url":"/posts/2020/04/19/45213/","content":"已经有两年多的Python使用经验了，也看了一些Python方面的书籍、视频教程，做了很多笔记，但是在学习《流畅的Python》，将最后术语表章节copy整理时，发现很多知识点虽然我知道、会用，但是让我像书中那样讲清楚，甚至举相关的demo来解释，我可能有点虚，还是需要查阅相关的文档才行，毕竟很多点很细，工作实践中使用的很粗，要想深耕这片领域，需要不断地学习。\n\nPython术语表\nCPython标准的Python解释器，使用C语言实现。讨论不同实现特有的行为，以及多个可用的Python解释器（如PyPy）时才会使用这个术语。\nCRUDCreate、Read、Update、Delete的首字母缩写，这是存储记录的应用程序中的四种基本操作。\ndoctest一个模块，其中的函数能解析并运行 Python 模块或纯文本文件的文档字符串中内嵌的示例。也可以在命令行中使用，如下所示：python -m doctes module_with_tests.py\nDRYDon’t Repeat Yourself（不要自我重复）的缩写，一种软件工程原则，意思是：“系统中的每一项知识都必须具有单一、无歧义、权威的表示。”首先由 Andy Hunt 与 Dave Thomas 的《程序员修炼之道：从小工到专家》一书提出。\ndunder首尾有两条下划线的特殊方法和属性的简洁读法（即把__len__读成“dunder len”）。\nEAFP“it’s easier to ask forgiveness than permission”（取得原谅比获得许可容易）的首字母缩写。人们认为这句话是计算机先驱Grace Hopper说的，Python程序员使用这个缩写指代一种动态编程方式，例如访问属性前不测试有没有属性，如果没有就捕获异常。 hasattr函数的文档字符串是这样描述它的工作方式的：“调用getattr(object,name)，然后捕获AttributeError异常。”\ngenexpgenerator expression（生成器表达式）的简称。\nKISS原则KISS是“Keep It Simple, Stupid”的首字母缩写。这个原则要求尽量寻找最简单的方案，尽量减少可变部分。这个警句是Kelly Johnson首创的。Kelly是一位多才多艺的航空工程师，在真实存在的51区工作，设计出了20世纪最先进的几架航天飞机。\nlistcomplist comprehension（列表推导）的简称。\nORMObject-Relational Mapper（对象关系映射器）的缩写，通过这种API可以使用Python类和对象访问数据库中的表和记录，而且调用方法可以执行数据库操作。SQLAlchemy是流行的独立Python ORM，Django和Web2py自带了ORM。\nPyPIPython包索引，里面有超过60000个包可用。也叫奶酪店（参见奶酪店词条）。为了防止与PyPy混淆，PyPI应该读作“pie-P-eye”。\nPyPyPython编程语言的另一种实现，使用一个工具链把部分Python编译成机器码，因此解释器的源码其实是使用Python编写的。PyPy还提供了JIT，即时把用户的程序编译成机器码——与Java VM的作用相同。根据PyPy公布的基准测试，从2014年11月起，PyPy平均比CPython快6.8倍。为了防止与PyPI混淆， PyPy应该读作“pie-pie”。\nPythonic用于赞扬符合Python风格的代码，即充分利用Python语言的特性，写出简洁明了、可读性强，通常运行速度也快的代码。还指API符合Python高手的编程方式。\nPython之禅从Python 2.2起，在Python控制台中输入import this后看到的输出。\nREPLread-eval-print loop（读取－求值－输出循环）的简称，一种交互式控制台，如标准的python或非主流的ipython和bpython，以及Python Anywhere。\nYAGNIYou Ain’t Gonna Need It（你不需要这个）的首字母缩写，这个口号的意思是，根据对未来需求的预测，不要实现非立即需要的功能。\n绑定方法（bound method）通过实例访问的方法会绑定到那个实例上。方法其实是描述符，访问方法时，会返回一个包装自身的对象，把方法绑定到实例上。那个对象就是绑定方法。调用绑定方法时，可以不传入self的值。例如，像my_method=my_obj.method 这样赋值之后，可通过my_method()调用绑定方法。请与非绑定方法相比较。\n编码解码器（codec）:（编码器&#x2F;解码器）提供编码和解码函数的模块，通常在str和bytes之间转换，不过Python也提供了在bytes和bytes，以及str和str之间转换的编码解码器。\n别名（aliasing）:为同一个对象指定两个或多个名称。例如，在a&#x3D;[]; b&#x3D;a中，a和b是别名，指向同一个列表对象。对于把对象引用存储在变量中的语言来说，别名无处不在。为了避免混淆，要摒弃这种想法：变量是存储对象的盒子（毕竟同一个对象不可能放在两个盒子里）。我们要把变量看做对象的标注（一个对象可以有多个标注）。\n并行赋值（parallel assignment）:使用类似a, b&#x3D;[c, d]这样的句法，把可迭代对象中的元素赋值给多个变量，也叫解构赋值。这是元组拆包的常见用途。\n抽象基类（abstract base class，ABC）:无法实例化，只能扩展的类。Python通过ABC实现接口。除了继承ABC之外，类还可以注册成为ABC的虚拟子类，声明自己实现了接口。\n初始化方法（initializer）:__init__ 方法更贴切的名称（取代构造方法）。__init__方法的任务是初始化通过self参数传入的实例。实例其实是由 __new__ 方法构建的。\n存取方法（accessor）:用于存取单个数据属性的方法。有些作者把存取方法当作通用术语使用，包括读值方法和设值方法；另一些作者则用存取方法指代读值方法，而用变值方法指代设值方法。\n代码异味（code smell）:一种代码形式，表明程序的设计可能有问题。例如，过度使用isinstance检查具体的类是一种代码异味，因为这样会导致程序以后难以扩展，无法处理新类型。\n单例（singleton）:一个类唯一存在的实例——这通常不是巧合，而是故意为之，防止类创建多个实例。有一种设计模式就叫单例模式，指明如何编写这样的类。在Python中，None对象是单例。\n导入时（import time）:Python解释器加载模块，从上到下计算，把里面的代码编译成字节码之后，开始执行模块的那一刻。类和函数在此时定义，变成真实存在的对象。装饰器也在此时执行。\n迭代器（iterator）:实现了无参数方法__next__的对象；这个方法返回级数里的下一个元素，如果没有元素了就抛出StopIteration异常。在Python中，迭代器还实现了__iter__方法，因此迭代器也是可迭代的对象。根据最初的设计模式，经典迭代器返回集合里的元素。生成器也是迭代器，不过更灵活。 \n生成器（generator）：使用生成器函数或生成器表达式构建的迭代器，无需迭代集合就可能生成值。生成斐波纳契数列的生成器是个典型示例，这是一种无穷数列，在集合中绝对放不下。这个术语除了表示调用生成器函数得到的对象之外，有时还表示生成器函数。\n生成器表达式（generator expression）：放在括号里的表达式，句法与列表推导一样，不过返回的不是列表，而是生成器。生成器表达式可以理解为列表推导的惰性版本。\n生成器函数（generator function）：放在括号里的表达式，句法与列表推导一样，不过返回的不是列表，而是生成器。生成器表达式可以理解为列表推导的惰性版本。\n惰性求值（lazy）:指可迭代的对象按需生成元素。在Python中，生成器会惰性求值。\n二进制序列（binary sequence）:一个通用术语，表示元素是二进制数据的序列类型。内置的二进制序列类型有byte、bytearray和memoryview。\n泛函数（generic function）:以不同的方式为不同类型的对象实现相同操作的一组函数。从Python 3.4起，创建泛函数的标准方式是使用functools.singledispatch装饰器。在其他语言中，这叫多分派方法。\n非绑定方法（unbound method）:直接通过类访问的实例方法没有绑定到特定的实例上，因此把这种方法称为“非绑定方法”。若想成功调用非绑定方法，必须显式传入类的实例作为第一个参数。那个实例会赋值给方法的self参数。参见绑定方法词条。\n描述符（descriptor）：一个类，实现__get__、__set__ 和 __delete__ 特殊方法中的一个或多个，其实例作为另一个类（托管类）的类属性。描述符管理托管类中托管属性的存取和删除，数据通常存储在托管实例中。\n非覆盖型描述符（nonoverriding descriptor）:未实现__set__方法的描述符，不干涉托管实例中托管属性的设置。因此，托管实例中的同名属性会遮盖实例中的描述符。也叫非数据描述符或遮盖型描述符。请与覆盖型描述符相比较。\n覆盖型描述符（overriding descriptor）:实现了__set__方法的描述符，设置托管实例中的托管属性时会遭到拦截并覆盖相关操作。也叫数据描述符或强制描述符。请与非覆盖型描述符相比较。\n高阶函数（higher-order function）:以其他函数为参数的函数，例如sorted、map和filter；或者，返回值为函数的函数，例如Python中的装饰器。\n构造方法（constructor）:类的__init__实例方法称为类的构造方法，因为这个方法的语义类似于Java中的构造方法。然而，这样称呼并不规范，__init__更应该称为初始化方法，因为它并不会构建实例，而是把实例传给self参数。Python在__init__方法之前调用的__new__类方法更合乎构造方法这个术语，__new__方法才会创建实例并将其返回。参见初始化方法词条。\n函数（function）:严格来说，是指 def 块或 lambda 表达式计算得到的对象。通常，函数这个词用于表示任何可调用的对象，例如方法，有时甚至表示类。官方文档中的内置函数列表列出了几个内置的类，例如dict、range和str。另见可调用的对象词条。\n猴子补丁（monkey patching）:在运行时动态修改模块、类或函数，通常是添加功能或修正缺陷。猴子补丁在内存中发挥作用，不会修改源码，因此只对当前运行的程序实例有效。因为猴子补丁破坏了封装，而且容易导致程序与补丁代码的实现细节紧密耦合，所以被视为临时的变通方案，不是集成代码的推荐方式。\n混入方法（mixin method）:抽象基类或混入类中方法的具体实现。\n混入类（mixin class）:用于随着多重继承类树中的一个或多个类一起扩展的类。混入类绝不能实例化，它的具体子类也应该是其他非混入类的子类。\n活性（liveness）:异步系统、线程系统或分布式系统在“期待的事情终于发生”（即虽然期待的计算不会立即发生，但最终会完成）时展现出来的特性叫活性。如果系统死锁了，活性也就没有了。\n及早求值（eager）:指可迭代对象一次构建好全部元素。在Python中，列表推导会及早求值。请与惰性求值相比较。\n集合（collection）:泛指由元素组成，可以单独访问各个元素的数据结构。有些集合可以包含任意类型的对象（参见容器词条），有些则只能包含一种原子类型的对象（参见平坦序列词条）。list和bytes都是集合，只不过list是容器，而bytes是平坦序列。\n假值（falsy）:只要bool(x)返回False，x就是假值。需要布尔值时，Python会隐式使用bool计算对象，例如控制if和while循环的表达式。与此相对的是真值（truthy）。\n尽早失败（fail-fast）:一种系统设计方式，建议应该尽早报告错误。Python比其他大多数动态编程语言更遵守这一原则。例如，Python中没有“未定义”的值：在初始化之前引用变量会报错；如果k不存在，my_dict[k]会抛出异常（JavaScript则不然）。还有一例：在Python中通过元组拆包做并行赋值，必须显式处理元组的每一个元素才行；而在Ruby中，如果&#x3D;两边的元素数量不一致，右边未用到的元素会被忽略，或者把nil赋给左边多余的变量。\n可迭代的（iterable）:使用内置的iter函数可以从中获得迭代器的对象。可迭代的对象为for循环、列表推导和元组拆包提供元素。如果对象的__iter__方法能返回迭代器，这就是可迭代的对象。序列都是可迭代的对象；此外，实现__getitem__ 方法的对象也是可迭代的对象。\n可散列的（hashable）:在散列值永不改变，且如果a==b，那么hash(a)==hash(b)也是True的情况下，如果对象既有__hash__方法，也有__eq__方法，那么这样的对象称为可散列的对象。在内置的类型中，大多数不可变的类型都是可散列的；但是，仅当元组的每一个元素都是可散列的时，元组才是可散列的。\n可调用的对象（callable object）：可以使用调用运算符（）调用，能返回结果或执行某项操作的对象。在Python中，可调用的对象有七种：用户定义的函数、内置的函数、内置的方法、实例方法、生成器函数、类，还有实现特殊方法__call__的类的实例。\n类型（type）:程序中的各种数据，限定可取的值和可对数据做的操作。有些Python类型近似于机器数据类型（例如float和bytes），而另一些则是机器数据类型的扩展（例如，int不受CPU字长的限制，str包含多字节Unicode数据码位）和特别高层的抽象（例如dict、 deque，等等）。类型分为两类：用户定义的类型和解释器内置的类型。在Python2.2统一类型和类之前，类型和类是不同的实体，用户定义的类不能扩展内置的类型。而在那之后，内置的类型和新式类兼容了，类是type的实例。在Python 3中，所有类都是新式类。\n列表推导（list comprehension）:放在方括号里的表达式，使用关键字for和in，通过处理和过滤一个或多个可迭代对象里的元素构建列表。列表推导会及早求值。\n码位（code point）：介于0~0x10FFFF之间的整数，用于标识Unicode字符数据库中的字符。截至Unicode 7.0，所有码位中只有不到3%指定了字符。在Python文档中，这个术语可能拼成一个词，也可能拼成两个词。例如，在Python标准库参考手册的“2. Built-in Functions”一章中，说char函数的参数是一个整数“码位”（codepoint），却说作用相反的ord函数返回一个“Unicode码位”（Unicode code point）。\n名称改写（name mangling）:Python解释器在运行时自动把私有属性__x重命名为_MyClass__x。\n内置函数（built-in function，BIF）:随Python解释器一起提供的函数，使用底层实现语言（也就是说，CPython用C语言， Jython用Java，以此类推）编写。这个术语通常指代无需导入就能使用的函数，参见Python标准库参考手册中的“2. Built-in Functions”一章。不过，内置的模块（如sys、math、re等）也包含内置函数。\n平坦序列（flat sequence）:这种序列类型存储的是元素的值本身，而不是其他对象的引用。内置的类型中， str、bytes、bytearray、memoryview 和 array.array 是平坦序列；而list、tuple和collections.deque是容器序列。容器：包含其他对象引用的对象。\n切片（slicing）:使用切片表示法生成序列的子集，例如my_sequence[2:6]。切片经常复制数据，生成新对象；然而，my_sequence[:]是对整个序列的浅复制。不过，memoryview对象的切片虽是一个memoryview新对象，但会与源对象共享数据。\n弱引用（weak reference）：一种特殊的对象引用方式，不计入指示对象的引用计数。弱引用使用 weakref 模块里的某个函数和数据结构创建。\n指示对象（referent）：引用的目标对象。谈及弱引用时最常使用这个术语。\n上下文管理器（context manager）：实现了 __enter__ 和 __exit__ 特殊方法的对象，在with块中使用。\n蛇底式（snake_case）:标识符的一种命名约定，使用下划线（_）连接单词，例如run_until_complete。PEP-8把这种风格称为“使用下划线分隔的小写单词”，建议用于命名函数、方法、参数和变量。PEP-8建议包名直接把各个单词拼接起来，不使用分隔符。Python标准库中有很多使用蛇底式命名的标识符，不过也有单词之间没有分隔的标识符（例如，getattr、classmethod、isinstance、str.endswith，等等）。\n驼峰式（CamelCase）：驼峰式（CamelCase）标识符的一种命名约定，单词的首字母大写，然后连接起来（例如ConnectionRefusedError）。PEP-8建议类名使用驼峰式，但是Python标准库没有遵守这个建议。\n深复制（deep copy）:复制对象时把对象的所有属性一起复制。\n视图（view）：在Python 3中，视图是一种特殊的数据结构，由字典的 .keys()、.values() 和 .items() 方法返回，作用是在不重复数据的前提下，提供字典的键和值的动态视图。在Python 2中，那些方法返回的是列表。字典视图都是可迭代的对象，支持in运算符。此外，如果视图引用的元素都是可散列的对象，那么视图还实现了collections.abc.Set接口。.keys()方法返回的视图都是这样；对 .items()方法返回的视图来说，如果其中的值都是可散列的对象，那么也是如此。\n属性（attribute）：在Python中，方法和数据属性（即Java术语中的“字段”）都是属性。方法也是属性，只不过恰好是可调用的对象（通常是函数，但也不一定）。\n统一访问原则（uniform access principle）：Eiffel语言之父Bertrand Meyer写道：“不管服务是由存储还是计算实现的，一个模块提供的所有服务都应该通过统一的方式使用。”在Python中，可以使用特性和描述符实现统一访问原则。由于没有new运算符，函数调用和对象实例化看起来相似，这也体现了这一原则：调用方无需知道被调用的对象是类、函数，还是其他可调用的对象。\n储存属性（storage attribute）:托管实例中的属性，用于存储由描述符管理的属性的值。\n托管类（managed class）：使用描述符对象管理类中某个属性的类。\n托管属性（managed attribute）：由描述符对象管理的公开属性。虽然托管属性在托管类中定义，但是作用相当于实例属性（即各个实例通常有各自的值，存储在储存属性中）。\n文档字符串（docstring）：documentation string的简称。如果模块、类或函数的第一个语句是字符串字面量，那个字符串会当作所在对象的文档字符串，解释器把那个字符串存储在对象的 __doc__ 属性中。\n像文件的对象（file-like object）:官方文档使用的一个非正式称呼，指代实现了文件协议的对象，有read、write和close等方法。常见的变体有：逐行读写，包含编码字符串的纯文本文件；作为保存在内存中的纯文本文件的StringIO实例；包含未编码的字节的二进制文件。最后一种可能有缓冲，也可能没有缓冲。从Python 2.6起，这些标准文件类型的抽象基类在io模块里。\n像字节的对象（bytes-like object）:泛指字节序列。最常见的像字节的类型有bytes、bytearray和memoryview；不过，支持低层CPython缓冲协议的对象，如果元素是单个字节，那么也属于此类。\n协程（coroutine）:用于并发编程的生成器，从调度程序，或者通过 coro.send(value)方法从事件循环中接收值。这个术语可以表示通过调用生成器函数获得的生成器函数或生成器对象。 \n虚拟子类（virtual subclass）:不继承自超类，而是使用 TheSuperClass.register(TheSubClass) 注册的类。\n序列（sequence）:泛指长度（例如，len(s)）固定，可以使用从零开始的整数索引（例如s[0]）获取元素的数据结构。Python出现伊始，序列这个词就存在了，不过直到Python 2.6才由collections.abc.Sequence确定为一个抽象类。\n序列化（serialization）:把对象在内存中的结构转换成便于存储或传输的二进制或文本格式，而且以后可以在同一个系统或不同的系统中重建对象的副本。pickle模块能把任何Python对象序列化成二进制格式。\n鸭子类型（duck typing）:多态的一种形式，在这种形式中，不管对象属于哪个类，也不管声明的具体接口是什么，只要对象实现了相应的方法，函数就可以在对象上执行操作。\n一等函数（first-class function）:在语言中属于一等对象的函数（即能在运行时创建，赋值给变量，当作参数传入，以及作为另一个函数的返回值）。Python中的函数都是一等函数。\n引用计数（refcount）:CPython内部对各个对象的引用计数，用于确定垃圾回收程序何时销毁对象。\n用户定义的（user-defined）:在Python文档中，用户这个词几乎都是指我和你，即使用Python语言的程序员。用户与实现Python解释器的开发者是相对的。因此，“用户定义的类”表示使用Python编写的类，而不是使用C语言编写的内置类，如str。\n预激（prime，动词）:在协程上调用next(coro)，让协程向前运行到第一个yield表达式，准备好从后续的 coro.send(value) 调用中接收值。\n元编程（metaprogramming）:编写的程序使用程序的运行时信息改变程序的行为。例如，ORM可能会内省模型类的声明，确定如何验证数据库记录里的字段，以及如何把数据库类型转换成Python类型。\n元类（metaclass）:实例为类的类。默认情况下，Python中的类是type类的实例；例如，type(int)得到的结果是type类，因此type是元类。用户可以通过扩展type类定义元类。\n元组拆包（tuple unpacking）:把可迭代对象中的元素赋值给多个变量（例如，first, second, third&#x3D;&#x3D;my_list）。Python高手通常使用这个术语，不过也有人使用可迭代对象的拆包。\n装饰器（decorator）：一个可调用的对象A，返回另一个可调用的对象B，在可调用的对象C的定义体之前使用句法@A调用。Python解释器读取这样的代码时，会调用A(C)，把返回的B绑定给之前赋予C的变量，也就是把C的定义体换成B。如果目标可调用对象C是函数，那么A是函数装饰器；如果C是类，那么A是类装饰器。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 从协议到抽象基类","url":"/posts/2020/01/29/62496/","content":"序列定义为抽象基类的 Sequence 正式接口：\n\nSequence 抽象基类和 collections.abc 中相关抽象类的 UML 类图，箭头由子类指向超类，以斜体显示的是抽象方法。\ndemo：\n类Foo，它没有继承 abc.Sequence，而且只实现了序列协议的一个方法：__getitem__（没有实现 __len__ 方法），这样足够访问元素、迭代和使用 in 运算符了。\n如果没有 __iter__ 和 __contains__ 方法，Python 会调用__getitem__ 方法，设法让迭代和 in 运算符可用。\n&gt;&gt;&gt; class Foo:\tdef __getitem__(self, pos):\t\treturn range(0, 30, 10)[pos]&gt;&gt;&gt; f = Foo()&gt;&gt;&gt; f[1]10&gt;&gt;&gt; for i in f:\tprint(i)01020&gt;&gt;&gt; 20 in fTrue&gt;&gt;&gt; 15 in fFalse\n\n第 1 章定义的 FrenchDeck 类也没有继承 abc.Sequence，但是实现了序列协议的两个方法__getitem__ 和 __len__。\nimport collectionsCard = collections.namedtuple(&#x27;Card&#x27;, [&#x27;rank&#x27;, &#x27;suit&#x27;])class FrenchDeck:    ranks = [str(n) for n in range(2, 11)] + list(&#x27;JQKA&#x27;)    suits = &#x27;spades diamonds clubs hearts&#x27;.split()  # 黑桃 方块 梅花 红心    def __init__(self):        self._cards = [Card(rank, suit) for suit in self.suits                       for rank in self.ranks]    def __len__(self):        return len(self._cards)    def __getitem__(self, position):        return self._cards[position]\n\n\n猴子补丁使用猴子补丁在运行时实现协议。\nFrenchDeck 类有个大缺陷：无法洗牌，如果尝试使用shuffle打乱 FrenchDeck 实例，会出现异常。\n&gt;&gt;&gt; from random import shuffle&gt;&gt;&gt; l = list(range(10))&gt;&gt;&gt; l[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; shuffle(l)&gt;&gt;&gt; l[8, 6, 0, 5, 2, 1, 9, 7, 3, 4]\n\n&gt;&gt;&gt; deck = FrenchDeck()&gt;&gt;&gt; &gt;&gt;&gt; shuffle(deck)Traceback (most recent call last):  File &quot;&lt;pyshell#54&gt;&quot;, line 1, in &lt;module&gt;    shuffle(deck)  File &quot;D:\\Python3.6.0\\lib\\random.py&quot;, line 274, in shuffle    x[i], x[j] = x[j], x[i]TypeError: &#x27;FrenchDeck&#x27; object does not support item assignment\n\n报错原因是，shuffle 函数要调换集合中元素的位置，而FrenchDeck 只实现了不可变的序列协议。可变的序列还必须提供 __setitem__ 方法。Python 是动态语言，因此我们可以在运行时修正这个问题，甚至还可以在交互式控制台中。\n为 FrenchDeck 打猴子补丁，把它变成可变的，让 random.shuffle 函数能处理：\n&gt;&gt;&gt; def set_card(self, position, card):\tself._cards[position] = card&gt;&gt;&gt; FrenchDeck.__setitem__ = set_card&gt;&gt;&gt; shuffle(deck)&gt;&gt;&gt; deck[:5][Card(rank=&#x27;A&#x27;, suit=&#x27;hearts&#x27;), Card(rank=&#x27;5&#x27;, suit=&#x27;diamonds&#x27;), Card(rank=&#x27;6&#x27;, suit=&#x27;spades&#x27;), Card(rank=&#x27;6&#x27;, suit=&#x27;clubs&#x27;), Card(rank=&#x27;3&#x27;, suit=&#x27;diamonds&#x27;)]\n\n特殊方法 __setitem__  中默认用的参数是 self、key 和 value，而这里使用的是 self、position 和 card。这么做是为了表达：每个 Python 方法说到底都是普通函数，把第一个参数命名为 self 只是一种约定。在控制台会话中使用那几个参数没问题，不过在 Python 源码文件中最好按照文档那样使用 self、key 和 value。\n这里的关键是，set_card 函数要知道 deck 对象有一个名为 _cards 的属性，而且 _cards 的值必须是可变序列。然后，把 set_card 函数赋值给特殊方法 __setitem__，从而把它依附到 FrenchDeck 类上。这种技术叫 猴子补丁：在运行时修改类或模块，而不改动源码。 猴子补丁很强大，但是打补丁的代码与要打补丁的程序耦合十分紧密，而且往往要处理隐藏和没有文档的部分。\n示例还说明了协议是动态的：random.shuffle 函数不关心参数的类型，只要那个对象实现了部分可变序列协议即可。即便对象一开始没有所需的方法也没关系，后来再提供也行。\n本章讨论的主题是 “鸭子类型”：对象的类型无关紧要，只要实现了特定的协议即可。\n\n定义抽象基类的子类这里先利用现有的抽象基类（collections.MutableSequence），然后再自己定义。在示例中，明确把 FrenchDeck2 声明为 collections.MutableSequence 的子类。\nimport collectionsCard = collections.namedtuple(&#x27;Card&#x27;, [&#x27;rank&#x27;, &#x27;suit&#x27;])class FrenchDeck2(collections.MutableSequence):    ranks = [str(n) for n in range(2, 11)] + list(&#x27;JQKA&#x27;)    suits = &#x27;spades diamonds clubs hearts&#x27;.split()  # 黑桃 方块 梅花 红心    def __init__(self):        self._cards = [Card(rank, suit) for suit in self.suits                       for rank in self.ranks]    def __len__(self):        return len(self._cards)    def __getitem__(self, position):        return self._cards[position]    # 为了支持洗牌，只需要实现__setitem__方法    def __setitem__(self, position, value):        self._cards[position] = value    # 继承MutableSequence类，必须实现它的一个抽象方法__delitem__    def __delitem__(self, position):        del self._cards[position]    # 还要实现 insert 方法，这是 MutableSequence 类的第三个抽象方法。    def insert(self, position, value):        self._cards.insert(position, value)french = FrenchDeck2()\n\n导入时（加载并编译 上述代码所在的 模块时），Python 不会检查抽象方法的实现，在运行时实例化 FrenchDeck2 类时才会真正检查。如果没有正确实现某个抽象方法，Python 会抛出 TypeError 异常：TypeError: Can&#39;t instantiate abstract class FrenchDeck2 with abstract methods __delitem__, __setitem__, insert。正是这个原因，即便 FrenchDeck2 类不需要 __delitem__ 和 insert 提供的行为，也要实现，因为 MutableSequence 抽象基类需要它们。\nSequence 和 MutableSequence 抽象基类的方法不全是抽象的：下面是MutableSequence 抽象基类和 collections.abc 中它的超类的 UML 类图（箭头由子类指向祖先；以斜体显示的名称是抽象类和抽象方法）。FrenchDeck2 从 Sequence 继 承 了 几 个 拿 来 即 用 的 具 体 方 法：__contains__ 、__iter__、 __reversed__、index 和 count 。FrenchDeck2 从 MutableSequence 继 承 了 append、extend、pop、remove 和 __iadd__。\n\n标准库中的基类从 Python 2.6 开始，标准库提供了抽象基类。大多数抽象基类在 collections.abc 模块中定义，不过其他地方也有。例如，numbers 和 io 包中有一些抽象基类。但是，collections.abc 中的抽象基类最常用。\n标准库中有两个名为 abc 的模块，这里说的是 collections.abc。为了减少加载时间，Python 3.4 在 collections 包之外实现这个模块（在 Lib/_collections_abc.py 中 https://hg.python.org/cpython/file/3.4/Lib/_collections_abc.py ），因此要与 collections 分开导入。另一个 abc 模块就是 abc（即 Lib/abc.py，https://hg.python.org/cpython/file/3.4/Lib/abc.py），这里定义的是 abc.ABC 类。每个抽象基类都依赖这个类，但是不用导入它，除非定义新抽象基类。\ncollections.abc 模块中的抽象基类Python 3.5 在 collections.abc 模块中定义了 22 个抽象基类，简要的 UML 类图（没有属性名称）。collections.abc 的官方文档中有个不错的表格（https://docs.python.org/3.7/library/collections.abc.html#collections-abstract-base-classes），对各个抽象基类做了总结，说明了相互之间的关系，以及各个基类提供的抽象方法和具体方法（称为“混入方法”）。图中有很多多重继承。\n\nIterable、Container 和 Sized各个集合应该继承这三个抽象基类，或者至少实现兼容的协议。Iterable 通过 __iter__ 方法支持迭代，Container 通过 __contains__ 方法支持 in 运算符，Sized 通过 __len__ 方法支持 len() 函数。\n\nSequence、Mapping 和 Set\n这三个是主要的不可变集合类型，而且各自都有可变的子类。\n\nMappingView\n在 Python 3 中，映射方法 .items()、.keys() 和 .values() 返回的对象分别是 ItemsView、KeysView 和 ValuesView 的实例，前两个类还从 Set 类继承了丰富的接口。\n\nCallable 和 Hashable\n这两个抽象基类与集合没有太大的关系，只不过因为 collections.abc 是标准库中定义抽象基类的第一个模块，而它们又太重要了，因此才把它们放到 collections.abc 模块中。基本未见过 Callable 或 Hashable 的子类。这两个抽象基类的主要作用是为内置函数 isinstance 提供支持，以一种安全的方式判断对象能不能调用或散列（若想检查是否能调用，可以使用内置的 callable() 函数；但是没有类似的 hashable() 函数，因此测试对象是否可散列，最好使用 isinstance(my_obj, Hashable)。）\n\nIterator\n它是 Iterable 的子类。在第 14 章详细讨论。\n\n\ncollections.abc 的官方文档中的表格：\n抽象基类的数字塔继 collections.abc 之后，标准库中最有用的抽象基类包是 numbers。\nnumbers 包（https://docs.python.org/3/library/numbers.html）定义的是“数字塔”（即各个抽象基类的层次结构是线性的），其中 Number 是位于最顶端的超类，随后是 Complex 子类，依次往下，最底端是 Integral 类：\n\nNumber\nComplex\nReal\nRational\nIntergral\n\n如果想检查一个数是不是整数，可以使用 isinstance(x,  numbers.Integral)，如果一个值可能是浮点数类型，可以使用 isinstance(x,  numbers.Real) 检查。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 动态属性和特征","url":"/posts/2020/04/03/31259/","content":"使用动态属性转换数据import osimport jsonimport warningsfrom urllib.request import urlopenURL = &#x27;https://www.oreilly.com/pub/sc/osconfeed&#x27;JSON_FILE = r&#x27;D:\\keeplearning\\myLearning\\python\\book2\\osconfeed.json&#x27;def load():    if not os.path.exists(JSON_FILE):        msg = f&#x27;downloading &#123;URL&#125; to &#123;JSON_FILE&#125;&#x27;        warnings.warn(msg)        with urlopen(URL) as remote, open(JSON_FILE, &#x27;wb&#x27;) as local:            local.write(remote.read())    # with open(JSON_FILE, mode=&#x27;rb&#x27;) as fp:    with open(JSON_FILE, mode=&#x27;r&#x27;, encoding=&#x27;utf8&#x27;) as fp:        print(json.load(fp))if __name__ == &#x27;__main__&#x27;:    # load()    feed = load2()    print(sorted(feed[&#x27;Schedule&#x27;].keys()))    # [&#x27;conferences&#x27;, &#x27;events&#x27;, &#x27;speakers&#x27;, &#x27;venues&#x27;]    for key, value in sorted(feed[&#x27;Schedule&#x27;].items()):        print(f&#x27;&#123;len(value)&#125;,&#123;key&#125;&#x27;)    # 1,conferences    # 494,events    # 357,speakers    # 53,venues\n\n在with语句中 使用两个上下文管理器（从Python 3.1起允许这么做），分别用于读取和保存远程文件。json.load 函数解析JSON文件，返回Python原生对象。在这个数据源中有这几种数据类型：dict、list、str和int。\n\n使用动态属性访问JSON类数据from collections import abcclass FronzenJSON():    &#x27;&#x27;&#x27;    一个只读接口，使用属性表示法访问JSON类对象    &#x27;&#x27;&#x27;    def __init__(self, mapping):        self.__data = dict(mapping)    def __getattr__(self, name):        if hasattr(self.__data, name):            return getattr(self.__data, name)        else:            return FronzenJSON.build(self.__data[name])    @classmethod    def build(cls, obj):        if isinstance(obj, abc.Mapping):            return cls(obj)        elif isinstance(obj, abc.MutableSequence):            return [cls.build(item) for item in obj]        else:            return obj\n\n使用mapping参数构建一个字典。这么做有两个目的：(1)确保传入的是字典（或者是能转换成字典的对象）；(2)安全起见，创建一个副本。\n仅当没有指定名称（name）的属性时才调用 __getattr__ 方法，调用keys、items等方法就是通过这种方式处理的；build 函数中，如果obj是映射，那就构建一个FrozenJSON对象；如果是MutableSequence对象，必然是列表，因此，我们把obj中的每个元素递归地传给 .build() 方法，构建一个列表。\n\n处理无效属性名FrozenJSON类有个缺陷：没有对名称为Python关键字的属性做特殊处理。比如说像下面这样构建一个对象： grad = FrozenJSON(&#123;&#39;name&#39;: &#39;Jim Bo&#39;, &#39;class&#39;: 1982&#125;)，此时无法读取 grad.class 的值，在pycharm中直接会提示此处代码有问题，因为在 Python 中 class 是保留字。\ngrad = FrozenJSON(&#123;&#x27;name&#x27;: &#x27;Jim Bo&#x27;, &#x27;class&#x27;: 1982&#125;)print(getattr(grad, &#x27;class&#x27;))\n\nFrozenJSON类的目的是为了便于访问数据，因此更好的方法是检查传给FrozenJSON.__init__ 方法的映射中是否有键的名称为关键字，如果有，那么在键名后加上_，然后通过下述方式读取：\nimport keywordfrom collections import abcclass FrozenJSON():    def __init__(self, mapping):        self._data = &#123;&#125;        for key, value in mapping.items():            if keyword.iskeyword(key):  # 处理无效属性名                key += &#x27;_&#x27;            self._data[key] = value    def __getattr__(self, name):        if hasattr(self._data, name):            print(&quot;hasattr:&quot;, name)            return getattr(self._data, name)        else:            if keyword.iskeyword(name): # 这里也需要处理无效属性名                name += &#x27;_&#x27;            return FrozenJSON.build(self._data[name])    @classmethod    def build(cls, obj):        if isinstance(obj, abc.Mapping):            return cls(obj)        elif isinstance(obj, abc.MutableSequence):            return [cls.build(item) for item in obj]        else:            return obj          if __name__ == &#x27;__main__&#x27;:    grad = FrozenJSON(&#123;&#x27;name&#x27;: &#x27;Jim Bo&#x27;, &#x27;class&#x27;: 1982&#125;)    print(getattr(grad, &#x27;class&#x27;))    print(grad.class_)\n\n\n使用__new__方法以灵活的方式创建对象通常把 __init__ 称为构造方法，这是从其他语言借鉴过来的术语。其实，用于构建实例的是特殊方法 __new__ ：这是个类方法（使用特殊方式处理，因此不必使用@classmethod装饰器），必须返回一个实例。\n返回的实例会作为第一个参数（即self）传给 __init__ 方法。因为调用 __init__ 方法时要传入实例，而且禁止返回任何值，所以 __init__ 方法其实是“初始化方法”。\n真正的构造方法是 __new__。我们几乎不需要自己编写 __new__ 方法，因为从object类继承的实现已经足够了。\n从 __new__ 方法到 __init__ 方法，是最常见的，但不是唯一的。__new__ 方法也可以返回其他类的实例，此时，解释器不会调用 __init__ 方法。\n使用 __new__ 方法取代build方法，构建可能是也可能不是FrozenJSON实例的新对象：\nimport keywordfrom collections import abcclass FrozenJSON():    def __new__(cls, arg):        if isinstance(arg, abc.Mapping):            return super().__new__(cls)        elif isinstance(arg, abc.MutableSequence):            return [cls(item) for item in arg]        else:            return arg    def __init__(self, mapping):        self._data = &#123;&#125;        for key, value in mapping.items():            if keyword.iskeyword(key):                key += &#x27;_&#x27;            self._data[key] = value                def __getattr__(self, name):        if hasattr(self._data, name):            return getattr(self._data, name)        else:            if keyword.iskeyword(name):                name += &#x27;_&#x27;            return FrozenJSON(self._data[name])if __name__ == &#x27;__main__&#x27;:    grad = FrozenJSON(&#123;&#x27;name&#x27;: &#x27;Jim Bo&#x27;, &#x27;class&#x27;: 1982&#125;)    print(getattr(grad, &#x27;class&#x27;))    print(grad.class_)\n\n__new__ 是类方法，第一个参数是类本身，余下的参数与 __init__  方法一样，只不过没有 self。\nreturn super().__new__(cls) 默认的行为是委托给超类的 __new__ 方法，这里调用的是object基类的 __new__ 方法，把唯一的参数设为FrozenJSON。__new__ 方法中余下的代码与原先的build方法完全一样，之前，这里调用的是FrozenJSON.build方法，现在只需调用FrozenJSON构造方法。\n__new__ 方法的第一个参数是类，因为创建的对象通常是那个类的实例。所以，在FrozenJSON.__new__ 方法中，super（　）.__new__(cls) 表达式会调用object.__new__(FrozenJSON)，而object类构建的实例其实是FrozenJSON实例，即那个实例的__class__ 属性存储的是FrozenJSON类的引用。不过，真正的构建操作由解释器调用C语言实现的object.__new__方法执行。\n\n使用特性验证属性：property假设有个销售散装有机食物的电商应用，客户可以按重量订购坚果、干果或杂粮。在这个系统中，每个订单中都有一系列商品，而每个商品都可以使用示例中的类表示：\nclass LineItem:    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.price    @property      def weight(self):        return self.__weight    @weight.setter    def weight(self, value):        if value &gt; 0:            self.__weight = value        else:            raise ValueError(&#x27;value must be &gt; 0&#x27;)item = LineItem(&#x27;TestItem&#x27;, 1, 10)print(item.weight)\n\n@property 装饰读值方法，此时的 weight 函数将真正的值存储在私有属性 __weight 中，被装饰的读值方法有个 .setter 属性，这个属性也是装饰器，这个装饰器把读值方法和设值方法绑定在一起。\n\n虽然内置的 property 经常用作装饰器，但它其实是一个类。在 Python 中，函数和类通常可以互换，因为二者都是可调用的对象，而且没有实例化对象的 new 运算符，所以调用构造方法与调用工厂函数没有区别。此外，只要能返回新的可调用对象，代替被装饰的函数，二者都可以用作装饰器。\nproperty 构造方法的完整签名：property(fget=None, fset=None, fdel=None, doc=None)所有参数都是可选的，如果没有把函数传给某个参数，那么得到的特性对象就不允许执行相应的操作。\n曾经没有 @ 装饰器句法，不使用装饰器定义特性的“经典”句法如示例：\nclass LineItem:    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.price    def get_weight(self):        return self.__weight    def set_weight(self, value):        if value &gt; 0:            self.__weight = value        else:            raise ValueError(&#x27;value must be &gt; 0&#x27;)    weight = property(get_weight, set_weight)item = LineItem(&#x27;TestItem&#x27;, 1, 10)print(item.weight)\n\nweight = property(get_weight, set_weight) 通过构建 property 对象，然后赋值给公开的类属性。\n通过加断点debug，看出两种方法的执行过程是不同的：\n\n使用 property(get_weight, set_weight)：\n\n  \n\n使用 @property：  \n\n\n特性会覆盖属性特性都是类属性，但是特性管理的其实是实例属性的存取。\n实例属性掩盖类的数据属性：\nclass Class:    data = &#x27;class data attr&#x27;    @property    def prop(self):        return &#x27;prop func&#x27;    obj = Class()vars(obj)    # vars 函数返回 obj 的 __dict__ 属性，表明没有实例属性。Out[4]: &#123;&#125;obj.dataOut[5]: &#x27;class data attr&#x27;obj.data = &#x27;new data attr&#x27;vars(obj)Out[7]: &#123;&#x27;data&#x27;: &#x27;new data attr&#x27;&#125;obj.dataOut[8]: &#x27;new data attr&#x27;Class.dataOut[9]: &#x27;class data attr&#x27;\n\n尝试覆盖 obj 实例的 prop 特性：\nClass.propOut[10]: &lt;property at 0x27ba3839cc8&gt;obj.propOut[11]: &#x27;prop func&#x27;obj.prop = &#x27;new prop func&#x27;  # 设置实例属性 prop ，结果失败Traceback (most recent call last):  ......    obj.prop = &#x27;new prop func&#x27;AttributeError: can&#x27;t set attributeobj.__dict__[&#x27;prop&#x27;] = &#x27;nnew&#x27;vars(obj)Out[14]: &#123;&#x27;data&#x27;: &#x27;new data attr&#x27;, &#x27;prop&#x27;: &#x27;nnew&#x27;&#125;obj.propOut[15]: &#x27;prop func&#x27;Class.prop = &#x27;class prop&#x27;obj.propOut[17]: &#x27;nnew&#x27;Class.propOut[18]: &#x27;class prop&#x27;\n\n为 Class 类新添一个特性，覆盖实例属性:\nobj.dataOut[19]: &#x27;new data attr&#x27;Class.dataOut[20]: &#x27;class data attr&#x27;Class.data = property(lambda self: &#x27;the &quot;data&quot; prop value&#x27;)obj.dataOut[22]: &#x27;the &quot;data&quot; prop value&#x27;del Class.dataobj.dataOut[24]: &#x27;new data attr&#x27;\n\nobj.attr 这样的表达式不会从 obj 开始寻找 attr，而是从 obj.__class__ 开始，而且，仅当类中没有名为 attr 的特性时，Python 才会在 obj 实例中寻找。\n\n定义一个特性工厂函数# 工厂函数def quantity(storage_name):    def qty_getter(instance):        # 值直接从 instance.__dict__ 中获取，为的是跳过特性，防止无限递归。        return instance.__dict__[storage_name]    def qty_setter(instance, value):        if value &gt; 0:            instance.__dict__[storage_name] = value  # 也是为了跳过特性        else:            raise ValueError(&#x27;value must be &gt; 0&#x27;)    return property(qty_getter, qty_setter)  class LineItem:    weight = quantity(&#x27;weight&#x27;)    price = quantity(&#x27;price&#x27;)    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.price      if __name__ == &#x27;__main__&#x27;:    item = LineItem(&quot;Test Item&quot;, 8, 18)    print(item.weight, item.price)    print(sorted(vars(item).items()))\n\n在工厂函数的最后一行，使用 property 对象包装 qty_getter 和 qty_setter 函数。需要运行这两个函数时，它们会从闭包中读取 storage_name，确定从哪里获取属性的值，或者在哪里存储属性的值。\n工厂函数构建的特性利用了前面所述的行为：weight 特性覆盖了 weight 实例属性，因此对 self.weight 或 item.weight 的每个引用都由特性函数处理，只有直接存取 __dict__ 属性才能跳过特性的处理逻辑。\n\n影响属性处理方式的特殊属性__class__ \n对象所属类的引用（即 obj.__class__ 与 type(obj) 的作用相同）。Python的某些特殊方法，例如__getattr__，只在对象的类中寻找，而不在实例中寻找。\n__dict__\n一个映射，存储对象或类的可写属性。有 __dict__ 属性的对象，任何时候都能随意设置新属性。如果类有 __slots__ 属性，它的实例可能没有 __dict__ 属性。参见下面对__slots__ 属性的说明。\n__slots__ \n类可以定义这个这属性，限制实例能有哪些属性。__slots__ 属性的值是一个字符串组成的元组，指明允许有的属性。如果 __slots__ 中没有 ‘__dict__‘，那么该类的实例没有 __dict__ 属性，实例只允许有指定名称的属性。\n\n处理属性的内置函数dir([object])\n列出对象的大多数属性。官方文档说，dir函数的目的是交互式使用，因此没有提供完整的属性列表，只列出一组“重要的”属性名。dir函数能审查有或没有 __dict__ 属性的对象。dir函数不会列出__dict__ 属性本身，但会列出其中的键。dir函数也不会列出类的几个特殊属性，例如 __mro__、__bases__ 和 __name__。如果没有指定可选的object参数，dir函数会列出当前作用域中的名称。\ngetattr(object, name[, default])\n从object对象中获取 name 字符串对应的属性。获取的属性可能来自对象所属的类或超类。如果没有指定的属性，getattr函数抛出AttributeError异常，或者返回default参数的值（如果设定了这个参数的话）。\nhasattr(object, name)\n如果object对象中存在指定的属性，或者能以某种方式（例如继承）通过object对象获取指定的属性，返回True。文档说道：“这个函数的实现方法是调用getattr(object, name)函数，看看是否抛出AttributeError异常。”\nsetattr(object, name, value)\n把object对象指定属性的值设为value，前提是object对象能接受那个值。这个函数可能会创建一个新属性，或者覆盖现有的属性。\nvars([object])\n返回object对象的 __dict__ 属性；如果实例所属的类定义了 __slots__ 属性，实例没有 __dict__ 属性，那么vars函数不能处理那个实例（相反，dir函数能处理这样的实例）。如果没有指定参数，那么 vars() 函数的作用与 locals() 函数一样：返回表示本地作用域的字典。\n\n处理属性的特殊方法使用点号或内置的getattr、hasattr和setattr函数存取属性都会触发下述列表中相应的特殊方法。但是，直接通过实例的__dict__属性读写属性不会触发这些特殊方法——如果需要，通常会使用这种方式跳过特殊方法。\n假设有个名为Class的类，obj是Class类的实例，attr是obj的属性。\n__delattr__(self, name) \n只要使用del语句删除属性，就会调用这个方法。例如，del obj.attr 语句触发 Class.__delattr__(obj, &#39;attr&#39;) 方法。\n__dir__(self) \n把对象传给dir函数时调用，列出属性。例如，dir(obj) 触发 Class.__dir__(obj) 方法。\n__getattr__(self, name) \n仅当获取指定的属性失败，搜索过obj、Class和超类之后调用。表达式 obj.no_such_attr、getattr(obj, &#39;no_such_attr&#39;) 和 hasattr(obj, &#39;no_such_attr&#39;) 可能会触发Class.__getattr__(obj,&#39;no_such_attr&#39;) 方法，但是，仅当在obj、Class和超类中找不到指定的属性时才会触发。\n__getattribute__(self, name) \n尝试获取指定的属性时总会调用这个方法，不过，寻找的属性是特殊属性或特殊方法时除外。点号与 getattr 和 hasattr 内置函数会触发这个方法。调用 __getattribute__ 方法且抛出AttributeError异常时，才会调用 __getattr__ 方法。为了在获取obj实例的属性时不导致无限递归，__getattribute__ 方法的实现要使用 super().__getattribute__(obj, name) 。\n__setattr__(self, name, value)\n尝试设置指定的属性时总会调用这个方法。点号和setattr内置函数会触发这个方法。例如，obj.attr=42 和 setattr(obj, &#39;attr&#39;, 42) 都会触发 Class.__setattr__(obj, ‘attr’, 42) 方法。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 可迭代的对象、迭代器和生成器","url":"/posts/2020/02/22/3652/","content":"单词序列Sentenceimport reimport reprlibRE_WORD = re.compile(&quot;\\w+&quot;)class Sentence:    &#x27;&#x27;&#x27;    定义了一个 Sentence 类，通过索引从文本中提取单词。    &#x27;&#x27;&#x27;    def __init__(self, text):        self.text = text        self.words = RE_WORD.findall(text)    def __getitem__(self, item):        return self.words[item]    def __len__(self):        return len(self.text)    def __repr__(self):        print(reprlib.repr(self.text))        return f&quot;&#123;type(self).__name__&#125;(&#123;self.text&#125;):&#123;self.words&#125;&quot;sentence = Sentence(&#x27;&quot;The time has come,&quot; Tom said,&#x27;)print(sentence)for i in sentence:    print(i, end=&#x27; &#x27;)print(&quot;\\n&quot; + sentence[0], sentence[-1])\n\n\n序列可以迭代的原因：iter函数解释器需要迭代对象 x 时，会自动调用 iter(x)。\n内置的 iter 函数有以下作用：\n\n检查对象是否实现了 __iter__ 方法，如果实现了就调用它，获取一个迭代器。\n如果没有实现 __iter__ 方法，但是实现了 __getitem__ 方法，Python 会创建一个迭代器，尝试按顺序（从索引 0 开始）获取元素。\n如果尝试失败，Python 抛出 TypeError 异常，通常会提示“C object is not iterable”（C对象不可迭代），其中 C 是目标对象所属的类。\n\n任何 Python 序列都可迭代的原因是，它们都实现了 __getitem__ 方法。其实，标准的序列也都实现了 __iter__ 方法，因此也应该这么做。\n检查一个对象是否可迭代：\nfrom collections import abcprint(iter(sentence))  # &lt;iterator object at 0x000001E1A53E7AC8&gt;print(isinstance(sentence, abc.Iterable))  # Falses = 1print(iter(s))  # TypeError: &#x27;int&#x27; object is not iterable\n\n检查对象 x 能否迭代，最准确的方法是：调用 iter(x) 函数，如果不可迭代，再处理TypeError 异常。 这比使用 isinstance(x, abc.Iterable) 更准确，因为 iter(x) 函数会考虑到遗留的 __getitem__ 方法，而 abc.Iterable 类则不考虑。\n\n可迭代的对象与迭代器的对比可迭代的对象：使用 iter 内置函数可以获取迭代器的对象。如果对象实现了能返回迭代器的 __iter__方法，那么对象就是可迭代的。序列都可以迭代；另外，实现了 __getitem__ 方法，而且其参数是从零开始的索引，这种对象也可以迭代。\n可迭代的对象和迭代器之间的关系：Python 从可迭代的对象中获取迭代器。\n字符串 ‘abc’ 是可迭代的对象。背后是有迭代器的，只不过我们看不到：\ns = &quot;abc&quot;for i in s:    print(i)\n\n如果没有 for 语句，不得不使用 while 循环模拟：\ns_iter = iter(s)   # 使用可迭代的对象构建迭代器 s_iter。while True:    try:        print(next(s_iter))    except StopIteration:        del s_iter  # 释放对s_iter的引用，即废弃迭代器对象。        break\n\nStopIteration 异常表明迭代器到头了。Python 语言内部会处理 for 循环和其他迭代上下文（如列表推导、元组拆包，等等）中的 StopIteration 异常。\n标准的迭代器接口有两个方法:\n\n__next__返回下一个可用的元素，如果没有元素了，抛出 StopIteration 异常。\n\n__iter__返回 self，以便在应该使用可迭代对象的地方使用迭代器，例如在 for 循环中。\n\n\n这个接口在 collections.abc.Iterator 抽象基类中制定。这个类定义了 __next__ 抽象方法，而且继承自 Iterable 类；__iter__ 抽象方法则在 Iterable 类中定义。\n\n图解：Iterable 和 Iterator 抽象基类。以斜体显示的是抽象方法。具体的 Iterable.__iter__ 方法应该返回一个 Iterator 实例。具体的 Iterator 类必须实现 __next__ 方法。Iterator.__iter__ 方法直接返回实例本身。\nIterator 抽象基类实现 __iter__ 方法的方式是返回实例本身（return  self）。这样，在需要可迭代对象的地方可以使用迭代器。 abc.Iterator 类的源码：\n# from Lib._collections_abc import Iteratorclass Iterable(metaclass=ABCMeta):    __slots__ = ()    @abstractmethod    def __iter__(self):        while False:            yield None    @classmethod    def __subclasshook__(cls, C):        if cls is Iterable:            return _check_methods(C, &quot;__iter__&quot;)        return NotImplemented      class Iterator(Iterable):    __slots__ = ()    @abstractmethod    def __next__(self):        &#x27;Return the next item from the iterator. When exhausted, raise StopIteration&#x27;        raise StopIteration    def __iter__(self):        return self    @classmethod    def __subclasshook__(cls, C):        if cls is Iterator:            return _check_methods(C, &#x27;__iter__&#x27;, &#x27;__next__&#x27;)        return NotImplemented\n\n检查对象 x 是否为迭代器最好的方式是调用 isinstance(x,  abc.Iterator)，相应的，检查是都是迭代对象用 isinstance(x, abc.Iterable)。\nfrom collections import abcs = &quot;abc&quot;print(isinstance(iter(s), abc.Iterator))  # True\n\n迭代器只需 __next__ 和 __iter__ 两个方法，所以除了调用 next() 方法，以及捕获 StopIteration  异常之外，没有办法检查是否还有遗留的元素。此外，也没有办法“还原”迭代器。如果想再次迭代，那就要调用 iter(…)，传入之前构建迭代器的可迭代对象。传入迭代器本身没用，因为前面说过 Iterator.__iter__ 方法的实现方式是返回实例本身，所以传入迭代器无法还原已经耗尽的迭代器。\ns1 = Sentence(&quot;I am zyp&quot;)iter_s1 = iter(s1)  # 使用 iter(...)函数构建迭代器print(isinstance(iter_s1, abc.Iterable))  # Trueprint(isinstance(iter_s1, abc.Iterator))  # Trueprint(next(iter_s1))  # I 使用 next(...) 函数使用迭代器print(next(iter_s1))  # amprint(next(iter_s1))  # zyp# print(next(iter_sentence))  # StopIterationprint(list(iter_s1))  # []print(next(iter(s1)))  # I # 重新传入可迭代对象print(list(iter(s1)))  # [&#x27;I&#x27;, &#x27;am&#x27;, &#x27;zyp&#x27;]\n\n迭代器迭代器是这样的对象：实现了无参数的 __next__ 方法，返回序列中的下一个元素；如果没有元素了，那么抛出 StopIteration 异常。Python 中的迭代器还实现了 __iter__ 方法，因此迭代器也可以迭代。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 协程(基础)","url":"/posts/2020/03/11/64845/","content":"用作协程的生成器的基本行为def simple_coroutine():    print(&quot;—&gt; Coroutines started&quot;)    var = yield   # 协程使用生成器函数定义：定义体中有yield关键字。    print(f&quot;—&gt; Coroutines received &#123;var&#125;&quot;)    cor = simple_coroutine()corOut[4]: &lt;generator object simple_coroutine at 0x000001D368E8F410&gt;  next(cor)  # 激活协程—&gt; Coroutines startedcor.send(123)—&gt; Coroutines received 123Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-6-3cd430c98ae0&gt;&quot;, line 1, in &lt;module&gt;    cor.send(123)StopIteration\n\nvar = yield：yield在表达式中使用；如果协程只需从客户那里接收数据，那么产出的值是None——这个值是隐式指定的，因为yield关键字右边没有表达式。首先要调用 next(...) 函数，因为生成器还没启动，没在yield语句处暂停，所以一开始无法发送数据。\n协程可以身处四个状态中的一个。当前状态可以使用 inspect.getgeneratorstate(...) 函数确定，该函数会返回下述字符串中的一个：\n\n‘GEN_CREATED’：等待开始执行；\n‘GEN_RUNNING’：解释器正在执行；\n‘GEN_SUSPENDED’：在yield表达式处暂停；\n‘GEN_CLOSED’：执行结束；\n\n因为send方法的参数会成为暂停的yield表达式的值，所以，仅当协程处于暂停状态时才能调用send方法，例如cor.send(123)。不过，如果协程还没激活（即，状态是’GEN_CREATED’），情况就不同了。因此，**始终要调用next(cor)激活协程——也可以调用cor.send(None)**，效果一样。\ncor = simple_coroutine()cor.send(None)  # 激活协程# &lt;generator object simple_coroutine at 0x000002601BE2E200&gt;# Coroutines started\n\n如果创建协程对象后立即把None之外的值发给它，会出现下述错误：can’t send non-None value to a just-started generator.\ncor = simple_coroutine()cor.send(123)Traceback (most recent call last):  File &quot;D:\\Python3.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py&quot;, line 2961, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File &quot;&lt;ipython-input-12-3cd430c98ae0&gt;&quot;, line 1, in &lt;module&gt;    cor.send(123)TypeError: can&#x27;t send non-None value to a just-started generator\n\n最先调用 next(cor) 函数这一步通常称为“预激”（prime）协程（即，让协程向前执行到第一个yield表达式，准备好作为活跃的协程使用）。\n\ndef simple_coroutine2(a):    print(f&quot;——&gt; started a:&#123;a&#125;&quot;)    b = yield a    print(f&quot;——&gt; receiced b:&#123;b&#125;&quot;)    c = yield a + b    print(f&quot;——&gt; receiced c:&#123;c&#125;&quot;)cor2 = simple_coroutine2(1)print(getgeneratorstate(cor2))  # GEN_CREATED  协程未启动cor2.send(None)print(getgeneratorstate(cor2))  # GEN_SUSPENDEDprint(cor2.send(2))print(cor2.send(10))&#x27;&#x27;&#x27;GEN_CREATED——&gt; started a:1GEN_SUSPENDED——&gt; receiced b:23——&gt; receiced c:10Traceback (most recent call last):  File &quot;.../a5_3_demo_coroutine.py&quot;, line 29, in &lt;module&gt;    print(cor2.send(10))StopIteration&#x27;&#x27;&#x27;\n\n协程在yield关键字所在的位置暂停执行。在赋值语句中，&#x3D;右边的代码在赋值之前执行。因此，对于b=yield a 这行代码来说，等到客户端代码再激活协程时才会设定b的值。\nsimple_coroutine2 协程的执行过程分为3个阶段：各个阶段都在yield表达式中结束，而且下一个阶段都从那一行代码开始，然后再把yield表达式的值赋给变量。\n\n使用协程计算移动平均值def average():    total, count = 0, 0    average = None    while True:        var = yield average        total += var        count += 1        average = total / countavg = average()avg.send(None)  # 预激协程print(avg.send(1))print(avg.send(3))print(avg.send(5))\n\n无限循环表明，只要调用方不断把值发给这个协程，它就会一直接收值，然后生成结果。仅当调用方在协程上调用.close（）方法，或者没有对协程的引用而被垃圾回收程序回收时，这个协程才会终止。这里的yield表达式用于暂停执行协程，把结果发给调用方；还用于接收调用方后面发给协程的值，恢复无限循环。\n\n预激协程的装饰器使用协程之前必须预激，可是这一步容易忘记。为了避免忘记，可以在协程上使用一个特殊的装饰器。\n如果不预激，那么协程没什么用。调用my_coro.send(x)之前，记住一定要调用 next(my_coro) 或者my_coro.send(None) 。为了简化协程的用法，有时会使用一个预激装饰器。\nfrom functools import wrapsdef coroutine(func):    # 装饰器：向前执行到第一个yield表达式，预激func    @wraps(func)    def primer(*args, **kwargs):        gen = func(*args, **kwargs)        next(gen)        return gen    return primer@coroutinedef average_primer():    total, count = 0, 0    average = None    while True:        var = yield average        total += var        count += 1        average = total / countif __name__ == &#x27;__main__&#x27;:    from inspect import getgeneratorstate    avg_primer = average_primer()    print(getgeneratorstate(avg_primer))  # GEN_SUSPENDED    print(avg_primer.send(1))    print(avg_primer.send(3))    print(avg_primer.send(5))\n\n在 coroutine 函数中把被装饰的生成器函数替换成这里的 primer 函数，接着调用被装饰的函数，获取生成器对象，预激生成器，最后返回预激后的生成器。根据 getgeneratorstate 得到的状态为 GEN_SUSPENDED 可知，此时 avg_primer 状态已经不是 GEN_CREATED 协程未启动状态，而是在yield表达式处暂停。\n\n终止协程和异常处理协程中未处理的异常会向上冒泡，传给next函数或send方法的调用方（即触发协程的对象）。\n客户代码可以在生成器对象上调用两个方法，显式地把异常发给协程。这两个方法是 throw 和close 。\ngenerator.throw(exc_type[, exc_value[, traceback]]) 致使生成器在暂停的yield表达式处抛出指定的异常。如果生成器处理了抛出的异常，代码会向前执行到下一个yield表达式，而产出的值会成为调用generator.throw方法得到的返回值。如果生成器没有处理抛出的异常，异常会向上冒泡，传到调用方的上下文中。\ngenerator.close（） 致使生成器在暂停的yield表达式处抛出GeneratorExit异常。如果生成器没有处理这个异常，或者抛出了StopIteration异常（通常是指运行到结尾），调用方不会报错。如果收到GeneratorExit异常，生成器一定不能产出值，否则解释器会抛出RuntimeError异常。生成器抛出的其他异常会向上冒泡，传给调用方。\nfrom inspect import getgeneratorstateclass DemoException(BaseException):    &quot;&quot;&quot;为这次演示定义的异常类型。&quot;&quot;&quot;    passdef demo_exc_handling():    print(&#x27;-&gt; coroutine started&#x27;)    while True:        try:            var = yield        except DemoException as e:            print(&#x27;*** DemoException handled. Continuing...&#x27;)        else:            print(&#x27;-&gt; coroutine received: &#123;!r&#125;&#x27;.format(var))    # raise RuntimeError(&#x27;This line should never run.&#x27;)if __name__ == &#x27;__main__&#x27;:    cor_exc = demo_exc_handling()    cor_exc.send(None)    print(getgeneratorstate(cor_exc))  # GEN_SUSPENDED    cor_exc.send(1)               # -&gt; coroutine received: 1       cor_exc.send(2)               # -&gt; coroutine received: 2    cor_exc.close()    print(getgeneratorstate(cor_exc))  # GEN_CLOSED\n\n# 如果把DemoException异常传入demo_exc_handling协程，它会处理，然后继续运行cor_exc.throw(DemoException)  # *** DemoException handled. Continuing...print(getgeneratorstate(cor_exc))  # GEN_SUSPENDED\n# 如果传入协程的异常没有处理，协程会停止，即状态变成&#x27;GEN_CLOSED&#x27;cor_exc.throw(ZeroDivisionError)Traceback (most recent call last):\t\t...    ZeroDivisionError# 由于前面已经抛出异常了，所以后面的代码无法执行，只有在控制台操作才能看出状态print(getgeneratorstate(cor_exc))  # GEN_CLOSED\n\n如果不管协程如何结束都想做些清理工作，要把协程定义体中相关的代码放入try&#x2F;finally块中，\ndef demo_exc_handling():    print(&#x27;-&gt; coroutine started&#x27;)    try:        while True:            try:                var = yield            except DemoException as e:                print(&#x27;*** DemoException handled. Continuing...&#x27;)            else:                print(&#x27;-&gt; coroutine received: &#123;!r&#125;&#x27;.format(var))    finally:        print(&#x27;-&gt; coroutine ending, clearing something.&#x27;)\n\n\n让协程返回值from collections import namedtupleResult = namedtuple(&#x27;Result&#x27;, &#x27;count average&#x27;)def average():    total, count = 0, 0    _avg = None    while True:        var = yield        if var is None:            break        total += var        count += 1        _avg = total / count    return Result(count, _avg)if __name__ == &#x27;__main__&#x27;:    avg = average()    avg.send(None)    avg.send(1)    avg.send(2)    avg.send(3)    avg.send(None)&#x27;&#x27;&#x27;Traceback (most recent call last):   ...StopIteration: Result(count=3, average=2.0)&#x27;&#x27;&#x27;\n\n发送 None 会终止循环，导致协程结束，返回结果。一如既往，生成器对象会抛出StopIteration 异常。异常对象的 value 属性保存着返回的值。\n何获取协程返回的值: 把  avg.send(None) 用try包含。\ntry:    avg.send(None)except StopIteration as e:    print(e)# Result(count=3, average=2.0)\n\n\n使用yield fromyield  from 结构会在内部自动捕获 StopIteration 异常。这种处理方式与for 循环处理StopIteration 异常的方式一样：循环机制使用用户易于理解的方式处理异常。对 yield  from 结构来说，解释器不仅会捕获 StopIteration 异常，还会把 value 属性的值变成 yield  from 表达式的值。\nyield from 可用于简化 for 循环中的 yield 表达式：\ndef gen():    for i in &quot;ABC&quot;:        yield i    for j in [1, 2, 3]:        yield jprint(list(gen()))  # [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, 1, 2, 3]\n\n使用yield from：\ndef gen2():    yield from &quot;ABC&quot;    yield from [1, 2, 3]print(list(gen2()))  # [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, 1, 2, 3]\n\nyield from 在扁平化处理嵌套型的序列中的应用：\ndef gen3(*args):    for item in args:        yield from itema = (1, 2, 3)b = &quot;ABC&quot;print(list(gen3(a, b)))  # [1, 2, 3, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]\n\nyield  from  x  表达式对 x 对象所做的第一件事是，调用 iter(x)，从中获取迭代器，因此 x 可以是任何可迭代的对象。\n如果 yield  from 结构唯一的作用是替代产出值的嵌套 for 循环，这个结构很有可能不会添加到 Python 语言中。yield  from 结构的本质作用无法通过简单的可迭代对象说明，而要发散思维，使用嵌套的生成器。\nyield  from 的主要功能是打开双向通道，把最外层的调用方与最内层的子生成器连接起来，这样二者可以直接发送和产出值，还可以直接传入异常，而不用在位于中间的协程中添加大量处理异常的样板代码。有了这个结构，协程可以通过以前不可能的方式委托职责。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 属性描述符—验证属性","url":"/posts/2020/04/05/700/","content":"描述符是对多个属性运用相同存取逻辑的一种方式。例如，Django ORM和SQL Alchemy等ORM中的字段类型是描述符，把数据库记录中字段里的数据与Python对象的属性对应起来。\n描述符是实现了特定协议的类，这个协议包括 __get__、__set__和 __delete__ 方法。property类实现了完整的描述符协议。通常，可以只实现部分协议。其实，我们在真实的代码中见到的大多数描述符只实现了 __get__ 和 __set__ 方法，还有很多只实现了其中的一个。\n描述符是Python的独有特征，不仅在应用层中使用，在语言的基础设施中也有用到。除了特性之外，使用描述符的Python功能还有方法及classmethod和staticmethod装饰器。理解描述符是精通Python的关键。\n\n描述符示例：验证属性实现了 __get__、__set__ 或 __delete__ 方法的类是描述符。描述符的用法是，创建一个实例，作为另一个类的类属性。\n将定义一个Quantity描述符，LineItem类会用到两个Quantity实例：一个用于管理weight属性，另一个用于管理price属性。示意图有助于理解，如图所示：\n\n在图中，“weight”这个词出现了两次，因为其实有两个不同的属性都叫weight：一个是LineItem的类属性，另一个是各个LineItem对象的实例属性。price也是如此。\n描述符类：实现描述符协议的类。图中的Quantity类。\n托管类：把描述符实例声明为类属性的类。图中的LineItem类。\n描述符实例：描述符类的各个实例，声明为托管类的类属性。在图中，各个描述符实例使用箭头和带下划线的名称表示（在UML中，下划线表示类属性）。与黑色菱形接触的LineItem类包含描述符实例。\n托管实例：托管类的实例。在这个示例中，LineItem实例是托管实例。\n储存属性：托管实例中存储自身托管属性的属性。在图中，LineItem实例的weight和price属性是储存属性。这种属性与描述符实例不同，描述符属性都是类属性。\n托管属性：托管类中由描述符实例处理的公开属性，值存储在储存属性中。也就是说，描述符实例和储存属性为托管属性建立了基础。\nQuantity实例是LineItem类的类属性，这一点一定要理解。\nclass Quantity:  # 描述符基于协议实现，无需创建子类    def __init__(self, storage_name):        self.storage_name = storage_name    def __set__(self, instance, value):        if value &gt; 0:            instance.__dict__[self.storage_name] = value        else:            raise ValueError(&#x27;value must &gt;0&#x27;)class LineItem:    weight = Quantity(&#x27;weight&#x27;)  # 第一个描述符实例绑定给weight属性    price = Quantity(&#x27;price&#x27;)\t # 第二个描述符实例绑定给price属性    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.price\n\n在 Quantity 类中：\nself.storage_name = storage_name ：表示Quantity实例有个storage_name属性，这是托管实例中存储值的属性的名称。\n__set__ 函数：尝试为托管属性赋值时，会调用 __set__ 方法。这里，self 是描述符实例（即LineItem.weight 或 LineItem.price），instance是托管实例（LineItem实例），value是要设定的值。\n另外，必须直接处理托管实例的 __dict__ 属性；如果使用内置的setattr函数，会再次触发 __set__ 方法，导致无限递归。\n各个托管属性的名称与储存属性一样，而且读值方法不需要特殊的逻辑，所以Quantity类不需要定义__get__ 方法。\n编写 __set__ 方法时，要记住 self 和 instance 参数的意思：self 是描述符实例，instance 是托管实例。管理实例属性的描述符应该把值存储在托管实例中。因此，Python才为描述符中的那个方法提供了instance 参数。\nself 是描述符实例，它其实是托管类的类属性。同一时刻，内存中可能有几千个LineItem实例，不过只会有两个描述符实例：LineItem.weight 和 LineItem.price。因此，存储在描述符实例中的数据，其实会变成LineItem类的类属性，从而由全部LineItem实例共享。\n\n自动获取储存属性的名称为了避免在描述符声明语句中重复输入属性名，我们将为每个Quantity实例的storage_name属性生成一个独一无二的字符串。更新后的Quantity和LineItem类的UML类图：\n\n为了生成storage_name，我们以&#39;_Quantity#&#39;为前缀，然后在后面拼接一个整数：Quantity.__counter类属性的当前值，每次把一个新的Quantity描述符实例依附到类上，都会递增这个值。在前缀中使用井号能避免storage_name与用户使用点号创建的属性冲突，因为nutmeg._Quantity#0是无效的Python句法。但是，内置的getattr和setattr函数可以使用这种“无效的”标识符获取和设置属性，此外也可以直接处理实例属性__dict__。\nclass Quantity:    __counter = 0    def __init__(self):        cls = self.__class__  # cls是Quantity类的引用。        prefix = cls.__name__        index = cls.__counter        self.storage_name = f&#x27;_&#123;prefix&#125;#&#123;index&#125;&#x27;  # 每个描述符实例的storage_name属性都是独一无二的        print(self.storage_name)        cls.__counter += 1    def __get__(self, instance, owner):        return getattr(instance, self.storage_name)    def __set__(self, instance, value):        if value &gt; 0:            setattr(instance, self.storage_name, value)        else:            raise ValueError(&#x27;value must &gt; 0&#x27;)class LineItem:    weight = Quantity()  # 不用把托管属性的名称传给Quantity构造方法。    price = Quantity()    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.priceif __name__ == &#x27;__main__&#x27;:    item = LineItem(&#x27;test&#x27;, 10, 20)    print(f&#x27;weight:&#123;item.weight&#125;, price:&#123;item.price&#125;&#x27;)    print(getattr(item, &#x27;_Quantity#0&#x27;), getattr(item, &#x27;_Quantity#1&#x27;))    &#x27;&#x27;&#x27;    _Quantity#0    _Quantity#1    weight:10, price:20    10 20    &#x27;&#x27;&#x27;\n\n这里可以使用内置的高阶函数getattr和setattr存取值，无需使用 instance.__dict__，因为托管属性和储存属性的名称不同，所以把储存属性传给getattr函数不会触发描述符，不会像上一个那样出现无限递归。\n\n注意，__get__ 方法有三个参数：self、instance和owner。owner参数是托管类（如LineItem）的引用，通过描述符从托管类中获取属性时用得到。如果使用 LineItem.weight 从类中获取托管属性（以weight为例），描述符的 __get__ 方法接收到的instance参数值是None。因此，下述控制台会话才会抛出AttributeError异常：\nitem = LineItem(&#x27;test&#x27;, 10, 20)print(LineItem.weight)\n\n......\tprint(LineItem.weight)  File &quot;D:/keeplearning/myLearning/python/book2/a6_2_QuantityLineItem2.py&quot;, line 13, in __get__    return getattr(instance, self.storage_name)AttributeError: &#x27;NoneType&#x27; object has no attribute &#x27;_Quantity#0&#x27;\n\n抛出AttributeError异常是实现 __get__ 方法的方式之一，如果选择这么做，应该修改错误消息，去掉令人困惑的NoneType和_Quantity#0，这是实现细节。把错误消息改成”‘LineItem’ class has no such attribute”更好。最好能给出缺少的属性名，但是在这个示例中，描述符不知道托管属性的名称，因此目前只能做到这样。此外，为了给用户提供内省和其他元编程技术支持，通过类访问托管属性时，最好让 __get__ 方法返回描述符实例。如下做了小幅改动，为 Quantity.__get__ 方法添加了一些逻辑：\ndef __get__(self, instance, owner):    if instance is None:  # 如果不是通过实例调用，返回描述符自身。        return self    return getattr(instance, self.storage_name)\n\n此时：\nitem = LineItem(&#x27;test&#x27;, 10, 20)print(LineItem.weight)# &lt;__main__.Quantity object at 0x00000187E175FA58&gt;\n\n可能觉得就为了管理几个属性而编写这么多代码不值得，但是要知道，描述符逻辑现在被抽象到单独的代码单元（Quantity类）中了。通常，我们不会在使用描述符的模块中定义描述符，而是在一个单独的实用工具模块中定义，以便在整个应用中使用——如果开发的是框架，甚至会在多个应用中使用。\n\n描述符的常规用法：将描述符从另一个模块中导入调用。\n# model.pyclass Quantity:    __counter = 0    def __init__(self):        cls = self.__class__        prefix = cls.__name__        index = cls.__counter        self.storage_name = f&#x27;_&#123;prefix&#125;#&#123;index&#125;&#x27;        print(self.storage_name)        cls.__counter += 1    def __get__(self, instance, owner):        if instance is None:  # 如果不是通过实例调用，返回描述符自身。            return self        return getattr(instance, self.storage_name)    def __set__(self, instance, value):        if value &gt; 0:            setattr(instance, self.storage_name, value)        else:            raise ValueError(&#x27;value must &gt; 0&#x27;)\n\nimport model  # 描述符常规用法：将描述符从另一个模块中导入class LineItem:    weight = model.Quantity()    price = model.Quantity()    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.price\n\n就目前的实现来说，Quantity描述符能出色地完成任务。它唯一的缺点是，储存属性的名称是生成的（如_Quantity#0），导致用户难以调试。但这是不得已而为之，如果想自动把储存属性的名称设成与托管属性的名称类似，需要用到类装饰器或元类。\n描述符在类中定义，因此可以利用继承重用部分代码来创建新描述符。\n\n一种新型描述符虚构的有机食物网店遇到一个问题：不知怎么回事儿，有个商品的描述信息为空，导致无法下订单。为了避免出现这个问题，我们要再创建一个描述符，NonBlank。在设计NonBlank的过程中，我们发现，它与Quantity描述符很像，只是验证逻辑不同。\n回想 Quantity 的功能，我们注意到它做了两件不同的事：管理托管实例中的储存属性，以及验证用于设置那两个属性的值。由此可知，可以重构，并创建两个基类。\nAutoStorage：自动管理储存属性的描述符类。\nValidated：扩展AutoStorage类的抽象子类，覆盖 __set__ 方法，调用必须由子类实现的validate方法。\nValidated、Quantity和NonBlank三个类之间的关系体现了模板方法设计模式。具体而言，Validated.__set__方法是这种模板方法的例证：一个模板方法用一些抽象的操作定义一个算法，而子类将重定义这些操作以提供具体的行为。\n这里，抽象的操作是验证：\n# model.pyimport abcclass AutoStorage:    __counter = 0    def __init__(self):        cls = self.__class__        prefix = cls.__name__        index = cls.__counter        self.storage_name = f&#x27;_&#123;prefix&#125;#&#123;index&#125;&#x27;        cls.__counter += 1    def __get__(self, instance, owner):        if instance is None:            return self        else:            return getattr(instance, self.storage_name)    def __set__(self, instance, value):        setattr(instance, self.storage_name, value)class Validated(abc.ABC, AutoStorage):    def __set__(self, instance, value):        value = self.validate(instance, value)        super().__set__(instance, value)    @abc.abstractmethod    def validate(self, instance, value):        &#x27;&#x27;&#x27;return validated value or raise ValueError&#x27;&#x27;&#x27;        passclass Quantity(Validated):    &quot;&quot;&quot;a number bigger than zero&quot;&quot;&quot;    def validate(self, instance, value):        if value &lt;= 0:            raise ValueError(&#x27;value must &gt; 0&#x27;)        return valueclass NoneBlank(Validated):    &#x27;&#x27;&#x27;a string with at least one none-space character&#x27;&#x27;&#x27;    def validate(self, instance, value):        value = value.strip()        if len(value) == 0:            raise ValueError(&#x27;value cannot be empty or blank&#x27;)        return value\n\nimport modelclass LineItem:    weight = model.Quantity()    price = model.Quantity()    def __init__(self, description, weight, price):        self.description = description        self.weight = weight        self.price = price    def subtotal(self):        return self.weight * self.priceif __name__ == &#x27;__main__&#x27;:    item = LineItem(&#x27;test&#x27;, 10, 20)    print(LineItem.weight)    print(f&#x27;weight:&#123;item.weight&#125;, price:&#123;item.price&#125;&#x27;)    print(getattr(item, &#x27;_Quantity#0&#x27;), getattr(item, &#x27;_Quantity#1&#x27;))    &#x27;&#x27;&#x27;    &lt;__main__.Quantity object at 0x000002D5D1C8B9B0&gt;    weight:10, price:20    10 20    &#x27;&#x27;&#x27;\n\nLineItem示例演示了描述符的典型用途——管理数据属性。这种描述符也叫做覆盖型描述符，因为描述符的__set__方法使用托管实例中的同名属性覆盖（即插手接管）了要设置的属性。不过，也有非覆盖型描述符。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 可迭代的对象、迭代器和生成器","url":"/posts/2020/03/04/3653/","content":"典型的迭代器import reimport reprlibRE_WORD = re.compile(&quot;\\w+&quot;)class SentenceIterator:    def __init__(self, words):        self.words = words        self.index = 0    def __next__(self):        try:            word = self.words[self.index]        except IndexError as e:            raise StopIteration        self.index += 1        return word    def __iter__(self):        return selfclass Sentence:    def __init__(self, text):        self.text = text        self.word = RE_WORD.findall(text)    def __repr__(self):        return f&quot;&#123;type(self).__name__&#125;:&#123;reprlib.repr(self.text)&#125;&quot;    def __iter__(self):  # 明确表明这个类可以迭代        # 根据可迭代协议，__iter__ 方法实例化并返回一个迭代器。        return SentenceIterator(self.word)# 在SentenceIterator中实现 __iter__ 可以让能让迭代器通过以下测试：from collections import abcprint(issubclass(SentenceIterator, abc.Iterator))\n\n可迭代的对象有个 __iter__ 方法，每次都实例化一个新的迭代器；而迭代器要实现 __next__ 方法，返回单个元素，此外还要实现 __iter__ 方法，返回迭代器本身。因此，迭代器可以迭代，但是可迭代的对象不是迭代器。\n除了 __iter__ 方法之外，有人可能还想在Sentence类中实现 __next__ 方法，让Sentence实例既是可迭代的对象，也是自身的迭代器。可是，这种想法非常糟糕的（原因不详述）。\n可迭代的对象一定不能是自身的迭代器。也就是说，可迭代的对象必须实现 __iter__ 方法，但不能实现 __next__ 方法。\n\n生成器函数import reimport reprlibRE_WORD = re.compile(&quot;\\w+&quot;)class Sentence:    def __init__(self, text):        self.text = text        self.word = RE_WORD.findall(text)    def __repr__(self):        return f&quot;&#123;type(self).__name__&#125;:&#123;reprlib.repr(self.text)&#125;&quot;    def __iter__(self):    # 生成器函数        for word in self.word:            yield word\n\n生成器函数的工作原理：\n只要 Python 函数的定义体中有 yield 关键字，该函数就是生成器函数。调用生成器函数时，会返回一个生成器对象。也就是说，生成器函数是生成器工厂。\n使用准确的词语描述从生成器中获取结果的过程，有助于理解生成器。注意，产出或生成值。如果说生成器“返回”值，就会让人难以理解。函数返回值；调用生成器函数返回生成器；生成器产出或生成值。生成器不会以常规的方式“返回”值：生成器函数定义体中的 return 语句会触发生成器对象抛出 StopIteration 异常。\n使用 for 循环更清楚地说明了生成器函数定义体的执行过程：\ndef gen_AB():    print(&quot;start&quot;)    yield &quot;A&quot;    print(&quot;continue&quot;)    yield &quot;B&quot;    print(&quot;end&quot;)for i in gen_AB():  # for机制会捕获异常    print(&quot;--&gt; &quot;,i)    # start# --&gt;  A# continue# --&gt;  B# end\n\n\nSentence类升级版：惰性实现目前实现的几版 Sentence 类都不具有惰性，因为 __init__  方法急迫地构建好了文本中的单词列表，然后将其绑定到 self.words 属性上。这样就得处理整个文本，列表使用的内存量可能与文本本身一样多（或许更多，这取决于文本中有多少非单词字符）。如果只需迭代前几个单词，大多数工作都是白费力气。\nre.finditer 函数是 re.findall 函数的惰性版本，返回的不是列表，而是一个生成器，按需生成 re.MatchObject 实例。如果有很多匹配，re.finditer 函数能节省大量内存。\nimport reimport reprlibRE_WORD = re.compile(&quot;\\w+&quot;)class Sentence:    def __init__(self, text):        self.text = text  # 不再需要words列表    def __repr__(self):        return f&quot;&#123;type(self).__name__&#125;:&#123;reprlib.repr(self.text)&#125;&quot;    def __iter__(self):        for match in RE_WORD.finditer(self.text):            yield match.group()\n\n\nSentence类终极版：生成器表达式import reimport reprlibRE_WORD = re.compile(&quot;\\w+&quot;)class Sentence:    def __init__(self, text):        self.text = text    def __repr__(self):        return f&quot;&#123;type(self).__name__&#125;:&#123;reprlib.repr(self.text)&#125;&quot;    def __iter__(self):        return (match.group() for match in RE_WORD.finditer(self.text))\n\n和前一个示例唯一的区别是 __iter__ 方法，这里不是生成器函数了（没有 yield），而是使用生成器表达式构建生成器，然后将其返回。不过，最终的效果一样：调用 __iter__  方法会得到一个生成器对象。\n生成器表达式是语法糖：完全可以替换成生成器函数，不过有时使用生成器表达式更便利。\n遇到简单的情况时，可以使用生成器表达式；如果生成器表达式要分成多行写，倾向于定义生成器函数，以便提高可读性。此外，生成器函数有名称，因此可以重用。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：序列的修改、散列和切片","url":"/posts/2020/01/18/61287/","content":"使用reprlib.repr()的序列为了编写 Vector(3,  4)和 Vector(3,  4,  5) 这样的代码，我们可以让__init__方法接受任意个参数（通过 *args）；但是，序列类型的构造方法最好接受可迭代的对象为参数，因为所有内置的序列类型都是这样做的。\n如果 Vector 实例的分量超过 6 个，repr() 生成的字符串就会使用 … 省略一部分。包含大量元素的集合类型一定要这么做，因为字符串表示形式是用于调试的（因此不想让大型对象在控制台或日志中输出几千行内容）。使用 reprlib 模块可以生成长度有限的表示形式。\nimport mathimport reprlibfrom array import arrayclass Vector:    typecode = &#x27;d&#x27;    def __init__(self, components):        self._classname = type(self).__name__        self._components = array(self.typecode, components)  # array(&#x27;d&#x27;, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])    def __iter__(self):\t\t# 为了迭代        return iter(self._components)    def __repr__(self):        components = reprlib.repr(self._components)  # 获取有限长度表示        # &quot;array(&#x27;d&#x27;, [1.0, 2.0, 3.0, 4.0, 5.0, ...])&quot;        components = components[components.find(&#x27;[&#x27;):-1]        return f&#x27;&#123;self._classname&#125;(&#123;components&#125;)&#x27;    def __str__(self):        return str(tuple(self))    def __bytes__(self):        return (bytes([ord(self.typecode)]) + bytes(self._components))      \t# 这里不能像abs和bool函数里写的那样直接写self，会导致循环调用__bytes__    def __eq__(self, other):        return tuple(self) == tuple(other)    def __abs__(self):        return math.sqrt(sum(x * x for x in self))    def __bool__(self):        return bool(abs(self))    @classmethod    def frombytes(cls, octets):        typecode = chr(octets[0])  # d b&#x27;d\\x00\\x00\\x00\\x0.....        memv = memoryview(octets[1:]).cast(typecode)        return cls(memv)vector = Vector([1, 2, 3, 4, 5, 6, 7, 8])print(vector)  # (1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0)print(repr(vector))\t\t# Vector([1.0, 2.0, 3.0, 4.0, 5.0, ...])print(bytes(vector))# b&#x27;d\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00\\x14@\\x00\\x00\\x00\\x00\\x00\\x00\\x18@\\x00\\x00\\x00\\x00\\x00\\x00\\x1c@\\x00\\x00\\x00\\x00\\x00\\x00 @&#x27;print(vector.frombytes(bytes(vector)))  # (1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0)\n\nreprlib.repr 这个函数用于生成大型结构或递归结构的安全表示形式，它会限制输出字符串的长度，用 ‘…’ 表示截断的部分。希望 Vector 实例的表示形式是 Vector([3.0,  4.0,  5.0]) 这样，而不是 Vector(array(‘d’,  [3.0,  4.0, 5.0]))，因为 Vector 实例中的数组是实现细节。\n写__repr__方法时，本可以生成简化的 components 显示形式 reprlib.repr(list(self._components))，然而，这么做有点浪费，因为要把 self._components  中的每个元素复制到一个列表中，然后使用列表的表示形式。而是直接把 self._components 传给 reprlib.repr 函数，然后去掉 [] 外面的字符，\n调用 repr() 函数的目的是调试，因此绝对不能抛出异常。如果 __repr__ 方法的实现有问题，那么必须处理，尽量输出有用的内容，让用户能够识别目标对象。\n\n协议和鸭子模型在 Python 中创建功能完善的序列类型无需使用继承，只需实现符合序列协议的方法。\n在面向对象编程中，协议是非正式的接口，只在文档中定义，在代码中不定义。例如，Python 的序列协议只需要 __len__和 __getitem__ 两个方法。任何类（如 Spam），只要使用标准的签名和语义实现了这两个方法能用在任何期待序列的地方。Spam 是不是哪个类的子类无关紧要，只要提供了所需的方法即可。\nimport collectionsCard = collections.namedtuple(&#x27;Card&#x27;, [&#x27;rank&#x27;, &#x27;suit&#x27;])class FranchDeck:    ranks = [str(n) for n in range(2, 11)] + list(&#x27;JQKA&#x27;)    suits = &#x27;spades diamends clubs hearts&#x27;.split()    def __init__(self):        self._cards = [Card(rank, suit)                       for suit in self.suits                       for rank in self.ranks]    def __len__(self):        return len(self._cards)    def __getitem__(self, position):        return self._cards[position]f = FranchDeck()for i in f:    print(i)print(len(f))\n\n FrenchDeck 类能充分利用 Python 的很多功能，因为它实现了序列协议，不过代码中并没有声明这一点。我们说它是序列，因为它的行为像序列，这才是重点。\n不要检查它是不是鸭子、它的叫声像不像鸭子、它的走路姿势像不像鸭子，等等。具体检查什么取决于你想使用语言的哪些行为。 ——  Alex Martelli \n协议是非正式的，没有强制力，因此如果你知道类的具体使用场景，通常只需要实现一个协议的部分。例如，为了支持迭代，只需实现 __getitem__ 方法，没必要提供 __len__ 方法。\n\n可切片的序列让 Vector 表现为序列所需的两个方法：__len__ 和 __getitem__ 。\nclass Vector:    typecode = &#x27;d&#x27;    # 省略其他函数，加入len、getitem\t\tdef __len__(self):        return len(self._components)    def __getitem__(self, index):        return self._components[index]vector = Vector(range(7))print(len(vector))  # 7print(vector[0])  # 0.0print(vector[1:3])  # array(&#x27;d&#x27;, [1.0, 2.0])  \n\n这里切片生成还只是普通的数组。\n\n切片原理举例：\nclass Myseq:    def __getitem__(self, index):        return indexseq = Myseq()seq[1]1seq[1:4]slice(1, 4, None)seq[1:4:2]slice(1, 4, 2)seq[1:4:2, 9](slice(1, 4, 2), 9)  # 如果[]中有逗号，那么__getitem__收到的是元组。seq[1:4:2, 7:9]   # 元组中甚至可以有多个切片对象。(slice(1, 4, 2), slice(7, 9, None))\n\n关于slice：\n&gt;&gt;&gt; slice&lt;class &#x27;slice&#x27;&gt;  # slice 是内置的类型&gt;&gt;&gt; dir(slice)[&#x27;__class__&#x27;, &#x27;__delattr__&#x27;, &#x27;__dir__&#x27;, &#x27;__doc__&#x27;, &#x27;__eq__&#x27;, &#x27;__format__&#x27;, &#x27;__ge__&#x27;, &#x27;__getattribute__&#x27;, &#x27;__gt__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__init_subclass__&#x27;, &#x27;__le__&#x27;, &#x27;__lt__&#x27;, &#x27;__ne__&#x27;, &#x27;__new__&#x27;, &#x27;__reduce__&#x27;, &#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;, &#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;, &#x27;__subclasshook__&#x27;, &#x27;indices&#x27;, &#x27;start&#x27;, &#x27;step&#x27;, &#x27;stop&#x27;]\n\nslice 有 start、stop 和 step 数据属性，以及 indices 方法。\nhelp(slice.indices)Help on method_descriptor:indices(...)    S.indices(len) -&gt; (start, stop, stride)        Assuming a sequence of length len, calculate the start and stop    indices, and the stride(步幅) length of the extended slice described by    S. Out of bounds indices are clipped(截断) in a manner consistent with the    handling of normal slices.\n\nindices 方法开放了内置序列实现的棘手逻辑，用于优雅地处理缺失索引和负数索引，以及长度超过目标序列的切片。这个方法会“整顿”元组，把 start、stop 和 stride 都变成非负数，而且都落在指定长度序列的边界内。\nslice(None, 10, 2).indices(5)(0, 5, 2)slice(-3, None, None).indices(5)(2, 5, 1)&#x27;ABCDE&#x27;[:10:2] &#x27;ACE&#x27;&#x27;ABCDE&#x27;[-3:]&#x27;CDE&#x27;\n\n\n能处理切片的 __getitem__ 方法import mathimport numbersimport reprlibfrom array import arrayclass Vector:    typecode = &#x27;d&#x27;    def __init__(self, components):        self._classname = type(self).__name__  # Vector        self._components = array(self.typecode, components)  # array(&#x27;d&#x27;, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])    def __iter__(self):        return iter(self._components)    def __repr__(self):        components = reprlib.repr(self._components)  # &quot;array(&#x27;d&#x27;, [1.0, 2.0, 3.0, 4.0, 5.0, ...])&quot;        components = components[components.find(&#x27;[&#x27;):-1]        return f&#x27;&#123;self._classname&#125;(&#123;components&#125;)&#x27;    def __str__(self):        return f&#x27;&#123;self._classname&#125;(&#123;list(self)&#125;)&#x27;    def __bytes__(self):        return (bytes([ord(self.typecode)]) + bytes(self._components))        # 这里不能像abs和bool函数里写的那样直接写self，会导致循环调用__bytes__    def __eq__(self, other):        return tuple(self) == tuple(other)    def __abs__(self):        return math.sqrt(sum(x * x for x in self))    def __bool__(self):        return bool(abs(self))    @classmethod    def frombytes(cls, octets):        typecode = chr(octets[0])  # d b&#x27;d\\x00\\x00\\x00\\x0.....        memv = memoryview(octets[1:]).cast(typecode)        return cls(memv)    def __len__(self):        return len(self._components)\t\t# 主要是__getitem__函数的修改    def __getitem__(self, index):        cls = type(self)  # &lt;class &#x27;__main__.Vector&#x27;&gt;        if isinstance(index, slice):            return cls(self._components[index])        elif isinstance(index, numbers.Integral):            return self._components[index]        else:            msg = f&#x27;&#123;cls.__name__&#125; indices must be integers&#x27;            raise TypeError(msg.format(cls=cls))vector = Vector(range(7))print(repr(vector))  # Vector([0.0, 1.0, 2.0, 3.0, 4.0, ...])print(vector)  # Vector([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0])print(len(vector))  # 7print(vector[0])  # 0.0print(vector[1:3])  # Vector([1.0, 2.0])print(vector.frombytes(bytes(vector)))  # Vector([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n\n\n动态存取属性在 Vector2d 中，使用 @property 装饰器把 x 和 y 标记为只读特性（以前的例子）。我们可以在Vector 中编写四个特性，但这样太麻烦。特殊方法 __getattr__ 提供了更好的方式。属性查找失败后，解释器会调用 __getattr__ 方法：\n\n对于 my_obj.x 表达式，Python会检查 my_obj 实例有没有名为 x 的属性；\n若没有，到类（my_obj.__class__）中查找 (可查阅 dir(vector.__class__ )；\n若仍没有，顺着继承树继续查找；\n若依旧找不到，调用 my_obj 所属类中定义的 __getattr__ 方法，传入 self 和属性名称的字符串形式（如 ‘x’）。\n\nclass Vector:    typecode = &#x27;d&#x27;    shortcut_name = &#x27;xyzw&#x27;    def __init__(self, components):        self.cls = type(self)  # &lt;class &#x27;__main__.Vector&#x27;&gt;        self._classname = self.cls.__name__  # Vector        self._components = array(self.typecode, components)      # 属性查找失败后，解释器会调用 __getattr__ 方法    def __getattr__(self, item):        if len(item) == 1 and item in self.shortcut_name:            return self._components[self.shortcut_name.index(item)]        # if len(item) == 1:        #     index = self.cls.shortcut_name.find(item)        #     if 0 &lt;= index &lt; len(self._components):        #         return self._components[index]        else:            msg = f&#x27;&#123;self.cls&#125; object has no attribute &#123;item&#125;&#x27;            raise AttributeError(msg)                 # 省略其他函数    vector = Vector(range(1,7))print(vector.x)  # 1.0  使用 vector.x 获取第一个元素（v[0]）vector.x = 10    # 为 vector.x 赋新值，这个操作应该抛出异常。print(vector.x)  # 10   向量的分量没变。print(vector)    # Vector([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n\n最后打印vector，发现向量的分量数组中没有新值，为什么 vector.x 返回10 ？之所以前后矛盾，是 __getattr__ 的运作方式导致的：\n仅当对象没有指定名称的属性时，Python 才会调用 __getattr__ 方法，这是一种后备机制。可是，像 v.x  &#x3D;  10 这样赋值之后，v 对象有 x 属性了，因此使用 v.x 获取 x 属性的值时不会调用 __getattr__ 方法了，解释器直接返回绑定到 v.x 上的值，即 10。另一方面，__getattr__ 方法的实现没有考虑到self._components 之外的实例属性，而是从这个属性中获取 shortcut_names 中所列的“虚拟属性”。\n如何才能处理上述现象，使用 __setattr__，避免这种前后矛盾的现象，需要改写 Vector 类中设置属性的逻辑。 之前是使用 @property 装饰器把 x 和 y 标记为只读特性，现在不使用这种方式，但是想达到的目的是一样的：如果为 .x 或 .y 实 例 属 性 赋 值， 会 抛 出AttributeError；为了避免歧义，在 Vector 类中，如果为名称是单个小写字母的属性赋值，我们也想抛出那个异常。为此，我们要实现 __setattr__ 方法：\nclass Vector:    typecode = &#x27;d&#x27;    shortcut_name = &#x27;xyzw&#x27;    def __init__(self, components):        self.cls = type(self)         self._classname = self.cls.__name__          self._components = array(self.typecode, components)      def __getattr__(self, item):        if len(item) == 1 and item in self.shortcut_name:            return self._components[self.shortcut_name.index(item)]        else:            msg = f&#x27;&#123;self._classname&#125; object has no attribute: &#123;item&#125;&#x27;            raise AttributeError(msg)    def __setattr__(self, key, value):        if len(key) == 1:  # 这里只特别处理名称是单个字符的属性            if key in self.cls.shortcut_name:                error = f&#x27;readonly attribute &#123;self._classname&#125;&#x27;            elif key.islower():                error = f&#x27;can\\&#x27;t set attrbute &quot;a&quot; to &quot;z&quot; in &#123;self._classname&#125;&#x27;            else:                error = &#x27;&#x27;            if error:                raise AttributeError(error)        super().__setattr__(key, value)  # 默认情况：在超类上调用 __setattr__ 方法，提供标准行为。           # 省略其他函数    vector = Vector(range(1,7))# print(vector.a)  # AttributeError: Vector object has no attribute: aprint(vector.x)  # 1.0vector.x = 10  # AttributeError: readonly attribute Vector# vector.a = 10  # AttributeError: can&#x27;t set attrbute &quot;a&quot; to &quot;z&quot; in Vector# vector.A = 10# print(vector.A)  # 10\n\n抄注：super() 函数用于动态访问超类的方法，对 Python 这样支持多重继承的动态语言来说，必须能这么做。程序员经常使用这个函数把子类方法的某些任务委托给超类中适当的方法。\n\n散列和快速等值测试计算聚合异或的 3 种方式：一种使用 for 循环，两种使用 reduce 函数：\nimport functoolsimport operatorn = 0for i in range(6):    n ^= iprint(n)print(functools.reduce(lambda a, b: a ^ b, range(6)))print(functools.reduce(operator.xor, range(6)))\n\n注：operator 模块以函数的形式提供了 Python 的全部中缀运算符，从而减少使用 lambda 表达式。\n再次实现 __hash__ 方法，加上现有的 __eq__方法，这会把 Vector 实例变成可散列的对象。之前的示例中的 __hash__ 方法简单地计算 hash(self.x) ^ hash(self.y)。这一次，我们要使用 ^（异或）运算符依次计算各个分量的散列值，像这样：v[0]  ^  v[1]  ^  v[2]…。这正是 functools.reduce 函数的作用。之前说 reduce 没有以往那么常用，但是计算向量所有分量的散列值非常适合使用这个函数。\nclass Vector:    typecode = &#x27;d&#x27;    shortcut_name = &#x27;xyzw&#x27;    def __init__(self, components):        self.cls = type(self)  # &lt;class &#x27;__main__.Vector&#x27;&gt;        self._classname = self.cls.__name__  # Vector        self._components = array(self.typecode, components)             def __iter__(self):        return iter(self._components)    # 省略其他函数        def __len__(self):        return len(self._components)          def __hash__(self):        hashed = (hash(x) for x in self._components)  # 创建生成器表达式，惰性计算各个分量的散列值。        return functools.reduce(operator.xor, hashed, 0)  # 把hashed给reduce 函数，使用xor函数计算聚合的散列值；第三个参数，0是初始值。    vector = Vector(range(1,7))\n\n注：使用 reduce 函数时最好提供第三个参数，reduce(function,  iterable, initializer)，这样能避免这个异常：TypeError: reduce() of empty sequence with  no  initial  value。如果序列为空，initializer 是返回的结果；否则，在归约中使用它作为第一个参数，因此应该使用恒等值。比如，对 +、| 和 ^ 来说，initializer 应该是 0；而对 * 和 &amp; 来说，应该是 1。\n修改  __eq__ 方法，减少处理时间和内存用量——对大型向量来说：\ndef __eq__(self, other):    # return tuple(self) == tuple(other)  # 对于多维向量比较太耗时、低效    if len(self) != len(other):        return False    for a, b in zip(self, other):  # zip 函数生成一个由元组构成的生成器        if a != b:            return False    return True\n\n用于计算聚合值的整个 for 循环可以替换成一行 all 函数调用：如果所有分量对的比较结果都是 True，那么结果就是 True。只要有一次比较的结果是False，all 函数就返回 False。\ndef __eq__(self, other):    # 使用聚合函数 all    return len(self) == len(other) and all(a == b for a, b in zip(self, other))\n首先要检查两个操作数的长度是否相同，因为 zip 函数会在最短的那个操作数耗尽时停止。\n关于 zip 函数：\n内置的 zip 函数。使用 zip 函数能轻松地并行迭代两个或更多可迭代对象，它返回的元组可以拆包成变量，分别对应各个并行输入中的一个元素。zip 函数的名字取自拉链系结物（zipper fastener），因为这个物品用于把两个拉链边的链牙咬合在一起，这形象地说明了 zip(left,  right) 的作用。zip 函数与文件压缩没有关系。\n&gt;&gt;&gt; zip(range(3), &#x27;abc&#x27;)&lt;zip object at 0x0000023375683D08&gt;&gt;&gt;&gt; list(zip(range(3), &#x27;abc&#x27;))[(0, &#x27;a&#x27;), (1, &#x27;b&#x27;), (2, &#x27;c&#x27;)]&gt;&gt;&gt; list(zip(range(3), &#x27;abc&#x27;, [0.0, 1.1, 2.2, 3.3]))[(0, &#x27;a&#x27;, 0.0), (1, &#x27;b&#x27;, 1.1), (2, &#x27;c&#x27;, 2.2)]&gt;&gt;&gt; from itertools import zip_longest&gt;&gt;&gt; list(zip_longest(range(3), &#x27;ABC&#x27;, [0.0, 1.1, 2.2, 3.3], fillvalue=-1))[(0, &#x27;A&#x27;, 0.0), (1, &#x27;B&#x27;, 1.1), (2, &#x27;C&#x27;, 2.2), (-1, -1, 3.3)]\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python 继承的优缺点","url":"/posts/2020/02/08/59889/","content":"子类化内置类型很麻烦在Python3中，内置类型可以子类化，但是有个重要的注意事项：内置类型（CPython）不会调用用户定义的类覆盖的特殊方法。\n内置类型的方法不会调用子类覆盖的方法。例如，dict 的子类覆盖的 __getitem__() 方法不会被内置类型的 get() 方法调用。\nclass DoppelDict(dict):    def __setitem__(self, key, value):        super().__setitem__(key, [key] * 2)d = DoppelDict(one=1)d[&quot;two&quot;] = 2d.update(three=3)print(d)# &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: [&#x27;two&#x27;, &#x27;two&#x27;], &#x27;three&#x27;: 3&#125;\n\n可以看出继承自 dict 的 __init__ 、update 方法显然忽略了覆盖的 __setitem__ 方法，[] 运算符会调用覆盖的 __setitem__  方法。\n原生类型的这种行为违背了面向对象编程的一个基本原则：始终应该从实例（self）所属的类开始搜索方法，即使在超类实现的类中调用也是如此。在这种糟糕的局面中， __missing__ 方法却能按预期方式工作，不过这只是特例。\n不只实例内部的调用有这个问题（self.get() 不调用 self.__getitem__()），内置类型的方法调用的其他类的方法，如果被覆盖了，也不会被调用。\nclass answerDict(dict):    def __getitem__(self, item):        return 100ad = answerDict(one=1)print(ad[&quot;one&quot;])  # 100  不管传入什么键，AnswerDict.__getitem__ 方法始终返回100。new_ad = &#123;&#125;new_ad.update(ad)print(new_ad)  # &#123;&#x27;one&#x27;: 1&#125;print(new_ad[&quot;one&quot;])  # 1  dict.update 方法忽略了AnswerDict.__getitem__方法。\n\n小结：直接子类化内置类型（如 dict、list 或 str）容易出错，因为内置类型的方法通常会忽略用户覆盖的方法。不要子类化内置类型，用户自己定义的类应该继承 collections 模块中的类，例如 UserDict、UserList 和 UserString，这些类做了特殊设计，因此易于扩展。\nfrom collections import UserDictclass DoppelDict(UserDict):    def __setitem__(self, key, value):        super().__setitem__(key, [key] * 2)class answerDict(UserDict):    def __getitem__(self, item):        return 100\n\n\n多重继承和方法解析顺序任何实现多重继承的语言都要处理潜在的命名冲突，这种冲突由不相关的祖先类实现同名方法引起。\nclass A:    def ping(self):        print(&quot;A ping&quot;, self)class B(A):    def pong(self):        print(&quot;B pong&quot;, self)class C(A):    def pong(self):        print(&quot;C pong&quot;, self)class D(B, C):    def ping(self):        super().ping()        print(&quot;D ping&quot;, self)    def pingpong(self):        self.ping()        super().ping()        self.pong()        super().pong()        C.pong(self)d = D()# 直接调用 d.pong() 运行的是 B 类中的版本d.pong()  # B pong &lt;__main__.D object at 0x000001984DC16AC8&gt;# 超类中的方法都可以直接调用，此时要把实例作为显式参数传入C.pong(d) # C pong &lt;__main__.D object at 0x000001984DC16AC8&gt;B.pong(d) # B pong &lt;__main__.D object at 0x000001984DC16AC8&gt;\n\nPython 能区分 d.pong() 调用的是哪个方法，是因为 Python 会按照特定的顺序遍历继承图。这个顺序叫方法解析顺序（Method Resolution Order，MRO）。类都有一个名为 __mro__ 的属性，它的值是一个元组，按照方法解析顺序列出各个超类，从当前类一直向上，直到object 类。有了这一机制，继承方法的名称不再会发生冲突。\nprint(D.__mro__)# (&lt;class &#x27;__main__.D&#x27;&gt;, &lt;class &#x27;__main__.B&#x27;&gt;, &lt;class &#x27;__main__.C&#x27;&gt;, &lt;class &#x27;__main__.A&#x27;&gt;, &lt;class &#x27;object&#x27;&gt;)print(bool.__mro__)  # 可以看出 bool 从 int 和 object 中继承方法和属性。# (&lt;class &#x27;bool&#x27;&gt;, &lt;class &#x27;int&#x27;&gt;, &lt;class &#x27;object&#x27;&gt;)\n\n若想把方法调用委托给超类，推荐的方式是使用内置的 super() 函数。然而，有时可能需要绕过方法解析顺序，直接调用某个超类的方法——这样做有时更方便。例如，D.ping 方法可以这样写：\ndef ping(self):    # super().ping()    A.ping(self)  # 直接在类上调用实例方法时，必须显式传入self参数，因为这样访问的是未绑定方法（unbound method）    print(&quot;D ping&quot;, self)\n\n使用 super() 最安全，也不易过时。调用框架或不受自己控制的类层次结构中的方法时，尤其适合使用 super()。使用 super() 调用方法时，会遵守方法解析顺序。\nd.ping()# A ping &lt;__main__.D object at 0x0000026DB0765B38&gt;# D ping &lt;__main__.D object at 0x0000026DB0765B38&gt;\n\ndef pingpong(self):    self.ping()  # A ping、D ping、    super().ping()  # A ping    self.pong()  # B pong    super().pong()  # B pong    C.pong(self)  # C pong\n\n其中，第三个调用是 self.pong()，根据 __mro__，找到的是 B 类实现的 pong 方法。第四个调用是 super().pong()，也根据 __mro__，找到 B 类实现的 pong 方法。第五个调用是 C.pong(self)，忽略 __mro__，找到的是 C 类实现的 pong 方法。\n方法解析顺序不仅考虑继承图，还考虑子类声明中列出超类的顺序。也就是说，如果在把 D 类声明为 class  D(C,  B):，那么 D 类的 __mro__ 属性就会不一样：先搜索 C 类，再搜索 B 类。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"流畅的Python：符合Python风格的对象","url":"/posts/2020/01/05/43772/","content":"对象表示形式每门面向对象的语言至少都有一种获取对象的字符串表示形式的标准方式。Python 提供了两种方式。\n\nrepr() : 以便于开发者理解的方式返回对象的字符串表示形式。\n\nstr() : 以便于用户理解的方式返回对象的字符串表示形式。\n\n\n在 Python 3 中，__repr__、__str__ 和__format__ 都必须返回 Unicode 字符串（str 类型），只有 __bytes__ 方法应该返回字节序列（bytes 类型）。\n\n向量类的示例import mathfrom array import arrayclass Vector2d(object):    typecode = &#x27;d&#x27;    def __init__(self, x, y):        self.x = float(x)        self.y = float(y)    def __iter__(self):   # TypeError: &#x27;Vector2d&#x27; object is not iterable        return (i for i in (self.x, self.y))  # a, b = v    def __str__(self):        return &quot;str:&quot; + str(tuple(self))  # print(v)    def __repr__(self):        class_name = type(self).__name__        return f&#x27;&#123;class_name&#125;(&#123;self.x&#125;,&#123;self.y&#125;)&#x27;  # repr(v)        # return &#x27;&#123;&#125;(&#123;!r&#125;,&#123;!r&#125;)&#x27;.format(class_name, *self)  # repr(v)        # return f&#x27;repr:&#123;class_name&#125;(&#123;self.x&#125;,&#123;self.y&#125;)&#x27;  # repr(v)    def __bytes__(self):        return (bytes([ord(self.typecode)]) + bytes(array(self.typecode,self)))    def __eq__(self, other):        return tuple(self) == tuple(other)    def __abs__(self):        return math.hypot(self.x, self.y)    def __bool__(self):        return bool(abs(self))    def __call__(self, *args, **kwargs):        return self\n\nv = Vector2d(3, 4)print(v.x ,v.y)  # Vector2d 实例的分量可以直接通过属性访问（无需调用读值方法）。# 3.0 4.0x, y = v  # 拆包成变量元组x, y# (3.0, 4.0)v  # repr 函数调用 Vector2d 实例，得到的结果类似于构建实例的源码。# Vector2d(3.0,4.0)v_clone = eval(repr(v)) # 使用eval函数，表明repr函数调用Vector2d实例得到的是对构造方法的准确表述。v == v_clone   # Vector2d 实例支持使用 == 比较；这样便于测试# Truev_clone.x ,v_clone# (3.0, 4.0)print(v)  # print 函数会调用 str 函数，对 Vector2d 来说，输出的是一个有序对。# str:(3.0, 4.0)bytes(v)# b&#x27;d\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@&#x27;abs(v)# 5.0bool(v), bool(Vector2d(0, 0))# (True, False)\n\n\nclassmethod与staticmethodclassmethod 用法：定义操作类，而不是操作实例的方法。classmethod 改变了调用方法的方式，因此类方法的第一个参数是类本身，而不是实例。classmethod 最常见的用途是定义备选构造方法。按照约定，类方法的第一个参数名为 cls。\nstaticmethod 装饰器也会改变方法的调用方式，但是第一个参数不是特殊的值。其实，静态方法就是普通的函数，只是碰巧在类的定义体中，而不是在模块层定义。\nclass Demo():    @classmethod    def cls_method(*args):        return args    @staticmethod    def static_method(*args):        return argsprint(Demo.cls_method())  # (&lt;class &#x27;__main__.Demo&#x27;&gt;,)print(Demo.cls_method(&#x27;a&#x27;))  # (&lt;class &#x27;__main__.Demo&#x27;&gt;, &#x27;a&#x27;)print(Demo.static_method())  # () print(Demo.static_method(&#x27;b&#x27;))  # (&#x27;b&#x27;,)  \n\nclassmethod 装饰器非常有用，但是从未见过不得不用 staticmethod 的情况。如果想定义不需要与类交互的函数，那么在模块中定义就好了。有时，函数虽然从不处理类，但是函数的功能与类紧密相关，因此想把它放在近处。即便如此，在同一模块中的类前面或后面定义函数也就行了。\n\n格式化显示内置的 format() 函数和 str.format() 方法把各个类型的格式化方式委托给相应的\n.__format__(format_spec) 方法。format_spec 是格式说明符，它是：\n\nformat(my_obj, format_spec) 的第二个参数，或者\n\nstr.format() 方法的格式字符串，{} 里代换字段中冒号后面的部分\n\n\nbrl = 1 / 2.43  # BRL到USD的货币兑换比价brl# 0.4115226337448559format(brl, &#x27;0.4f&#x27;)# &#x27;0.4115&#x27;&#x27;1 BRL = &#123;rate:0.2f&#125; USD&#x27;.format(rate=brl)# &#x27;1 BRL = 0.41 USD&#x27;\n\n格式说明符是’0.4f’、 ‘0.2f’。代换字段中的 ‘rate’ 子串是字段名称，与格式说明符无关，但是它决定把 .format() 的哪个参数传给代换字段。\n格式规范微语言为一些内置类型提供了专用的表示代码。比如，b 和 x 分别表示二进制和十六进制的 int 类型，f 表示小数形式的 float 类型， % 表示百分数形式：\nformat(17, &#x27;x&#x27;)# &#x27;11&#x27;format(8, &#x27;b&#x27;)# &#x27;1000&#x27;format(2 / 5, &#x27;.1%&#x27;)# &#x27;40.0%&#x27;format(2 / 5, &#x27;.1f&#x27;)# &#x27;0.4&#x27;\n\n格式规范微语言是可扩展的，因为各个类可以自行决定如何解释 format_spec 参数。例如datetime 模块中的类，它们的 __format__ 方法使用的格式代码与 strftime() 函数一样。下面是内置的 format() 函数和 str.format() 方法的几个示例：\nfrom datetime import datetimenow = datetime.now()now# datetime.datetime(2020, 1, 1, 20, 36, 45, 959123)format(now, &#x27;%H:%M:%S&#x27;)# &#x27;20:36:45&#x27;&#x27;now is &#123;:%I:%M %p&#125;&#x27;.format(now)# &#x27;now is 08:36 PM&#x27;\n\n如果类没有定义__format__方法，从 object 继承的方法会返回 str(my_object)。我们为Vector2d 类定义了 __str__ 方法，因此可以这样做：\nclass Vector2d(object):  # 省略其他函数\tdef __str__(self):        return &quot;str:&quot; + str(tuple(self))  # print(v)v = Vector2d(3, 4)print(format(V))  # str:(3.0, 4.0)print(format(v, &#x27;.3f&#x27;))  # 如果传入格式说明符，报错TypeError: unsupported format string passed to Vector2d.__format__\n\n如果想要实现自己的微语言来处理这个报错，且想要的效果如下：\nprint(format(v, &#x27;.3f&#x27;))# (3.000, 4.000)print(format(v, &#x27;.3e&#x27;))# (3.000e+00, 4.000e+00)\n\nclass Vector2d(object):    # 省略其他函数    def __format__(self, format_spec=&#x27;&#x27;):        # 使用内置的format函数把fmt_spec应用到向量的各个分量上，构建一个可迭代的格式化字符串        components = (format(item, format_spec) for item in self)        # 把格式化字符串代入公式 &#x27;(x, y)&#x27;         return &#x27;(&#123;&#125;, &#123;&#125;)&#x27;.format(*components)\n\n\n可散列的Vector2d为了把 Vector2d 实例变成可散列的，必须使用__hash__方法（还需要 __eq__ 方法，前面已经实现了）。此外，还要让向量不可变。\n目前，我们可以为分量赋新值，如 v.x &#x3D; 7，Vector2d 类的代码并不阻止这么做。为此，我们要把 x 和 y 分量设为只读特性，这样才能实现__hash__方法。\nimport mathfrom array import arrayclass Vector2d(object):    typecode = &#x27;d&#x27;    def __init__(self, x, y):        self.__x = float(x)  # 属性标记为私有的        self.__y = float(y)    @property  # @property 装饰器把读值方法标记为特性    def x(self):  # 读值方法与公开属性同名，都是x        return self.__x    @property    def y(self):        return self.__y    def __hash__(self):        return hash(self.x) ^ hash(self.y)  # 异或          # 需要读取x和y分量的方法可保持不变，通过self.x和self.y读取公开特性，不必读取私有属性    def __iter__(self):        return (i for i in (self.x, self.y))          def __eq__(self, other):        return tuple(self) == tuple(other)\t\t# 其他函数省略    v = Vector2d(3, 4)print(v.x, v.y)v.x = 10  # AttributeError: can&#x27;t set attributeprint(v.x)\n\nhash方法应该返回一个整数，理想情况下还要考虑对象属性的散列值（__eq__ 方法也要使用），因为相等的对象应该具有相同的散列值，最好使用位运算符 异或（^）混合各分量的散列值。添加 __hash__ 方法之后，向量变成可散列的了：\nv1 = Vector2d(3, 4)v2 = Vector2d(3.1, 4.1)print(hash(v1))  # 7print(hash(v2))  # 1031\n\n要想创建可散列的类型，不一定要实现特性，也不一定要保护实例属性，只需正确地实现 __hash__ 和__eq__方法即可。但是，实例的散列值绝不应该变化，因此我们借机提到了只读特性。\n\nPython的私有属性和“受保护的”属性 Python 有个简单的机制，能避免子类意外覆盖“私有”属性。\n举个例子。有人编写了一个名为 Dog 的类，这个类的内部用到了 mood 实例属性，但是没有将其开放。现在，你创建了 Dog 类的子类：Beagle。如果你在毫不知情的情况下又创建了名为 mood 的实例属性，那么在继承的方法中就会把 Dog 类的 mood 属性覆盖掉。这是个难以调试的问题。\n为了避免这种情况，如果以 __mood 的形式（两个前导下划线，尾部没有或最多有一个下划线）命名实例属性，Python 会把属性名存入实例的 __dict__ 属性中，而且会在前面加上一个下划线和类名。因此，对 Dog 类来说，__mood 会变成  _Dog__mood ；对 Beagle 类来说，会变成 _Beagle__mood 。这个语言特性叫名称改写（name mangling）。\nclass Vector2d(object):    def __init__(self, x, y):        self.__x = float(x)  # 属性标记为私有的        self.__y = float(y)v = Vector2d(3, 4)print(v.__dict__)# &#123;&#x27;_Vector2d__x&#x27;: 3.0, &#x27;_Vector2d__y&#x27;: 4.0&#125;print(v._Vector2d__x)# 3.0\n\n名称改写是一种安全措施，不能保证万无一失：它的目的是避免意外访问，不能防止故意做错事。比如：只要知道改写私有属性名的机制，任何人都能直接读取私有属性——这对调试和序列化倒是有用。此外，只要编写 v1._Vector__x  =  7 这样的代码，就能轻松地为 Vector2d 实例的私有分量直接赋值。\nPython 解释器不会对使用单个下划线的属性名做特殊处理，这不过是很多 Python 程序员严格遵守的约定，他们不会在类外部访问这种属性。 遵守使用一个下划线标记对象的私有属性很容易，就像遵守使用全大写字母编写常量那样容易。\n\n使用__slot__ 类属性节省空间默认情况下，Python 在各个实例中名为 __dict__ 的字典里存储实例属性。\n为了使用底层的散列表提升访问速度，字典会消耗大量内存。如果要处理数百万个属性不多的实例，通过__slots__类属性，能节省大量内存，方法是让解释器在元组中存储实例属性，而不用字典。\n继承自超类的 __slots__ 属性没有效果。Python 只会使用各个类中定义的 __slots__ 属性。\n定义__slots__ 的方式是，创建一个类属性，使用 __slots__ 这个名字，并把它的值设为一个字符串构成的可迭代对象，其中各个元素表示各个实例属性。\nclass Vector2d(object):    # 这里使用元组，因为这样定义的__slots__中所含的信息不会变化    __slots__ = (&#x27;__x&#x27;, &#x27;__y&#x27;)    def __init__(self, x, y):        self.__x = float(x)        self.__y = float(y)v = Vector2d(3, 4)print(v.__slots__)# (&#x27;__x&#x27;, &#x27;__y&#x27;)# print(v.__dict__)  # 有了__slot__后就没有__dict__属性了# AttributeError: &#x27;Vector2d&#x27; object has no attribute &#x27;__dict__&#x27;print(v._Vector2d__x)# 3.0\n\n在类中定义 __slots__ 属性的目的是告诉解释器：“这个类中的所有实例属性都在这里了。”这样，Python 会在各个实例中使用类似元组的结构存储实例变量，从而避免使用消耗内存的__dict__属性。如果有数百万个实例同时活动，这样做能节省大量内存。\n在类中定义__slots__属性之后，实例不能再有__slots__中所列名称之外的其他属性。这只是一个副作用，不是__slots__存在的真正原因。不要使用 __slots__ 属性禁止类的用户新增实例属性。__slots__ 是用于优化的，不是为了约束程序员。\n__slots__ 属性有些需要注意的地方，而且不能滥用，不能使用它限制用户能赋值的属性。\n总之，如果使用得当，__slots__ 能显著节省内存，不过有几点要注意。\n\n每个子类都要定义__slots__属性，因为解释器会忽略继承的__slots__属性。\n实例只能拥有__slots__中列出的属性，除非把&#39;__dict__&#39;加入 __slots__ 中（这样做就失去了节省内存的功效）。\n如果不把 &#39;__weakref__&#39; 加入 __slots__，实例就不能作为弱引用的目标。\n\n\n覆盖类属性Python 有个很独特的特性：类属性可用于为实例属性提供默认值。\nclass Vector2d(object):    typecode = &#x27;d&#x27;    def __init__(self, x, y):        self.x = float(x)        self.y = float(y)            def __bytes__(self):        return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self)))\n\nVector2d 中有个 typecode类属性，__bytes__ 方法两次用到了它，而且都故意使用 self.typecode 读取它的值。因为Vector2d 实例本身没有 typecode 属性，所以 self.typecode 默认获取的是 Vector2d.typecode类属性的值。\n但是，如果为不存在的实例属性赋值，会新建实例属性。假如我们为 typecode 实例属性赋值，那么同名类属性不受影响。然而，自此之后，实例读取的 self.typecode 是实例属性typecode，也就是把同名类属性遮盖了。借助这一特性，可以为各个实例的 typecode 属性定制不同的值。\nclass Vector2d(object):    typecode = &#x27;d&#x27;    def __init__(self, x, y):        self.__x = float(x)        self.__y = float(y)v = Vector2d(3, 4)print(v.typecode)  # dv.typecode = &#x27;f&#x27;print(v.typecode)   # fprint(Vector2d.typecode)  # d\n\n如果想修改类属性的值，必须直接在类上修改，不能通过实例修改。如果想修改所有实例（没有 typecode 实例变量）的 typecode 属性的默认值，可以这么做：Vector2d.typecode = &#39;e&#39; 。\n有种修改方法更符合 Python 风格，而且效果持久，也更有针对性。类属性是公开的，因此会被子类继承，于是经常会创建一个子类，只用于定制类的数据属性。Django 基于类的视图就大量使用了这个技术。\nclass Vector2d(object):    typecode = &#x27;d&#x27;    def __init__(self, x, y):        self.x = float(x)        self.y = float(y)        # 没有硬编码class_name的值，而是使用type(self).__name__获取        self.class_name = type(self).__name__    def __str__(self):        return f&quot;str：&#123;self.class_name&#125;&quot; + str(tuple(self))  # print(v)            #  把 ShortVector2d 定义为 Vector2d 的子类，只用于覆盖 typecode 类属性class ShortVector2d(Vector2d):    typecode = &#x27;f&#x27;sv = ShortVector2d(1,2)print(sv)  # str：ShortVector2d(1.0, 2.0)print(sv.typecode)  # s\n\n同时，如果硬编码 class_name 的值，那么 Vector2d 的子类（如 ShortVector2d）要覆盖 __str__方法。从实例的类型中读取类名，__str__ 方法就可以放心继承。\n最后小结一下就是，通过一个简单的类Vector说明了如何利用数据模型处理 Python 的其他功能：提供不同的对象表示形式、实现自定义的格式代码、公开只读属性，以及通过 hash() 函数支持集合和映射。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"自动化测试—部分工作小结","url":"/posts/2020/07/04/1049/","content":"本周上班6天，从端午的假期结束开始，到现在，感觉时间好像过了很久似的。\n这周主要是在调试脚本、修改Gitlab上同事提交的问题了。其中上周的一个新增脚本继续调试，现在只要有环境就可以跑了。本周剩余的时间几乎都在修改问题，修改问题还是挺舒服的，没有很大的压力，只是不总是一直有问题改。\n通过改以前的脚本，可以发现一些问题：对于报错的地方，思考为什么当初没想到会出现这种问题；以前的代码写的哪里不好、哪里考虑不周，哪些地方可以写的更好，如果遇到自己都看的费劲的地方说明代码写的不好，需要优化。 经常回过头看自己写的东西，还是有不一样的体会的。\n在写有的脚本时，还是对很多东西欠缺考虑，举例本周的小问题，在写音频文件导入测试的case时，考虑到测试利用例的要求是模拟用户操作在UI层实现，所以直接写成UI自动化了，没有抓包看是否有纯接口的纯接口方式来实现，其实是有的，只是导入音频文件在浏览器开发工具中无法抓包，但是通过wireshark可以抓到文件post请求；同时在清理测试环境时，删除音频文件导入时在浏览器开发者工具中就可以抓到Delete的报文，当时没有去尝试，其实也有想到测试完音频文件导入后怎么清空已经导入的文件，对此用了其他方式来处理，是我这个case写的不好，今天算是做了修缮。\n经常做脚本的优化和问题单的修改，想想也是有写体会的。比如如何快速定位问题，现在是驾轻就熟了，主要是看测试报告中的报错信息、日志打印，语法问题都不算是问题了，基本可以解决，主要是一些不好确定是哪里有问题的Assert报错，脚本不稳定等一些无法复现的问题。对此，我一般都是在出现问题的环境中争取复现，若能复现基本就可以通过debug来解决所有问题。除此，还有异常处理和规避、兼容是适配 …… \n目前，我遇到的这块问题可以归类为以下几种情况：\n\n脚本语法问题，考虑不周\n环境问题影响\n异常处理、规避\n同事修改问题引入了其他问题\n测试场景构建没有达到预期的条件而报错\n测试场景达到后，没有得到预期的结果而Assert报错\n网络、设备不稳定导致的请求超时、接口配置下发后返回值有误\n版本不兼容、需要适配\n策略选择：哪些需要执行、哪些只在特定版本上执行\n脚本性能优化，如何提升执行效率、减少无谓耗时\n\n小结：\n\n多回顾自己以前写的代码和文章。\n多复习以前学的东西。\n多总结\n\n","categories":["技术","工作小结"],"tags":["总结"]},{"title":"Android 简单控件实现简易计算器","url":"/posts/2024/10/25/38516/","content":"学了一些Android的简单控件，用这些布局和控件，设计并实现一个简单计算器。\n计算器的界面分为两大部分，第一部分是上方的计算表达式，既包括用户的按键输入，也包括计算结果 数字；第二部分是下方的各个按键，例如：从0到9的数字按钮、加减乘除与等号、正负号按钮、小数点 按钮、求倒数按钮、平方按钮、开方按钮，以及退格、清空、取消等控制按钮。通过这些按键操作，能 够实现整数和小数的四则运算，以及求倒数、求平方、求开方等简单运算\n按照计算器App的效果图，大致分布着下列Android控件： \n\n线性布局LinearLayout：因为计算器界面整体从上往下布局，所以需要垂直方向的LinearLayout。\n网格布局GridLayout：计算器下半部分的几排按钮，正好成五行四列表格分布，适合采用 GridLayout。 \n滚动视图ScrollView：虽然计算器界面不宽也不高，但是以防万一，最好还是加个垂直方向的 ScrollView。 \n文本视图TextView：很明显顶部标题“简单计算器”就是TextView，且文字居中显示；标题下面的计 算结果也需要使用TextView，且文字靠右靠下显示。\n按钮Button：几乎所有的数字与运算符按钮都采用了Button控件。 \n图像按钮ImageButton：开根号的运算符“√”虽然能够打出来，但是右上角少了数学课本上的一横， 所以该按钮要显示一张标准的开根号图片，这用到了ImageButton。\n\n\nCalculatorActivity.java\npackage com.example.chapter03;import androidx.appcompat.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.TextView;public class CalculatorActivity extends AppCompatActivity implements View.OnClickListener &#123;    private TextView tv_result;    private String firstNum = &quot;&quot;; // 记录第一个操作数    private String secondNum = &quot;&quot;; // 记录第二个操作数    private String operator = &quot;&quot;; // 记录运算符    private String result = &quot;&quot;; // 记录运算结果    private String showText = &quot;&quot;; // 记录显示文本    @Override    protected void onCreate(Bundle savedInstanceState) &#123;        super.onCreate(savedInstanceState);        setContentView(R.layout.activity_calculator);        tv_result = findViewById(R.id.tv_result);        // 给每个按钮控件注册点击监听器        findViewById(R.id.btn_clear).setOnClickListener(this);        findViewById(R.id.btn_cancel).setOnClickListener(this);        findViewById(R.id.btn_plus).setOnClickListener(this);        findViewById(R.id.btn_minus).setOnClickListener(this);        findViewById(R.id.btn_multiply).setOnClickListener(this);        findViewById(R.id.btn_reciprocal).setOnClickListener(this);        findViewById(R.id.btn_equal).setOnClickListener(this);        findViewById(R.id.ib_sqrt).setOnClickListener(this);        findViewById(R.id.btn_divide).setOnClickListener(this);        findViewById(R.id.btn_zero).setOnClickListener(this);        findViewById(R.id.btn_one).setOnClickListener(this);        findViewById(R.id.btn_two).setOnClickListener(this);        findViewById(R.id.btn_three).setOnClickListener(this);        findViewById(R.id.btn_four).setOnClickListener(this);        findViewById(R.id.btn_five).setOnClickListener(this);        findViewById(R.id.btn_six).setOnClickListener(this);        findViewById(R.id.btn_seven).setOnClickListener(this);        findViewById(R.id.btn_eight).setOnClickListener(this);        findViewById(R.id.btn_nine).setOnClickListener(this);        findViewById(R.id.btn_dot).setOnClickListener(this);    &#125;    @Override    public void onClick(View v) &#123;        String inputText;        if (v.getId() == R.id.ib_sqrt) &#123;            inputText = &quot;√&quot;;        &#125; else &#123;            inputText = ((TextView) v).getText().toString();        &#125;        switch (v.getId()) &#123;            // 清除            case R.id.btn_clear:                clear();                break;            case R.id.btn_cancel:                if (!showText.equals(&quot;&quot;)) &#123;                    showText = showText.substring(0, showText.length() - 1);                    if (operator.equals(&quot;&quot;)) &#123;                        firstNum = showText;                    &#125; else &#123;                        secondNum = showText;                    &#125;                    refreshResult(showText);                &#125;                break;            case R.id.btn_plus:            case R.id.btn_minus:            case R.id.btn_multiply:            case R.id.btn_divide:                if (firstNum.equals(&quot;&quot;)) &#123;                    firstNum = &quot;0&quot;;                &#125;                operator = inputText;                refreshResult(showText + inputText);                break;            case R.id.btn_equal:                double calculate_result = calculateFour();                if (calculate_result == 0) &#123;                    result = showText;                &#125; else &#123;                    refreshOperate(String.valueOf(calculate_result));                    refreshResult(showText + &quot;=&quot; + result);                &#125;                break;            case R.id.ib_sqrt:                if (operator.equals(&quot;&quot;)) &#123;                    double sqrt_result = Math.sqrt(Double.parseDouble(firstNum));                    refreshOperate(String.valueOf(sqrt_result));                    refreshResult(&quot;√&quot; + firstNum + &quot;=&quot; + result);                &#125; else &#123;                    double sqrt_result = Math.sqrt(Double.parseDouble(secondNum));                    secondNum = String.valueOf(sqrt_result);                    refreshResult(firstNum + operator + secondNum);                &#125;                break;            case R.id.btn_reciprocal:                double reciprocal_result = 1 / Double.parseDouble(firstNum);                refreshOperate(String.valueOf(reciprocal_result));                refreshResult(&quot;1/&quot; + showText + &quot;=&quot; + result);                break;            default:                // 数字键                if ((result.contains(&quot;Error&quot;)) || (!result.equals(&quot;&quot;) &amp;&amp; operator.equals(&quot;&quot;))) &#123;                    clear();                &#125;                if (operator.equals(&quot;&quot;)) &#123;                    firstNum += inputText;                &#125; else &#123;                    secondNum += inputText;                &#125;                if (showText.equals(&quot;0&quot;) &amp;&amp; !inputText.equals(&quot;.&quot;)) &#123;                    refreshResult(inputText);                &#125; else &#123;                    refreshResult(showText + inputText);                &#125;                break;        &#125;    &#125;    private double calculateFour() &#123;        if (secondNum.equals(&quot;&quot;)) &#123;            secondNum = &quot;0&quot;;        &#125;        switch (operator) &#123;            case &quot;+&quot;:                return Double.parseDouble(firstNum) + Double.parseDouble(secondNum);            case &quot;-&quot;:                return Double.parseDouble(firstNum) - Double.parseDouble(secondNum);            case &quot;x&quot;:                return Double.parseDouble(firstNum) * Double.parseDouble(secondNum);            case &quot;÷&quot;:                if (Double.parseDouble(secondNum) == 0) &#123;                    clear();                    tv_result.setText(&quot;Error: 除数不能为0&quot;);                    return 0;                &#125;                return Double.parseDouble(firstNum) / Double.parseDouble(secondNum);        &#125;        return 0;    &#125;    // 清除    private void clear() &#123;        refreshOperate(&quot;&quot;);        refreshResult(&quot;&quot;);        firstNum = &quot;&quot;;        secondNum = &quot;&quot;;        operator = &quot;&quot;;        result = &quot;&quot;;        showText = &quot;&quot;;    &#125;    // 刷新运算结果    private void refreshOperate(String new_result) &#123;        result = new_result;        firstNum = result;        secondNum = &quot;&quot;;        operator = &quot;&quot;;    &#125;    // 刷新文本显示    private void refreshResult(String text) &#123;        showText = text;        tv_result.setText(showText);    &#125;&#125;\n\n代码：CalculatorActivity.java，res&#x2F;layout&#x2F;activity_calculator.xml \n","categories":["技术","Android"],"tags":["Android","Java"]},{"title":"Jenkins 数据备份到 Windows FTP 服务器","url":"/posts/2025/02/09/9722/","content":"背景在 CentOS 上搭建了 Jenkins 服务，为了防止意外丢失数据，我们需要定期备份 Jenkins 数据。本方案采用 FileZilla Server 作为 FTP 服务器，并使用 lftp 进行数据同步。\n\n1. 安装配置 FileZilla Server（Windows）在 Windows 上安装并配置 FileZilla Server 以接收 Jenkins 备份数据。\n参考：FileZilla Server&#x2F;Client 的简单使用-CSDN博客\n1.1 下载并安装 FileZilla Server\n下载 FileZilla Server 0.9.60.2 中文安装版\n安装并启动 FileZilla Server，弹出配置窗口：\n主机：localhost\n密码：留空，直接连接\n\n\n\n1.2 配置 FTP 用户和共享目录\n添加用户（用于 CentOS 连接 FTP 服务器上传文件）\n设置共享目录，假设目录路径为 F:\\FileZillaServer，用于存放备份数据。\n\n最终，FTP 服务器上的 Jenkins 备份目录路径为：\nF:\\FileZillaServer\\jenkins_home\n\n\n2. 安装并配置 FTP 客户端（CentOS）2.1 在 CentOS 安装 lftpsudo yum update -y  # 更新系统（CentOS 7/8）sudo yum install -y lftp\n\n\n3. 编写 Jenkins 备份脚本在 CentOS 服务器上创建 backup_jenkins_ftp.sh，用于定期同步 Jenkins 数据到 FTP 服务器。\n#!/bin/bash# FTP 配置FTP_HOST=&quot;xxx.22.212.xx&quot;FTP_USER=&quot;autotest&quot;FTP_PASS=&quot;autotest&quot;FTP_TARGET_DIR=&quot;jenkins_home&quot;  # Windows FTP 服务器上的目标目录（映射到 F:\\FileZillaServer\\jenkins_home）# Jenkins 数据目录（CentOS）SOURCE_DIR=&quot;/var/jenkins_home&quot;# 日志文件LOG_FILE=&quot;/var/log/jenkins_ftp_backup.log&quot;# 使用 lftp 进行文件同步lftp -u $FTP_USER,$FTP_PASS $FTP_HOST &lt;&lt;EOFset ftp:ssl-allow no  # 如果 FTP 服务器不支持 SSL，则禁用 SSLmirror -R $SOURCE_DIR $FTP_TARGET_DIR  # 递归同步 Jenkins 目录到 FTP 服务器quitEOF# 记录日志if [ $? -eq 0 ]; then    echo &quot;$(date &#x27;+%Y-%m-%d %H:%M:%S&#x27;) - 备份成功&quot; &gt;&gt; $LOG_FILEelse    echo &quot;$(date &#x27;+%Y-%m-%d %H:%M:%S&#x27;) - 备份失败&quot; &gt;&gt; $LOG_FILEfi\n\n3.1 赋予执行权限chmod +x backup_jenkins_ftp.sh\n\n3.2 测试执行sudo ./backup_jenkins_ftp.sh\n\n\n4. 配置定时任务（Crontab）为了实现自动备份，我们使用 crontab 定时执行脚本。\n4.1 编辑 Crontab 任务crontab -e\n\n添加以下任务，每天凌晨 2 点执行备份：\n0 2 * * * /home/xxx/jenkins/backup_jenkins_ftp.sh\n\n4.2 重启 Crontab 服务（适用于部分系统）sudo systemctl restart crond\n\n4.3 确认定时任务是否生效crontab -l\n\n\n5. 可能遇到的问题及解决方案5.1 脚本执行时报 &#39;&#39;: command not found 该问题通常是由于脚本文件包含 Windows 换行符 (\\r\\n)，而 Linux 只支持 \\n 造成的。\n解决方法：转换文件格式\ndos2unix backup_jenkins_ftp.sh\n\n如果 dos2unix 未安装，可用 sed 命令处理：\nsed -i &#x27;s/\\r$//&#x27; backup_jenkins_ftp.sh\n\n5.2 权限问题若执行时遇到权限不足的错误，可尝试：\nsudo chmod +x backup_jenkins_ftp.shsudo chmod 666 /var/log/jenkins_ftp_backup.log\n\n5.3 FTP 连接失败\n检查 FTP 服务器是否开启\ntelnet 172.22.212.25 21\n\n如果连接失败，需检查 Windows 上 FileZilla Server 是否正常运行。\n\n检查防火墙是否开放 21 端口\nsudo firewall-cmd --add-port=21/tcp --permanentsudo firewall-cmd --reload\n\n\n6. 总结通过以上步骤，我们完成了 Jenkins 备份到 Windows FTP 服务器的自动化流程，主要包括：\n\n在 Windows 上安装 FileZilla Server 作为 FTP 服务器。\n在 CentOS 上安装 lftp 并编写同步脚本。\n配置 Crontab 实现每日自动备份。\n处理常见问题，确保备份流程稳定运行。\n\n🎯 至此，Jenkins 数据将每日自动备份至 Windows FTP 服务器，确保数据安全可靠！ 🚀\n\n7. 使用备份数据未来我重新使用 docker-compose.yml 搭建一个 jenkins 服务，使用备份的 jenkins_home 数据重建 Jenkins 服务，主要步骤如下：\n首先编写 docker-compose.yml 文件，需要特别注意卷映射配置：\nversion: &#x27;3.2&#x27;services:  jenkins:    image: jenkins/jenkins:lts    container_name: jenkins    ports:      - &quot;8080:8080&quot;      - &quot;50000:50000&quot;    volumes:      # 这里的 ./jenkins_home 就是你要放置备份数据的本地目录      - ./jenkins_home:/var/jenkins_home    restart: always\n\n准备备份数据：\n\n在 docker-compose.yml 同级目录下创建 jenkins_home 文件夹\n将 Windows FTP 服务器上的备份数据（F:\\FileZillaServer\\jenkins_home 下的所有内容）复制到这个本地的 jenkins_home 文件夹中\n\n设置正确的权限：\n# Jenkins 容器中的 jenkins 用户的 UID 通常是 1000sudo chown -R 1000:1000 ./jenkins_home\n\n启动服务：docker-compose up -d\n这样启动后，Jenkins 将会：\n\n使用备份数据（包括所有的任务配置、插件、凭据等）\n无需重新进行初始化设置\n保持原有的所有配置和历史数据\n\n注意事项：\n\n确保新环境的 Jenkins 版本与备份时的版本兼容，最好使用相同版本\n如果备份数据中包含了特定路径的配置（如工作目录、工具路径等），可能需要根据新环境进行调整\n如果有自定义的环境变量或系统配置，也要在新环境中相应设置\n首次启动可能会稍慢，因为 Jenkins 需要验证所有配置和插件\n\n如果启动过程中遇到问题，可以：\n\n检查 docker logs jenkins 查看详细日志\n确认文件权限是否正确\n验证所有必要的插件是否都在备份中\n\n对于敏感数据（如凭据），最好再次检查确认是否需要更新或重新配置。\n\n8. 其他使用 lftp 的 mirror 命令。默认情况下，mirror 命令会进行增量同步，具体行为如下：\n\n对于新文件：会被传输到目标目录\n对于已存在的文件：\n如果源文件(Centos上)比目标文件(Windows上)新，则会覆盖\n如果文件未修改(时间戳和大小相同)，则会跳过，不会重新传输\n\n\n对于已删除的文件：\n默认情况下，目标目录中对应的文件不会被删除\n如果想删除目标目录中已不存在的文件，需要添加 --delete 参数\n\n\n\n可以在脚本中添加一些参数来更精确地控制同步行为，例如：\nmirror -R --only-newer --ignore-time --size-only $SOURCE_DIR $FTP_TARGET_DIR\n\n\n--only-newer: 只传输新文件或修改过的文件\n--ignore-time: 忽略时间戳比较，只比较文件大小\n--size-only: 只比较文件大小来决定是否需要更新\n--delete: 删除目标目录中在源目录不存在的文件\n-v: 显示详细的传输信息\n\n如果想在日志中看到具体哪些文件被传输或跳过，可以添加 -v 参数：\nmirror -R -v $SOURCE_DIR $FTP_TARGET_DIR","categories":["技术","Jenkins"],"tags":["Jenkins"]},{"title":"Python os.environ 应用","url":"/posts/2024/12/19/47787/","content":"1. 基本概念os.environ 是 Python 中的一个字典型对象，它提供了对系统环境变量的访问和修改能力。这个对象实际上是 os._Environ 类的一个实例，它继承自内置的 dict 类，但提供了一些特殊的行为。\n1.1 工作原理\nos.environ 在 Python 进程启动时从系统中读取环境变量\n它维护了一个类似字典的映射，键和值都是字符串类型\n对 os.environ 的修改会影响当前进程及其子进程的环境变量\n这些修改不会影响父进程或系统级的环境变量设置\n\n2. 主要特性2.1 字典操作# 读取环境变量path = os.environ[&#x27;PATH&#x27;]home = os.environ.get(&#x27;HOME&#x27;, &#x27;/default/path&#x27;)# 设置环境变量os.environ[&#x27;MY_VAR&#x27;] = &#x27;my_value&#x27;# 删除环境变量del os.environ[&#x27;MY_VAR&#x27;]\n\n2.2 特殊行为\n键值必须是字符串类型\n在 Windows 系统中，键的大小写不敏感\n在类 Unix 系统中，键的大小写敏感\n某些特殊字符可能在不同操作系统中有不同的处理方式\n\n3. 常见使用场景3.1 环境区分与兼容性处理3.1.1 自动化测试平台兼容在自动化测试项目中，经常需要处理本地开发环境和测试平台执行环境的差异。以下是一个实际案例：\n# 通过环境变量区分执行环境，处理参数冲突if os.environ.get(&#x27;BUILD_ID&#x27;) or os.environ.get(&#x27;buildId&#x27;):  # xxx 平台环境    print(f&quot;BUILD_ID: &#123;os.environ.get(&#x27;BUILD_ID&#x27;)&#125;, buildId:&#123;os.environ.get(&#x27;buildId&#x27;)&#125;&quot;)else:  # 本地环境    parser.addoption(        &quot;--serial&quot;, action=&quot;store&quot;, default=None,         help=&quot;the id of the master device to be executed. &quot;)\n\n这种方式解决了以下问题：\n\n避免了手动修改代码的需求\n消除了参数重复冲突\n提高了代码的可维护性\n降低了人为错误的风险\n\n3.1.2 路径适配在不同环境下，系统路径的处理也需要特别注意。例如：\ndef get_default_download_path():    # 优先检查 Jenkins 环境    jenkins_home = os.environ.get(&#x27;JENKINS_HOME&#x27;)    if jenkins_home:        default_path = os.path.join(jenkins_home, &#x27;workspace&#x27;)    else:        default_path = os.path.expanduser(&quot;~&quot;)  # 本地用户目录    return os.path.join(default_path, &quot;FTP&quot;)\n\n这段代码解决了以下问题：\n\n处理了 Jenkins 环境和本地环境的路径差异\n确保了文件下载位置的可访问性\n集中化了资源管理\n提高了代码的可移植性\n\n3.2 配置管理# 从环境变量读取数据库配置db_host = os.environ.get(&#x27;DB_HOST&#x27;, &#x27;localhost&#x27;)db_port = int(os.environ.get(&#x27;DB_PORT&#x27;, &#x27;5432&#x27;))db_name = os.environ[&#x27;DB_NAME&#x27;]  # 必需的配置项\n\n3.3 开发与部署环境分离# 根据环境变量决定运行模式debug_mode = os.environ.get(&#x27;ENV&#x27;, &#x27;development&#x27;) == &#x27;development&#x27;if debug_mode:    # 开发环境配置    config = DevelopmentConfig()else:    # 生产环境配置    config = ProductionConfig()\n\n3.4 敏感信息管理# 从环境变量读取敏感信息api_key = os.environ[&#x27;API_KEY&#x27;]secret_key = os.environ[&#x27;SECRET_KEY&#x27;]\n\n3.5 多环境测试def setup_test_env():    # 临时修改环境变量用于测试    original_env = os.environ.copy()    os.environ[&#x27;TEST_MODE&#x27;] = &#x27;true&#x27;        try:        run_tests()    finally:        # 恢复原始环境变量        os.environ.clear()        os.environ.update(original_env)\n\n4. 最佳实践4.1 安全性考虑\n避免在代码中硬编码敏感信息\n使用 .env 文件管理环境变量\n注意环境变量的访问权限\n\n4.2 错误处理try:    api_key = os.environ[&#x27;API_KEY&#x27;]except KeyError:    raise ConfigurationError(&quot;API_KEY environment variable is required&quot;)\n\n4.3 类型转换# 安全地转换环境变量值def get_int_env(key, default=None):    value = os.environ.get(key)    if value is None:        return default    try:        return int(value)    except ValueError:        raise ValueError(f&quot;Environment variable &#123;key&#125; must be an integer&quot;)\n\n5. 常见陷阱\n修改环境变量不会影响系统环境变量\n子进程会继承环境变量，但对子进程的修改不会影响父进程\n在多线程环境中修改环境变量可能导致竞态条件\nWindows 和 Unix 系统对环境变量的处理有所不同\n\n6. 调试技巧6.1 环境变量查看# 打印所有环境变量for key, value in os.environ.items():    print(f&quot;&#123;key&#125;: &#123;value&#125;&quot;)# 检查特定环境变量是否存在if &#x27;MY_VAR&#x27; in os.environ:    print(&quot;MY_VAR is set&quot;)\n\n6.2 临时环境变量import contextlib@contextlib.contextmanagerdef temporary_env(**kwargs):    &quot;&quot;&quot;临时设置环境变量的上下文管理器&quot;&quot;&quot;    original = &#123;&#125;    try:        for key, value in kwargs.items():            if key in os.environ:  # 将已存在的环境变量临时存储，更新环境变量                original[key] = os.environ[key]            os.environ[key] = str(value)  # 如果要添加的变量不存在，直接添加        yield    finally:        for key in kwargs:            if key in original:  # 将临时存储的变量改为初始值                os.environ[key] = original[key]            else:                del os.environ[key]  # 之前不存在的变量，删除# 使用示例with temporary_env(DEBUG=&#x27;true&#x27;, ENV=&#x27;testing&#x27;):    run_tests()\n\n7. 性能考虑\nos.environ 的访问和修改操作是线程安全的\n频繁访问环境变量可能影响性能，建议缓存常用值\n大量环境变量可能增加进程启动时间\n\n8. 与其他工具的集成8.1 python-dotenvfrom dotenv import load_dotenv# 从 .env 文件加载环境变量load_dotenv()# 使用环境变量database_url = os.environ.get(&quot;DATABASE_URL&quot;)\n\n8.2 Docker 集成# Dockerfile 中设置环境变量# ENV APP_ENV=production# ENV DEBUG=false# Python 代码中读取app_env = os.environ.get(&#x27;APP_ENV&#x27;, &#x27;development&#x27;)debug = os.environ.get(&#x27;DEBUG&#x27;, &#x27;true&#x27;).lower() == &#x27;true&#x27;\n\n9. 总结os.environ 是 Python 中管理环境变量的强大工具，它提供了：\n\n安全的配置管理机制\n环境隔离能力\n跨平台兼容性\n便捷的字典式接口\n\n正确使用 os.environ 可以提高应用的可配置性、安全性和可维护性。在实际应用中，建议结合项目需求，采用适当的环境变量管理策略，并注意处理好相关的安全性和兼容性问题。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python __func 与 _func 的区别引起的思考","url":"/posts/2024/12/06/39467/","content":"Python中的__function和_function有不同的约定和用途。\n__function__function（双下划线前缀）:\n\n这被称为”name mangling”（名称修饰）\n用于实现类的私有属性和方法\nPython会将这样的名称在内部重命名，使其更难从外部直接访问\n主要目的是防止子类意外覆盖或重写这些方法\n例如，__init__是一个特殊的魔术方法（构造函数）\n通过名称修饰，__method会被改变为_ClassName__method\n\n示例：\nclass MyClass:    def __private_method(self):        print(&quot;This is a private method&quot;)        def public_method(self):        # 可以在类的内部正常调用私有方法        self.__private_method()obj = MyClass()# obj.__private_method()  # 这会报错# 但实际上可以这样访问：# obj._MyClass__private_method()  # 不推荐这样做\n\n\n_function_function（单下划线前缀）:\n\n这是一个约定，表示”这是一个供内部使用的方法”\n不是严格的私有方法\n只是一个社区约定，表示”这个方法不应该被直接外部调用”\n从语法上讲，仍然可以直接访问\n通常用于表示”这是一个内部实现，不应该被视为公共API的一部分”\n\n示例：\nclass MyClass:    def _internal_method(self):        print(&quot;This is an internal method&quot;)        def public_method(self):        self._internal_method()  # 正常使用obj = MyClass()obj._internal_method()  # 虽然可行，但不推荐\n\n\n主要区别总结：\n\n__function：通过名称修饰实现更强的私有性，Python会改变其名称\n_function：只是一个约定，表示不应直接使用，但实际上仍可访问\n\n最佳实践：\n\n尊重_function的约定，不要直接调用带有单下划线的方法\n如果真的需要严格的私有性，使用__function\n在设计类时，考虑方法的intended使用方式\n\n\n深入名称修饰机制名称修饰（Name Mangling）是Python中一种特殊的标识符重命名机制，主要用于类的属性和方法。\n当你在类中定义一个以双下划线（__）开头的属性或方法时，Python会自动修改其名称。\nclass AdvancedClass:    def __init__(self):        self.__secret = &quot;私有属性&quot;        self._protected = &quot;受保护属性&quot;    def __private_method(self):        print(&quot;这是一个私有方法&quot;)    def _protected_method(self):        print(&quot;这是一个受保护方法&quot;)    def access_private(self):        # 展示名称修饰的实际机制        print(self.__dict__)  # 查看实际属性名        self.__private_method()  # 内部可以调用obj = AdvancedClass()# print(obj.__secret)  # 直接访问会报错print(obj.__dict__)  # 会发现__secret实际上被重命名print([item for item in dir(obj) if not item.startswith(&#x27;__&#x27;)])print(obj._AdvancedClass__secret)  # 这才是正确的访问方式&quot;&quot;&quot;&#123;&#x27;_AdvancedClass__secret&#x27;: &#x27;私有属性&#x27;, &#x27;_protected&#x27;: &#x27;受保护属性&#x27;&#125;[&#x27;_AdvancedClass__private_method&#x27;, &#x27;_AdvancedClass__secret&#x27;, &#x27;_protected&#x27;, &#x27;_protected_method&#x27;, &#x27;access_private&#x27;]私有属性&quot;&quot;&quot;\n\nclass Parent:    def __init__(self):        self.__secret = &quot;父类秘密&quot;class Child(Parent):    def __init__(self):        super().__init__()        self.__secret = &quot;子类秘密&quot;  # 这实际上是一个新的属性    def print_secrets(self):        print(&quot;父类秘密:&quot;, self._Parent__secret)        print(&quot;子类秘密:&quot;, self.__secret)child = Child()child.print_secrets()&quot;&quot;&quot;父类秘密: 父类秘密子类秘密: 子类秘密&quot;&quot;&quot;\n\n名称修饰的目的\n防止意外重写：子类不会意外覆盖父类的私有属性\n提供一定的封装：虽然不是绝对私有，但增加了访问的复杂性\n命名冲突避免：在继承中防止命名冲突\n\n实现原理Python 的名称修饰是在编译时进行的：\n\n编译器检测到以__开头的标识符\n自动将类名插入到标识符前\n创建一个新的、唯一的名称\n以双下划线开头并以双下划线结尾的方法（如__init__）不会被修饰\n\n查看名称修饰的字节码实现：\nimport disclass InspectMangling:    def __init__(self):        self.__hidden = &quot;隐藏内容&quot;    def show_bytecode(self):        print(dis.dis(self.__init__))obj = InspectMangling()obj.show_bytecode()&quot;&quot;&quot;  6           0 LOAD_CONST               1 (&#x27;隐藏内容&#x27;)              2 LOAD_FAST                0 (self)              4 STORE_ATTR               0 (_InspectMangling__hidden)              6 LOAD_CONST               0 (None)              8 RETURN_VALUENone&quot;&quot;&quot;\n\n\n属性访问控制的高级模式在属性的 setter 方法中调用私有方法是一种常见且实用的模式。这种方式可以帮助我们实现更复杂的验证、转换或预处理逻辑。\n基本模式扩展class SmartAccessClass:    def __init__(self):        self.__private_attr = None    @property    def private_attr(self):        &quot;&quot;&quot;        获取属性，可以添加额外的访问控制逻辑        &quot;&quot;&quot;        if self.__private_attr is None:            return 0  # 提供默认值        return self.__private_attr    @private_attr.setter    def private_attr(self, value):        &quot;&quot;&quot;        setter方法中调用私有方法进行验证和转换        &quot;&quot;&quot;        converted_value = self.__convert_value(value)        if self.__validate_value(converted_value):            self.__private_attr = converted_value        else:            raise ValueError(&quot;值未通过验证&quot;)    def __convert_value(self, value):        try:            return int(value)        except (TypeError, ValueError):            return 0    def __validate_value(self, value):        return 0 &lt;= value &lt;= 100class InheritanceTest(SmartAccessClass):    def __init__(self):        super().__init__()        # 尝试访问父类的私有属性会失败        # self.__private_attr = 10  # 这会创建一个新的属性，而不是访问父类的    def attempt_access(self):        # 这种方式无法直接访问父类的私有属性        # print(self.__private_attr)  # 会报错        pass\n\n复杂的转换和验证逻辑class AdvancedAccessControl:    def __init__(self):        self.__sensitive_data = None    @property    def sensitive_data(self):        &quot;&quot;&quot;        安全地获取敏感数据        &quot;&quot;&quot;        return self.__decrypt_data(self.__sensitive_data)    @sensitive_data.setter    def sensitive_data(self, value):        &quot;&quot;&quot;        设置敏感数据，包括加密和验证        &quot;&quot;&quot;        # 先验证输入        if not self.__is_valid_input(value):            raise ValueError(&quot;输入不合法&quot;)        # 进行数据转换和加密、存储        encrypted_value = self.__encrypt_data(value)        self.__sensitive_data = encrypted_value    def __is_valid_input(self, value):        return (                isinstance(value, str) and                len(value) &gt; 5 and                any(char.isdigit() for char in value)        )    def __encrypt_data(self, value):        return &#x27;&#x27;.join(chr(ord(c) + 1) for c in value)    def __decrypt_data(self, encrypted_value):        if encrypted_value is None:            return None        return &#x27;&#x27;.join(chr(ord(c) - 1) for c in encrypted_value)obj = AdvancedAccessControl()obj.sensitive_data = &quot;secret123&quot;  # 设置成功print(obj.sensitive_data)  # 解密后输出\n\n带有日志和审计的访问控制import loggingfrom functools import wrapsclass AuditedAccessClass:    def __init__(self):        self.__critical_value = None        self.__logger = logging.getLogger(self.__class__.__name__)    def audit_access(method):        &quot;&quot;&quot;        装饰器：记录方法调用        &quot;&quot;&quot;        @wraps(method)        def wrapper(self, *args, **kwargs):            try:                result = method(self, *args, **kwargs)                self.__logger.info(f&quot;成功调用 &#123;method.__name__&#125;&quot;)                return result            except Exception as e:                self.__logger.error(f&quot;调用 &#123;method.__name__&#125; 失败: &#123;str(e)&#125;&quot;)                raise        return wrapper    @property    @audit_access    def critical_value(self):        &quot;&quot;&quot;        带审计的属性获取        &quot;&quot;&quot;        return self.__critical_value    @critical_value.setter    @audit_access    def critical_value(self, value):        &quot;&quot;&quot;        带审计的属性设置        &quot;&quot;&quot;        # 调用私有方法进行处理        processed_value = self.__process_critical_value(value)        # 存储处理后的值        self.__critical_value = processed_value    def __process_critical_value(self, value):        &quot;&quot;&quot;        私有方法：处理关键值        &quot;&quot;&quot;        # 复杂的处理逻辑        if not isinstance(value, (int, float)):            raise TypeError(&quot;必须是数值类型&quot;)        return round(float(value), 2)audit_obj = AuditedAccessClass()audit_obj.critical_value = 123.456  # 将被四舍五入为123.46print(audit_obj.critical_value)  # 123.46\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python subprocess与Popen","url":"/posts/2024/12/04/35272/","content":"subprocessstdin stdout stderrsubprocess.run(command, check=True, text=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE,  stderr=subprocess.PIPE) 与 subprocess.run(command, check=True, text=True) 区别在哪？\n主要区别如下：\n\n输入输出重定向\n# 默认方式（不指定）# 继承父进程的标准输入、输出、错误流subprocess.run(command, check=True, text=True)# 指定 stdin/stdout/stderrsubprocess.run(    command,     check=True,     text=True,     stdin=subprocess.PIPE,   # 重定向标准输入    stdout=subprocess.PIPE,  # 重定向标准输出    stderr=subprocess.PIPE   # 重定向标准错误)\n\n主要不同点：\n\nstdin=subprocess.PIPE：子进程的标准输入被重定向到一个管道\nstdout=subprocess.PIPE：子进程的标准输出被捕获到一个管道\nstderr=subprocess.PIPE：子进程的标准错误输出被捕获到一个管道\n\n\n使用场景：\n# 默认方式：命令直接输出到控制台subprocess.run([&quot;ls&quot;, &quot;-l&quot;])# 捕获输出方式：将输出存储在变量中result = subprocess.run(    [&quot;ls&quot;, &quot;-l&quot;],     capture_output=True,     text=True)print(result.stdout)\n\n详细对比：\n# 不指定 PIPE 的情况result1 = subprocess.run([&quot;echo&quot;, &quot;hello&quot;], check=True, text=True)# 输出会直接打印到控制台# result1.stdout 为 None# 指定 PIPE 的情况result2 = subprocess.run(    [&quot;echo&quot;, &quot;hello&quot;],     check=True,     text=True,     stdout=subprocess.PIPE)# result2.stdout 会包含 &quot;hello\\n&quot;# 输出不会直接打印到控制台\n\n完整示例：\nimport subprocess# 不捕获输出subprocess.run([&quot;ls&quot;, &quot;-l&quot;], check=True, text=True)# 捕获并处理输出result = subprocess.run(    [&quot;ls&quot;, &quot;-l&quot;],     check=True,     text=True,     stdout=subprocess.PIPE,     stderr=subprocess.PIPE)print(&quot;标准输出:&quot;, result.stdout)print(&quot;错误输出:&quot;, result.stderr)\n\n关键区别：\n\n默认方式：输出直接到控制台\n使用 PIPE：\n输出被捕获到内存\n不直接显示在控制台\n可以通过 result.stdout/stderr 获取输出\n适合需要处理命令输出的场景\n\n\n\n通常建议：\n\n需要捕获或处理输出时，使用 PIPE\n只是执行命令，不关心输出时，使用默认方式\n\n\nsubprocess.run and subprocess.Popensubprocess 的作用：\n\n允许 Python 程序调用和控制外部系统命令或其他程序\n创建的是子进程，不是并行的 Python 进程\n主要用于系统交互，执行外部命令\n\nsubprocess.run() 和 subprocess.Popen() 都是用于在 Python 中执行外部命令的方法，但它们有一些关键区别：\n\n抽象层次： subprocess.run() 是对 subprocess.Popen() 的高级封装。我们可以通过查看 Python 的源码来验证这一点。让我们看看 run() 函数的实现：\n def run(*popenargs, input=None, capture_output=False, timeout=None, check=False, **kwargs):    if input is not None:        if kwargs.get(&#x27;stdin&#x27;) is not None:            raise ValueError(&#x27;stdin and input arguments may not both be used.&#x27;)        kwargs[&#x27;stdin&#x27;] = PIPE    if capture_output:        if kwargs.get(&#x27;stdout&#x27;) is not None or kwargs.get(&#x27;stderr&#x27;) is not None:            raise ValueError(&#x27;stdout and stderr arguments may not be used &#x27;                             &#x27;with capture_output.&#x27;)        kwargs[&#x27;stdout&#x27;] = PIPE        kwargs[&#x27;stderr&#x27;] = PIPE    with Popen(*popenargs, **kwargs) as process:        try:            stdout, stderr = process.communicate(input, timeout=timeout)        except TimeoutExpired as exc:            process.kill()            if _mswindows:                exc.stdout, exc.stderr = process.communicate()            else:                process.wait()            raise        except:  # Including KeyboardInterrupt, communicate handled that.            process.kill()            # We don&#x27;t call process.wait() as .__exit__ does that for us.            raise        retcode = process.poll()        if check and retcode:            raise CalledProcessError(retcode, process.args,                                     output=stdout, stderr=stderr)    return CompletedProcess(process.args, retcode, stdout, stderr)\n\n主要区别：\n\nsubprocess.Popen()：\n\n创建进程后立即返回\n需要手动管理进程（等待、读取输出、关闭）\n提供更细粒度的进程控制\n适合需要更复杂进程管理的场景\n\n\nsubprocess.run()：\n\n创建进程并等待其完成\n自动处理进程等待、输出捕获\n返回一个 CompletedProcess 对象\n更简单、更直接的使用方式\n适合简单的命令执行\n\n\n\n\n使用示例：\nPopen() 方式：\nimport subprocess# 手动管理进程process = subprocess.Popen([&#x27;ls&#x27;, &#x27;-l&#x27;],                            stdout=subprocess.PIPE,                            stderr=subprocess.PIPE,                            text=True)stdout, stderr = process.communicate()print(stdout)\n\nrun() 方式：\nimport subprocess# 简单直接的方式result = subprocess.run([&#x27;ls&#x27;, &#x27;-l&#x27;],                         capture_output=True,                         text=True)print(result.stdout)\n\n\n实现原理：\n从源码可以看出，run() 实际上是：\n\n创建一个 Popen 对象\n使用 communicate() 方法等待进程完成\n处理超时\n检查返回码\n返回一个包含执行结果的 CompletedProcess 对象\n\n\n性能和使用建议：\n\n对于简单的命令执行，使用 run()\n对于需要实时交互、复杂进程控制的场景，使用 Popen()\n\n\n\n总结：subprocess.run() 是对 subprocess.Popen() 的高级封装，提供了更简单、更直接的命令执行方式，同时在底层仍然使用 Popen 来创建和管理进程。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python 数据类型，是否可变、可哈希","url":"/posts/2024/10/01/1800/","content":"可变性\n可变对象：可以在对象创建后修改其内容（值）。\n不可变对象：对象一旦创建后，其内容不能再被修改。\n\n常见的可变和不可变类型：\n\n可变对象：\n列表 (list)\n字典 (dict)\n集合 (set)\n用户自定义的类实例（默认情况下）\n\n\n不可变对象：\n整数 (int)\n浮点数 (float)\n字符串 (str)\n元组 (tuple)\n布尔值 (bool)\nfrozenset (frozenset)\n\n\n\n例子：\n# 可变对象：列表lst = [1, 2, 3]lst[0] = 100  # 修改成功# 不可变对象：元组tup = (1, 2, 3)# tup[0] = 100  # 这一行会报错，因为元组不可修改\n\n与引用的关系：\n\n可变对象通过引用传递时，如果外部函数对对象进行修改，则在原作用域中对象的内容也会改变。\n不可变对象通过引用传递时，由于内容不能更改，传递的是一个新的对象引用。\n\n\n是否可哈希\n可哈希对象：对象具有一个固定的哈希值，可以通过调用 hash() 函数来获得，并且它们的内容在对象生命周期内不能改变。\n不可变对象：int、float、str、tuple（如果所有元素都是可哈希的）、frozenset。\n这些对象通常可以作为 字典的键 或 集合的元素。\n\n\n不可哈希对象：没有哈希值，通常因为对象是可变的，其内容可能随时更改，从而使哈希值不再一致。\n可变对象：list、dict、set。\n这些对象不能作为 字典的键 或 集合的元素。\n\n\n\n# 可哈希对象print(hash(&quot;hello&quot;))  # 字符串是不可变的，可哈希print(hash((1, 2, 3)))  # 元组是不可变的，可哈希# 不可哈希对象# print(hash([1, 2, 3]))  # 列表是可变的，无法哈希# print(hash(&#123;&#x27;a&#x27;: 1&#125;))   # 字典是可变的，无法哈希# print(hash(&#123;1, 2, 3&#125;))  # 集合是可变的，无法哈希\n\n哈希性与可变性的关系：\n\n可哈希对象通常是不可变对象，因为只有不可变对象才能保证哈希值在其生命周期内不会改变。\n不可哈希对象往往是可变对象，因为其内容可以改变，哈希值会随之发生变化。\n\n\nPython 的参数传递机制Python 中的参数传递既不是值传递也不是引用传递，而是对象的引用传递。这意味着函数接收到的是对象的引用，而不是对象本身的拷贝。因此，如果对象是可变的，修改它会影响到调用者范围内的对象。\n具体的表现可以根据对象的可变性来区分：\n\n可变对象：当你将可变对象（如 list、dict、set）作为参数传递到函数时，函数内部的修改会影响到外部的变量，因为函数操作的是对象的引用，即它们指向同一个对象。\n不可变对象：当你将不可变对象（如 int、float、str、tuple、bool、frozenset）作为参数传递到函数时，任何修改都会创建一个新的对象，函数内部的修改不会影响外部的变量。\n\n\n可变对象和不可变对象在引用传递中的表现# 可变对象（列表）def modify_list(lst):    lst.append(4)my_list = [1, 2, 3]modify_list(my_list)print(my_list)  # 输出: [1, 2, 3, 4]\n\n在这个例子中，my_list 是一个可变对象（列表）。当我们把它传递给 modify_list 函数时，函数内部对列表的修改（append 操作）会直接影响外部的 my_list，因为它们引用的是同一个对象。\n# 可变对象（字典）def modify_dict(d):    d[&#x27;new_key&#x27;] = &#x27;new_value&#x27;my_dict = &#123;&#x27;key&#x27;: &#x27;value&#x27;&#125;modify_dict(my_dict)print(my_dict)  # 输出: &#123;&#x27;key&#x27;: &#x27;value&#x27;, &#x27;new_key&#x27;: &#x27;new_value&#x27;&#125;\n\n这里的 my_dict 是一个字典（可变对象），传递到函数 modify_dict 后，函数内部对字典的修改直接反映在外部的 my_dict 上。\n# 不可变对象（字符串）def modify_string(s):    s = &quot;new string&quot;  # 试图修改传入的字符串my_str = &quot;old string&quot;modify_string(my_str)print(my_str)  # 输出: &quot;old string&quot;\n\n这里的 my_str 是一个不可变对象（字符串）。当我们把它传递给 modify_string 函数时，函数内部的赋值操作创建了一个新的字符串对象，my_str 本身并没有被修改，外部的变量仍然保持原样。\n# 不可变对象（整数）def modify_number(n):    n += 10  # 修改传入的数值my_num = 5modify_number(my_num)print(my_num)  # 输出: 5\n\nmy_num 是一个不可变对象（整数）。即使在 modify_number 函数内部对其进行了修改，这也不会影响外部的 my_num。在函数内部，修改操作实际上生成了一个新的整数对象，而原来的 my_num 仍指向原来的值。\n\n总结可变性直接决定了对象是否可以被哈希。如果对象是可变的，它的值可以在生命周期中改变，导致哈希值也不固定，因此可变对象不可哈希。\n可哈希对象通常是不可变的，它们具有稳定的哈希值，并且可以用作 字典的键 或 集合的元素。\n引用使得多个变量可以指向同一个对象。对于可变对象，多个引用之间会互相影响。而对于不可变对象，修改操作实际上是在创建一个新的对象，原有的引用保持不变。\n实际工作中：\n哈希性的要求决定了对象的使用场景。例如，字典的键和集合的元素必须是可哈希的对象，所以必须是不可变的。\n可变对象可以通过引用进行修改，因此在编写代码时要小心引用的共享，避免意外的修改。如果不希望对象被意外修改，考虑使用不可变对象或创建对象副本。\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python 查看某个库的版本","url":"/posts/2023/12/03/39705/","content":"使用 pip 命令：\npip show package_name\n\n例如查看 numpy 的版本：\npip show numpy\n\n\n\n在 Python 交互环境中查看：\npython -c &quot;import package_name; print(package_name.__version__)&quot;\n\n例如查看 pandas 的版本：\npython -c &quot;import pandas; print(pandas.__version__)&quot;\n\n\n\n如果已经在 Python 环境中，也可以直接导入包查看：\n&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; print(tf.__version__)\n\n\n\n查看已安装的所有包及其版本：\npip list\n\n这些方法中，pip show 会显示最详细的信息，包括版本号、安装位置、依赖关系等。而 pip list 则适合需要查看所有已安装包的情况。\n如果在 Pycharm 中，直接在 Project - Python Interpreter 中查看了。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Python 使用property 重构类","url":"/posts/2024/11/02/51099/","content":"重构的实例重构前的设计问题\n\nPhone 类中同时存在 get_device_id() 方法和 device_id 属性，造成了接口的不一致性\n初始化逻辑分散，设备 ID 的获取可能在多个地方发生\nPackageManager 需要了解 Phone 类的内部实现细节\n\nclass Phone:    def __init__(self):        self.__device_id = None    def set_device_id(self, device_id):        self.__device_id = device_id    @property    def device_id(self):        return self.__device_id    @device_id.setter    def device_id(self, value):        if isinstance(value, str):            self.__device_id = value        else:            raise TypeError(&quot;device_id must be a string&quot;)    def get_device_id(self):        device_list = []        if self.__device_id is None:            # 执行adb指令获取手机序列号            outputs = os.popen(&quot;adb devices&quot;).read().split(&quot;\\n&quot;)            for output in outputs:                if &quot;\\t&quot; in output:                    device_list.append(output.split(&#x27;\\t&#x27;)[0])            if len(device_list) == 0:                print(&quot;未检测到手机！&quot;)                return None            else:                self.__device_id = device_list[0]                print(&quot;手机序列号:&#123;&#125;&quot;.format(device_list[0]))                return device_list[0]        else:            return self.__device_idclass PackageManager:    def __init__(self, device: Phone):        self.device = device        self.phone_device_id = self.device.device_id if self.device.device_id else self.device.get_device_id()\n\n\n\n重构后\nclass Phone:    def __init__(self):        self.__device_id = None            @property    def device_id(self):        &quot;&quot;&quot;        懒加载方式获取设备ID        如果ID不存在，则自动获取；如果存在，则直接返回        &quot;&quot;&quot;        if self.__device_id is None:            self.__device_id = self.__detect_device()        return self.__device_id    @device_id.setter    def device_id(self, value: str):        if not isinstance(value, str):            raise TypeError(&quot;device_id must be a string&quot;)        self.__device_id = value        def __detect_device(self) -&gt; str | None:        &quot;&quot;&quot;私有方法，用于检测设备&quot;&quot;&quot;        device_list = []        outputs = os.popen(&quot;adb devices&quot;).read().split(&quot;\\n&quot;)        for output in outputs:            if &quot;\\t&quot; in output:                device_list.append(output.split(&#x27;\\t&#x27;)[0])                        if not device_list:            print(&quot;未检测到手机！&quot;)            return None                    print(f&quot;手机序列号: &#123;device_list[0]&#125;&quot;)        return device_list[0]class PackageManager:    def __init__(self, device: Phone):        self.device = device        if self.device.device_id is None:            raise ValueError(&quot;No device detected&quot;)\n\n改进点：\na) 使用懒加载模式：\n\n只在真正需要 device_id 时才去获取\n避免了重复的检查和获取逻辑\n\nb) 简化接口：\n\n移除了 get_device_id() 方法，统一使用 property\n将设备检测逻辑移到私有方法中，隐藏内部实现细节\n\nc) 更清晰的职责划分：\n\nPhone 类完全负责设备 ID 的管理和获取\nPackageManager 只需要关心设备是否可用\n\n\n好的重构通常遵循以下原则：\n\n保持行为不变 - 外部接口和功能保持一致\n提高可读性 - 代码更容易理解\n提高可维护性 - 更容易修改和扩展\n减少重复 - 消除重复代码\n单一职责 - 每个类和方法只做一件事\n\n\n重构小技巧Python 在重构时有许多独特且强大的优势：\n\n动态特性优势\n\n鸭子类型(Duck Typing)：允许更灵活的代码重构\n动态属性和方法：可以轻松替换和修改类的行为\n\n\n反射和自省能力\n# 动态检查和修改对象属性hasattr(obj, &#x27;method&#x27;)  # 检查方法是否存在getattr(obj, &#x27;method&#x27;, default_value)  # 安全获取属性setattr(obj, &#x27;new_method&#x27;, new_function)  # 动态添加方法\n\n装饰器\n在不修改原函数的情况下添加功能\ndef logger(func):    def wrapper(*args, **kwargs):        print(f&quot;Calling &#123;func.__name__&#125;&quot;)        return func(*args, **kwargs)    return wrapper@loggerdef some_function():    pass  # 无需修改原函数即可添加日志\n\n上下文管理器\n简化资源管理和异常处理\nclass RefactoredResource:    def __enter__(self):        # 资源初始化        return self        def __exit__(self, exc_type, exc_val, exc_tb):        # 资源清理        pass\n\n类型提示(Type Hints)\n提供代码重构时的静态类型检查\nfrom typing import List, Optional, Uniondef refactored_function(    items: List[str],     optional_param: Optional[int] = None) -&gt; Union[str, None]:    pass\n\n函数式编程特性\n# 使用 lambda 和高阶函数重构numbers = [1, 2, 3, 4]squared = list(map(lambda x: x**2, numbers))\n\nProperty 装饰器\nclass RefactoredClass:    def __init__(self):        self._value = None        @property    def value(self):        # 可以添加计算逻辑        return self._value        @value.setter    def value(self, new_value):        # 可以添加验证逻辑        self._value = new_value\n\n元编程\ndef add_method(cls):    def new_method(self):        print(&quot;Dynamically added method&quot;)    setattr(cls, &#x27;dynamic_method&#x27;, new_method)    return cls@add_methodclass MyClass:    pass\n\n数据类和 Dataclasses\nfrom dataclasses import dataclass, field@dataclassclass RefactoredData:    name: str    value: int = field(default=0)\n\n魔法方法(Magic Methods)\nclass SmartCompare:    def __eq__(self, other):        # 自定义相等比较        pass        def __lt__(self, other):        # 自定义小于比较        pass\n\n示例：\n# 重构前class OldClass:    def __init__(self, data):        self.data = data        def process(self):        result = []        for item in self.data:            if item &gt; 0:                result.append(item * 2)        return result# 重构后from typing import Listfrom functools import reduceclass RefactoredClass:    def __init__(self, data: List[int]):        self._data = data        @property    def processed_data(self) -&gt; List[int]:        return list(filter(lambda x: x &gt; 0,                            map(lambda x: x * 2, self._data)))        def reduce_data(self):        return reduce(lambda x, y: x + y, self.processed_data, 0)\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"drawio画流程图","url":"/posts/2024/10/26/16911/","content":"Draw.io 是市面上使用频率较高的流程图制作软件之一，对于流程图的制作，它具有拖放功能、可自定义的图表模板和广泛的形状库。用户可以创建和编辑各种图表，包括流程图、组织结构图、流程图、ER图、UML和网络图。\n下载地址：draw.io画图工具及模板资源:draw.io画图工具及模板资源 - GitCode\n主要特点：\n\n制作流程图自由灵活，拖拉、放缩功能提高制作效率；\n支持从文本到图表的插入；\n可以绘制流程图等多种图表；\n\n优点：\n\n制图过程中导入和导出数据便捷；\n允许多个用户在一个项目上协同制作流程图。\n\n缺点：\n\n如果使用一段时间，应用程序会滞后并变慢；\n缺乏模板配置，对新手不友好；\n缺乏图表阐述所需的一些定制工具。\n\n\n画图很快，有自动对齐，拖拽灵活。\n画了一张 Android Activity 的生命周期\n\n","categories":["生产力","工具"],"tags":["tools"]},{"title":"Python高级特性：setattr、property 与动态属性的解析","url":"/posts/2024/11/03/18498/","content":"setattr 的两种用法1.实例级别的属性设置setattr(self, name, value)\n\n这种方式只会影响特定实例，相当于 self.name = value。新添加的属性只存在于当前实例中，不会影响类的其他实例。\n2.类级别的属性设置setattr(self.__class__, name, value)\n\n这种方式会影响类的所有实例，包括现有和将来创建的实例。它实际上是在类级别添加了一个新的属性。\n示例代码：\nclass Example:    def __init__(self, x):        self.x = xobj1 = Example(1)obj2 = Example(2)# 实例级别setattr(obj1, &#x27;y&#x27;, 10)print(obj1.y)  # 输出: 10# print(obj2.y)  # 报错：AttributeError# 类级别setattr(Example, &#x27;z&#x27;, 20)print(obj1.z)  # 输出: 20print(obj2.z)  # 输出: 20\n\n\n\n动态属性的嵌套当我们需要为动态添加的属性再添加属性时，有几种实现方式：\n1.使用 getattr 和 setattr 组合适合直接在属性上添加属性\nclass Example:    def add_dynamic_attr(self, name, value, name2, value2):        setattr(self.__class__, name, value)        attr = getattr(self.__class__, name)        setattr(attr, name2, value2)\n\n2.使用嵌套字典适合需要字典风格存储的场景\nclass Example:    def add_dynamic_attr(self, name, value, name2, value2):        attr_dict = &#123;name2: value2&#125;        setattr(self.__class__, name, attr_dict)\n\n3.使用容器类适合需要更复杂对象结构的场景\nclass DynamicContainer:    passclass Example:    def add_dynamic_attr(self, name, value, name2, value2):        container = DynamicContainer()        setattr(container, name2, value2)        setattr(self.__class__, name, container)\n\n\n\nproperty 与动态属性的结合在实际开发中，我们经常需要创建动态的、计算型的属性。这时可以结合 property 和 setattr：\nsetattr(self.__class__,         f&quot;&#123;page_name&#125;_&#123;locator[&#x27;name&#x27;]&#125;&quot;,         property(lambda self, loc=locator: self._create_element_proxy(loc)))\n\n解释：\n\nproperty() 函数：\n\n创建一个属性描述符\n允许你定义一个”动态”的属性，每次访问时都会调用一个特定的方法\n可以在属性被访问时动态生成或计算值\n\n\nlambda self, loc=locator: self._create_element_proxy(loc):\n\n这是一个匿名函数（lambda）\nloc=locator 是默认参数，捕获当前的 locator\n每次访问这个属性时，都会调用 self._create_element_proxy(loc)\n\n\n结合 setattr() 和 property()：\n\n动态地为类添加一个属性\n这个属性是一个 property，每次访问时都会调用 _create_element_proxy()\n\n\n\n这种模式常用于：\n\n页面对象模型（POM）\n自动化测试框架\n需要延迟加载的场景\n\n完整示例：\nclass PageObject:    def __init__(self, driver):        self.driver = driver        locators = &#123;            &#x27;login_button&#x27;: &#123;&#x27;name&#x27;: &#x27;login&#x27;, &#x27;selector&#x27;: &#x27;#login-btn&#x27;&#125;,            &#x27;username_field&#x27;: &#123;&#x27;name&#x27;: &#x27;username&#x27;, &#x27;selector&#x27;: &#x27;#username&#x27;&#125;        &#125;                for page_name in [&#x27;homepage&#x27;, &#x27;loginpage&#x27;]:            for locator in locators.values():                setattr(                    self.__class__,                     f&quot;&#123;page_name&#125;_&#123;locator[&#x27;name&#x27;]&#125;&quot;,                     property(lambda self, loc=locator: self._create_element_proxy(loc))                )        def _create_element_proxy(self, locator):        return self.driver.find_element(locator[&#x27;selector&#x27;])\n\n\n\n最佳实践与注意事项\n谨慎使用动态属性\n可能导致代码难以理解和维护\nIDE 可能无法提供良好的代码补全\n可能带来性能开销\n\n\n文档化\n清晰记录动态属性的创建逻辑\n说明属性的用途和行为\n\n\n测试覆盖\n确保动态属性的行为符合预期\n测试边界情况和错误处理\n\n\n\n总结Python 的动态属性特性为我们提供了强大的元编程能力，但这种能力需要谨慎使用。合理运用 setattr 和 property 可以让代码更加优雅和灵活，但过度使用可能会带来维护困难。在实际开发中，应该根据具体场景选择合适的实现方式，并注意代码的可维护性和可读性。\n这些高级特性展示了 Python 语言的灵活性和强大性，但也提醒我们在使用时要权衡利弊，选择最适合项目需求的方案。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"gitlab-runner.exe exec 调试 ci 配置","url":"/posts/2024/02/11/57207/","content":"介绍使用 gitlab-runner.exe exec 可以在本地调试 CI&#x2F;CD 配置，而无需每次都提交代码到 GitLab，从而提高调试效率。\n前置条件在开始调试之前，请确保满足以下条件：\n\n已下载 gitlab-runner.exe。\n配置好 config.toml 文件，并确保 gitlab-runner 能成功连接 GitLab。\n已安装 Python 及相关依赖（如 flake8）。\n\n基本命令在本地执行 GitLab CI&#x2F;CD 配置的基本命令如下：\ngitlab-runner.exe exec shell &lt;job_name&gt;\n\n例如，执行 pep8_check 任务：\ngitlab-runner.exe exec shell pep8_check\n\n此命令会调用 gitlab-runner.exe，并在当前目录下执行 .gitlab-ci.yml 文件中的 pep8_check 任务。\n编辑 .gitlab-ci.yml 并进行调试在实际调试时，需要进入 .gitlab-ci.yml 所在的目录，并使用 exec 命令执行 job 任务。\n示例配置：PEP8 代码风格检查以下 gitlab-ci.yml 配置定义了 pep8_check 任务，使用 flake8 进行 Python 代码风格检查。\n# 定义阶段stages:  - lint# PEP8 代码风格检查test_pep8:  stage: lint  before_script:    - where python    - python --version    - python -c &quot;import os, sys; print(os.path.join(os.path.dirname(sys.executable), &#x27;Scripts&#x27;, &#x27;activate.bat&#x27;))&quot; &gt; activate_path.txt    - set /p ACTIVATE_PATH=&lt;activate_path.txt    - call &quot;%ACTIVATE_PATH%&quot; envPython    - where python    - python --version    - pip install flake8  script:    - flake8 --version    - flake8 .  only:    - branches\n\n在本地调试 pep8_check\n进入 .gitlab-ci.yml 所在目录。\n\n运行以下命令执行 pep8_check 任务：\ngitlab-runner.exe exec shell pep8_check\n\n仅检查提交的 Python 代码由于历史原因，仓库中可能包含大量不符合 PEP8 规范的代码。为了避免检查旧代码，可以仅扫描本次提交中修改的 Python 文件。\n过滤提交的 Python 文件以下 gitlab-ci.yml 配置只检查本次提交中变更的 .py 文件。\n# 定义阶段stages:  - lint# PEP8 代码风格检查pep8_check:  stage: lint  before_script:    - where python    - python --version    - python -c &quot;import os, sys; print(os.path.join(os.path.dirname(sys.executable), &#x27;Scripts&#x27;, &#x27;activate.bat&#x27;))&quot; &gt; activate_path.txt    - set /p ACTIVATE_PATH=&lt;activate_path.txt    - call &quot;%ACTIVATE_PATH%&quot; envPython    - where python    - python --version  script:    # 获取当前分支与目标分支的共同祖先 commit    - git merge-base HEAD origin/master &gt; merge_base.txt    - set /p MERGE_BASE=&lt;merge_base.txt    - git diff --name-only %MERGE_BASE% HEAD | findstr /i /r &quot;.py&quot; || (echo No .py files changed &amp;&amp; exit 0)    - pip install flake8    - flake8 --version    - for /F &quot;delims=&quot; %%F in (&#x27;git diff --name-only %MERGE_BASE% HEAD ^| findstr /i /r &quot;.py&quot;&#x27;) do (      flake8 --max-line-length=120 &quot;%%F&quot; || (echo Flake8 found issues in %%F &amp;&amp; exit 0))  only:    - branches\n\n本地调试命令示例\n手动获取当前分支与 origin/master 的共同祖先 commit：\ngit merge-base HEAD origin/master &gt; merge_base.txtset /p MERGE_BASE=&lt;merge_base.txt\n\n获取本次提交变更的 .py 文件：\ngit diff --name-only %MERGE_BASE% HEAD | findstr /i /r &quot;.py&quot; || (echo No .py files changed)\n\n输出示例：\nutils/constant.py\n\n运行 flake8 仅检查变更的文件：\nfor /F &quot;delims=&quot; %F in (&#x27;git diff --name-only %MERGE_BASE% HEAD ^| findstr /i /r &quot;.py&quot;&#x27;) do (   flake8 --max-line-length=120 &quot;%F&quot; || (echo Flake8 found issues in %F))\n\n示例输出：\nutils/constant.py:10:1: E303 too many blank lines (4)Flake8 found issues in utils/constant.py\n\n总结使用 gitlab-runner.exe exec shell &lt;job_name&gt; 进行本地调试，可以大幅提升 GitLab CI&#x2F;CD 配置的调试效率。结合 git diff 过滤提交文件，可以避免对整个代码库执行不必要的检查，进一步优化 CI&#x2F;CD 任务的执行效率。\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Sphinx 一键生成文档","url":"/posts/2024/11/02/61561/","content":"在线展示我的Demo: Content — Sphinx-Auto 2.0 documentation\n关于现在自动化框架暂无清晰的API文档，给今后的代码编写、查阅及维护造成一定的困扰，为了实现将所有测试用例脚本中的注释导出、查阅，查阅网上多数人使用的工具，决定采用sphinx实现自动产生参考文档、索引等。\nsphinx的优点：\n\n支持多种输出格式：html、Latex、ePub等；\n丰富的扩展\n结构化文档\n自动索引\n支持语法高亮\n\n环境配置\n\n安装 Python3\nsphinx：pip install sphinx\n\n常规操作\n进入 doc 目录下，输入 sphinx-quickstart，会出现一些选项，根据需要填写即可\nPS D:\\Developer\\SphinxAuto\\doc&gt; sphinx-apidoc -o ./source ../src/PS D:\\Developer\\SphinxAuto\\doc&gt; sphinx-quickstartWelcome to the Sphinx 8.1.3 quickstart utility.Please enter values for the following settings (just press Enter toaccept a default value, if one is given in brackets).You have two options for placing the build directory for Sphinx output.Either, you use a directory &quot;_build&quot; within the root path, or you separate&quot;source&quot; and &quot;build&quot; directories within the root path.&gt; Separate source and build directories (y/n) [n]: yThe project name will occur in several places in the built documentation.&gt; Project name: Sphinx-Auto&gt; Project release []: 2.0If the documents are to be written in a language other than English,you can select a language here by its language code. Sphinx will thentranslate text that it generates into that language.For a list of supported codes, seehttps://www.sphinx-doc.org/en/master/usage/configuration.html#confval-language.&gt; Project language [en]: zh_CNCreating file D:\\Developer\\SphinxAuto\\doc\\source\\conf.py.Creating file D:\\Developer\\SphinxAuto\\doc\\source\\index.rst.Creating file D:\\Developer\\SphinxAuto\\doc\\Makefile.Creating file D:\\Developer\\SphinxAuto\\doc\\make.bat.Finished: An initial directory structure has been created.You should now populate your master file D:\\Developer\\SphinxAuto\\doc\\source\\index.rst and create other documentationsource files. Use the Makefile to build the docs, like so:   make builderwhere &quot;builder&quot; is one of the supported builders, e.g. html, latex or linkcheck.\n\n然后出现以下目录结构：\ndoc├── build├── source│   ├── conf.py│   ├── index.rst│   ├─_static│   └─_templates├── make.bat└── Makefile\n\n部分分解说明\n\nMakefile：可以将它看作是一个包含指令的文件，在使用 make 命令时，使用这些指令来构建文档输出。\nbuild：这是触发特定输出后用来存放所生成的文件的目录。\nconf.py：这是一个 Python 文件，用于存放 Sphinx 的配置值，包括在终端执行 sphinx-quickstart 时选中的那些值。\nindex.rst：文档项目的 root 目录。如果将文档划分为其他文件，该目录会连接这些文件。\n\n\nconf.py文件中可以修改配置：\n配置confi.py：\nimport osimport syssys.path.insert(0, os.path.abspath(&#x27;../../src&#x27;))  # 指向src(需要导出用例的目录)\n\n为sphinx添加扩展：\nextensions = [&#x27;sphinx.ext.autodoc&#x27;,    &#x27;sphinx.ext.doctest&#x27;,    &#x27;sphinx.ext.intersphinx&#x27;,    &#x27;sphinx.ext.todo&#x27;,    &#x27;sphinx.ext.coverage&#x27;,    &#x27;sphinx.ext.mathjax&#x27;,    &#x27;sphinx.ext.napoleon&#x27;]\n\n更换sphinx的主题：\n# html_theme = &#x27;alabaster&#x27; 默认主题import sphinx_rtd_theme    # 需要先pip install sphinx_rtd_themehtml_theme = &#x27;sphinx_rtd_theme&#x27;html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n大部分主题 Sphinx Themes Gallery (sphinx-themes.readthedocs.io)，特别是对于命名+入参很长的函数,显示效果都不如 furo 和 sphinx_book_theme 。\n使用发现这两个主题有一些差异：\n\nfuro\n在渲染 markdown 文件时，会将所有一级标题（# 标题）都显示在侧边栏中，因此会展示 README.md 文件中的所有一级标题（如 Usage、接口文档、其他注意事项 等）\n展示 python 模块时，右侧边栏会列出所有的函数，包括类的方法\n\n\nsphinx_book_theme\n在渲染 markdown 文件时，默认只显示第一个一级标题，不展开后续的一级标题内容，简化左侧边栏，不支持定制\n展示 python 模块时，右侧边栏只会列出类名、函数，不包括类的方法\n\n\n\n\n生成html文件\n进入 doc 目录，如下操作，会把src所有文件一次性生成，可能会产生重复内容：\nsphinx-apidoc -o ./source ../src/ # 这是将src目录下的所有py脚本注释导出，包括src中所有子目录中的脚本\n\n需要导出哪个目录的脚本注释，就单独导出。\n正确操作：命令行切换到doc目录下，依次执行：\nsphinx-apidoc -o [生成rst的位置] [项目代码的位置] -f(强制重新覆盖写，否则会检测，如果有同名文件存在，会跳过不更新)\n\nsphinx-apidoc -o ./source ../src/scripts1/  # 这是将src/scriptes1/目录下的所有py脚本注释导出，包含子目录中的py脚本sphinx-apidoc -o ./source ../src/scripts2/\n\n再执行：\nmake clean  # 删除build目录下的文件（第一次build为空文件夹）make html\t# 在build目录下生成 doctrees、html 目录\n\n确认最后输出中含有 build succeesed，再去build&#x2F;html目录中检查是否生成了对应的html等其他文件。\n\n谷歌浏览器打开build&#x2F;html&#x2F;index.html，查看API文档\n\n\n有个问题，sphinx-apidoc -o ./source ../src/ 方式生成的 .rst 文件后，打开 html，没有展示出各个模块，需要手动去修改 index.rst 文件，很复杂。所以不采用这种命令生成方式。而是手动配置 .rst 文件， 不断调试，让页面展示成我想要的样子，接着用 python 脚本处理，自动化构造 .rst 文件。\n\n一键生成文档为了省事，编写  auto_generate.py ，完成文档的编译和更新，并在浏览器中打开。\n脚本已经很好地实现了自动化生成 Sphinx 文档的功能，包括创建 .rst 文件、构建 index.rst 索引、拷贝 README 文件，并调用 sphinx-autobuild ，在生成 .rst 文件后进行编译，生成实时 HTML 文档。不用再手动执行  make clean，make html 手动编译。\n自动化脚本没有使用 sphinx-apidoc 来生成 .rst 文件，而是构造色生成 .rst 文件，通过排版布局，来显示文档。\nindex.rst 文件\nContent==================.. toctree::   :maxdepth: 2   README   module1/script_a.rst   module1/submodule1/script1.rst   module1/submodule2/script2.rst   module2/script_b.rst   module2/submoduleA/sub_script_a.rst   module2/submoduleB/sub_script_b.rstIndices and Tables==================* :ref:`genindex`* :ref:`modindex`* :ref:`search`\n\n\n\n\n启动服务查看\n本地直接打开 html 文件， Content — Sphinx Demo 2.0 文档\n\n使用 python3 自带的 http.server 模块快速启动一个静态文件服务器\npython -m http.server 8001\nPS D:\\Developer\\SphinxAuto\\doc\\build&gt; python -m http.server 8001 Serving HTTP on :: port 8001 (http://[::]:8001/) ...::ffff:127.0.0.1 - - [02/Nov/2024 01:01:20] &quot;GET / HTTP/1.1&quot; 200 -::ffff:127.0.0.1 - - [02/Nov/2024 01:01:20] &quot;GET /_static/pygments.css?v=a746c00c HTTP/1.1&quot; 200 -\n\n执行命令，在 doc/build 启动一个 HTTP 服务器，访问：Content — Sphinx Demo 2.0 文档\n\nSphinx 内置服务器\npip install sphinx-autobuild\n\nsphinx-autobuild &lt;source_dir&gt; &lt;build_dir&gt; --host 0.0.0.0 --port 8001sphinx-autobuild .\\source\\  .\\build\\  --host 0.0.0.0 --port 8001\n\nPS D:\\Developer\\SphinxAuto\\doc&gt; sphinx-autobuild .\\source\\  .\\build\\  --host 0.0.0.0 --port 8001[sphinx-autobuild] Starting initial build[sphinx-autobuild] &gt; python -m sphinx build &#x27;.\\source\\&#x27; &#x27;.\\build\\&#x27;Running Sphinx v8.1.3loading translations [zh_CN]... doneWARNING: html_static_path entry &#x27;_static&#x27; does not existloading pickled environment... The configuration has changed (4 options: &#x27;html_permalinks_icon&#x27;, &#x27;html_sourcelink_suffix&#x27;, &#x27;html_theme_options&#x27;, &#x27;templates_path&#x27;)donemyst v4.0.0: MdParserConfig(commonmark_only=False, gfm_only=False, enable_extensions=set(), disable_syntax=[], all_links_external=False, links_external_new_tab=False, url_schemes=(&#x27;http&#x27;, &#x27;https&#x27;, &#x27;mailto&#x27;, &#x27;ftp&#x27;), ref_domains=None, fence_as_directive=set(), number_code_blocks=[], title_to_header=False, heading_anchors=0, heading_slug_func=None, html_meta=&#123;&#125;, footnote_sort=True, footnote_transition=True, words_per_minute=200, substitutions=&#123;&#125;, linkify_fuzzy_links=True, dmath_allow_labels=True, dmath_allow_space=True, dmath_allow_digits=True, dmath_double_inline=False, update_mathjax=True, mathjax_classes=&#x27;tex2jax_process|mathjax_process|math|output_area&#x27;, enable_checkboxes=False, suppress_warnings=[], highlight_code_blocks=True)building [mo]: targets for 0 po files that are out of datewriting output... building [html]: targets for 0 source files that are out of dateupdating environment: 0 added, 0 changed, 0 removedreading sources... looking for now-outdated files... none foundno targets are out of date.build succeeded, 1 warning.The HTML pages are in build.[sphinx-autobuild] Serving on http://0.0.0.0:8001[sphinx-autobuild] Waiting to detect changes...\n\n访问：Content — Sphinx Demo 2.0 文档\n好处：监测 doc 目录中的文件是否变化，在第一次编译成功后，只要改动了文件内容、文件位置变化等，它会自动重新编译。当然，如果是 src 工程代码变化，不会被自动检测到，需要手动更新 rst 文件。\n\n\n\nsphinx 语法sphinx采用 reStructuredText (reST) 的概念和语法 。\n\n章节标题： 在双上划线符号之间（或为下划线）, 并且符号的长度不能小于文本的长度: \nWelcome to UTest API documentation!=======================================\n\n通常没有专门的符号表示标题的等级，但是对于Python 文档，可以这样认为:\n\n# 及上划线表示部分\n* 及上划线表示章节\n=, 小章节\n-, 子章节\n^, 子章节的子章节\n&quot;, 段落\n\n\n内联标记 (与markdown语法一致)\n\n星号: *text*   斜体： example演示\n双星号: **text**  加粗 ：example演示\n反引号: ```code```   代码样式： example演示\n\n 注：星号及反引号在文本中容易与内联标记符号混淆，可使用反斜杠符号转义. \n标记的一些限制：\n\n不能相互嵌套\n内容前后不能由空白: 这样写* text* 是错误的\n如果内容需要特殊字符分隔. 使用反斜杠转义，如: thisis\\ *one*\\ word\n\n\n列表\n 列表标记仅在段落的开头，列表可以嵌套，但是需跟父列表使用空行分隔 \n* Item Foo      * childitem foo1   * childitem foo2   * Item Bar      1. childitem bar1   2. childitem bar2       #. Item 1#. Item2   * childitem foo1   * childitem foo2   1. item32. item4      1. childitem1   2. chidlitem2   \n\n跳转到某一标签\n方式一：\n 标签直接放在章节标题前面\n在 demo1.rst 中设置标签：\n.. _demo1.py-label:demo1 module============\n\n 在其他文件中可以通过 :ref:`demo1.py-label` 来跳转\n:ref:`demo1.py-label`.\n\n\n方式二：\n 标签不放在章节开头，但是需要给出明确的链接\n在demo3.rst中设置标签，此时标签可以不放在章节开头：\ndemo3 module============.. _demo3.py-label:\n\n 在其他文件中可以通过 :ref:`name &lt;demo3.py-label&gt;`. 来跳转，这里name可以任意命名\n:ref:`name &lt;demo3.py-label&gt;`.\n\n显性标记\n显性标记不展示在html中，有点像注释的感觉。主要是用在那些需做特殊处理的reST结构中，如尾注，突出段落，评论，通用指令。显式标记以 .. 开始，后跟空白符，段落的缩进一样。（在显示标记与正常的段落间需有空行）\n.. sphinx_demo documentation master file, created by   sphinx-quickstart on Fri Nov  1 11:10:41 2019... toctree::   :maxdepth: 4   :caption: Contents:\n\n某个测试框架使用模板：\ndef test_123():    &quot;&quot;&quot;    [用例描述]：        版本测试用例简述（通俗易懂）    [测试策略]：        * 跳过条件；        * 设备间策略差异等.    [测试数据]：        1. 示例1:遍历测试所有支持的编码格式        2. 示例2:不同采集制式下，遍历不同ucode模式    [前置条件]：        1. module-setup_module:        2. class-setup_class:        3. function-setup_function:    [测试步骤]：        1. 示例1：            1. 设置（修改）。。。。，检查。。。；            2. 设置。。。。，检查。。。；            3. 设置。。。。，检查。。。；        2. 示例2：            1. 设置。。。。；            2. 设置。。。。；            3. 检查的违章包括：                * 压线、 11                * 压双黄线、 9                * 压单黄线、10                * 逆行、2    [后置条件]：        1. function-setup_function:        2. class-setup_class:        3. module-setup_module:    &quot;&quot;&quot;    pass\n\n注意点：\n\n注释中的换行一律使用Enter，然后使用Tab缩进；\n在[用例描述]：[测试策略]：这样的标题后面不要写文字，Enter换行后写； 如果没有需要添加的内容，换行后写“无”字；\n对于选择用序号1.2.3还是* ， 如果有明确的先后步骤请使用1.2.3. ， 没有先后顺序或步骤根据自己审美选择用1.2.3或* ；\n使用1.2.3.时需要英文输入法, 同时注意标记符号与 内容之间需要有空格；\n\n\n\n\nReference\n代码风格：\n\nstyleguide | Style guides for Google-originated open-source projects\n\nExample — numpydoc v1.9.0rc0.dev0 Manual\n\n\n\nmarkdown 纯文档 sphinx demo\nsource&#x2F;Cpp&#x2F;01设计模式&#x2F;index.rst · xxpcb&#x2F;SphinxDemo - 码云 - 开源中国 (gitee.com)\n小记：他这边用了多个 index.rst，配合多级目录，嵌套使用，侧边栏可以点击展开。\n\n\n","categories":["生产力","工具"],"tags":["tools","sphinx"]},{"title":"hexo 博客搭建部署","url":"/posts/2024/10/02/32734/","content":"hexo 本地搭建D:\\Developer&gt;hexo init github_blogINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitINFO  Install dependenciesINFO  Start blogging with Hexo!D:\\Developer&gt;cd github_blogD:\\Developer\\github_blog&gt;hexo gINFO  Validating configINFO  Start processingINFO  Files loaded in 175 msINFO  Generated: archives/index.htmlINFO  Generated: index.htmlINFO  Generated: css/style.css...INFO  Generated: css/images/banner.jpgINFO  11 files generated in 163 msD:\\Developer\\github_blog&gt;hexo serverINFO  Validating configINFO  Start processingINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.\n\nhexo new &quot;my new post&quot;  # Create a new posthexo generate    # Generate static fileshexo server  # Run serverhexo deploy  # Deploy to remote sites\n\n\n\n部署到 githubnpm install hexo-deployer-git --savehexo clean  # 清除旧的生成文件和缓存。hexo g  # 根据内容生成新的静态页面。hexo deploy  # 将生成的页面部署到服务器或 GitHub Pages。\n\n\n\nnext 主题安装和配置从  https://github.com/iissnan/hexo-theme-next fork 一份到自己的 github 上，为了方便跟踪改了哪些配置，再克隆到 github_blod 目录中。\nD:\\Developer\\github_blog&gt;git clone git@github.com:zypdominate/hexo-theme-next.git themes/next\n\n修改 _config.yaml，\n# Extensions# theme: landscapetheme: next\n\n重新启动服务，出现一个报错：\n&#123;% extends &#x27;_layout.swig&#x27; %&#125; &#123;% import &#x27;_macro/post.swig&#x27; as post_template %&#125; &#123;% import &#x27;_macro/sidebar.swig&#x27; as sidebar_template %&#125; &#123;% block title %&#125;&#123;&#123; config.title &#125;&#125;&#123;% if theme.index_with_subtitle and config.subtitle %&#125; - &#123;&#123;config.subtitle &#125;&#125;&#123;% endif %&#125;&#123;% endblock %&#125; &#123;% block page_class %&#125; &#123;% if is_home() %&#125;page-home&#123;% endif -%&#125; &#123;% endblock %&#125; &#123;% block content %&#125;&#123;% for post in page.posts %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endfor %&#125;&#123;% include &#x27;_partials/pagination.swig&#x27; %&#125; &#123;% endblock %&#125; &#123;% block sidebar %&#125; &#123;&#123; sidebar_template.render(false) &#125;&#125; &#123;% endblock %&#125;\n\n解决：npm i hexo-renderer-swig\nD:\\Developer\\github_blog&gt;npm i hexo-renderer-swignpm warn deprecated hexo-renderer-swig@2.0.0: hexo-renderer-swig has been deprecated. Please use other template engines. (e.g. nunjucks https://github.com/hexojs/hexo-renderer-nunjucks)npm warn deprecated swig-templates@2.0.3: unmaintainedadded 28 packages, and audited 256 packages in 5m23 packages are looking for funding  run `npm fund` for details6 vulnerabilities (2 low, 1 high, 3 critical)To address all issues (including breaking changes), run:  npm audit fix --forceRun `npm audit` for details.\n\n\n\n标签和分类设置菜单栏，修改 _config.yaml\nmenu:  home: /  categories: /categories/  tags: /tags/  archives: /archives/  about: /about/\n\n\n\n创建页面：categories，tages，about。在此之前，如果没有创建，点击主页上的这些菜单，会出现 Cannot GET /categories/ 这样的报错。\nD:\\Developer\\github_blog&gt;hexo new page categoriesINFO  Validating configINFO  Created: D:\\Developer\\github_blog\\source\\categories\\index.mdD:\\Developer\\github_blog&gt;hexo new page tagsINFO  Validating configINFO  Created: D:\\Developer\\github_blog\\source\\tags\\index.mdD:\\Developer\\github_blog&gt;hexo new page aboutINFO  Validating configINFO  Created: D:\\Developer\\github_blog\\source\\about\\index.md\n\n分别修改对应的index.md文件\n---title: categoriesdate: 2018-07-01 23:37:24type: &quot;categories&quot;---\n\ntitle: tagesdate: 2018-07-01 23:33:14type: &quot;tags&quot;\n\n\n\n一篇文章多个分类在很多情况下，我们希望在 Hexo 中写的一篇文章能够同时属于多个分类，例如我写一篇 [《Python自动化测试》]，我既想将它放在 [Python] 这个分类中，又想将它放入 [自动化测试] 这个分类。\n子分类\n下面的分类会将该分章放到 Python/Automation这个分类下\ncategories:  - Python  - Automation\n\n或者\ncategories: [Python, Automation]\n\n\n\n多个分类\n如果要求是将文章同时分到多个不同的分类中呢，应该这样：\ncategories:  -[Python]  -[Automation]\n\n这样，就可以将上面的文章分类到 Python 和 Automation 这两个不同的目录中了。\n扩展一下，如果我们将其分类到 Python/Servlet 和 Programming 两个不同的目录下，我们应该如下写：\ncategories:  -[Python, Automation]  -[Programming]\n\n\n\n网站描述# Sitetitle: Magnolia的博客subtitle: &#x27;持续成长&#x27;description: &#x27;Just do it&#x27;keywords:author: Magnolialanguage: entimezone: Asia/Nanjing\n\n\n\n头像将图片放到 source&#x2F;images 里面\n# Sidebar Avataravatar: /images/avatar.jpg\n\n\n\n侧边栏社交链接social:  CSDN: https://blog.csdn.net/xxxx || cndn  Gitee: https://gitee.com/xxxx || gitee  GitHub: https://github.com/xxxx || github  E-Mail: mailto:xxxx@gmail.com || envelope\n\n\n\n字数统计和阅读时长安装插件\nnpm install hexo-symbols-count-time --save\n\n修改配置\nsymbols_count_time:  #文章内是否显示  symbols: true  time: true  # 网页底部是否显示  total_symbols: true  total_time: true  separated_meta: true  item_text_post: true  item_text_total: false  awl: 4  wpm: 275  suffix: mins.\n\n\n遇到的报错问题并解决文章摘要显示数字解决：\n在文章的 front-matter 中添加 description: xxx，description 的内容就是被显示在首页上，其他的不显示。\n或者在文件内容中加入截断，&lt;!--more--&gt;，在这之后的内容就不会显示。\n分页的前一页下一页显示不对将以下内容：\n&#123;% if page.prev or page.next %&#125;  &lt;nav class=&quot;pagination&quot;&gt;    &#123;&#123;      paginator(&#123;        prev_text: &#x27;&lt;i class=&quot;fa fa-angle-left&quot;&gt;&lt;/i&gt;&#x27;,        next_text: &#x27;&lt;i class=&quot;fa fa-angle-right&quot;&gt;&lt;/i&gt;&#x27;,        mid_size: 1      &#125;)    &#125;&#125;  &lt;/nav&gt;&#123;% endif %&#125;\n\n改为：\n&#123;% if page.prev or page.next %&#125;  &lt;nav class=&quot;pagination&quot;&gt;    &#123;&#123;      paginator(&#123;        prev_text: &#x27;&lt;i class=&quot;fa fa-angle-left&quot; aria-label=&quot;&#x27; + __(&#x27;accessibility.prev_page&#x27;) + &#x27;&quot;&gt;&lt;/i&gt;&#x27;,        next_text: &#x27;&lt;i class=&quot;fa fa-angle-right&quot; aria-label=&quot;&#x27; + __(&#x27;accessibility.next_page&#x27;) + &#x27;&quot;&gt;&lt;/i&gt;&#x27;,        mid_size: 1,        escape: false      &#125;)    &#125;&#125;  &lt;/nav&gt;&#123;% endif %&#125;\n\n\n\n部署报错fatal: unable to access &#x27;https://github.com/zypdominate/zypdominate.github.io.git/&#x27;: Failed to connect to github.com port 443 after 21084 ms: Could not connect to serverFATAL Something&#x27;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.htmlError: Spawn failed    at ChildProcess.&lt;anonymous&gt; (D:\\Developer\\github_blog\\node_modules\\hexo-deployer-git\\node_modules\\hexo-util\\lib\\spawn.js:51:21)    at ChildProcess.emit (node:events:519:28)    at cp.emit (D:\\Developer\\github_blog\\node_modules\\cross-spawn\\lib\\enoent.js:34:29)    at ChildProcess._handle.onexit (node:internal/child_process:294:12)\n\n重新执行了一遍：\nnpm install hexo-deployer-git --savehexo clean  # 清除旧的生成文件和缓存。hexo g  # 根据内容生成新的静态页面。hexo d  # 将生成的页面部署到服务器或 GitHub Pages。\n\n修改 Hosts 文件（解决 DNS 污染）：在 C:\\Windows\\System32\\drivers\\etc\\hosts 中添加：\n140.82.112.4 github.com\n\n\n\n点击目录无法跳转在文章中，点击左侧的含中文的目录，没法跳转到对应的标题。\n解决：\n// Handle the clicking of TOC links$(&#x27;.post-toc a&#x27;).on(&#x27;click&#x27;, function (e) &#123;  e.preventDefault();  var targetId = decodeURIComponent($(this).attr(&#x27;href&#x27;));  var target = $(targetId);  if (target.length) &#123;    $(&#x27;html, body&#x27;).animate(&#123;      scrollTop: target.offset().top    &#125;, 500);  &#125;&#125;);\n\n\n等待文档加载完成\n为所有目录链接添加点击事件监听器\n阻止默认的跳转行为\n解码链接中的中文字符\n平滑滚动到目标位置\n\n清除浏览器缓存并重新生成静态文件，hexo clean，hexo generate\n侧边栏目录带有编号问题默认情况下，Next 主题会给侧边栏的目录自动编号。\n文章中标题本身没有 1. 2. 3. 这样的有序列表前的数字，但是启动服务后，加载出来的文件的侧边栏目录中带有 1. 2. 3. 4.，如果原来标题就有1.2.3，那么出现 1.1 2.2 3.3 这样的显示，很难看。\n解决：打开 themes/next/_config.yml 文件，找到 toc 相关的配置部分，修改以下配置：\ntoc:  enable: true  # 将 number 设置为 false 来关闭自动编号  number: false    wrap: false  expand_all: false  max_depth: 6\n\n主要是将 number: true 改为 number: false，这样就能关闭目录的自动编号功能。侧边栏的目录就不会自动添加数字编号了，会保持和文章标题一致的格式。\n点击多级标题无法展开询问 Claude，问题出在目录的 HTML 结构上，给 Claude 我博客文章点击目录后的结构 html，针对性地修改 JavaScript 代码。发现目录结构使用了 nav-child 类来表示子目录，于是修改如下后，解决问题。\n$(document).ready(function() &#123;  // 处理目录点击展开/折叠  $(&#x27;.post-toc .nav-item&#x27;).on(&#x27;click&#x27;, function(e) &#123;    e.stopPropagation(); // 阻止事件冒泡        var $this = $(this);    var $subNav = $this.children(&#x27;.nav-child&#x27;);        // 如果有子目录    if ($subNav.length &gt; 0) &#123;      e.preventDefault(); // 阻止默认跳转      $subNav.slideToggle(200);      $this.toggleClass(&#x27;expanded&#x27;);    &#125;  &#125;);    // 初始展开当前活动的目录项  function expandActiveNav() &#123;    var $activeItem = $(&#x27;.post-toc .active-current&#x27;).parent();    $activeItem.parents(&#x27;.nav-child&#x27;).show();    $activeItem.parents(&#x27;.nav-item&#x27;).addClass(&#x27;expanded&#x27;);  &#125;    // 首次加载时展开  expandActiveNav();    // 滚动时保持展开状态  $(window).on(&#x27;activate.bs.scrollspy&#x27;, function() &#123;    expandActiveNav();  &#125;);&#125;);\n\ngif 图片没有加载配置 _config.yml\npost_asset_folder: true\n\n修改图片命令，去除图片中的空格。\n","categories":["生产力","工具"],"tags":["github","hexo"]},{"title":"iOS 平台自动化测试升级","url":"/posts/2024/07/01/32936/","content":"iOS App 测试环境升级，遇到的问题以及解决方法\n\nMac 实体机升级到 Sonima 14.5\nXcode 升级到 15.3\n\n问题1： WebDriverAgent 编译失败\n尝试下载 最新版本的WDA 源码编译，可以编译成功。\n问题2：具体坐标直接点击的代码都会报错。\n向 appium 开源项目报了这个问题，过了10分钟就得到回复\n\nPlease use W3C Actions instead.Also, we do not support Appium 1 anymore - please upgrade to Appium 2.\n\n于是升级相关配置和修改所有涉及到的代码，使用 W3C Action 替换原来的 MultiAction、TouchAction。\n问题3：升级 Appium 从 1.2.0 升级到 2.9，执行报错，unexpected keyword argument ‘desired_capabilites’\n\n排查，搜到一个解决方法 https://github.com/appium/python-client/issues/878\n该问题已经在 2.10 以上版本修复，于是再更新 Appium 到 2.11.1\n问题4：系统弹框元素无法被识别到\n\n之前也有这个问题，但是可以通过 driver.page_source 来定位到，现在升级后不行。\n解决：不直接点击元素，而是使用脚本语句处理\ndriver.execute_script(&#39;mobile: alert&#39;,&#123;&#39;action&#39;: &#39;accept&#39;, &#39;buttonLabel&#39;: “Continue”&#125;\n问题5：登录google页面元素无法获取\n之前偶尔也会遇到这个问题，但是重启模拟器、在Xcode重新编译WDA、重启Appium后，就可以定位到登录页面元素，这次升级后却不行。\n\n重新安装了 Appium Server GUI 1.22.1版本（之前用的是 Appium 1.21.0-1），发现只要启动了Appium Server GUI 客户端后，不需要再通过 Xcode 编译出 WDA 到模拟器中，直接运行代码启动webdriver，模拟器中会自动生成 WDA，此时 Editor app 也能启动起来。\n虽然现在不用自己去编译WDA 了，但是进入 Appium Server GUI 1.22.1 安装路径下的 /Applications/Appium\\ Server\\ GUI.app/Contents/Resources/app/node_modules/appium/node_modules/appium-webdriveragent，打开 WebDriverAgent.xcodeproj 来编译 WDA 会报错，无法生成WDA，但用 github 上的 WebDriverAgent-8.7.2 包来编译，是没问题的。\n所以，现在使用 Appium Server GUI 1.22.1版本时，要么不自己去编译WDA，要么要用最新的包来编译 WDA，才能正常运行代码。\n\n部分修改代码\n点击坐标的方式改变，使用 PointerInput 和 ActionBuilder，不再支持 TouchAction(self.driver).tap(x=x, y=y, count=1).perform()\nfrom selenium.webdriver import ActionChainsfrom selenium.webdriver.common.actions import interactionfrom selenium.webdriver.common.actions.mouse_button import MouseButtonfrom selenium.webdriver.common.actions.action_builder import ActionBuilderfrom selenium.webdriver.common.actions.pointer_input import PointerInput\n\npointer = PointerInput(kind=interaction.POINTER_TOUCH, name=&#x27;finger1&#x27;)actions = ActionBuilder(self.driver, mouse=pointer)actions.pointer_action.move_to_location(x, y)actions.pointer_action.pointer_down()actions.pointer_action.pointer_up()actions.perform()\n\npointer = PointerInput(kind=interaction.POINTER_TOUCH, name=&#x27;finger1&#x27;)actions = ActionBuilder(self.driver, mouse=pointer)actions.pointer_action.move_to_location(start_x, start_y)actions.pointer_action.pointer_down()actions.pointer_action.pause(duration)actions.pointer_action.move_to_location(end_x, end_y)actions.pointer_action.pointer_up()actions.perform()\n\nactions = ActionChains(self.driver)actions.w3c_actions.devices = []pointer_input0 = actions.w3c_actions.add_pointer_input(&#x27;touch&#x27;, &#x27;finger0&#x27;)pointer_input0.create_pointer_move(x=x, y=y)pointer_input0.create_pointer_down()pointer_input0.create_pause(0.5)pointer_input0.create_pointer_move(x=x1, y=y1)pointer_input0.create_pointer_up(MouseButton.LEFT)pointer_input1 = actions.w3c_actions.add_pointer_input(&#x27;touch&#x27;, &#x27;finger1&#x27;)pointer_input1.create_pointer_move(x=x, y=y)pointer_input1.create_pointer_down()pointer_input1.create_pause(0.5)pointer_input1.create_pointer_move(x=x2, y=y2)pointer_input1.create_pointer_up(MouseButton.LEFT)actions.perform()\n\npointer = PointerInput(kind=interaction.POINTER_TOUCH, name=&#x27;finger1&#x27;)actions = ActionBuilder(self.driver, mouse=pointer)for index, point in enumerate(coordinate_list):    x, y = point    if index == 0:        # Long press on the first point        actions.pointer_action.move_to_location(x=x, y=y)        actions.pointer_action.pointer_down().pause(0.5)    else:        # Move to subsequent points        actions.pointer_action.move_to_location(x=x, y=y).pause(0.5)actions.pointer_action.pointer_up()actions.perform()\n\n不再支持像 find_element_by_accessibility_id、find_element_by_name 这类的接口，而是使用 find_element(MobileBy.ACCESSIBILITY_ID, locator)、find_element(By.NAME, locator)\n# WebDriverWait(self.driver, timeout=time_out, poll_frequency=0.5, ignored_exceptions=None).until(lambda x: x.find_element_by_accessibility_id(locator))WebDriverWait(self.driver, timeout=time_out, poll_frequency=0.5, ignored_exceptions=None).until(lambda x: x.find_element(MobileBy.ACCESSIBILITY_ID, locator))\n\n处理系统弹框\ndef handle_system_alert(self, button=&#x27;Continue&#x27;):    try:        WebDriverWait(self.driver, 10).until(ec.alert_is_present())        self.driver.execute_script(&#x27;mobile: alert&#x27;, &#123;&#x27;action&#x27;: &#x27;accept&#x27;, &#x27;buttonLabel&#x27;: f&#x27;&#123;button&#125;&#x27;&#125;)        return True    except Exception as e:        print(f&quot;No alert present: &#123;e&#125;&quot;)        return False\n\n","categories":["技术","测开","环境搭建"],"tags":["FixBug","iOS"]},{"title":"pytest 高级用法：间接参数","url":"/posts/2024/12/31/50892/","content":"1. 引言在进行单元测试时，我们经常需要使用不同的参数来测试同一个功能。Pytest 提供了强大的参数化功能，并且可以与 fixture 结合使用，使得测试代码更加灵活和可维护。本文将深入探讨 pytest 中参数化和 fixture 的高级用法。\n2. 基础概念2.1 FixtureFixture 是 pytest 中的一个核心概念，它提供了一种方式来为测试提供可复用的依赖。Fixture 可以：\n\n提供测试数据\n设置测试环境\n处理测试资源的创建和清理\n\n2.2 参数化参数化允许我们使用不同的参数多次运行同一个测试。pytest 提供了两种主要的参数化方式：\n\n直接参数化：参数直接传递给测试函数\n间接参数化：参数通过 fixture 传递给测试函数\n\n3. 代码实例3.1 基础设置首先，我们需要创建两个文件：conftest.py 和 test_fixture_indirect.py。\n# conftest.pyimport pytest@pytest.fixture(scope=&#x27;module&#x27;)def fixture_indirect(request):    print(f&quot;fixture_indirect, request: &#123;request&#125;&quot;)    print(f&quot;fixture_indirect, request.param: &#123;request.param&#125;&quot;)    var = &#x27;var_from_fixture_indirect&#x27;    yield var@pytest.fixture(scope=&#x27;module&#x27;)def fixture_direct(request):  # request 参数可选    print(f&quot;fixture_direct, request: &#123;request&#125;&quot;)    var = &#x27;var_from_fixture_direct&#x27;    yield var\n\n3.2 测试用例示例示例 1：基础的间接参数化\n使用 indirect=True 表示参数会传递给同名的 fixture\nfixture 会接收到参数值，但测试函数只能获得 fixture 的返回值\n\n@pytest.mark.parametrize(&quot;fixture_indirect&quot;, [110, 120], indirect=True)def test_fixture_indirect(fixture_indirect):    print(f&quot;Case fixture_indirect: &#123;fixture_indirect&#125;&quot;)    # 注意：这里无法直接访问参数值 110, 120&quot;&quot;&quot;会运行两次测试，每次：- 先执行 fixture_indirect，获得参数 110/120- 然后运行测试函数，得到 fixture 的返回值&quot;&quot;&quot;\n\nfixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_indirect[110]&gt;&gt;fixture_indirect, request.param: 110PASSED          [ 50%]Case fixture_indirect: var_from_fixture_indirectfixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_indirect[120]&gt;&gt;fixture_indirect, request.param: 120PASSED          [100%]Case fixture_indirect: var_from_fixture_indirect\n\n\n\n示例 2：通过 request 获取参数值\n通过 request 参数获取原始的参数化值\n使用 request.node.callspec.params 访问参数字典\n\n@pytest.mark.parametrize(&quot;fixture_indirect&quot;, [110, 120], indirect=True)def test_fixture_indirect_request(fixture_indirect, request):    print(f&quot;Case fixture_indirect: &#123;fixture_indirect&#125;&quot;)    my_test_param = request.node.callspec.params[&#x27;fixture_indirect&#x27;]    print(f&quot;Case request.param: &#123;my_test_param&#125;&quot;)&quot;&quot;&quot;除了基本功能外，还能获取原始参数：- fixture 的返回值: var_from_fixture_indirect- 原始参数值: 110/120&quot;&quot;&quot;\n\nfixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_indirect_request[110]&gt;&gt;fixture_indirect, request.param: 110PASSED  [ 50%]Case fixture_indirect: var_from_fixture_indirectCase request.param: 110fixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_indirect_request[120]&gt;&gt;fixture_indirect, request.param: 120PASSED  [100%]Case fixture_indirect: var_from_fixture_indirectCase request.param: 120\n\n\n\n示例 3：多参数组合测试\n如何组合多个参数化装饰器\n直接参数化和间接参数化的混合使用\n\n@pytest.mark.parametrize(&quot;fixture_indirect&quot;, [111, 222], indirect=True)@pytest.mark.parametrize(&quot;test_param&quot;, [&#x27;a&#x27;, &#x27;b&#x27;])def test_fixture_param(fixture_indirect, test_param):    print(f&quot;fixture_indirect: &#123;fixture_indirect&#125;&quot;)    print(f&quot;test_param: &#123;test_param&#125;&quot;)&quot;&quot;&quot;会生成 4 个测试用例组合：(111, &#x27;a&#x27;)(111, &#x27;b&#x27;)(222, &#x27;a&#x27;)(222, &#x27;b&#x27;)&quot;&quot;&quot;\n\nfixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_param[a-111]&gt;&gt;fixture_indirect, request.param: 111PASSED           [ 25%]Case fixture_indirect: var_from_fixture_indirectCase test_param: aPASSED           [ 50%]Case fixture_indirect: var_from_fixture_indirectCase test_param: bfixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_param[a-222]&gt;&gt;fixture_indirect, request.param: 222PASSED           [ 75%]Case fixture_indirect: var_from_fixture_indirectCase test_param: aPASSED           [100%]Case fixture_indirect: var_from_fixture_indirectCase test_param: b\n\n\n\n示例 4：部分间接参数化\n如何在一个参数化中同时使用直接和间接参数\n使用 indirect 列表指定哪些参数是间接的\n\n@pytest.mark.parametrize(&quot;fixture_indirect, my_test_param&quot;,                         [(111, &#x27;a&#x27;), (222, &#x27;b&#x27;)],                         indirect=[&#x27;fixture_indirect&#x27;])def test_fixture_indirect_param_partial(fixture_indirect, my_test_param):    print(f&quot;Case fixture_indirect: &#123;fixture_indirect&#125;&quot;)    print(f&quot;Case test_param: &#123;my_test_param&#125;&quot;)&quot;&quot;&quot;会生成 2 个测试用例：(111, &#x27;a&#x27;)(222, &#x27;b&#x27;)&quot;&quot;&quot;\n\nfixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_indirect_param_partial[111-a]&gt;&gt;fixture_indirect, request.param: 111PASSED [ 50%]Case fixture_indirect: var_from_fixture_indirectCase test_param: afixture_indirect, request: &lt;SubRequest &#x27;fixture_indirect&#x27; for &lt;Function test_fixture_indirect_param_partial[222-b]&gt;&gt;fixture_indirect, request.param: 222PASSED [100%]Case fixture_indirect: var_from_fixture_indirectCase test_param: b\n\n\n\n4. 最佳实践\n选择合适的参数化方式\n\n简单参数使用直接参数化\n需要预处理或者复杂设置的参数使用间接参数化\n\n\n合理使用 scope\n\n对于耗时的 fixture，使用更大的 scope（如 module）可以提高测试效率\n注意 scope 对测试隔离的影响\n\n\n参数化组织建议\n\n相关的参数组合放在一起\n使用有意义的参数名\n考虑测试的可读性和维护性\n\n\n\n5. 总结Pytest 的参数化和 fixture 功能为我们提供了强大而灵活的测试工具：\n\n灵活性：可以根据需要选择直接或间接参数化\n可复用性：fixture 机制支持测试代码的重用\n可维护性：通过合理组织参数和 fixture，使测试代码更易维护\n效率：支持多种方式组合参数，提高测试效率\n\n掌握这些高级用法，可以帮助我们写出更好的测试代码，提高测试效率和代码质量。\n参考资料\nPytest 官方文档\nPytest Fixture 文档\nPytest Parametrize 文档\n\n","categories":["技术","pytest"],"tags":["Python","pytest"]},{"title":"生成 Django 中文文档 PDF 版","url":"/posts/2024/11/12/19051/","content":"本文档描述了使用 Sphinx 生成 Django 中文文档 PDF 版本的步骤。\n主要包括：克隆 Django 及其翻译仓库、配置 Sphinx 支持中文及 PDF 输出、设置翻译环境和生成 LaTeX 文件、安装 MikTeX 并生成 PDF 文档。\n此外，文档还提及可以使用 Sphinx 在本地生成 HTML 格式的文档。\n克隆 Django 文档和翻译仓库打开命令行，执行以下命令克隆仓库：\ngit clone https://github.com/django/django.gitgit clone https://github.com/django/django-docs-translations.git\n\n切换到需要的版本的分支\n# django-docs-translationsgit checkout stable/4.2.x# djangogit checkout stable/4.2.x\n\n安装第三方库\npip install sphinx sphinx-rtd-theme sphinx-intl  # 用于安装 Sphinx 和多语言支持pip install -U sphinx_rtd_theme recommonmark latexmk  # 用于生成 PDF 所需的依赖\n\n\n配置 conf.py在 django/docs/conf.py 中添加或修改以下配置来启用中文翻译：\n# 设置语言language = &#x27;zh_CN&#x27;# 加入 PDF 输出格式latex_engine = &#x27;xelatex&#x27;latex_elements = &#123;    &quot;fontpkg&quot;: r&quot;&quot;&quot;        \\setmainfont&#123;Symbola&#125;    &quot;&quot;&quot;,    &quot;preamble&quot;: r&quot;&quot;&quot;        \\usepackage&#123;newunicodechar&#125;        \\usepackage[UTF8]&#123;ctex&#125;        \\newunicodechar&#123;π&#125;&#123;\\ensuremath&#123;\\pi&#125;&#125;        \\newunicodechar&#123;≤&#125;&#123;\\ensuremath&#123;\\le&#125;&#125;        \\newunicodechar&#123;≥&#125;&#123;\\ensuremath&#123;\\ge&#125;&#125;        \\newunicodechar&#123;♥&#125;&#123;\\ensuremath&#123;\\heartsuit&#125;&#125;        \\newunicodechar&#123;…&#125;&#123;\\ensuremath&#123;\\ldots&#125;&#125;        \\usepackage&#123;ctex&#125;  % 中文支持        \\usepackage&#123;fontspec&#125;  % 字体支持        \\setmainfont&#123;Times New Roman&#125;  % 英文主字体        \\setsansfont&#123;Arial&#125;  % 英文无衬线字体        \\setmonofont&#123;Courier New&#125;  % 英文等宽字体        \\setCJKmainfont&#123;SimSun&#125;  % 中文字体    &quot;&quot;&quot;,&#125;# Sphinx theme，可以不改html_theme = &quot;sphinx_rtd_theme&quot;\n\n\n设置和同步翻译进入 django/docs 目录，用 sphinx-intl 设置语言环境。在生成多语言支持的翻译文件时，Sphinx 首先需要生成 .pot 文件。\n生成 .pot 文件在 django/docs 目录中运行以下命令，会将所有可翻译的文本提取为 .pot 文件，并放在 _build/gettext 目录中。\nsphinx-build -b gettext . _build/gettext\n\n运行 sphinx-intl update在生成 .pot 文件后，接着运行 sphinx-intl update 命令，这一步将根据 .pot 文件创建或更新 zh_CN 语言的 .po 文件，这里是在 doc 目录下创建了 locale/zh_CN\\LC_MESSAGES，并生成了一些后缀是po的文件。\nsphinx-intl update -p _build/gettext -l zh_CN\n\n复制翻译文件将 django-docs-translations/zh_Hans/LC_MESSAGES 下的 .po 文件复制到 django/docs/locale/zh_CN/LC_MESSAGES，替换掉相应的 .po 文件。\n\n构建 PDF生成 tex 文件在 django/docs 目录中运行以下命令生成 tex 文件（这里是在windows命令行）：\nsphinx-intl buildmake.bat latex\n\n成功后，这会在 _build/latex 文件夹中生成一个 django.tex 文件。\n安装  MikTeX安装  MikTeX 或 TeX Live 作为 LaTeX 引擎，用于生成 PDF。\n我尝试下载 MikTeX下载_latex文本编辑器最新64位版v21.8_3DM软件 (3dmgame.com)，安装目录是 D:\\Program Files\\MiKTeX。\n生成 pdf在 django\\docs\\_build\\latex 目录下，执行生成 pdf：\ncd _build/latex&quot;D:\\Program Files\\MiKTeX\\miktex\\bin\\x64\\lualatex&quot; -interaction=nonstopmode django.tex# &quot;D:\\Program Files\\MiKTeX\\miktex\\bin\\x64\\pdflatex&quot; django.tex  # 有报错，没搞成# &quot;D:\\Program Files\\MiKTeX\\miktex\\bin\\x64\\xelatex&quot; -interaction=nonstopmode django.tex  # 书签没有标题\n\n最后生成了如下 pdf。期间试了好几个方法，不是编译报错，就是生成了空白的 pdf，或者生成的 pdf 没有书签。\n\n\nsphinx 生成文档也能在本地生成文档。\nsphinx-build -b html . _build/html -D html_theme=sphinx_rtd_theme\n\n进入 docs/_build/html，通过浏览器打开 index.html，看到文档。\n\n","categories":["生产力","工具"],"tags":["Django","tools","sphinx"]},{"title":"分类和标签的区别","url":"/posts/2018/07/01/56967/","content":"1. 分类（Categories）分类是对文章内容的宏观分组，通常用于对文章进行较为严格的层次结构划分，类似于书的章节或目录。每篇文章通常只会属于一个或少数几个分类。分类具有一定的层次结构，可以是多级的。\n特点：\n层次化：可以创建多级分类（如父分类、子分类）。\n单一性：通常每篇文章只会放在一个或少数几个分类中，保持清晰的内容结构。\n文章归类：用于对文章进行大范围的归类，适合整体上描述文章的内容类型。\n\n示例：假设你的博客内容涉及技术、生活和个人成长，分类可以这样划分：\n\n技术\n编程\n自动化测试\n前端开发\n\n\n生活\n旅行\n美食\n\n\n个人成长\n心理学\n自我提升\n\n\n\n用法建议：分类一般用于对内容的主干划分，应该尽量简洁且有逻辑性。比如，一篇关于前端开发的文章可以放在“技术 &gt; 前端开发”分类下，而不应该放在多个不同领域的分类中。\n2. 标签（Tags）标签是对文章内容的补充描述，主要用来标记文章的具体主题或内容关键字。标签更加自由和灵活，可以为文章加上多个相关联的关键词。\n特点：\n自由性：不具备层次结构，更多的是用于细粒度的内容标记。\n多样性：每篇文章可以有多个标签，用来标记具体的主题或内容要素。\n描述具体主题：适合为文章添加多个不同方面的主题描述，便于搜索和筛选。\n\n示例：假设你写了一篇文章介绍如何使用 Vue.js 做前端开发，文章的标签可以是：\n\nJavaScript\nVue.js\n前端开发\n框架\n\n用法建议：标签主要用于补充和细化文章的内容描述，通常比分类更加灵活。例如，一篇文章可以同时带有多个标签，这些标签帮助用户通过关键词找到与主题相关的文章。\n3. 分类与标签的区别\n\n\n分类\n标签\n\n\n\n层次化，适合构建结构化的目录\n扁平化，适合标记具体内容\n\n\n通常每篇文章属于一个或少数几个分类\n每篇文章可以有多个标签\n\n\n体现文章的大范围归属\n体现文章的具体主题或特征\n\n\n适合用来搭建博客的主架构\n适合用来精细化、跨分类标记内容\n\n\n4. 如何划分文章的分类和标签\n选择分类：\n首先考虑文章的整体主题，决定其属于哪个大的内容板块（分类）。\n确定分类后，如果有需要，可以继续使用子分类对内容做进一步划分。\n\n\n添加标签：\n思考文章中涉及到的具体主题和关键词，将这些关键词作为标签。\n标签可以是文章中涉及到的工具、技术、概念等。比如，涉及到的编程语言、技术框架、具体的主题等。\n\n\n\n举例：\n文章内容：你写了一篇关于使用 \nSelenium\n\n 做自动化测试的文章。\n\n分类：技术 &gt; 自动化测试\n\n\n标签：Selenium、自动化测试、Python、测试工具\n\n\n总结\n分类：用于对内容进行宏观的、结构化的归类，一篇文章通常只会属于一个或少数几个分类。\n标签：用于对内容进行自由的、细粒度的标记，一篇文章可以拥有多个标签，方便用户通过关键词找到相关内容。\n\n分类适合用来构建清晰的内容架构，标签适合用来灵活地为文章添加关键词标记，二者相辅相成。\n","categories":["生产力","文字"],"tags":["blog"]},{"title":"AI潮流下的新学习方式","url":"/posts/2025/09/24/56935/","content":"CodeBuddy 很强大啊，相比以前用的同类 AI 工具（cursor、trae），真的是好用。\n当然了我都是用的免费版软件，收费、订阅使用 AI 的工具不在我讨论范围内。\n如果是国内公司开发的工具，可能还区分国际版和国内版，国际版可以使用更多的模型（如 claude），而国内基本限制于 deepseek 等。\n国际版的 CodeBuddy 支持 Claude、Chatgpt、Gemini。\n因此，同一款工具，不同版本，能发挥的功能、给人的体验自然无法相提并论。\n使用 CodeBuddy 的 Craft，我发送了一条需求：“关于 Flask，写几个能快速学习理解 jinja2 的教学demo”，它不仅给我创建了 demo 文件，令我震惊的是，它在设计案例上也有特别之处，由于是 Flask 教学内容，它给出的 app.py 中的视图函数分别对应几个教学的模块，并可以通过启动本地服务、在浏览器上访问的形式来呈现。\n也就是，它将教学内容与 Flask 应用相结合，真的太厉害了。不禁让我思考，在 AI 不断发展之下，学习将变得更加容易、有乐趣。以前枯燥的内容，现在可以直接“动”起来，用户与AI的关系就像是学生与老师，很多传统的教学资料和方式将受到很大的冲击。\n很多商业课程，比如极客时间，大部分都是入门级课程，内容浅尝辄止，特别是有一定经验后再看，就会觉得课程中的案例比较简单，没有很多价值，尤其是运用到实际工作中，AI agent 有取代大部分入门课程的趋势。看了下目前在看的 flask 教程，突然觉得视频里面的 demo 真的弱爆了。\n案例截图\n\n\n本地访问 http://127.0.0.1:5000/demo1，对应 demo1_basic.html、jinja2 基础语法，一边看代码，一边通过 flask 服务看对应的前端效果。\n","categories":["技术","tool"],"tags":["AI"]},{"title":"AI辅助生成mermaid流程图","url":"/posts/2025/06/22/22150/","content":"背景\n在 markdown 文档中虽然可以插入图片，但是也需要管理图片，一旦图片位置变了，文档中的图片就无法显示。\n图片占用空间较大，对于在线文档，为了加载速度，能不使用图片就不使用。\nMermaid 流程图是一个非常好的工具，基于文本快速绘制各种图表（如流程图、时序图、甘特图等）。\n人工手动编写 Mermaid 有点小繁琐，但是借用 AI 之力，绘制流程图效率非常高。\n\nMermaidMermaid 是一种基于文本的图表生成工具，可以通过简单的语法快速绘制各种图表（如流程图、时序图、甘特图等）。它易于编写、可嵌入 Markdown，并支持实时渲染，非常适合文档编写和技术绘图。\nMermaid 流程图核心特点\n\n简单直观\n使用纯文本描述，语法类似自然语言。\n无需图形界面，直接嵌入代码即可生成图表。\n\n\n常用图表支持\n流程图（Flowchart）：描述步骤和决策逻辑。\n时序图（Sequence Diagram）：展示交互时序（如支付流程例子）。\n其他：类图、状态图、甘特图等。\n\n\n跨平台兼容\n支持 GitHub、GitLab、VS Code、Obsidian 等平台的 Markdown 渲染。\n\n\n\n为什么用 Mermaid？\n\n效率高：改代码比拖拽图形更快。\n版本友好：文本格式便于 Git 管理。\n轻量化：无需依赖复杂工具（如 Visio）。\n\n使用 AI 编写 Mermaid很早就了解过 Mermaid，但是由于都需要自己手动编写文本，还是有些繁琐和困难，而且往往自己编写的效果不如自己想象的那么好。、\n借助 AI，将现有的图片格式的流程图丢给 AI 工具，让它根据图片生成 Mermaid 流程图，或者我描述流程内容，让它生成流程图，大大节省了时间和精力。\n目前用来生成 Mermaid 的 AI 工具有：Claude、Gemini、Grok、Deepseek、Chatgpt，为啥要用这么多呢？\n同样的一张流程图，丢给不同的 AI 工具，生成的 Mermaid 图，往往不一样，特别是流程稍微复杂一点。\n于是我集众多 AI 工具之力，第一版先得到一个预期结构符合的结果，将这个结果，也就是生成的 Mermaid 文本，分别再输入给 AI 工具，不断优化和调整局部。\n应用下面是3张 AI 生成的 Mermaid 图：\n下单支付流程\nsequenceDiagram\n    participant 用户\n    participant 前端\n    participant 服务端\n    participant 微信后端\n    \n    前端->>服务端: 1.创建订单\n    前端->>服务端: 2.提交订单\n    前端->>服务端: 3.支付下单\n    服务端-->>前端: 4.返回支付二维码地址\n    前端->>服务端: 5.前端轮询查询订单状态\n    前端->>前端: 6.前端将支付二维码地址转为二维码图形\n    用户->>前端: 7.用户扫码\n    用户->>微信后端: 7.用户发起支付\n    微信后端->>服务端: 8.商城回调接口\n    服务端->>服务端: 9.服务器接收并更新订单信息状态\n    \n    Note over 前端: 二维码包含商户信息、订单信息以及商城回调地址\n\ntoken鉴权\nsequenceDiagram\n    participant 用户\n    participant 客户端\n    participant 服务器\n\n    用户->>客户端: 输入用户名和密码\n    客户端->>服务器: 发送登录请求 (用户名, 密码)\n    服务器-->>客户端: 返回 Token (包含身份信息和有效期)\n    Note right of 服务器: Token 是加密字符串包含用户身份信息服务器不存储状态\n    客户端->>客户端: 存储 Token (如 LocalStorage)\n    \n    用户->>客户端: 发起操作请求\n    客户端->>服务器: 发送请求 (Header: Authorization: Bearer Token)\n    服务器->>服务器: 验证 Token (解密, 检查有效期)\n    Note right of 服务器: 无需查数据库直接验证 Token\n    服务器-->>客户端: 返回操作结果\n\nCookie+Session鉴权\nsequenceDiagram\n    participant 用户\n    participant 客户端\n    participant 服务器\n\n    用户->>客户端: 输入用户名和密码\n    客户端->>服务器: 发送登录请求 (用户名, 密码)\n    服务器->>服务器: 生成 Session ID, 存储 Session 数据\n    Note right of 服务器: Session 数据存储在服务器如内存或数据库\n    服务器-->>客户端: 返回 Cookie (包含 Session ID)\n    客户端->>客户端: 浏览器自动存储 Cookie\n    \n    用户->>客户端: 发起操作请求\n    客户端->>服务器: 发送请求 (自动携带 Cookie: Session ID)\n    服务器->>服务器: 根据 Session ID 查询 Session 数据\n    Note right of 服务器: 需查数据库或内存验证 Session 有效性\n    服务器-->>客户端: 返回操作结果\n\n\n\n","categories":["技术","tool"],"tags":["tools","AI"]},{"title":"AI辅助生成 Jenkins 流水线","url":"/posts/2025/08/19/57841/","content":"引言在现代软件开发中，持续集成和持续部署(CI&#x2F;CD)已成为标准实践。对于需要在多个平台上运行的应用程序，确保代码在不同操作系统上的兼容性尤为重要。本文将介绍如何使用Jenkins和Jenkinsfile创建跨平台(Windows和Linux)的自动化测试流水线，帮助开发团队快速发现并解决平台特定的问题。\n本文环境为 Windows11 和 WSL2。\n在 AI 的辅助下，根据需求，可以快速生成一份 Jenkinsfile，再结合实际应用场景，不断地迭代完善。\n效果展示：\n\n\n\n环境搭建：在WSL2中配置JenkinsDocker Compose配置首先，我们使用Docker在WSL2环境中部署Jenkins。以下是docker-compose.yml配置文件：\nversion: &#x27;3.8&#x27;services:  jenkins:    image: jenkins/jenkins:lts-jdk17    container_name: jenkins    ports:      - &quot;8081:8080&quot;      - &quot;50000:50000&quot;    volumes:      - jenkins_home:/var/jenkins_home      - /var/run/docker.sock:/var/run/docker.sock    user: &quot;1000:1000&quot;  # WSL2中通常使用1000:1000    environment:      - JENKINS_HOME=/var/jenkins_home      - JAVA_OPTS=-Xms512m -Xmx1g      - JENKINS_OPTS=--httpPort=8080      - TZ=Asia/Shanghai      - DOCKER_HOST=unix:///var/run/docker.sock    healthcheck:      test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:8081/login || exit 1&quot;]      interval: 30s      timeout: 10s      retries: 3      start_period: 90s    logging:      driver: &quot;json-file&quot;      options:        max-size: &quot;10m&quot;        max-file: &quot;3&quot;    deploy:      resources:        limits:          memory: 2G          cpus: &#x27;2.0&#x27;        reservations:          memory: 512M          cpus: &#x27;0.5&#x27;    restart: unless-stopped    networks:      - jenkinsnetworks:  jenkins:    driver: bridgevolumes:  jenkins_home:    driver: local\n\n启动Jenkins容器确保当前用户已添加到docker组，然后启动Jenkins容器：\nsudo usermod -aG docker $USERdocker-compose up -d\n\n初始化Jenkins启动后，可以通过以下命令查看初始管理员密码：\ndocker logs -f jenkins\n\n系统会生成一个初始密码，如：b91fb528a2ec464288d95a7783cc4fac，用于首次登录Jenkins。\n安装必要插件为了支持我们的流水线，需要安装以下插件：\n\nGit Parameter Plug-In：用于在构建时选择Git分支\nAllure Jenkins Plugin：用于生成测试报告\n\n对于Allure插件，还需要在Jenkins的”Manage Jenkins”-“Tools”-“Allure Commandline installations”中添加Allure命令行工具。\n跨平台测试流水线设计我们的目标是创建两个独立但结构相似的流水线，分别针对Windows和Linux平台。这样可以：\n\n并行测试不同平台，加快反馈速度\n隔离平台特定的问题\n确保代码在所有目标平台上正常工作\n\n流水线共同特性两个流水线共享以下特性：\n\n使用Git参数插件选择测试分支\n可配置测试目标路径\n自动检测代码变更并触发构建\n生成Allure测试报告\n构建命名包含平台、分支和提交信息\n错误处理和清理机制\n\nLinux流水线详解基本结构pipeline &#123;    agent &#123;        label &#x27;linux_label&#x27;    &#125;    // 配置触发器 - 代码更新后自动触发    triggers &#123;        // 轮询 SCM，检查代码变更（每2分钟检查一次，错开Windows流水线的触发时间）        pollSCM(&#x27;1-59/2 * * * *&#x27;)    &#125;    // 定义可配置的参数    parameters &#123;        // 分支选择参数        gitParameter(name: &#x27;BRANCH&#x27;, /* 其他配置 */)        // 测试目标参数        string(name: &#x27;TEST_TARGET&#x27;, defaultValue: &#x27;tests/&#x27;)    &#125;        // 各个阶段...&#125;\n\n关键阶段\n平台检测：确认当前运行环境\n\nstage(&#x27;Platform Detection&#x27;) &#123;    steps &#123;        script &#123;            echo &quot;=== Linux Platform Pipeline ===&quot;            env.CURRENT_PLATFORM = &#x27;linux&#x27;        &#125;    &#125;&#125;\n\n\n获取Git信息：获取当前提交的详细信息\n\nstage(&#x27;Get Git Info&#x27;) &#123;    steps &#123;        script &#123;            // 获取Git提交信息的代码            gitCommit = sh(returnStdout: true, script: &#x27;git rev-parse HEAD&#x27;).trim()            gitMessage = sh(returnStdout: true, script: &#x27;git log -1 --pretty=format:&quot;%s&quot;&#x27;).trim()                        env.GIT_COMMIT_SHORT = gitCommit.length() &gt; 7 ? gitCommit.take(7) : gitCommit            env.GIT_COMMIT_MESSAGE = gitMessage        &#125;    &#125;&#125;\n\n\n设置构建名称：使用平台、分支和提交信息创建有意义的构建名称\n\nstage(&#x27;Set Build Name&#x27;) &#123;    steps &#123;        script &#123;            // 获取触发用户            def user = currentBuild.rawBuild.getCause(hudson.model.Cause$UserIdCause)?.userId ?: &quot;Auto-Trigger&quot;                        // 处理分支名称            def branch_name = params.BRANCH ?: (env.GIT_BRANCH ? env.GIT_BRANCH.split(&#x27;/&#x27;).last() : &#x27;main&#x27;)                        // 设置构建名称和描述            currentBuild.displayName = &quot;#$&#123;BUILD_NUMBER&#125;-Linux-$&#123;branch_name&#125;-$&#123;env.GIT_COMMIT_SHORT&#125;-$&#123;user&#125;&quot;            currentBuild.description = &quot;Platform: Linux | Branch: $&#123;branch_name&#125; | Commit: $&#123;env.GIT_COMMIT_MESSAGE&#125;&quot;        &#125;    &#125;&#125;\n\n\n环境设置：配置Linux测试环境\n\nstage(&#x27;Setup Linux Environment&#x27;) &#123;    steps &#123;        script &#123;            sh &#x27;&#x27;&#x27;                echo &quot;=== Conda Environment Setup ===&quot;                eval &quot;$(conda shell.bash hook 2&gt;/dev/null)&quot; &gt; /dev/null                conda activate env3.10                echo &quot;Python: $(which python) ($(python --version))&quot;            &#x27;&#x27;&#x27;        &#125;    &#125;&#125;\n\n\n运行单元测试：执行测试并生成报告\n\nstage(&#x27;Run Unit Tests on Linux&#x27;) &#123;    steps &#123;        script &#123;            // 清理之前的测试结果            sh &#x27;&#x27;&#x27;                rm -rf allure-results                mkdir -p allure-results            &#x27;&#x27;&#x27;                        // 执行测试            try &#123;                sh &#x27;&#x27;&#x27;                    eval &quot;$(conda shell.bash hook 2&gt;/dev/null)&quot; &gt; /dev/null                    conda activate env3.10                    python -m pytest &#x27;&#x27;&#x27; + params.TEST_TARGET + &#x27;&#x27;&#x27; -v -s --alluredir=allure-results                &#x27;&#x27;&#x27;                                currentBuild.result = &#x27;SUCCESS&#x27;            &#125; catch (Exception e) &#123;                currentBuild.result = &#x27;UNSTABLE&#x27;                echo &quot;Unit tests have failed test cases on Linux: $&#123;e.message&#125;&quot;            &#125;        &#125;    &#125;    post &#123;        always &#123;            // 发布测试报告            allure results: [[path: &#x27;allure-results&#x27;]]        &#125;    &#125;&#125;\n\nWindows流水线详解关键差异Windows流水线与Linux流水线结构相似，但有以下关键差异：\n\n使用不同的执行器：\n\nagent &#123;    label &#x27;win_label&#x27;&#125;\n\n\n不同的命令执行方式：使用bat而不是sh\n\n// Linux中gitCommit = sh(returnStdout: true, script: &#x27;git rev-parse HEAD&#x27;).trim()// Windows中gitCommit = bat(returnStdout: true, script: &#x27;@git rev-parse HEAD 2&gt;nul&#x27;).trim()\n\n\nWindows特定的环境设置：\n\nstage(&#x27;Setup Windows Environment&#x27;) &#123;    steps &#123;        script &#123;            bat &#x27;&#x27;&#x27;                echo Checking Python environment on Windows...                where python                python --version                echo Getting virtual environment activation script path...                python -c &quot;import os, sys; print(os.path.join(os.path.dirname(sys.executable), &#x27;Scripts&#x27;, &#x27;activate.bat&#x27;), end=&#x27;&#x27;)&quot; &gt; activate_path.txt            &#x27;&#x27;&#x27;        &#125;    &#125;&#125;\n\n\nWindows特定的测试执行：\n\nbat &#x27;&#x27;&#x27;    echo Starting unit tests on Windows...    set /p ACTIVATE_PATH=&lt;activate_path.txt    call &quot;%ACTIVATE_PATH%&quot; envPy3.12    python --version    python -m pytest &#x27;&#x27;&#x27; + params.TEST_TARGET + &#x27;&#x27;&#x27; -v -s --alluredir=allure-results&#x27;&#x27;&#x27;\n\n\nWindows特定的文件操作：\n\n// Linux中sh &#x27;rm -rf allure-results&#x27;// Windows中bat &#x27;if exist allure-results rmdir /s /q allure-results&#x27;\n\n流水线高级特性错开触发时间为避免同时触发两个流水线导致资源竞争，我们错开了SCM轮询时间：\n// Linux流水线pollSCM(&#x27;1-59/2 * * * *&#x27;)  // 奇数分钟触发// Windows流水线pollSCM(&#x27;H/2 * * * *&#x27;)     // 每两分钟触发一次，时间由Jenkins决定\n\n构建选项两个流水线都配置了相同的构建选项：\noptions &#123;    // 保留构建日志的策略    buildDiscarder(logRotator(numToKeepStr: &#x27;100&#x27;, artifactNumToKeepStr: &#x27;50&#x27;))    // 超时处理    timeout(time: 60, unit: &#x27;MINUTES&#x27;)    // 跳过默认的 checkout    skipDefaultCheckout(false)    // 时间戳    timestamps()&#125;\n\n构建后操作根据构建结果执行不同的操作：\npost &#123;    success &#123;        echo &quot;Unit tests executed successfully! All test cases passed.&quot;    &#125;    unstable &#123;        echo &quot;Unit tests completed, but some test cases failed. Please check the test report.&quot;    &#125;    failure &#123;        echo &quot;Unit test execution failed. Please check build logs and test reports.&quot;    &#125;    always &#123;        // 清理临时文件    &#125;&#125;\n\n最佳实践与经验总结\n平台特定代码隔离：将平台特定的命令和路径处理隔离在各自的流水线中\n统一测试报告：使用Allure等工具统一不同平台的测试报告格式\n错开触发时间：避免资源竞争\n优雅处理失败：即使测试失败也生成报告，方便排查问题\n清晰的构建命名：包含平台、分支和提交信息，便于快速识别\n环境变量管理：使用环境变量传递信息，避免重复计算\n\n常见问题及解决方案在WSL环境中使用Jenkins时，可能会遇到一些网络或权限相关的问题。例如，在WSL命令行中无法下载agent.jar文件：\ncurl.exe -sO http://127.0.0.1:8081/jnlpJars/agent.jar  # 无法下载\n\n这种情况可能是由于WSL的网络配置问题导致的，可以尝试从Windows下载后复制到WSL环境。\n结论通过使用Jenkins和Jenkinsfile创建跨平台测试流水线，我们可以：\n\n自动化测试在不同平台上的执行\n快速发现平台特定的兼容性问题\n提高代码质量和可靠性\n加速开发和发布周期\n\n这种方法特别适合需要在多个平台上运行的应用程序，如跨平台桌面应用、库或框架。通过持续集成和自动化测试，开发团队可以更加专注于功能开发，同时保持高质量的代码库。\n","categories":["技术","Jenkins"],"tags":["Jenkins","AI"]},{"title":"Android基础教程","url":"/posts/2025/04/12/45353/","content":"视频学习教程视频链接：2022 最新 Android 基础教程，从开发入门到项目实战，看它就够了，更新中_哔哩哔哩_bilibili\n学习下来，有遇到很多问题，在 chatgpt、claude 和 Android Studio 插件通义千问的帮助下，一一解决。\n目前还是有很多不懂的，虽然学了一遍，敲了一遍，但是 Android 体系还是太多，需要不断地学习。\nGitee 地址Magnolia&#x2F;AndroidLearning\n\n下面是一些记录。\n资源IDs 变成 non-finalResource IDs will be non-final by default in Android Gradle Plugin version 8.0, avoid using them in switch case statements.\n在 Android Gradle Plugin 8.0 中，资源 ID 默认变为 non-final，意思是它们不再是编译时常量，而是动态生成的。这是因为 Android 的资源 ID 现在默认使用了新的构建优化方式，使得每次构建时资源 ID 可能发生变化，从而减少了重编译时间，但也带来了以下变化：\n解释 non-final\n\n原本的 final 行为：在 Android Gradle Plugin 8.0 之前，资源 ID（如 R.id.example_button）被编译成 final 常量（不可变的静态值），因此可以直接用于 switch 语句，因为编译器在编译时可以确定它们的值。\nnon-final 意味着动态生成：从 8.0 开始，资源 ID 不再是 final 的。它们的值在每次构建时可能会动态生成，无法在编译时确定。因此，在 switch 语句中使用这些非固定值会导致编译错误，因为 switch 语句要求常量。\n\n影响和替代方案\n由于资源 ID 变为 non-final，在 Android Gradle Plugin 8.0+ 中，不能在 switch 语句中使用它们。可以使用 if-else 结构来替代 switch。\n变量声明为 final将变量声明为 final 有以下好处：\n\n不可变性：确保该变量在初始化后不能被修改，提高代码的安全性和可预测性。\n线程安全：在多线程环境中，final 变量可以避免多个线程同时修改同一个变量带来的问题。\n优化：编译器可以对 final 变量进行一些优化，提高性能。\n\nprivate String mRequest = &quot;你好，在吗？&quot;;// 可以写成:private final String mRequest = &quot;你好，在吗？&quot;;\n\n\n\noverride 注解@Override 注解在 Java 中用于表示一个方法是在重写父类或实现接口中的方法。使用 @Override 有以下几个好处：\n\n提高可读性：明确告知其他开发者这个方法是一个重写的方法。\n编译器检查：如果方法签名与父类或接口中的方法不匹配，编译器会报错，帮助开发者发现潜在的错误。\n\n如果不加 @Override 注解，代码仍然可以正常编译和运行，但会有以下问题：\n\n缺乏明确性：其他开发者阅读代码时可能不清楚这个方法是否是重写的。\n潜在错误：如果方法签名写错了（例如拼写错误或参数类型不匹配），编译器不会报错，但方法不会被正确调用，导致难以调试的问题。\n\n.9.png在 Android 开发中，.9.png 是一种特殊的图片格式，称为 Nine-Patch (九宫格) 图片。这种格式的图片在 .png 图片基础上做了特殊处理，主要用于实现拉伸和缩放效果，适应不同尺寸的屏幕和控件。\n特点与用途\n\n灵活拉伸：Nine-Patch 图片可以指定哪些区域可被拉伸，哪些区域保持不变。这对于按钮、对话框背景等需要根据内容大小动态调整的控件非常有用。\n边界标记：Nine-Patch 图片的边界上有一像素宽的黑色线条，Android 会根据这些标记确定哪些部分可以拉伸，哪些部分保持原样。具体来说：\n左侧和上侧边界：定义图片可以被拉伸的区域。\n右侧和下侧边界：定义内容显示区域。\n\n\n高效适配：Nine-Patch 图片在适应不同分辨率和屏幕尺寸时，不会失真或模糊，提供较好的视觉效果。适合用于各种弹窗、输入框背景、气泡等需要拉伸的图形背景。\n\n示例应用\n\n按钮背景、输入框背景、对话框背景等需要根据内容大小动态变化的 UI 元素。\n\n创建方法\nNine-Patch 图片可以通过 Android Studio 的 Draw 9-Patch 工具制作，或直接在图片上手动添加一像素的黑色边界。Android 会根据这些边界像素的标记进行渲染处理。\nNine-Patch 图片通过简单的标记，能以更小的资源量适配不同屏幕，是一种高效的图片处理方式。\n复合按钮由复合按钮 CompoundButton 派生而来的控件包括：CheckBox，RadioButton，Switch。\n导入 Nullableimport androidx.annotation.Nullable; \n作用是导入 Nullable 注解。这个注解来自 AndroidX 库，用于标记方法参数、返回值或字段，表示它们可以为 null。\n\n代码可读性：提高代码的可读性和维护性，明确指出某个变量或参数可以为 null。\n静态分析：帮助 IDE 和静态代码分析工具进行更准确的检查，减少潜在的空指针异常。\n\n示例\n@Nullablepublic String getName() &#123;    return name;&#125;\n\n\n在这个示例中，@Nullable 注解表明 getName 方法的返回值可以为 null。\nBoolean 与 booleanBoolean married = ck_married.isChecked(); boolean married = ck_married.isChecked(); 这两种写法有什么区别？\n\n\nBoolean married = ck_married.isChecked();\n\n类型：Boolean 是 boolean 的包装类。\n值：可以为 true、false 或 null。\n使用场景：适用于需要表示 null 值的情况，例如在集合中存储布尔值或处理可能为 null 的返回值。\n\n\nboolean married = ck_married.isChecked();\n\n类型：boolean 是基本数据类型。\n值：只能为 true 或 false。\n使用场景：适用于不需要表示 null 值的情况，性能更好，占用内存更少。\n\n\n\n在代码中：\n\n**Boolean married = ck_married.isChecked();**：这里 married 变量可以为 true、false 或 null。但由于 isChecked() 方法总是返回 true 或 false，所以 married 不会为 null。\n**boolean married = ck_married.isChecked();**：这里 married 变量只能为 true 或 false，更符合实际需求，因为 isChecked() 方法不会返回 null。\n\n推荐做法\n在大多数情况下，特别是当你确定变量不会为 null 时，推荐使用基本数据类型 boolean，因为它更高效且占用内存更少。\nboolean married = ck_married.isChecked();\n\n总结\n\n**Boolean**：包装类，可以为 null。\n**boolean**：基本数据类型，不能为 null。\n推荐：在不需要表示 null 值的情况下，使用 boolean。\n\n参数化查询和静态查询参数化查询\nString sql = &quot;select * from &quot; + TABLE_NAME + &quot; where phone=? and remember=1&quot;;Cursor cursor = mRDB.rawQuery(sql, new String[]&#123;phone&#125;);\n\n\n\nSQL 查询：\n\nselect * from &lt;TABLE_NAME&gt; where phone=? and remember=1：这条 SQL 语句从表中选择所有列，条件是 phone 等于某个值且 remember 等于 1。\n? 是一个占位符，用于防止 SQL 注入攻击。\n\n\n参数化查询：\n\nnew String[]&#123;phone&#125;：这是一个字符串数组，包含一个元素 phone。这个数组中的值会替换 SQL 语句中的 ? 占位符。\n例如，如果 phone 的值是 &quot;1234567890&quot;，那么最终的 SQL 语句会变成 select * from &lt;TABLE_NAME&gt; where phone=&#39;1234567890&#39; and remember=1。\n\n\n\n静态查询\nString sql = &quot;select * from &quot; + TABLE_NAME + &quot; where remember=1 order by _id desc limit 1&quot;;Cursor cursor = mRDB.rawQuery(sql, null);\n\n\n\nSQL 查询：\n\nselect * from &lt;TABLE_NAME&gt; where remember=1 order by _id desc limit 1：这条 SQL 语句从表中选择所有列，条件是 remember 等于 1，并按 _id 列降序排列，只取第一行。\n没有使用占位符 ?，因为查询条件中没有动态参数。\n\n\n参数化查询：\n\nnull：表示没有参数需要传递给 SQL 语句。\n\n\n\n为什么前者多了 new String[]&#123;phone&#125;\n\n参数化查询：new String[]&#123;phone&#125; 用于传递动态参数 phone 给 SQL 语句中的占位符 ?。这样做可以防止 SQL 注入攻击，提高安全性。\n静态查询：第二段代码没有动态参数，因此不需要传递参数数组，直接使用 null 即可。\n\n总结\n\n第一段代码：使用参数化查询，动态传递 phone 参数。\n第二段代码：使用静态查询，没有动态参数。\n\n\nandroid.intent.action.VIEW &quot;android.intent.action.VIEW&quot; 或者 &quot;android.intent.action.ACTION_VIEW&quot; 都可以\nIntent intent = new Intent(Intent.ACTION_VIEW);\n\n&lt;activity    android:name=&quot;.ThirdActivity&quot;    android:exported=&quot;false&quot;    tools:ignore=&quot;AppLinkUrlError&quot;&gt;    &lt;intent-filter&gt;        &lt;action android:name=&quot;android.intent.action.ACTION_VIEW&quot; /&gt;        &lt;category android:name=&quot;android.intent.category.DEFAULT&quot; /&gt;        &lt;data android:scheme=&quot;http&quot; /&gt;    &lt;/intent-filter&gt;&lt;/activity&gt;\n\n简要解释原因\n在 Android 中，Intent 的 action 属性用于指定操作类型。&quot;android.intent.action.VIEW&quot; 和 &quot;android.intent.action.ACTION_VIEW&quot; 实际上是同一个常量的不同表示形式。\n\n**&quot;android.intent.action.VIEW&quot;**：这是直接使用字符串形式的 action 名称。\n**&quot;android.intent.action.ACTION_VIEW&quot;**：这是通过 Intent 类中的静态常量 Intent.ACTION_VIEW 来引用的。\n\n这两种方式在功能上是等价的，因为它们都指向同一个标准的 Android 操作名称 &quot;android.intent.action.VIEW&quot;。\n分点描述\n\n字符串形式 vs 常量形式：\n\n使用字符串形式（如 &quot;android.intent.action.VIEW&quot;）时，代码更直观，但容易出现拼写错误。\n使用常量形式（如 Intent.ACTION_VIEW）时，代码更安全，编译器可以进行类型检查和自动补全，减少错误。\n\n\n推荐使用常量形式：\n\n使用常量形式可以提高代码的可读性和维护性。\n编译器可以在编译时检查常量的有效性，避免运行时错误。\n\n\n\n示例代码\n在 AndroidManifest.xml 中使用常量形式\n&lt;activity    android:name=&quot;.ThirdActivity&quot;    android:exported=&quot;false&quot;    tools:ignore=&quot;AppLinkUrlError&quot;&gt;    &lt;intent-filter&gt;        &lt;action android:name=&quot;android.intent.action.VIEW&quot; /&gt;        &lt;!-- 或者使用 --&gt;        &lt;action android:name=&quot;android.intent.action.ACTION_VIEW&quot; /&gt;        &lt;category android:name=&quot;android.intent.category.DEFAULT&quot; /&gt;        &lt;data android:scheme=&quot;http&quot; /&gt;    &lt;/intent-filter&gt;&lt;/activity&gt;\n\n在 Java 代码中使用常量形式\nelse if (v.getId() == R.id.btn_jump2web) &#123;    Intent intent = new Intent(Intent.ACTION_VIEW);    intent.setData(Uri.parse(&quot;http://www.baidu.com&quot;));    startActivity(intent);&#125;\n\n虽然 &quot;android.intent.action.VIEW&quot; 和 &quot;android.intent.action.ACTION_VIEW&quot; 都可以正常工作，但建议使用常量形式 Intent.ACTION_VIEW，以提高代码的安全性和可维护性。\n\nBug记录购物车数目只更新一次private void addToCart(int goodsId, String goodsName) &#123;    int goodsCount = MyApplication.getInstance().goodsCount;    ++goodsCount;    tv_count.setText(String.valueOf(goodsCount));    mDBHelper.insertCardInfo(goodsId);    ToastUtil.show(this, &quot;已添加一件&quot; + goodsName + &quot;到购物车&quot;);&#125;\n\n原因：仅对局部变量 goodsCount 进行自增操作，此时MyApplication.getInstance().goodsCount的值并没有被修改，首次操作时， goodsCount 加一了，所以购物车数目会加一。但是，后面再添加就不会更新，因为每次获取的 goodsCount 都是一样的值，tv_count 更新也都是第一次更新的数字。\n先对MyApplication.getInstance().goodsCount进行自增操作，然后将自增后的结果赋值给goodsCount，确保MyApplication.getInstance().goodsCount 和UI显示同步更新。\nprivate void addToCart(int goodsId, String goodsName) &#123;    int goodsCount = ++MyApplication.getInstance().goodsCount;    tv_count.setText(String.valueOf(goodsCount));    mDBHelper.insertCardInfo(goodsId);    ToastUtil.show(this, &quot;已添加一件&quot; + goodsName + &quot;到购物车&quot;);&#125;\n\n\n问题处理Run后模拟器未启动app可能的原因或者解决方法\n\n模拟器是否多开，在另一个中启动\n\n重启模拟器，清除模拟器数据（wipe data）后重启\n\nadb devices 查看状态\n如果是 unauthorized，尝试 adb kill-server, adb start-server，设置 cold boot 启动\n\n查看 AndroidManifest.xml  是否配置正确\n\n\n模拟器进程被占用\nAVD Pixel_2_API_31 is already running. If that is not the case, delete the files at D:\\software\\Android.android\\avd&#x2F;Pixel_2_API_31.avd&#x2F;*.lock and try again.\n\ntaskkill /F /IM qemu-system-* /IM emulator-* /IM adb.exedel /F /Q D:\\software\\Android\\.android\\avd\\Pixel_2_API_31.avd\\*.lock\n\n使用 procexp.exe 找到并结束进程。\n\n记录AndroidStudio 中， debug 运行代码，生成包 build/intermediates/apk/debug/chapter06-debug.apk \n","categories":["技术","Android"],"tags":["Android"]},{"title":"Cursor 的 MCP 应用：playwright-mcp-server","url":"/posts/2025/12/21/8980/","content":"Playwright 简介Playwright 是由 Microsoft 开发的现代化端到端测试和网页自动化框架。它允许开发者通过代码控制浏览器，模拟用户操作，实现自动化测试、网页爬取、数据采集等任务。\n核心特性\n\n跨浏览器支持\n支持 Chromium、Firefox、WebKit（Safari）\n统一的 API，一套代码多浏览器运行\n\n\n强大的自动化能力\n页面导航和元素交互（点击、输入、滚动）\n截图和录屏\n网络拦截和模拟\n文件上传下载\n\n\n现代化设计\n自动等待机制，减少不稳定的测试\n支持多页面、多标签、iframe 操作\n移动设备模拟\n异步操作友好\n\n\n\n典型应用场景\n\n自动化测试：回归测试、UI 测试\n网页爬虫：动态页面数据采集、信息监控\n任务自动化：表单填写、报表生成、批量操作\n屏幕截图：网页快照、可视化回归测试\n性能监控：页面加载时间、资源分析\n\n基本工作流程\n1. 启动浏览器 → 2. 打开页面 → 3. 定位元素 → 4. 执行操作 → 5. 获取结果\n\n与 MCP 的集成价值通过 MCP（Model Context Protocol），Playwright 可以被 AI 助手（如 cursor）直接调用，实现：\n\n自然语言控制浏览器：用对话方式描述需求，AI 自动生成并执行 Playwright 脚本\n智能化自动化：AI 理解页面结构，自适应不同网站布局\n实时反馈循环：根据执行结果动态调整操作策略\n\n这使得复杂的浏览器自动化任务变得更加直观和易用，非技术人员也能通过自然语言完成高级的网页操作。\ncursor 配置github：microsoft&#x2F;playwright-mcp: Playwright MCP server\nTools &amp; MCP - Installed MCP Servers，配置 mcp.json。\n安装方式\n\n方式一：如果当前环境中安装了 npx（需要安装 Nodejs），只要直接配置 mcp.json\n方式二：参考 Playwright MCP server 的 README 文档进行配置（点击 cursor，浏览器会自动弹出启动 cursor 并安装 playwright mcp服务安装）。\n区别：  以上两种方式最终都是使用 npx 来执行，而 npx 的机制是：1. 检查本地是否有该包2. 如果没有，临时下载到 npx 缓存目录3. 执行完毕后，包保留在缓存中（不是全局安装）npx 缓存位置：# macOS/Linux~/.npm/_npx/# Windows%LOCALAPPDATA%\\npm-cache\\_npx\\\n\nmcp.json\n&#123;  &quot;mcpServers&quot;: &#123;    &quot;playwright&quot;: &#123;      &quot;command&quot;: &quot;npx&quot;,      &quot;args&quot;: [        &quot;@playwright/mcp@latest&quot;      ]    &#125;  &#125;&#125;\n\n案例实践prompt 中最好指定要调用 mcp\n请使用 Playwright mcp 帮我完成：1. 打开浏览器访问 https://github.com/trending2. 等待页面完全加载3. 截取页面截图4. 提取前 10 个趋势项目的以下信息：   - 项目名称（仓库名）   - 项目描述   - Star 数量   - 今日新增 Star 数   - 编程语言   - 项目 URL5. 将获取的信息，写入 txt 文件\n\n\n\n","categories":["生产力","工具"],"tags":["Cursor","Playwright"]},{"title":"Chocolatey","url":"/posts/2025/04/19/29956/","content":"安装Chocolatey Software | Installing Chocolatey\n管理员权限打开 Windows PowerShell，\n\nRun Get-ExecutionPolicy. If it returns Restricted, then run Set-ExecutionPolicy AllSigned or Set-ExecutionPolicy Bypass -Scope Process.\nPS C:\\Users\\magnolia&gt; Get-ExecutionPolicyBypass\n\n输入：\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(&#x27;https://community.chocolatey.org/install.ps1&#x27;))\n\n版本：\nchoco -v2.4.3\n\n使用安装软件的路径：C:\\ProgramData\\chocolatey\\lib\n\njava：choco install jdk8\ngolang： choco install golang\n\n指定安装路径\nchoco install golang --install-args=&quot;/DIR=D:\\software\\golang&quot;\n","categories":["生产力","工具"],"tags":["tools"]},{"title":"Cursor 的 MCP 应用：mysql-mcp-server","url":"/posts/2025/12/20/53525/","content":"插件 MySQL侧边栏：Explorer，Search，Source Control，Run and Debug，Extensions，Service，Database\n在 Extensions 中搜索安装 MySQL，连接数据库。\nMCP 应用 mysql-mcp-server安装 uvx 工具# 在自己的 python 环境中pip install uvuvx --version# uvx 0.9.18 (0cee76417 2025-12-16)\n\n配置cursorGeneral - Tools&amp; MCP，Add Custom MCP，\ngithub：designcomputer&#x2F;mysql_mcp_server: A Model Context Protocol (MCP) server that enables secure interaction with MySQL databases，\n拷贝 With Visual Studio Code 中的配置（这里用到了 uvx），替换自己的环境信息（我在本地的 WSL2 中配置了一个 mysql 数据库），并适配 cursor（将 “servers” 字段改成 cursor 要求的 “mcpServers”，由于我的 uvx 是通过 Python 虚拟环境安装，所以要用绝对路径）：\n&#123;  &quot;mcpServers&quot;: &#123;      &quot;mysql&quot;: &#123;            &quot;type&quot;: &quot;stdio&quot;,            &quot;command&quot;: &quot;D:\\\\software\\\\miniforge3\\\\envs\\\\envPython3.12\\\\Scripts\\\\uvx.exe&quot;,            &quot;args&quot;: [                &quot;--from&quot;,                &quot;mysql-mcp-server&quot;,                &quot;mysql_mcp_server&quot;            ],      &quot;env&quot;: &#123;        &quot;MYSQL_HOST&quot;: &quot;localhost&quot;,        &quot;MYSQL_PORT&quot;: &quot;3306&quot;,        &quot;MYSQL_USER&quot;: &quot;root&quot;,        &quot;MYSQL_PASSWORD&quot;: &quot;admin123.&quot;,        &quot;MYSQL_DATABASE&quot;: &quot;test_track&quot;      &#125;    &#125;  &#125;&#125;\n\n配置保存后，在 Tools - Installed MCP Servers 界面，可以看到小绿点，表示已经连通正常能使用了。\n注意：点击 execute_sql，在点击 show less，此时可以看到有一个 1 tools，表示启用了 mcp 服务工具。\n\n最后，在 chat 框中，切换为 Agent 模式，通过自然语言对话，指定连接的 mysql数据库，就可以让它给我进行数据库操作，例如根据 Flask 框架中的 models.py 中的模型类，在数据库中创建对应的数据库表，并生成随机数据。\n","categories":["生产力","工具"],"tags":["Cursor"]},{"title":"GitLab Pages 托管静态网站","url":"/posts/2025/03/02/46741/","content":"曾经用 Github Pages 来托管博客内容，但是有一些不足：\n\n在不科学上网的情况下，是没法访问的，或者访问速度非常慢\n代码仓库必须是公开的，如果设置为私有，得另外配置很多东西\n\n\n新建项目这里的 Project name 一定要写成 xxxx.gitlab.io，这样后面形成的部署地址会很简洁，不然会有些麻烦（生成含有随机字数和字母的链接，或者链接有二级地址，显的很长）。\n\n配置博客修改博客工程的配置文件 _config.yml\ndeploy:  type: git  repo: git@gitlab.com:username/username.gitlab.io.git  branch: main\n\n部署博客\nhexo cleanhexo ghexo d\n\n添加 .gitlab-ci.ymlGitlab Pages 的运行和 Github 还不一样，它是通过 pipeline 执行 job 来部署。\n所以要在新建的项目中添加一个 .gitalb-ci.yml，在上一步配置部署博客地址后，第一步中新建的项目中，应该可以看到我本地提交的代码或者文件等。\n# The Docker image that will be used to build your appdefault:  image: ruby:3.2  # defaultpages:  stage: deploy  script:    - mkdir .public    - cp -r ./* .public    - rm -rf public    - mv .public public  artifacts:    paths:      - public  rules:    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n新建  .gitalb-ci.yml 后，会自动触发 pipeline，正常情况下，执行通过。\n\n进入 Deploy-Pages，点击 pages 链接，访问我部署的博客。\n\n其他配置转到 Settings &gt; Repository &gt; Protected branches。\n查看 main 分支是否被保护。如果是，开启“Allowed to force push”。\n\n展示：Magnolia’s Blog\n","categories":["生产力","工具"],"tags":["gitlab"]},{"title":"Docker 从入门到掌握，必知必会","url":"/posts/2025/12/10/19377/","content":"Docker 从入门到掌握：我的实战指南合集分享一下我在 Docker 学习过程中整理的一系列实战指南。\n记得刚开始接触 Docker 时，我被各种概念搞得一头雾水。什么镜像、容器、Dockerfile、Volume、网络…看起来每个都很重要，但又不知道它们之间是如何配合工作的。\n经过学习和实践，我就把自己在学习和使用 Docker 过程中的心得体会整理成了这一系列文档，涵盖了从基础操作到高级应用的方方面面。\n文档源码链接：Docker 操作指导，有任何问题或建议，欢迎随时交流讨论，有问题必改。\n\n主要内容\nDocker 基础操作：包括容器管理、镜像操作、Docker Compose 使用等日常必备技能\n构建自己的镜像：如何从零开始创建自己的 Docker 镜像，包括 commit 方式和 Dockerfile 方式\nDockerfile 实战：深入讲解如何编写高质量的 Dockerfile，包括多阶段构建、参数化等高级技巧\n镜像上传与管理：如何把自己的镜像分享给他人，以及如何使用各种镜像仓库\n数据持久化存储：解决容器数据易失性问题，让你的数据安全无忧\nDocker 网络管理：掌握容器间通信的秘密，构建复杂的多容器应用\n解决实际问题：比如如何解决 Node.js 的 GLIBC 依赖问题等\n\n按照以下路径来学习\n先从《Docker 必会操作》开始，了解基本命令\n然后学习《构建自己的镜像》和《Dockerfile 实战》，掌握镜像制作\n接着看《Docker 上传镜像》，学会分享你的成果\n《Docker 数据持久化存储》和《Docker 网络》是进阶内容，可以帮你解决实际问题\n最后，《解决 Node.js 依赖问题》这类专项指南可以帮助你应对特定场景\n\n每个指南的重点内容《Docker 必会操作》：\n\n容器的启动、停止、删除等基本操作\n镜像的查看和删除\nDocker Compose 的使用方法\n常见故障排查技巧\n\n《构建自己的镜像》：\n\ncommit 方式快速构建镜像\n镜像分层机制的理解\n镜像标签管理的最佳实践\n\n《Dockerfile 实战》：\n\nDockerfile 编写规范和技巧\n多阶段构建优化镜像大小\n健康检查和参数化构建\n\n《Docker 上传镜像》：\n\nDocker Hub 的使用方法\n私有仓库的搭建和配置\n镜像版本管理策略\n\n《Docker 数据持久化存储》：\n\nVolume、Bind Mount、tmpfs 三种方式的区别和使用场景\n数据备份和恢复方法\n容器间数据共享技巧\n\n《Docker 网络》：\n\n四种网络模式详解\n容器间通信方案\n复杂应用的网络架构设计\n\n《解决 Node.js 依赖问题》：\n\n使用 Docker 解决 GLIBC 版本兼容问题\n实用的容器化部署方案\n\n","categories":["技术","Docker"],"tags":["Docker"]},{"title":"Python包导入的最佳实践","url":"/posts/2025/02/15/43653/","content":"案例分析案例在 python 工程中，有一个包 log，里面是一个 log_util.py 文件，它里面写了一个 LogUtils 类，同时 log 目录下有一个 __init__ 文件：\nfrom .log_util import LogUtils__all__ = [&#x27;LogUtils&#x27; ]\n\n从其他py文件中有两种方式可以 import 这个类：\nfrom my_test_prj.common.log import LogUtils from my_test_prj.common.log.log_util import LogUtils\n\n这两种方式有啥区别吗，哪种更好？\n分析第一种方式：from my_test_prj.common.log import LogUtils \n\n优点：\n更简洁，符合使用__init__.py的设计意图\n隐藏了内部实现细节，用户不需要知道LogUtils实际定义在哪个文件中\n如果LogUtils将来被移到包内的另一个文件，只需更新__init__.py，使用这种导入方式的代码不需要修改\n\n\n推荐原因：\n这是Python包设计的最佳实践，通过__init__.py公开API\n\n\n\n第二种方式：from my_test_prj.common.log.log_util import LogUtils\n\n特点：\n直接从定义文件导入，绕过了__init__.py\n更明确地指出了类的实际位置\n如果实现文件发生变化，所有使用这种导入方式的代码都需要更新\n\n\n\n建议使用第一种方式，因为：\n\n它遵循了Python包设计的最佳实践\n它提供了更好的封装性，隐藏内部结构\n它使代码更容易维护，特别是当内部实现变化时\n既然你已经在__init__.py中明确导出了LogUtils，就应该利用这个设计\n\n除非你有特殊需求（比如需要同时导入log_util模块中的其他未在__init__.py中导出的内容），否则第一种方式通常是更好的选择。\nPython包结构基础在Python中，我们通常将代码组织成模块(module)和包(package)。模块是一个Python文件(.py)，而包是一个包含多个模块的目录，其中必须包含一个特殊的__init__.py文件。\n一个典型的Python包结构可能如下:\nmypackage/│├── __init__.py├── module1.py├── module2.py└── subpackage/    ├── __init__.py    └── module3.py\n\n\n\n导入方式对比与选择假设在上面的包结构中，module1.py中定义了一个MyClass类，且这个类已经在__init__.py中被导出，那么我们可以有两种导入方式:\n方式一: 通过包直接导入\nfrom mypackage import MyClass\n\n方式二: 从具体模块导入\nfrom mypackage.module1 import MyClass\n\n对比分析：\n\n\n\n特性\n方式1\n方式2\n\n\n\n简洁性\n✓ 更简洁\n较详细\n\n\n封装性\n✓ 隐藏实现细节\n暴露实现文件\n\n\n维护性\n✓ 实现变更时无需修改导入代码\n实现变更时需修改导入代码\n\n\n明确性\n不直接显示类的位置\n✓ 清晰显示类的定义位置\n\n\n__init__.py的作用与重要性__init__.py文件是Python包机制的核心，它有以下几个重要作用：\n\n标识目录为Python包\n空的__init__.py文件也能使Python将目录视为包。\n\n包的初始化代码\n当包被导入时，__init__.py中的代码会被执行。\n\n定义包的公共API\n通过在__init__.py中导入并重新导出模块内的内容，可以定义包的公共接口。\n# mypackage/__init__.pyfrom .module1 import MyClass, my_functionfrom .module2 import AnotherClass__all__ = [&#x27;MyClass&#x27;, &#x27;my_function&#x27;, &#x27;AnotherClass&#x27;]\n\n控制导入的命名空间\n使用__all__变量可以明确定义当其他模块使用from package import *语法时，哪些名称会被导入，对包公共API的有了精确控制。\n\n如果没有定义__all__，则import *会导入所有不以下划线开头的名称\n定义了__all__后，只有列表中指定的名称会被导入\n这是一种显式声明包公共接口的方式，提高了代码可读性和可维护性\n\n\n包的精确控制\n如果不写 __all__ = [&quot;xxx&quot;] \n# __init__.pyfrom .module1 import MyClass\n\n这样写的效果取决于其他模块如何导入你的包：\n如果其他人使用明确导入：\nfrom your_package import MyClass  # 这样没问题，可以工作\n\n如果其他人使用通配符导入：\nfrom your_package import *  # 注意：如果没有 __all__，这里不会导入 MyClass\n\n关键区别：\n\n不定义 __all__：只有模块级别的名称会被 import * 导入\n定义 __all__：明确控制哪些名称可以被 import * 导入\n\n所以最佳实践是：\n# __init__.pyfrom .module1 import MyClass__all__ = [&#x27;MyClass&#x27;]  # 建议保留这行\n\n包设计的最佳实践遵循封装原则\n\n隐藏实现细节\n只公开必要的API\n使用__init__.py作为包的”门面”\n\n明确定义公共API\n\n在__init__.py中使用__all__列表\n遵循命名约定，以下划线开头的名称通常表示私有\n\n版本兼容性考虑\n\n当内部实现变化时，保持公共API稳定\n使用导入重定向来维护向后兼容性\n\n避免循环导入\n\n设计良好的包层次结构\n必要时使用延迟导入(运行时导入)\n\n","categories":["技术","Python"],"tags":["Python"]},{"title":"Jenkins Pipeline Shell 脚本编写指南","url":"/posts/2025/10/19/38531/","content":"Jenkins Pipeline Shell 脚本编写指南目录\n1. 引言\n2. 单引号与双引号的核心区别\n3. 环境变量访问规则\n4. 实战案例分析\n5. 常见陷阱与解决方案\n6. 最佳实践\n7. 决策流程图\n\n\n1. 引言1.1 适用范围\nJenkins Pipeline (Declarative &amp; Scripted)\nLinux 平台（sh 命令）\nWindows 平台（bat 命令，原理相同）\n\n\n2. 单引号与双引号的核心区别2.1 单引号 &#39;&#39;&#39;...&#39;&#39;&#39;：Shell 直接执行特点：\n\nGroovy 不处理任何变量\n整个字符串原封不动传递给 Shell\nShell 负责解析所有 $&#123;&#125; 或 $ 语法\n\n示例：\nsh &#x27;&#x27;&#x27;    echo &quot;Test target: $&#123;FINAL_TEST_TARGET&#125;&quot;    echo &quot;Date: $(date +%Y-%m-%d)&quot;&#x27;&#x27;&#x27;\n\n执行流程：\nGroovy → [不处理] → Shell 接收原始字符串 → Shell 解析变量\n\n适用场景：\n\n✅ 纯 Shell 脚本逻辑\n✅ 使用 Shell 环境变量\n✅ 复杂的 Shell 语法（循环、条件、管道等）\n✅ 避免转义字符的困扰\n\n\n2.2 双引号 &quot;&quot;&quot;...&quot;&quot;&quot;：Groovy 先处理特点：\n\nGroovy 先替换所有 $&#123;...&#125; 变量\n替换后的字符串才传递给 Shell\n需要转义 Shell 变量（\\$&#123;VAR&#125; 或 \\$(command)）\n\n示例：\nsh &quot;&quot;&quot;    echo &quot;Branch: $&#123;env.TARGET_BRANCH&#125;&quot;    echo &quot;Build: $&#123;BUILD_NUMBER&#125;&quot;&quot;&quot;&quot;\n\n执行流程：\nGroovy → [替换变量] → Shell 接收已替换的字符串 → Shell 执行\n\n适用场景：\n\n✅ 需要 Jenkins 构建变量（BUILD_NUMBER, BUILD_URL 等）\n✅ 需要环境变量（env.*）\n✅ 需要 Pipeline 参数（params.*）\n✅ 需要 Groovy 变量\n\n\n2.3 对比示例假设环境：\n\nenv.TARGET_BRANCH = &quot;master&quot;\nBUILD_NUMBER = &quot;123&quot;\nShell 环境变量 TEST_VAR = &quot;hello&quot;\n\n单引号示例sh &#x27;&#x27;&#x27;    echo &quot;TEST_VAR: $&#123;TEST_VAR&#125;&quot;              # ✅ 输出: hello    echo &quot;BUILD_NUMBER: $&#123;BUILD_NUMBER&#125;&quot;      # ✅ 输出: 123 (Jenkins 导出)    echo &quot;TARGET_BRANCH: $&#123;env.TARGET_BRANCH&#125;&quot; # ❌ 输出: (空，Shell 没有 env 对象)&#x27;&#x27;&#x27;\n\n双引号示例sh &quot;&quot;&quot;    echo &quot;TEST_VAR: $&#123;TEST_VAR&#125;&quot;              # ❌ 输出: (空，Groovy 没有此变量)    echo &quot;BUILD_NUMBER: $&#123;BUILD_NUMBER&#125;&quot;      # ✅ 输出: 123    echo &quot;TARGET_BRANCH: $&#123;env.TARGET_BRANCH&#125;&quot; # ✅ 输出: master&quot;&quot;&quot;\n\n\n3. 环境变量访问规则3.1 在 Groovy Script 块中script &#123;    // ✅ 正确：使用 env. 前缀    echo &quot;Branch: $&#123;env.TARGET_BRANCH&#125;&quot;    echo &quot;Build: $&#123;env.BUILD_NUMBER&#125;&quot;        // ✅ 也可以不用 env（Jenkins 全局变量）    echo &quot;Build: $&#123;BUILD_NUMBER&#125;&quot;&#125;\n\n3.2 在 Shell 单引号中sh &#x27;&#x27;&#x27;    # ✅ 正确：直接使用变量名（无 env.）    echo &quot;Branch: $&#123;TARGET_BRANCH&#125;&quot;    echo &quot;Target: $&#123;FINAL_TEST_TARGET&#125;&quot;        # ❌ 错误：Shell 没有 env 对象    echo &quot;Branch: $&#123;env.TARGET_BRANCH&#125;&quot;&#x27;&#x27;&#x27;\n\n原因： Jenkins 会自动将 env.* 变量导出到 Shell 环境中，所以可以直接访问。\n3.3 在 Shell 双引号中sh &quot;&quot;&quot;    # ✅ 正确：Groovy 变量用 env.    echo &quot;Branch: $&#123;env.TARGET_BRANCH&#125;&quot;        # ✅ 正确：Shell 变量需转义    echo &quot;Shell var: \\$&#123;MY_VAR&#125;&quot;        # ✅ 正确：命令替换需转义    CURRENT_DATE=\\$(date +%Y-%m-%d)    echo &quot;Date: \\$&#123;CURRENT_DATE&#125;&quot;&quot;&quot;&quot;\n\n\n4. 实战案例分析4.1 案例：测试报告生成（双引号）stage(&#x27;Generate Test Results&#x27;) &#123;    steps &#123;        script &#123;            sh &quot;&quot;&quot;                conda activate vltenv                python ci/scripts/generate_test_summary.py \\\\                    --allure-dir allure-results \\\\                    --build-number $&#123;BUILD_NUMBER&#125; \\\\                    --branch $&#123;env.TARGET_BRANCH&#125; \\\\                    --test-target &quot;$&#123;env.FINAL_TEST_TARGET&#125;&quot;            &quot;&quot;&quot;        &#125;    &#125;&#125;\n\n为什么用双引号：\n\n需要 $&#123;BUILD_NUMBER&#125;（Jenkins 变量）\n需要 $&#123;env.TARGET_BRANCH&#125;（环境变量）\n需要 $&#123;env.FINAL_TEST_TARGET&#125;（环境变量）\n\n\n4.2 案例：路径验证（单引号）stage(&#x27;Validate Test Configuration&#x27;) &#123;    steps &#123;        script &#123;            sh &#x27;&#x27;&#x27;                if [ ! -e &quot;$&#123;FINAL_TEST_TARGET&#125;&quot; ]; then                    echo &quot;ERROR: Test target path does not exist&quot;                    exit 1                else                    echo &quot;✓ Test target path validation passed&quot;                fi            &#x27;&#x27;&#x27;        &#125;    &#125;&#125;\n\n为什么用单引号：\n\n使用 Shell 环境变量 $&#123;FINAL_TEST_TARGET&#125;\n纯 Shell 条件判断逻辑\n避免转义字符的麻烦\n\n\n4.3 案例：混合使用（双引号 + 转义）stage(&#x27;Run Tests&#x27;) &#123;    steps &#123;        script &#123;            sh &quot;&quot;&quot;                # Jenkins 变量（不转义）                echo &quot;Building branch: $&#123;env.TARGET_BRANCH&#125;&quot;                                # Shell 变量（转义）                for file in \\$(find $&#123;env.FINAL_TEST_TARGET&#125; -name &quot;*.py&quot;); do                    echo &quot;Testing: \\$&#123;file&#125;&quot;                    pytest \\$&#123;file&#125; --build-id $&#123;BUILD_NUMBER&#125;                done            &quot;&quot;&quot;        &#125;    &#125;&#125;\n\n关键点：\n\nJenkins 变量：$&#123;env.TARGET_BRANCH&#125; 不转义\nShell 变量：\\$&#123;file&#125; 需转义\nShell 命令：\\$(find ...) 需转义\n\n\n4.4 案例：延迟设置构建状态问题场景： 测试失败时，后续的报告生成和发送阶段被跳过。\n原因： 在测试阶段立即设置 currentBuild.result = &#39;UNSTABLE&#39;，触发了 skipStagesAfterUnstable() 选项。\n解决方案：\nstage(&#x27;Run Unit Tests&#x27;) &#123;    steps &#123;        script &#123;            def testResult = &#x27;SUCCESS&#x27;            try &#123;                sh &quot;&quot;&quot;                    pytest $&#123;env.FINAL_TEST_TARGET&#125;                &quot;&quot;&quot;                testResult = &#x27;SUCCESS&#x27;            &#125; catch (Exception e) &#123;                testResult = &#x27;UNSTABLE&#x27;                echo &quot;⚠️ Will continue to generate and send test reports...&quot;            &#125;                        // 保存结果，不立即设置构建状态            env.TEST_EXECUTION_RESULT = testResult        &#125;    &#125;&#125;stage(&#x27;Send Test Results&#x27;) &#123;    steps &#123;        script &#123;            def finalStatus = env.TEST_EXECUTION_RESULT ?: &#x27;SUCCESS&#x27;                        sh &quot;&quot;&quot;                python ci/scripts/send_test_results.py \\\\                    --build-status $&#123;finalStatus&#125;            &quot;&quot;&quot;                        // 发送通知后再设置构建状态            if (finalStatus == &#x27;UNSTABLE&#x27;) &#123;                currentBuild.result = &#x27;UNSTABLE&#x27;            &#125;        &#125;    &#125;&#125;options &#123;    // 移除此选项，允许 UNSTABLE 后继续执行    // skipStagesAfterUnstable()&#125;\n\n关键改进：\n\n不立即设置 currentBuild.result\n使用环境变量 env.TEST_EXECUTION_RESULT 保存状态\n移除 skipStagesAfterUnstable() 选项\n在发送通知后再设置构建状态\n\n\n5. 常见陷阱与解决方案5.1 陷阱：双引号中使用 Shell 变量❌ 错误写法：\nsh &quot;&quot;&quot;    MY_VAR=&quot;test&quot;    echo $&#123;MY_VAR&#125;  # Groovy 找不到 MY_VAR，输出为空&quot;&quot;&quot;\n\n✅ 正确写法：\nsh &quot;&quot;&quot;    MY_VAR=&quot;test&quot;    echo \\$&#123;MY_VAR&#125;  # 转义后，Shell 处理&quot;&quot;&quot;\n\n\n5.2 陷阱：单引号中使用 Jenkins 变量❌ 错误写法：\nsh &#x27;&#x27;&#x27;    echo $&#123;env.TARGET_BRANCH&#125;  # Shell 找不到 env 对象&#x27;&#x27;&#x27;\n\n✅ 解决方案 A：改用双引号\nsh &quot;&quot;&quot;    echo $&#123;env.TARGET_BRANCH&#125;  # Groovy 替换&quot;&quot;&quot;\n\n✅ 解决方案 B：先设置环境变量\nscript &#123;    env.MY_BRANCH = env.TARGET_BRANCH&#125;sh &#x27;&#x27;&#x27;    echo $&#123;MY_BRANCH&#125;  # Shell 使用环境变量&#x27;&#x27;&#x27;\n\n\n5.3 陷阱：Windows 路径中的反斜杠❌ 错误写法：\nbat &quot;&quot;&quot;    cd C:\\Users\\test   # \\U 和 \\t 被 Groovy 解析为转义字符&quot;&quot;&quot;\n\n✅ 解决方案 A：使用单引号\nbat &#x27;&#x27;&#x27;    cd C:\\Users\\test   # 单引号不处理转义&#x27;&#x27;&#x27;\n\n✅ 解决方案 B：双反斜杠\nbat &quot;&quot;&quot;    cd C:\\\\Users\\\\test  # 双反斜杠转义&quot;&quot;&quot;\n\n\n5.4 陷阱：命令替换被 Groovy 处理❌ 错误写法：\nsh &quot;&quot;&quot;    CURRENT_TIME=$(date +%H:%M:%S)  # Groovy 尝试执行 $(date)&quot;&quot;&quot;\n\n✅ 正确写法：\nsh &quot;&quot;&quot;    CURRENT_TIME=\\$(date +%H:%M:%S)  # 转义，让 Shell 处理&quot;&quot;&quot;\n\n\n5.5 陷阱：测试失败后跳过报告发送❌ 错误配置：\nstage(&#x27;Run Tests&#x27;) &#123;    steps &#123;        script &#123;            try &#123;                sh &quot;pytest&quot;            &#125; catch (Exception e) &#123;                currentBuild.result = &#x27;UNSTABLE&#x27;  // 立即设置状态            &#125;        &#125;    &#125;&#125;options &#123;    skipStagesAfterUnstable()  // 导致后续阶段被跳过&#125;\n\n✅ 正确配置：\nstage(&#x27;Run Tests&#x27;) &#123;    steps &#123;        script &#123;            try &#123;                sh &quot;pytest&quot;                env.TEST_RESULT = &#x27;SUCCESS&#x27;            &#125; catch (Exception e) &#123;                env.TEST_RESULT = &#x27;UNSTABLE&#x27;  // 只记录，不设置            &#125;        &#125;    &#125;&#125;stage(&#x27;Send Results&#x27;) &#123;    steps &#123;        script &#123;            sh &quot;send_notification.py --status $&#123;env.TEST_RESULT&#125;&quot;            // 发送后再设置构建状态            if (env.TEST_RESULT == &#x27;UNSTABLE&#x27;) &#123;                currentBuild.result = &#x27;UNSTABLE&#x27;            &#125;        &#125;    &#125;&#125;options &#123;    // 移除 skipStagesAfterUnstable()&#125;\n\n\n6. 最佳实践6.1 选择原则\n\n\n场景\n推荐引号\n原因\n\n\n\n需要 Jenkins 变量\n双引号 &quot;&quot;&quot;\n最常见，约 60-70%\n\n\n纯 Shell 命令\n单引号 &#39;&#39;&#39;\n避免转义麻烦\n\n\n两种变量都需要\n双引号 + 转义\n最灵活\n\n\n不确定\n双引号\n更安全，出错容易发现\n\n\n\n6.2 推荐模式模式 1：默认使用双引号sh &quot;&quot;&quot;    echo &quot;Branch: $&#123;env.TARGET_BRANCH&#125;&quot;    python test.py --build-id $&#123;BUILD_NUMBER&#125;&quot;&quot;&quot;\n\n优点：可以使用所有 Jenkins 变量，代码更清晰\n\n模式 2：简单命令用单引号sh &#x27;&#x27;&#x27;    rm -rf build/    mkdir -p dist/    ls -la&#x27;&#x27;&#x27;\n\n优点：不需要转义，适合纯 Shell 命令\n\n模式 3：复杂脚本写入文件writeFile file: &#x27;build.sh&#x27;, text: &#x27;&#x27;&#x27;    #!/bin/bash    set -e        # 复杂的 Shell 脚本    for i in &#123;1..10&#125;; do        echo &quot;Processing batch $&#123;i&#125;&quot;        ./process.sh $&#123;i&#125;    done&#x27;&#x27;&#x27;sh &#x27;chmod +x build.sh &amp;&amp; ./build.sh&#x27;\n\n优点：\n\n避免引号和转义问题\n脚本可以独立测试\n代码更易维护\n\n\n模式 4：环境变量传递（重要）script &#123;    // Groovy 层设置环境变量    env.TEST_DIR = env.FINAL_TEST_TARGET    env.BUILD_ID = BUILD_NUMBER&#125;sh &#x27;&#x27;&#x27;    # Shell 层直接使用    echo &quot;Testing directory: $&#123;TEST_DIR&#125;&quot;    pytest $&#123;TEST_DIR&#125; --id $&#123;BUILD_ID&#125;&#x27;&#x27;&#x27;\n\n优点：\n\n分离变量定义和使用\nShell 脚本更简洁\n\n\n6.3 编码规范1. 变量命名// 好的实践env.FINAL_TEST_TARGET = testTargetenv.TEST_EXECUTION_RESULT = testResult\n\n\n2. 长命令格式化Linux（反斜杠续行）：\nsh &quot;&quot;&quot;    python ci/scripts/send_results.py \\\\        --build-number $&#123;BUILD_NUMBER&#125; \\\\        --branch $&#123;env.TARGET_BRANCH&#125; \\\\        --recipients &quot;$&#123;params.NOTIFICATION_RECIPIENTS&#125;&quot;&quot;&quot;&quot;\n\nWindows（^ 续行）：\nbat &quot;&quot;&quot;    python ci/scripts/send_results.py ^        --build-number $&#123;BUILD_NUMBER&#125; ^        --branch $&#123;env.TARGET_BRANCH&#125; ^        --recipients &quot;$&#123;params.NOTIFICATION_RECIPIENTS&#125;&quot;&quot;&quot;&quot;\n\n\n3. 错误处理script &#123;    try &#123;        sh &quot;&quot;&quot;            python ci/scripts/generate_report.py \\\\                --output-dir test-results        &quot;&quot;&quot;                if (fileExists(&#x27;test-results/report.json&#x27;)) &#123;            echo &quot;✓ Report generated successfully&quot;            env.REPORT_AVAILABLE = &#x27;true&#x27;        &#125; else &#123;            echo &quot;⚠ Report file not found&quot;            env.REPORT_AVAILABLE = &#x27;false&#x27;        &#125;            &#125; catch (Exception e) &#123;        echo &quot;Failed to generate report: $&#123;e.message&#125;&quot;        env.REPORT_AVAILABLE = &#x27;false&#x27;    &#125;&#125;\n\n\n4. 条件执行stage(&#x27;Send Results&#x27;) &#123;    when &#123;        expression &#123;             params.SEND_RESULTS == true &amp;&amp;             env.REPORT_AVAILABLE == &#x27;true&#x27;         &#125;    &#125;    steps &#123;        sh &quot;&quot;&quot;            python ci/scripts/send_results.py \\\\                --report test-results/report.json        &quot;&quot;&quot;    &#125;&#125;\n\n\n6.4 性能优化避免重复激活环境❌ 低效写法：\nsh &quot;conda activate myenv &amp;&amp; python script1.py&quot;sh &quot;conda activate myenv &amp;&amp; python script2.py&quot;sh &quot;conda activate myenv &amp;&amp; python script3.py&quot;\n\n✅ 高效写法：\nsh &quot;&quot;&quot;    conda activate myenv    python script1.py    python script2.py    python script3.py&quot;&quot;&quot;\n\n\n合并相关命令❌ 低效写法：\nsh &quot;mkdir -p build&quot;sh &quot;cd build&quot;sh &quot;cmake ..&quot;sh &quot;make&quot;\n\n✅ 高效写法：\nsh &quot;&quot;&quot;    mkdir -p build    cd build    cmake ..    make&quot;&quot;&quot;\n\n\n7. 决策流程图开始编写 sh/bat 脚本        ↓问：是否需要 Jenkins 变量？（BUILD_NUMBER, env.*, params.* 等）        ↓    ┌───┴───┐    ↓       ↓   是      否    ↓       ↓使用双引号  问：是否有复杂 Shell 语法？  &quot;&quot;&quot;      （循环、条件、管道等）    ↓       ↓    │   ┌───┴───┐    │   ↓       ↓    │  是      否    │   ↓       ↓    │ 使用单引号  随意选择    │   &#x27;&#x27;&#x27;    （推荐双引号）    │   ↓       ↓    └───┴───────┘        ↓    完成编写\n\n\n8. 快速参考表8.1 变量访问速查\n\n\n上下文\nJenkins 变量\nShell 变量\n示例\n\n\n\nGroovy script\n$&#123;env.VAR&#125;\n❌ 不可用\necho &quot;$&#123;env.TARGET_BRANCH&#125;&quot;\n\n\nShell 单引号\n❌ 不可用\n$&#123;VAR&#125;\necho &quot;$&#123;FINAL_TEST_TARGET&#125;&quot;\n\n\nShell 双引号\n$&#123;env.VAR&#125;\n\\$&#123;VAR&#125;\necho &quot;$&#123;env.BRANCH&#125;&quot; \\$&#123;MY_VAR&#125;\n\n\n\n8.2 转义速查\n\n\n场景\n双引号中的写法\n说明\n\n\n\nJenkins 变量\n$&#123;env.VAR&#125;\n不转义\n\n\nShell 变量\n\\$&#123;VAR&#125;\n转义 $\n\n\n命令替换\n\\$(command)\n转义 $\n\n\n反斜杠（Windows）\nC:\\\\Users\n双反斜杠\n\n\n换行续行（Linux）\n\\\\\n双反斜杠\n\n\n换行续行（Windows）\n^\nWindows 专用\n\n\n\n8.3 常用命令模板Linux 平台// 激活 Conda 环境并执行sh &quot;&quot;&quot;    eval &quot;\\$(conda shell.bash hook 2&gt;/dev/null)&quot; &gt; /dev/null    conda activate myenv    python script.py&quot;&quot;&quot;// 条件判断sh &#x27;&#x27;&#x27;    if [ -f &quot;file.txt&quot; ]; then        echo &quot;File exists&quot;    fi&#x27;&#x27;&#x27;// 循环处理sh &#x27;&#x27;&#x27;    for file in $(find . -name &quot;*.py&quot;); do        echo &quot;Processing: $&#123;file&#125;&quot;    done&#x27;&#x27;&#x27;\n\nWindows 平台// 激活 Conda 环境并执行bat &quot;&quot;&quot;    @echo off    chcp 65001 &gt; nul    call conda activate myenv    python script.py&quot;&quot;&quot;// 条件判断bat &#x27;&#x27;&#x27;    @echo off    if exist file.txt (        echo File exists    )&#x27;&#x27;&#x27;// 设置编码bat &quot;&quot;&quot;    @echo off    chcp 65001 &gt; nul    set PYTHONIOENCODING=utf-8    python script.py&quot;&quot;&quot;\n\n\n9. 总结核心要点\n单引号 &#x3D; Shell 直接执行，适合纯 Shell 脚本\n双引号 &#x3D; Groovy 先处理，适合需要 Jenkins 变量\n实际项目中，双引号使用频率更高（约 60-70%）\n不确定时，优先选择双引号\n复杂脚本，考虑写入文件或使用环境变量传递\n\n记忆口诀单引号 → Shell 直接执行，Groovy 不插手双引号 → Groovy 先替换，Shell 后执行需转义 → 双引号里加 \\，Shell 变量留\n\n延伸阅读\nJenkins Pipeline 官方文档\nGroovy 字符串文档\nBash 脚本最佳实践\n\n 适用 Jenkins 版本： 2.x 及以上\n","categories":["技术","Jenkins"],"tags":["Jenkins"]},{"title":"Miniforge 管理 Python 虚拟环境","url":"/posts/2025/04/12/13174/","content":"Windows安装Miniforge官方GitHub仓库：https://github.com/conda-forge/miniforge/releases\n下载适用于Windows的最新版本安装程序(Miniforge3-Windows-x86_64.exe)\n验证：conda --version\n创建虚拟环境conda create -n myenv python=3.10\n\n\nmyenv 环境名称\npython=3.10指定Python版本\n\n常用命令# 查看所有环境conda list# 激活虚拟环境 conda activate myenv# 退出虚拟环境conda deactivate# 删除环境conda env remove -n myenv# 导出环境配置、从配置文件创建环境conda env export &gt; environment.ymlconda env create -f environment.yml# 复制环境(重命名环境)conda create -n new_name --clone old_nameconda env remove -n old_name\n\n\n\nLinux(CentOS)wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.shchmod +x Miniforge3-Linux-x86_64.sh./Miniforge3-Linux-x86_64.shsource ~/.bashrc\n\n\n\n换源查看当前配置：conda config --show\n编辑配置：vim ~/.condarc\nchannels:  - defaultsshow_channel_urls: truedefault_channels:  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/rcustom_channels:  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n\n","categories":["生产力","工具"],"tags":["tools"]},{"title":"SSH 密钥从 RSA 到 Ed25519","url":"/posts/2025/11/01/28740/","content":"问题背景最近帮几个同事排查 git clone 失败的问题，发现了一个有意思的现象。他们的报错信息都类似：\nPermission denied (publickey).fatal: Could not read from remote repository.\n\n一开始以为是网络问题、权限配置错了、生成sshkey时添加了密码，结果检查发现，这些同事的 .ssh 目录下都有密钥文件，但文件名多了两个，而且不是我们熟悉的 id_rsa 和 id_rsa.pub，而是 id_ed25519 和 id_ed25519.pub。\n更有意思的是，他们都说自己按照网上教程生成了 SSH 密钥，也把公钥添加到了 GitLab 上。把原来配置到 gitlab 上的公钥删除，将 id_rsa.pub 里的文本拷贝重新添加，还是会提示报错。\n这个问题其实挺典型的，反映了一个技术迁移期的常见困扰：工具的默认行为变了，但我们的认知还停留在过去。\n为什么会出现 Ed25519先说结论：这不是 bug，而是一种进步。\nSSH 密钥算法的变迁早些年，当运行 ssh-keygen 命令时，默认生成的是 RSA 算法的密钥对。RSA 是一种非常成熟的非对称加密算法，从 1977 年就开始使用了，安全性经过了时间的检验。\n但随着计算能力的提升和密码学研究的发展，RSA 也暴露出一些问题。比如为了保证安全性，RSA 密钥长度需要不断增加，现在通常推荐使用 2048 位甚至 4096 位。密钥越长，生成和验证的时间就越长。\nEd25519 是基于椭圆曲线密码学的一种算法，在 2011 年左右被提出。它的设计目标就是在保证安全性的同时，提供更好的性能。\n什么时候开始变化的OpenSSH 在较新的版本中开始推荐使用 Ed25519。具体来说：\n\nOpenSSH 6.5 版本（2014 年）开始支持 Ed25519\n一些 Linux 发行版和 macOS 的新版本中，ssh-keygen 的默认行为开始倾向于 Ed25519\nGit 官方文档和 GitHub 的帮助文档也开始推荐 Ed25519\n\n所以如果你最近重装了系统，或者升级了 Git 和 OpenSSH，很可能就会遇到这个变化。\nEd25519 到底是什么简单来说，Ed25519 是一种现代的公钥加密算法，专门为数字签名设计。\n技术层面的优势和 RSA 相比，Ed25519 有这些特点：\n安全性更高\nEd25519 使用 256 位的密钥长度，但提供的安全强度相当于 RSA 3072 位。这得益于椭圆曲线密码学的数学特性。而且它的设计从一开始就考虑了各种已知的攻击方式，包括侧信道攻击。\n性能更好\n密钥生成速度快很多。在我的机器上测试，生成一个 Ed25519 密钥几乎是瞬间完成，而生成 RSA 4096 位密钥需要几秒钟。\n签名和验证的速度也更快。虽然在日常使用中这个差异不太明显，但在需要频繁进行 SSH 连接的场景下，累积起来还是能感觉到的。\n密钥更短\nEd25519 的公钥只有 68 个字符左右，而 RSA 2048 位的公钥有 372 个字符以上。这让复制粘贴变得更方便，出错的概率也更小。\n实际使用中的体验老实说，对于普通用户来说，RSA 和 Ed25519 在日常使用中的差异几乎感觉不到。你不会因为换了 Ed25519 就觉得 git clone 快了多少。\n但从技术债务的角度考虑，现在开始用 Ed25519 是个明智的选择。它代表了未来的方向，各大平台的支持也越来越好。\n如何解决克隆问题回到最开始的问题，既然本地生成的是 Ed25519 密钥，那解决方案其实很简单。\n第一步：确认你的密钥先看看你的 .ssh 目录下有什么：\nls -la ~/.ssh/\n\n你可能会看到这些文件：\nid_rsaid_rsa.pubid_ed25519id_ed25519.pub\n\n如果同时存在 RSA 和 Ed25519 密钥，那说明你之前生成过 RSA，后来又生成了 Ed25519。\n第二步：查看你添加到 Git 平台的是哪个公钥登录 GitHub、GitLab 或者 Gitee，进入 SSH Keys 的设置页面，看看你之前添加的公钥内容。\nRSA 公钥通常以 ssh-rsa AAAA... 开头。Ed25519 公钥以 ssh-ed25519 AAAA... 开头。\n第三步：添加正确的公钥如果你想用 Ed25519（推荐），那就把新公钥添加到 Git 平台：\ncat ~/.ssh/id_ed25519.pub\n\n复制输出的内容，不同的平台配置路径不同：\n\nGitHub：Settings → SSH and GPG keys → New SSH key\nGitLab：Preferences → SSH Keys\nGitee：设置 → SSH 公钥\n\n把复制的内容粘贴进去，给这个密钥起个名字（比如”我的工作电脑”，默认会生成一个名字），保存。\n第四步：测试连接添加完公钥后，测试一下：\nssh -T git@github.com\n\n如果看到类似”Hi username! You’ve successfully authenticated”的消息，就说明配置成功了。\n如果你有多个密钥有些人可能需要在同一台机器上使用多个 Git 账号，或者需要连接多个不同的 Git 服务器。这时候就需要配置 SSH config 文件。\n创建或编辑 ~&#x2F;.ssh&#x2F;config 文件：\nnano ~/.ssh/config\n\n添加类似这样的配置：\nHost github.com    HostName github.com    User git    IdentityFile ~/.ssh/id_ed25519Host github-work    HostName github.com    User git    IdentityFile ~/.ssh/id_rsa_workHost gitlab.com    HostName gitlab.com    User git    IdentityFile ~/.ssh/id_ed25519\n\n这样你就可以为不同的 Host 指定不同的密钥。使用时，可以这样克隆：\ngit clone git@github-work:company/repo.git\n\n拓展知识如果我想继续用 RSA 呢虽然不推荐，但如果你确实需要生成 RSA 密钥（比如要连接的服务器太老，不支持 Ed25519），可以这样：\nssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;\n\n这里 -t 指定算法类型，-b 指定密钥长度，-C 添加一个注释（通常用邮箱）。\n其他的密钥算法除了 RSA 和 Ed25519，还有其他一些算法：\nECDSA\n这也是基于椭圆曲线的算法，在 Ed25519 流行之前比较常用。但现在一般直接推荐 Ed25519，因为它的设计更简洁，安全性审查更充分。\nDSA\n这是很老的算法了，OpenSSH 7.0 之后已经默认禁用。如果你看到 id_dsa 这样的文件，强烈建议换掉。\n密钥的安全管理生成密钥时，ssh-keygen 会询问你是否设置 passphrase（密码短语）。这是一个额外的保护层：即使有人拿到了你的私钥文件，没有 passphrase 也无法使用。\n建议设置 passphrase，但这样每次使用密钥时都需要输入。可以配合 ssh-agent 使用，输入一次密码后，在当前会话中就不用重复输入了：\neval &quot;$(ssh-agent -s)&quot;ssh-add ~/.ssh/id_ed25519\n\n在 macOS 上，还可以把密码存到 Keychain 里：\nssh-add --apple-use-keychain ~/.ssh/id_ed25519\n\n密钥权限问题SSH 对密钥文件的权限要求很严格。私钥文件必须只有所有者可读：\nchmod 600 ~/.ssh/id_ed25519chmod 644 ~/.ssh/id_ed25519.pub\n\n.ssh 目录本身的权限也要正确：\nchmod 700 ~/.ssh\n\n如果权限不对，SSH 会拒绝使用这个密钥，这也是一个常见的报错原因。\n密钥的备份私钥是你身份认证的唯一凭证，丢了就麻烦了。建议：\n\n把私钥备份到安全的地方（加密的移动硬盘、密码管理器等）\n不要把私钥存到云盘或者发给别人\n如果怀疑私钥泄露，立即删除对应的公钥，重新生成新的密钥对\n\nGit 平台的支持情况主流的 Git 托管平台都已经支持 Ed25519：\n\nGitHub：完全支持，推荐使用\nGitLab：完全支持\nGitee：支持\nBitbucket：支持\n自建的 GitLab&#x2F;Gitea&#x2F;Gogs：取决于服务器的 OpenSSH 版本\n\n如果你的公司使用的是很老的自建 Git 服务器，可能需要确认一下是否支持 Ed25519。\n什么时候需要重新生成密钥这些情况下建议重新生成：\n\n私钥可能泄露了\n电脑丢失或被盗\n离职换工作\n很多年没有更新过（虽然密钥理论上可以一直用，但定期更换是个好习惯）\n当前使用的是很老的算法（比如 DSA 或者短密钥的 RSA）\n\n总结从 RSA 到 Ed25519，这是技术进步的必然趋势。虽然在迁移过程中会遇到一些小问题，但长远来看，使用更现代、更安全的算法是值得的。\n如果你现在正在配置新的开发环境，建议直接使用 Ed25519。如果你已经在使用 RSA 密钥且运行良好，也不用急着换，等到下次重装系统或者遇到问题时再切换也不迟。\n最重要的是理解这个变化的原因和背景，这样遇到问题时就不会慌张，知道该往哪个方向排查。\n","categories":["技术","Git"],"tags":["Git","SSH"]},{"title":"Sphinx 文档图片点击放大","url":"/posts/2025/05/02/26504/","content":"本文将分享一个简单而有效的解决方案，通过添加少量的 JavaScript 代码，为 Sphinx 文档中的所有图片添加点击放大功能，大大提升用户体验。\n问题描述当我们在 Markdown 文件中添加图片时，生成的 HTML 中的图片标签通常如下所示：\n&lt;img alt=&quot;image-20250502161335681&quot; src=&quot;../../../_static/images/blog/test_some.png&quot;&gt;\n\n默认情况下，用户只能看到页面中嵌入的图片，无法通过点击查看原始大小的图片。\n解决方案我们可以通过添加一个简单的 JavaScript 文件，为所有图片添加点击放大功能，无需更改现有的 Markdown 文件或 Sphinx 配置。\n步骤 1：创建 JavaScript 文件首先，在 Sphinx 项目的 _static/js 目录下创建一个名为 image-click.js 的文件（如果目录不存在，需要先创建）：\nmkdir -p _static/jstouch _static/js/image-click.js\n\n步骤 2：编写 JavaScript 代码将下面的代码添加到 image-click.js 文件中：\ndocument.addEventListener(&#x27;DOMContentLoaded&#x27;, function() &#123;    // 为所有图片添加点击事件    var images = document.querySelectorAll(&#x27;img[alt^=&quot;image-&quot;]&#x27;);        images.forEach(function(img) &#123;        img.style.cursor = &#x27;pointer&#x27;;                img.addEventListener(&#x27;click&#x27;, function() &#123;            // 创建模态框            var modal = document.createElement(&#x27;div&#x27;);            modal.style.position = &#x27;fixed&#x27;;            modal.style.top = &#x27;0&#x27;;            modal.style.left = &#x27;0&#x27;;            modal.style.width = &#x27;100%&#x27;;            modal.style.height = &#x27;100%&#x27;;            modal.style.backgroundColor = &#x27;rgba(0,0,0,0.8)&#x27;;            modal.style.display = &#x27;flex&#x27;;            modal.style.alignItems = &#x27;center&#x27;;            modal.style.justifyContent = &#x27;center&#x27;;            modal.style.zIndex = &#x27;1000&#x27;;                        // 获取绝对路径            var imgSrc = img.getAttribute(&#x27;src&#x27;);            // 如果是相对路径,需要处理一下            if(imgSrc.startsWith(&#x27;../&#x27;) || imgSrc.startsWith(&#x27;./&#x27;)) &#123;                // 基于当前页面URL构建绝对路径                var basePath = window.location.href.substring(0, window.location.href.lastIndexOf(&#x27;/&#x27;) + 1);                imgSrc = new URL(imgSrc, basePath).href;            &#125;                        // 创建大图            var fullImg = document.createElement(&#x27;img&#x27;);            fullImg.src = imgSrc;            fullImg.style.maxWidth = &#x27;90%&#x27;;            fullImg.style.maxHeight = &#x27;90%&#x27;;            fullImg.style.objectFit = &#x27;contain&#x27;;                        // 点击关闭            modal.onclick = function() &#123;                document.body.removeChild(modal);            &#125;;                        modal.appendChild(fullImg);            document.body.appendChild(modal);        &#125;);    &#125;);&#125;);\n\n代码解释：\n\n选择所有 alt 属性以 “image-“ 开头的图片（指定文档中的图片命名）\n为每个图片添加点击事件\n点击时创建一个全屏模态框，显示原始图片\n处理相对路径，确保图片在模态框中正确显示\n允许用户通过点击模态框任意位置关闭它\n\n步骤 3：更新 Sphinx 配置在 conf.py 文件中添加以下配置，确保 Sphinx 加载这个 JavaScript 文件：\n# 添加静态目录路径html_static_path = [&#x27;_static&#x27;]# 添加 JavaScript 文件html_js_files = [    &#x27;js/image-click.js&#x27;,]\n\n\n\n高级定制如果想要进一步定制这个功能，可以考虑以下改进：\n为所有图片添加点击功能如果想为文档中的所有图片（而不仅仅是 alt 属性以 “image-“ 开头的图片）添加点击功能，只需修改选择器：\nvar images = document.querySelectorAll(&#x27;.document img&#x27;);\n\n添加缩放控制可以在模态框中添加缩放按钮，允许用户进一步放大或缩小图片：\n// 创建缩放控制按钮var zoomControls = document.createElement(&#x27;div&#x27;);zoomControls.style.position = &#x27;absolute&#x27;;zoomControls.style.bottom = &#x27;20px&#x27;;zoomControls.style.left = &#x27;50%&#x27;;zoomControls.style.transform = &#x27;translateX(-50%)&#x27;;zoomControls.style.zIndex = &#x27;1001&#x27;;var zoomIn = document.createElement(&#x27;button&#x27;);zoomIn.textContent = &#x27;+&#x27;;zoomIn.style.margin = &#x27;0 10px&#x27;;zoomIn.style.padding = &#x27;5px 10px&#x27;;zoomIn.onclick = function(e) &#123;    e.stopPropagation();    var currentScale = parseFloat(fullImg.style.transform.replace(&#x27;scale(&#x27;, &#x27;&#x27;).replace(&#x27;)&#x27;, &#x27;&#x27;) || 1);    fullImg.style.transform = &#x27;scale(&#x27; + (currentScale + 0.1) + &#x27;)&#x27;;&#125;;var zoomOut = document.createElement(&#x27;button&#x27;);zoomOut.textContent = &#x27;-&#x27;;zoomOut.style.margin = &#x27;0 10px&#x27;;zoomOut.style.padding = &#x27;5px 10px&#x27;;zoomOut.onclick = function(e) &#123;    e.stopPropagation();    var currentScale = parseFloat(fullImg.style.transform.replace(&#x27;scale(&#x27;, &#x27;&#x27;).replace(&#x27;)&#x27;, &#x27;&#x27;) || 1);    fullImg.style.transform = &#x27;scale(&#x27; + Math.max(0.1, currentScale - 0.1) + &#x27;)&#x27;;&#125;;zoomControls.appendChild(zoomOut);zoomControls.appendChild(zoomIn);modal.appendChild(zoomControls);\n\n总结通过添加少量的 JavaScript 代码，我们成功为 Sphinx 文档中的图片添加了点击放大功能，大大提升了用户体验。这个解决方案的优点包括：\n\n易于实现：只需添加一个 JavaScript 文件\n无需修改现有内容：不需要更改已有的 Markdown 文件\n轻量级：不依赖任何外部库\n可定制：可以根据需要轻松扩展功能\n\n无论是在编写技术文档、API 文档还是教程，这个简单的改进都能让图片更加实用，让用户能够方便地查看图片中的所有细节。\n","categories":["技术","测开"],"tags":["sphinx"]},{"title":"WSL安装docker","url":"/posts/2025/07/24/57324/","content":"迁移 WSL 位置将 WSL 从 C 盘迁移到 D 盘。\n当前版本\n&gt;wsl --list --verbose  NAME      STATE           VERSION* Ubuntu    Running         2\n\n关闭 wsl、注销、导出为归档文件\nwsl --shutdownwsl --export Ubuntu &quot;D:\\software\\WSL\\ubuntu_backup.tar&quot;wsl --unregister Ubuntu# 注销原先在C盘的 Ubuntu WSL 实例，删除原始文件并释放 C 盘空间。\n\n导入并启动\nwsl --import Ubuntu &quot;D:\\software\\WSL\\Ubuntu&quot; &quot;D:\\software\\WSL\\ubuntu_backup.tar&quot; --version 2wsl --list --verbosewsl\n\nInstall Dockersudo apt update &amp;&amp; sudo apt upgrade -ysudo apt install apt-transport-https ca-certificates curl gnupg lsb-releasecurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpgecho &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt updatesudo apt install docker-ce docker-ce-cli containerd.iosudo usermod -aG docker $USERsudo service docker startdocker --versiondocker run hello-world\n\nsudo apt install docker-composedocker-compose --version\n\n\n\n无法拉取docker镜像docker run hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallydocker: Error response from daemon: Get &quot;https://registry-1.docker.io/v2/&quot;: context deadline exceededRun &#x27;docker run --help&#x27; for more information\n\n解决：\n在 WSL 的 ~/.bashrc 加入如下内容:\nexport hostip=$(cat /etc/resolv.conf |grep -oP &#x27;(?&lt;=nameserver\\ ).*&#x27;)export https_proxy=&quot;http://$&#123;hostip&#125;:7890&quot;export http_proxy=&quot;http://$&#123;hostip&#125;:7890&quot;\n\n刷新：source ~/.bashrc\n编辑 /etc/resolv.conf（该文件在WSL重启后会恢复默认配置）使用如下：\nnameserver 8.8.8.8\n\n保存后设置文件为不可变（防止被修改）：\nsudo chattr +i /etc/resolv.conf\n\n同时宿主机器，使用 clash 开启虚拟网卡模式。\n","categories":["生产力","工具"],"tags":["docker"]},{"title":"gitlab-runner在实践中理解","url":"/posts/2025/10/01/6863/","content":"以前在 Mac、windows 上使用过 gitlab 的 pipeline，安装配置过 gitlab-runner。现在需要在 Linux 上再走一遍流程，一开始觉得应该挺容易的，流程比较熟悉，和其他平台大致相似吧，应该很快就搞好了。然而，实际操作时，发现有些不同，出现踩坑的原因也有环境的限制（部分网络无法访问），也有对 gitlab-runner 机制的不理解。现在整理一下遇到的问题吧。\n背景\n环境网络设备特殊，很多要求权限的步骤，在普通用户下无法直接使用 sudo，只能在 root 账户下操作\n一台公共的 Linux 设备，通过不同的个人账号登录\n配置的 pipeline 中有调用 python 脚本，后者里面有拉取多个工程仓库代码\n官方操作指导文档，亦有小问题，混用 install gitlab-runner 与启动方式\n\n账户差异导致的问题代码仓无法下载、访问\n如果是手动登录 Linux 机器，进行 git 克隆代码仓库，无法下载，出现如下报错，肯定第一时间就知道是没权限等原因，一般都去排查一下 ssh 秘钥有没配置、是否需要更新。\ngit clone git@qcp-gitlab.xxx.xyz:abc/abcdef.gitCloning into &#x27;abcdef&#x27;...GitLab: The project you were looking for could not be found.fatal: Could not read from remote repository.Please make sure you have the correct access rights\n\n但是，如果是通过 gitlab-runner、jenkins agent 等工具在机器上执行拉取仓库出现同样的问题时，可能让人会有疑惑。\nssh 秘钥对应不同的 gitlab 账户，root账户使用的SSH密钥(/root/.ssh/id_rsa.pub)和普通用户的SSH密钥对应的是不同的GitLab账户，而root对应的GitLab账户可能没有该仓库的访问权限。\n需要注意的是：在普通用户下配置了自己账户的秘钥，而 root 对应的秘钥也需要配置，同时将用户账号加入到项目成员中。\n检查 ssh 连接的 gitlab 的用户身份：\n# root 账户下，显示的是机器定制配置的名字ssh -T git@qcp-gitlab.xxxx.xyzWelcome to GitLab,  qcpmaster!# autotest 账户下，会显示用户的名字ssh -T git@qcp-gitlab.xxxx.xyzWelcome to GitLab, 周星星!\n\n\n\n目录或文件无法访问\n在安装 gitlab-runner 时，有的指导文档会使用 --user=gitlab-runner 参数，指定用户来安装，导致后续启动、执行时也是该用户。\n该用户可能没有权限访问很多目录，导致在执行 pipeline 遇到创建目录或者文件时，就会提示 no permission。\n解决办法\n对于代码仓无法下载\n\n如果是账户没有配置秘钥，那么只要切换到对应用户环境，生成公钥，配置到 gitlab 上\n在 gitlab 项目中，给执行环境的用户（比如这里的qcpmaster）添加为成员（至少 Developer 或 Reporter），让用户可以访问该仓库代码\n\n对于目录或文件无法访问\n\n给 gitlab-runner 用户必要的权限，比如特定目录访问权限（pipeline中配置的）\n# root账户下，或者加上sudo执行chown -R gitlab-runner:gitlab-runner /home/tools/gitlab-runnerchmod -R 755 /home/tools/gitlab-runner\n\n确保 gitlab 构建缓存目录有权限\nsudo chown -R gitlab-runner:gitlab-runner /home/gitlab-runner\n\n启动方式导致的问题重要提示：不要混用 gitlab-runner start/stop 和 systemctl 命令！\n学到了\n# ✅ 正确方式（通过 systemd 管理）sudo systemctl start gitlab-runnersudo systemctl stop gitlab-runnersudo systemctl restart gitlab-runnersudo systemctl status gitlab-runner# ❌ 不好的方式（直接命令，不通过 systemd）gitlab-runner startgitlab-runner stop\n\n问题复述\nrunner 明明已经启动了，但是 gitlab 上的 job 一直处于 pending 状态，于是去查看 runner 状态，发现服务启动失败了：\n(base) [root@dgvxl2905 tools]# gitlab-runner statusRuntime platform                                    arch=amd64 os=linux pid=26119 revision=139a0ac0 version=18.4.0gitlab-runner: Service is running(base) [root@dgvxl2905 tools]# gitlab-runner stopRuntime platform                                    arch=amd64 os=linux pid=26150 revision=139a0ac0 version=18.4.0(base) [root@dgvxl2905 tools]# gitlab-runner startRuntime platform                                    arch=amd64 os=linux pid=26205 revision=139a0ac0 version=18.4.0(base) [root@dgvxl2905 tools]#(base) [root@dgvxl2905 tools]# systemctl status gitlab-runner● gitlab-runner.service - GitLab Runner   Loaded: loaded (/etc/systemd/system/gitlab-runner.service; enabled; vendor preset: disabled)   Active: activating (auto-restart) (Result: exit-code) since Tue 2025-09-30 16:53:57 CST; 5s ago  Process: 26218 ExecStart=/usr/local/bin/gitlab-runner run --config /etc/gitlab-runner/config.toml --working-directory /home/tools/gitlab-runner --service gitlab-runner --user gitlab-runner (code=exited, status=1/FAILURE) Main PID: 26218 (code=exited, status=1/FAILURE)Sep 30 16:53:57 dgvxl2905 systemd[1]: Unit gitlab-runner.service entered failed state.Sep 30 16:53:57 dgvxl2905 systemd[1]: gitlab-runner.service failed.\n\n原因：多次启动了 gitlab-runner 服务，配置文件混乱，有的 runner 已经从 gitlab 页面上删除，但是机器上还保留着安装时对应的 toml 配置文件，导致每次使用 gitlab-runner start 启动都是旧的配置，看起来是在 running，但服务又 failed。\n解决\n# 以下均在 root 下执行，不再添加 sudo 了# 1. 停止所有进程pkill -9 gitlab-runner# 2. 检查并修复用户id gitlab-runner || useradd --system --shell /bin/bash --home /home/gitlab-runner gitlab-runner# 3. 修复工作目录，防止文件夹不存在mkdir -p /home/tools/gitlab-runnerchown -R gitlab-runner:gitlab-runner /home/tools/gitlab-runner# 使用 systemd 启动服务，而不是直接命令gitlab-runner verifysystemctl daemon-reloadsystemctl start gitlab-runnersystemctl status gitlab-runner\n\n记录的服务启动失败，到解决并成功启动的日志：\n(base) [root@dgvxl2905 tools]# systemctl status gitlab-runner● gitlab-runner.service - GitLab Runner   Loaded: loaded (/etc/systemd/system/gitlab-runner.service; enabled; vendor preset: disabled)   Active: inactive (dead) (Result: exit-code) since Tue 2025-09-30 17:01:28 CST; 12s ago  Process: 28734 ExecStart=/usr/local/bin/gitlab-runner run --config /etc/gitlab-runner/config.toml --working-directory /home/tools/gitlab-runner --service gitlab-runner --user gitlab-runner (code=exited, status=1/FAILURE) Main PID: 28734 (code=exited, status=1/FAILURE)Sep 30 16:59:56 dgvxl2905 systemd[1]: Unit gitlab-runner.service entered failed state.Sep 30 16:59:56 dgvxl2905 systemd[1]: gitlab-runner.service failed.Sep 30 17:01:28 dgvxl2905 systemd[1]: Stopped GitLab Runner.(base) [root@dgvxl2905 tools]# pkill -9 gitlab-runner(base) [root@dgvxl2905 tools]# id gitlab-runner || sudo useradd --system --shell /bin/bash --home /home/gitlab-runner gitlab-runneruid=5993(gitlab-runner) gid=5993(gitlab-runner) groups=5993(gitlab-runner)(base) [root@dgvxl2905 tools]# mkdir -p /home/tools/gitlab-runner(base) [root@dgvxl2905 tools]# chown -R gitlab-runner:gitlab-runner /home/tools/gitlab-runner(base) [root@dgvxl2905 tools]# ls /home/tools/gitlab-runner/(base) [root@dgvxl2905 tools]# cat /etc/gitlab-runner/config.tomlconcurrent = 1check_interval = 0connection_max_age = &quot;15m0s&quot;shutdown_timeout = 0[session_server]  session_timeout = 1800[[runners]]  name = &quot;build aws-doc&quot;  url = &quot;https://gitlab.vmic.xyz/&quot;  id = 3347  token = &quot;_pzPmGi-Nb3WByU1uS1E&quot;  token_obtained_at = 2025-09-30T08:31:35Z  token_expires_at = 0001-01-01T00:00:00Z  executor = &quot;shell&quot;  [runners.cache]    MaxUploadedArchiveSize = 0    [runners.cache.s3]    [runners.cache.gcs]    [runners.cache.azure](base) [root@dgvxl2905 tools]# gitlab-runner verifyRuntime platform                                    arch=amd64 os=linux pid=30312 revision=139a0ac0 version=18.4.0Running in system-mode.Verifying runner... is alive                        correlation_id=01K6CXRD9MN5Q0VH6TCFAFAEDV runner=_pzPmGi-N(base) [root@dgvxl2905 tools]# systemctl status gitlab-runner● gitlab-runner.service - GitLab Runner   Loaded: loaded (/etc/systemd/system/gitlab-runner.service; enabled; vendor preset: disabled)   Active: inactive (dead) (Result: exit-code) since Tue 2025-09-30 17:01:28 CST; 1min 36s ago  Process: 28734 ExecStart=/usr/local/bin/gitlab-runner run --config /etc/gitlab-runner/config.toml --working-directory /home/tools/gitlab-runner --service gitlab-runner --user gitlab-runner (code=exited, status=1/FAILURE) Main PID: 28734 (code=exited, status=1/FAILURE)Sep 30 16:59:56 dgvxl2905 systemd[1]: Unit gitlab-runner.service entered failed state.Sep 30 16:59:56 dgvxl2905 systemd[1]: gitlab-runner.service failed.Sep 30 17:01:28 dgvxl2905 systemd[1]: Stopped GitLab Runner.(base) [root@dgvxl2905 tools]# systemctl daemon-reload(base) [root@dgvxl2905 tools]# systemctl start gitlab-runner(base) [root@dgvxl2905 tools]# systemctl status gitlab-runner● gitlab-runner.service - GitLab Runner   Loaded: loaded (/etc/systemd/system/gitlab-runner.service; enabled; vendor preset: disabled)   Active: active (running) since Tue 2025-09-30 17:03:17 CST; 22s ago Main PID: 30494 (gitlab-runner)    Tasks: 13   Memory: 22.7M   CGroup: /system.slice/gitlab-runner.service           └─30494 /usr/local/bin/gitlab-runner run --config /etc/gitlab-runner/config.toml --working-directory /home/tools/gitlab-runner --service gitlab-runner --user gitlab-runnerSep 30 17:03:18 dgvxl2905 su[30521]: (to gitlab-runner) root on noneSep 30 17:03:18 dgvxl2905 su[30549]: (to gitlab-runner) root on noneSep 30 17:03:20 dgvxl2905 su[30609]: (to gitlab-runner) root on noneSep 30 17:03:20 dgvxl2905 su[30637]: (to gitlab-runner) root on noneSep 30 17:03:20 dgvxl2905 gitlab-runner[30494]: WARNING: Job failed: exit status 1Sep 30 17:03:20 dgvxl2905 gitlab-runner[30494]:   duration_s=0 job=508688 project=61926 runner=_pzPmGi-NSep 30 17:03:20 dgvxl2905 gitlab-runner[30494]: Appending trace to coordinator...ok                 code=202 correlation_id=01K6CXSBK54JNYV0JKE1GSSV9K job=508688 job-log=0-1504 job-status=ru...e-interval=3sSep 30 17:03:20 dgvxl2905 gitlab-runner[30494]: Updating job...                                     bytesize=1504 checksum=crc32:268fa141 job=508688 runner=_pzPmGi-NSep 30 17:03:20 dgvxl2905 gitlab-runner[30494]: Submitting job to coordinator...ok                  bytesize=1504 checksum=crc32:268fa141 code=200 correlation_id=01K6CXSBPW8M8CX40YVG25DN7X j...e-interval=0sSep 30 17:03:20 dgvxl2905 gitlab-runner[30494]: Removed job from processing list                    builds=0 job=508688 max_builds=1 project=61926 queue_depth=0 queue_size=0 repo_url=https:/...eue_seconds=0Hint: Some lines were ellipsized, use -l to show in full.\n\n小结\n提炼的安装、启动方式\n# 下载、赋予执行权限curl -L --output /usr/local/bin/gitlab-runner &quot;https://s3.dualstack.us-east-1.amazonaws.com/gitlab-runner-downloads/latest/binaries/gitlab-runner-linux-amd64&quot;chmod +x /usr/local/bin/gitlab-runner# 创建用户id gitlab-runner || useradd --comment &#x27;GitLab Runner&#x27; --create-home gitlab-runner --shell /bin/bash# 这一步创建了 systemd 服务！此时 systemd 知道了 gitlab-runner 服务的存在gitlab-runner install --user=gitlab-runner --working-directory=/home/tools/gitlab-runner# 此时最好不要用 gitlab-runner start 启动，而是用 systemdsystemctl start gitlab-runner\n\n备注：Install GitLab Runner manually on GNU&#x2F;Linux | GitLab Docs 官方指导中，先用了 gitlab-runner install，后用了 gitlab-runner start 是不好的。\n安全考虑\n\n安装阶段：需要 root 权限（使用 sudo）\n运行阶段：应该使用专用的普通用户（默认是 gitlab-runner 用户）\n注册：使用 sudo 注册（配置文件需要写入系统目录）\n\ngitlab-runner 用户报错\n$ set -euo pipefail # collapsed multi-line commanderror: could not lock config file /home/gitlab-runner/.gitconfig: No such file or directory，\n\nmkdir: cannot create directory ‘/home/autotest’: Permission denied\n\n原因\n\nGit 配置文件权限问题。GitLab Runner 在执行任务时，以 gitlab-runner 用户运行，但该用户的家目录配置不完整\n.gitlab-ci.yml 配置上，gitlab-runner 用户没有权限创建或访问 /home/autotest 目录及其子目录。\n\n解决\n创建并修复 gitlab-runner 家目录。\nsudo mkdir -p /home/gitlab-runnersudo chown -R gitlab-runner:gitlab-runner /home/gitlab-runnersudo chmod 755 /home/gitlab-runnersudo -u gitlab-runner touch /home/gitlab-runner/.gitconfigsudo chmod 644 /home/gitlab-runner/.gitconfig\n\nyml 中使用 CI 环境\nvariables:  # 使用 CI 工作目录或共享目录  TARGET_BUILD_DIR: &quot;$&#123;CI_PROJECT_DIR&#125;/doc/build&quot;  LOG_DIR: &quot;$&#123;CI_PROJECT_DIR&#125;/logs&quot;\n\n给 gitlab-runner 用户访问权限（如果必须使用 /home/autotest 路径）\n# 方法 A：将 gitlab-runner 加入 autotest 组sudo usermod -aG autotest gitlab-runner# 方法 B: 设置目录权限，允许组成员访问sudo chmod 755 /home/autotestsudo chmod -R 755 /home/autotest/toolssudo chmod -R 755 /home/autotest/vlt# 重启 gitlab-runner 使组权限生效sudo systemctl restart gitlab-runner\n\n755 的含义:\n\n7 (owner): 读+写+执行\n5 (group): 读+执行\n5 (others): 读+执行 ← 这是关键，任何用户(包括 gitlab-runner)都可以读取和访问这些目录，不需要加入任何组\n\n代码仓库权限错误信息：\n\nHost key verification failed - 缺少 known_hosts\nCould not read from remote repository - 缺少 SSH 密钥或权限\n\n问题分析\n\n手动可以克隆：用的是 root 或 autotest 用户，有配置好的 SSH 密钥\nPipeline 失败：gitlab-runner 用户没有 SSH 密钥，也没有 GitLab 服务器的 host key\n\n最佳解决：\n直接切换到 gitlab-runner 用户，ssh-keygen 生成并配置秘钥到仓库。\ngitlab runner 日志对于通过 systemd 管理的 Runner\n# 查看实时日志sudo journalctl -u gitlab-runner -f# 查看最近的日志sudo journalctl -u gitlab-runner -n 100# 查看指定时间范围的日志sudo journalctl -u gitlab-runner --since &quot;2024-09-30 10:00:00&quot; --until &quot;2024-09-30 12:00:00&quot;# 查看今天的日志sudo journalctl -u gitlab-runner --since today# 只看错误级别日志sudo journalctl -u gitlab-runner -p err\n\n检查 Runner 状态\n# 查看 Runner 服务状态sudo systemctl status gitlab-runner# 查看 Runner 版本和配置sudo gitlab-runner --versionsudo gitlab-runner verify# 查看配置文件内容、文件权限cat /etc/gitlab-runner/config.tomlls -la /etc/gitlab-runner/config.toml# 列出所有注册的 Runnersudo gitlab-runner list\n\n","categories":["技术","Gitlab"],"tags":["Gitlab","Linux"]},{"title":"Learning git branching","url":"/posts/2025/02/15/28297/","content":"learning git branching\nmerge\n创建新分支 bugFix\n用 git checkout bugFix 命令切换到该分支\n提交一次\n用 git checkout main 切换回 main\n再提交一次\n用 git merge 把 bugFix 合并到 main\n\ngit checkout -b bugFixgit commit git checkout maingit commitgit merge bugFix\n\n\nrebase操作：\n\n新建并切换到 bugFix 分支\n提交一次\n切换回 main 分支再提交一次\n再次切换到 bugFix 分支，rebase 到 main 上\n\ngit checkout -b bugFixgit commit git checkout maingit commitgit checkout bugFixgit rebase main\n\n\n分离 HEADgit checkout c4\n\n\n相对引用利用父节点git checkout HEAD^\n\n寻找 bugFix 的父节点\ngit checkout bugFix^\n\n\nbranch -f强制修改分支位置\ngit branch -f bugFix c0git branch -f main c6git checkout c1\n\n\n或者\ngit checkout c1git branch -f bugFix HEAD~1git branch -f main c6\n\n\n撤销变更git reset HEAD~1git checkout pushedgit revert HEAD\n\n\ncherry-pickgit cherry-pick c3 c4 c7\n\n\n交互式 rebasegit rebase -i HEAD~4\n\n\n只取一个提交记录git rebase -i maingit branch -f main bugFix\n\n\n或者\ngit checkout maingit cherry-pick bugFix\n\n\n提交的技巧rebase 在上一次提交上amendgit rebase -i maingit commit --amendgit rebase -i maingit branch -f main caption\n\n\n或者（多种方法尝试）\ngit rebase -i caption~2git commit --amendgit rebase -i HEAD~2git branch -f main caption\n\n\n\ncherry-pick 在上一次提交上 amendgit checkout maingit cherry-pick newImagegit commit --amendgit cherry-pick caption\n\n\ntaggit tag v0 c1git tag v1 c2git checkout v1\n\n\n多分支 rebasegit rebase main bugFixgit rebase bugFix sidegit rebase side anothergit branch -f main another\n\n\n两个parent节点操作符 ^ 与 ~ 符一样，后面也可以跟一个数字。\n但是该操作符后面的数字与 ~ 后面的不同，并不是用来指定向上返回几代，而是指定合并提交记录的某个 parent 提交。还记得前面提到过的一个合并提交有两个 parent 提交吧，所以遇到这样的节点时该选择哪条路径就不是很清晰了。\nGit 默认选择合并提交的“第一个” parent 提交，在操作符 ^ 后跟一个数字可以改变这一默认行为。\ngit checkout HEAD~^2~git branch -f bugWork HEAD  # git branch -f bugWorkgit checkout main\n\n\n或者\ngit branch bugWork HEAD~^2~\n\n\n纠缠不清的分支git checkout onegit cherry-pick c4 c3 c2git checkout twogit cherry-pick c5 c4 c3 c2git branch -f three c2\n\n\n偏离的提交历史git clonegit fakeTeamworkgit commitgit fetchgit rebase o/maingit push\n\n\n或者\ngit clonegit fakeTeamworkgit commitgit pull --rebasegit push\n\n\n锁定的Maingit reset --hard o/maingit checkout -b feature c2git push   # git push origin feature\n\n\n推送主分支git fetchgit rebase o/main side1git rebase side1 side2git rebase side2 side3git rebase side3 maingit push\n\n\n合并远程仓库git fetchgit rebase o/main maingit merge side1git merge side2git merge side3git push\n\n\n远程跟踪git checkout -b side o/maingit commitgit fetchgit rebase o/main sidegit push\n\n或者\ngit checkout -b side o/maingit commitgit pull --rebasegit push\n\n\npush 的参数git push origin maingit push origin foo\n\n\npush 的参数2git push origin foo:maingit push origin main^:foo\n\n\nfetch 的参数git fetch origin c3:foogit fetch origin c6:maingit checkout foogit merge main\n\n\n没有 source 的 sourcegit push origin :foogit fetch origin :bar\n\n\npull 参数git pull 到头来就是 fetch 后跟 merge 的缩写。可以理解为用同样的参数执行 git fetch，然后再 merge 所抓取到的提交记录。\ngit pull origin foo 相当于：git fetch origin foo; git merge o/foo\ngit pull origin bar:bugFix 相当于：git fetch origin bar:bugFix; git merge bugFix\ngit fetch origin c3:foogit fetch origin c2:sidegit merge foogit merge side\n\n或者\ngit pull origin c3:foogit pull origin c2:side\n\n\n","categories":["技术","Git"],"tags":["Git"]},{"title":"pytest中fixture与类继承交互导致的问题","url":"/posts/2025/05/31/34484/","content":"在 pytest 中，通常情况下，fixture 的执行顺序主要由 scope 决定，但并非简单地”高级别先执行”。实际上，pytest 按照一种”由外到内”的方式执行不同 scope 的 fixture。\n具体来说，fixture 执行顺序遵循以下规则：\n\n首先按照 scope 从大到小的顺序执行：session &gt; package &gt; module &gt; class &gt; function\n同一 scope 级别的 fixture 按照依赖关系执行：如果一个 fixture 依赖于另一个 fixture（通过参数引用），则先执行被依赖的 fixture\n同一 scope 级别且无依赖关系的 fixture 按照它们在代码中的声明顺序执行\n\n问题下面是 pytest 中 fixture 作用域(scope)与 Python 类继承之间的交互方式导致的一个问题。\n这个代码 TestBase 中，如果将 init 函数使用级别为 function 的scope 运行没问题，但是改成 class 级别后，子类中的方法就没使用 self.base 了。\nimport pytestclass TestBase:    # @pytest.fixture(scope=&#x27;class&#x27;, autouse=True)  # 在 test_derived 中无法使用 self.base    @pytest.fixture(scope=&#x27;function&#x27;, autouse=True)  # 可行    def init(self):        self.base = &quot;base&quot;class TestDerived(TestBase):    def test_derived(self):        assert self.base == &quot;base&quot;    def test_derived2(self):        assert self.base == &quot;base&quot;\n\n\n\n分析fixture 的触发机制问题：\n\n对于 autouse=True 的 fixture，pytest 需要确定何时以及在哪个对象上执行它\n当 fixture 定义在类内部且使用 scope=&#39;class&#39; 时，pytest 可能在处理 fixture 的执行上下文时出现了问题\n\n将属性绑定到 类 上import pytestclass TestBase:    @pytest.fixture(scope=&#x27;class&#x27;, autouse=True)    def init(self, request):        print(f&quot;Init fixture executing, self is: &#123;self&#125;&quot;)        print(f&quot;Request.cls is: &#123;request.cls&#125;&quot;)        request.cls.base = &quot;base&quot;  # 确保设置在类上而不是实例上class TestDerived(TestBase):    def test_derived(self):        print(f&quot;In test_derived, self is: &#123;self&#125;&quot;)        print(f&quot;self.__class__.base is: &#123;getattr(self.__class__, &#x27;base&#x27;, &#x27;NOT_FOUND&#x27;)&#125;&quot;)        assert hasattr(self.__class__, &#x27;base&#x27;)        assert self.__class__.base == &quot;base&quot;        assert self.base == &quot;base&quot;\n\n执行结果：\n============================== 1 passed in 0.10s ==============================Init fixture executing, self is: &lt;src.practice_demo.te.TestDerived object at 0x0000026EA6DE32E0&gt;Request.cls is: &lt;class &#x27;src.practice_demo.te.TestDerived&#x27;&gt;PASSED                                  [100%]In test_derived, self is: &lt;src.practice_demo.te.TestDerived object at 0x0000026EA6E50760&gt;self.__class__.base is: base\n\n可以发现：\n\nfixture 确实执行了：Init fixture executing 说明 scope=&#39;class&#39; 的 fixture 被正确触发\n执行顺序没问题：fixture 先执行，然后才是测试方法\n对象实例不同：注意两个关键的内存地址\nfixture 中的 self: 0x0000026EA6DE32E0\n测试方法中的 self: 0x0000026EA6E50760\n\n\n\n这就解释了为什么原始代码会失败，当使用类内部定义的 scope=&#39;class&#39; fixture 时：\n\nfixture 在一个 TestDerived 实例上执行（地址 2E0），设置了 self.base = &quot;base&quot;\n但测试方法 test_derived 在另一个不同的 TestDerived 实例上执行（地址 760）\n这两个是完全不同的对象实例\n\n解决：使用 request.cls.base = &quot;base&quot; 将属性设置在类上而不是实例上，所以无论哪个实例都能访问到这个类属性。\n使用 scope=&#39;function&#39;因为 function 级别的 fixture 会在每个测试方法的同一个实例上执行，所以 self.base 设置和访问都在同一个对象上。\nclass TestBase:    @pytest.fixture(scope=&#x27;function&#x27;, autouse=True)    def init(self):        print(f&quot;Init fixture executing, self is: &#123;self&#125;&quot;)        self.base = &#x27;base&#x27;class TestDerived(TestBase):    def test_derived(self):        print(f&quot;In test_derived, self is: &#123;self&#125;&quot;)        assert self.base == &quot;base&quot;\n\n运行结果，地址相同：\n============================== 1 passed in 0.10s ==============================Init fixture executing, self is: &lt;src.practice_demo.t.TestDerived object at 0x00000238DC562A90&gt;PASSED                                   [100%]In test_derived, self is: &lt;src.practice_demo.t.TestDerived object at 0x00000238DC562A90&gt;\n\n\n\n解决方法使用类属性代替实例属性\n如果 base 是类级别的共享状态，可以将其设置为类属性，而不是实例属性：\nclass TestBase:    @pytest.fixture(scope=&#x27;class&#x27;, autouse=True)    def init(self, request):        request.cls.base = &quot;base&quot;  # 设置类属性class TestDerived(TestBase):    def test_derived(self):        assert self.base == &quot;base&quot;    def test_derived2(self):        assert self.base == &quot;base&quot;\n\n\n在这里，request.cls 指向当前测试类（TestDerived），通过 request.cls.base 设置类属性。\n这样，base 成为 TestDerived 的类属性，所有的实例都可以通过 self.base 访问。\n\n或者，保持使用 function 级别，这确实更符合 Python 类实例的工作方式，因为每个测试方法实际上都是在一个新的类实例上运行的。\n为什么有两个不同的对象\n使用 scope=&#39;function&#39;情况下，因为 function 级别的 fixture 会在每个测试方法的同一个实例上执行，所以 self.base 设置和访问都在同一个对象上。\n\n但是，为啥 scope 为 class 时，会出现两个对象呢？\n这与 pytest 的 fixture 执行机制 和 Python 类方法调用机制 有关。\n核心原因：fixture 的执行上下文当在类内部定义 fixture 时，pytest 需要在某个对象实例上调用这个 fixture 方法。但是：\nscope=&#39;function&#39; 的情况\npytest 为每个测试方法创建一个新的 TestDerived 实例\n在这个实例上调用 init fixture\n然后在同一个实例上调用测试方法\n流程：创建实例 → 调用 fixture → 调用测试方法（都在同一个对象上）\n\nscope=&#39;class&#39; 的情况\npytest 需要在类级别执行 fixture，但 fixture 仍然是一个实例方法\npytest 创建一个 TestDerived 实例来调用 init fixture\n但当执行具体的测试方法时，pytest 又创建了另一个新的实例\n流程：创建实例A → 调用 fixture → 创建实例B → 调用测试方法\n\n为什么 pytest 要这样做？这实际上是 pytest 设计的一个特点（或者说是限制），打印对象 id ：\nimport pytestclass TestBase:    @pytest.fixture(scope=&#x27;class&#x27;, autouse=True)    def init(self):        print(f&quot;\\nFixture executing on instance: &#123;id(self)&#125;&quot;)        self.base = &quot;base&quot;class TestDerived(TestBase):    def test_derived(self):        print(f&quot;\\nTest executing on instance: &#123;id(self)&#125;&quot;)        print(f&quot;hasattr(self, &#x27;base&#x27;): &#123;hasattr(self, &#x27;base&#x27;)&#125;&quot;)        if hasattr(self, &#x27;base&#x27;):            print(f&quot;self.base: &#123;self.base&#125;&quot;)        else:            print(&quot;self.base does not exist&quot;)        # assert hasattr(self, &#x27;base&#x27;)  # 这行会失败，先注释掉\n\n运行这个代码：\nFixture executing on instance: 1523376596880PASSED                                  [100%]Test executing on instance: 1523376597312hasattr(self, &#x27;base&#x27;): Falseself.base does not exist\n\n这是 pytest 的设计局限pytest 在处理类内部定义的 scope=&#39;class&#39; fixture 时，无法很好地协调实例的生命周期。这就是为什么通常建议：\n\n避免在类内部定义 class 级别的 fixture\n将 class 级别的 fixture 定义在 conftest.py 中\n或者使用 request.cls 来操作类属性而不是实例属性\n\n所以看到的”两个对象”现象是 pytest 内部机制导致的，而不是 Python 或测试逻辑的问题。这也解释了为什么这种用法容易出现意想不到的行为。\n总结\nscope=&#39;function&#39; 有效是因为 init 方法在每个测试函数运行时都会为当前实例设置 self.base。\nscope=&#39;class&#39; 失败是因为 init 方法的 self 没有正确绑定到 TestDerived 的实例上，导致 self.base 未被设置。\n通过调整为类属性，可以解决这个问题。\n\n","categories":["技术","pytest"],"tags":["Python","pytest"]},{"title":"subprocess.run 字符串与列表参数对比","url":"/posts/2025/05/03/21338/","content":"基本语法对比两种传参方式的基本语法：\n字符串形式import subprocessresult = subprocess.run(&quot;ls -la&quot;, shell=True, capture_output=True, text=True)print(result.stdout)\n\n列表形式import subprocessresult = subprocess.run([&quot;ls&quot;, &quot;-la&quot;], capture_output=True, text=True)print(result.stdout)\n\n表面上看，两种方式都能实现同样的功能，但它们在处理机制和安全性上存在显著差异。\n核心区别1. 命令解析方式\n字符串形式：当使用字符串形式时，必须设置shell=True。此时，Python会将整个命令字符串传递给系统shell（比如bash或cmd），由shell来解析和执行这个命令。\n\n列表形式：当使用列表形式时，Python会直接执行程序，而不通过shell。第一个元素是要执行的程序，后续元素是传递给该程序的参数。\n\n\n2. 安全性考虑\n字符串形式：存在严重的命令注入风险。如果命令字符串中包含用户输入，可能导致恶意代码执行。\n\n列表形式：更安全，因为每个参数都是列表中的单独元素，不会被解释为shell命令的一部分。\n\n\n3. 命令复杂度处理\n字符串形式：能够直接使用shell功能，如管道(|)、重定向(&gt;, &lt;)、通配符(*)等。\n\n列表形式：不支持shell特性，除非明确设置shell=True，但这样会失去列表形式的安全优势。\n\n\n应用场景适合使用字符串形式的场景\n需要shell特性的场景：\n# 使用管道组合命令subprocess.run(&quot;grep &#x27;error&#x27; /var/log/app.log | wc -l&quot;, shell=True)# 使用通配符subprocess.run(&quot;rm *.tmp&quot;, shell=True)\n\n执行简单且可信的命令：\n# 不含用户输入的简单命令subprocess.run(&quot;echo Hello World&quot;, shell=True)\n\n命令结构在运行时动态生成且复杂：\ncommand = f&quot;find &#123;directory&#125; -name &#x27;*.py&#x27; -exec grep &#x27;&#123;pattern&#125;&#x27; &#123;&#123;&#125;&#125; \\\\;&quot;subprocess.run(command, shell=True)\n\n适合使用列表形式的场景\n处理包含用户输入的命令：\nuser_input = &quot;file with spaces.txt; rm -rf /&quot;  # 潜在的恶意输入# 不安全的方式# subprocess.run(f&quot;cat &#123;user_input&#125;&quot;, shell=True)  # 危险！# 安全的方式subprocess.run([&quot;cat&quot;, user_input])\n\n执行简单的命令，无需shell功能：\nsubprocess.run([&quot;mkdir&quot;, &quot;-p&quot;, &quot;new_directory&quot;])\n\n需要准确控制参数传递的场景：\n# 确保文件名被作为整体处理，即使包含空格subprocess.run([&quot;grep&quot;, &quot;pattern&quot;, &quot;file with spaces.txt&quot;])\n\n跨平台兼容性要求高的应用：\n# 在不同操作系统上都能正确工作subprocess.run([&quot;python&quot;, &quot;-c&quot;, &quot;print(&#x27;Hello World&#x27;)&quot;])\n\n性能考虑在性能方面，列表形式通常更高效，因为它避免了启动shell的开销。当需要频繁执行命令或在资源受限的环境中运行时，这一点尤为重要。\n# 列表形式：直接执行程序，无shell开销subprocess.run([&quot;ls&quot;, &quot;-la&quot;])# 字符串形式：需要启动shell，增加了开销subprocess.run(&quot;ls -la&quot;, shell=True)\n\n最佳实践\n默认使用列表形式：除非确实需要shell功能，否则应始终使用列表形式以提高安全性和性能。\n\n处理用户输入时必须使用列表形式：这是防止命令注入攻击的关键。\n\n需要shell功能时的安全使用：如果必须使用shell功能，确保所有用户输入都经过严格验证和转义。\n\n使用参数而非字符串拼接：\n# 不好的做法file_name = &quot;report.txt&quot;subprocess.run(f&quot;cat &#123;file_name&#125; | grep ERROR&quot;, shell=True)# 更好的做法import subprocessprocess1 = subprocess.run([&quot;cat&quot;, file_name], capture_output=True, text=True)process2 = subprocess.run([&quot;grep&quot;, &quot;ERROR&quot;], input=process1.stdout, text=True)\n\n进阶示例复杂Shell命令的替代方案对于需要shell功能的复杂命令，可以考虑使用Python的原生功能代替：\n# 使用shell的方式subprocess.run(&quot;find . -name &#x27;*.py&#x27; | xargs grep &#x27;import os&#x27;&quot;, shell=True)# 使用Python替代import osimport repy_files = []for root, dirs, files in os.walk(&#x27;.&#x27;):    for file in files:        if file.endswith(&#x27;.py&#x27;):            py_files.append(os.path.join(root, file))for file in py_files:    with open(file, &#x27;r&#x27;) as f:        if re.search(r&#x27;import\\s+os&#x27;, f.read()):            print(file)\n\n组合多个命令# 使用管道连接多个命令的shell方式subprocess.run(&quot;ps aux | grep python | grep -v grep&quot;, shell=True)# 不使用shell的Python方式ps_process = subprocess.run([&quot;ps&quot;, &quot;aux&quot;], capture_output=True, text=True)grep1_process = subprocess.run([&quot;grep&quot;, &quot;python&quot;], input=ps_process.stdout, capture_output=True, text=True)grep2_process = subprocess.run([&quot;grep&quot;, &quot;-v&quot;, &quot;grep&quot;], input=grep1_process.stdout, capture_output=True, text=True)print(grep2_process.stdout)\n\n结论选择字符串还是列表形式主要取决于具体需求：\n\n安全性是首要考虑：使用列表形式\n需要shell特性：使用字符串形式，但要注意安全问题\n跨平台兼容性：优先考虑列表形式\n简单且可信的命令：两种形式都可以，但列表形式更符合最佳实践\n\n在实际开发中，建议默认使用列表形式，只有在明确需要shell功能且了解相关安全风险的情况下才使用字符串形式。通过合理选择命令传递方式，可以使Python subprocess模块既强大又安全。\n参考资料\nPython官方文档: subprocess\nPython安全编程指南\n\n","categories":["技术","Python"],"tags":["python"]},{"title":"windows上使用wsl","url":"/posts/2025/03/04/5474/","content":"准备给 Windows11 上安装 wsl，没有安装前，搜索 wsl 后点击，弹出窗口并闪退。\n检查状态 wsl --status\n&gt;wsl --status默认版本: 2当前计算机配置不支持 WSL1。若要使用 WSL1，请启用“Windows Subsystem for Linux”可选组件。当前计算机配置不支持 WSL2。请启用“虚拟机平台”可选组件，并确保在 BIOS 中启用虚拟化。通过运行以下命令启用“虚拟机平台”: wsl.exe --install --no-distribution有关信息，请访问 https://aka.ms/enablevirtualization\n\n\n打开”控制面板” &gt; “程序” &gt; “启用或关闭 Windows 功能”\n勾选以下选项后重启：\n“Hyper-V” （我的win11上无）\n“Windows 虚拟机监控程序平台”\n“Windows Subsystem for Linux”\n\n\n\n&gt;wsl --status默认版本: 2&gt;wsl --list --verbose适用于 Linux 的 Windows 子系统没有已安装的分发。可通过安装包含以下说明的分发来解决此问题：使用“wsl.exe --list --online&#x27; ”列出可用的分发和 “wsl.exe --install &lt;Distro&gt;” 进行安装。\n\n安装 wslwsl --install Ubuntu\n&gt;wsl --list --online以下是可安装的有效分发的列表。使用 &#x27;wsl.exe --install &lt;Distro&gt;&#x27; 安装。NAME                            FRIENDLY NAMEDebian                          Debian GNU/LinuxSUSE-Linux-Enterprise-15-SP5    SUSE Linux Enterprise 15 SP5SUSE-Linux-Enterprise-15-SP6    SUSE Linux Enterprise 15 SP6Ubuntu                          UbuntuUbuntu-24.04                    Ubuntu 24.04 LTSkali-linux                      Kali Linux RollingopenSUSE-Tumbleweed             openSUSE TumbleweedopenSUSE-Leap-15.6              openSUSE Leap 15.6Ubuntu-18.04                    Ubuntu 18.04 LTSUbuntu-20.04                    Ubuntu 20.04 LTSUbuntu-22.04                    Ubuntu 22.04 LTSOracleLinux_7_9                 Oracle Linux 7.9OracleLinux_8_7                 Oracle Linux 8.7OracleLinux_9_1                 Oracle Linux 9.1&gt;wsl --install Ubuntu正在下载: Ubuntu正在安装: Ubuntu已成功安装分发。它可通过 “wsl.exe -d Ubuntu” 启动\n\nwsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。Provisioning the new WSL instance UbuntuThis might take a while...Create a default Unix user account: MagnoliaInvalid username. A valid username must start with a lowercase letter or underscore, and can contain lowercase letters, digits, underscores, and dashes.Create a default Unix user account: magnoliaNew password:Retype new password:passwd: password updated successfullyTo run a command as administrator (user &quot;root&quot;), use &quot;sudo &lt;command&gt;&quot;.See &quot;man sudo_root&quot; for details.Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 5.15.167.4-microsoft-standard-WSL2 x86_64) * Documentation:  https://help.ubuntu.com * Management:     https://landscape.canonical.com * Support:        https://ubuntu.com/pro System information as of Tue Mar  4 21:26:59 CST 2025  System load:  0.03                Processes:             36  Usage of /:   0.1% of 1006.85GB   Users logged in:       0  Memory usage: 3%                  IPv4 address for eth0: 172.20.107.81  Swap usage:   0%This message is shown once a day. To disable it please create the/home/magnolia/.hushlogin file.\n\n命令wsl --list --verbose  # 查看可用的 WSL 发行版wsl --shutdown  # 重启WSLwsl pwd  # 可以查看当前路径，来验证 WSL 是否正常工作wsl lswsl --update# 收集 WSL 诊断信息wsl --statuswsl --systeminfo# 更新包sudo apt update# treesudo apt install treetree -L 3 -a -I &quot;syslog|__pycache__|*.log&quot;  # 展示筛选后的当前目录结构\n\n在 Windows 命令行\nC:\\Users\\username&gt;wsl pwd/mnt/c/Users/username\n\n创建 /etc/wsl.conf，禁用 Windows 访问 Linux 文件系统：\n[automount]enabled = trueoptions = &quot;metadata&quot;mountFsTab = false\n\n这样可以 加速 WSL 访问 Windows 文件系统，避免不必要的同步。\n使用 wsl --shutdown 释放 WSL 资源：\nwsl --shutdown\n\n\n\n访问 WSL 目录\n在 Windows 资源管理器 中访问 WSL 目录：\n\n打开 资源管理器 - 地址栏 \\\\wsl$，看到 WSL 安装的所有 Linux 发行版，比如 Ubuntu。\n进入 \\\\wsl$\\Ubuntu\\home\\yourname，像管理普通文件一样操作 WSL 里的文件。\n\n在 WSL 中遇到 ls 命令显示中文文件名出现 ?????? 的问题，通常是由于字符编码或语言环境（Locale）设置不正确导致的。以下是解决方法：\n\n语言配置检查并设置正确的 Locale\nWSL 默认可能未配置中文语言环境，需要手动启用：\n# 查看当前 locale 设置locale# 安装中文语言包（Ubuntu/Debian 示例）sudo apt update &amp;&amp; sudo apt install locales fonts-noto-cjk# 生成并设置中文 locale（UTF-8 编码）sudo locale-gen zh_CN.UTF-8sudo update-locale LANG=zh_CN.UTF-8# 临时生效（仅当前会话）export LANG=zh_CN.UTF-8\n\n重启 WSL 后生效（关闭终端重新打开）。\n","categories":["生产力","工具"],"tags":["tools"]},{"title":"windows 文件被占用","url":"/posts/2025/03/15/6513/","content":"进程资源管理器界面由两个子窗口组成。 顶部窗口始终显示当前活动进程的列表，包括其所属帐户的名称，而底部窗口中显示的信息取决于进程资源管理器所处的模式：如果它处于句柄模式，你将看到顶部窗口中选择的进程已打开的句柄；如果进程资源管理器处于 DLL 模式，则会看到进程已加载的 DLL 和内存映射文件。 进程资源管理器还具有强大的搜索功能，可快速显示哪些进程打开了特定的句柄或加载了 DLL。\n进程资源管理器的独特功能可用于跟踪 DLL 版本问题或句柄泄漏，并提供 Windows 和应用程序工作方式的见解。\n微软官方工具 Process Explorer。\n\n以管理员身份运行 → 按 Ctrl + F 搜索文件夹名称或路径。\n找到占用进程后，右键选择 Kill Process。再也不用担心找不到被占用的程序了，再也不用非得重启才解决问题了。\n\n\n","categories":["生产力","工具"],"tags":["tools"]},{"title":"不恰当的import导致的问题","url":"/posts/2020/07/05/15577/","content":"1. 直接执行被导入模块的代码在 Python 中，import 语句会被执行，也就是在导入某个模块的的类、函数等时候，会执行该模块，此时如果该模块中有实例化的对象或者可以执行的函数，那么就会执行。用一个工作中遇到的问题来解释：\n（关于业务的描述可以忽略）在执行工装测试套时，正确填写好需要测试的工装IPC的信息后，发现实际执行的是默认的IP值是device_info.json文件中默认值，而不是当时需要测试的203.1.2.35。\n\n在 pycharm 本地调试 main_tooling.py，发现是一个导包问题导致的：引入了一个类的实例化。\n解决过程：\n首先是复制console打印日志中的“查看update -v异常”，到Utest工程中全局查找，发现只有在xxx的地方出现，于是在这边添加断点：\n\n通过debug可以回溯前面调用的地方：\n\n通过 git 历史提交记录发现是同事处理某个问题时引入：\n\n通过回溯回顾，发现：\n在最初执行的 main_tooling.py 中调用 liveoperator模块中的类 ：\nfrom src.components.liveoperator import LiveOperator\n\n在 liveoperator.py 中调用 videoaction 模块中的类 ：\nfrom src.components.videoaction import VideoActionLapi\n\n在 videoaction.py 中调用 video_parameters 模块中的类：\nfrom src.parameters.video_parameters import videoparameters\n\n在 video_parameters.py 中实例化了 VideoParameters 类：\nvideoparameters = VideoParameters()\n\n在实例化过程中，就出现了问题的原因所在，抛开业务来说就是在不合适的时机，实例化了我不想实例化的类，我还没做 xxx 呢，你现在就给我实例化，我不能让你这么做。\n解决办法：\n可以在将 main_tooling.py 中导入liveoperator 的代码放入需要执行的地方，而不是放在文件的首部，这样可以等到我做了某一业务操作后再执行导入就没有问题了，也就是一个先后问题。\n\n2. import 循环Python 是可以循环引用的，只要循环引用中的模块并不是在定义阶段就马上使用：\n# module1.pyimport module2class ModuleDemo():    def module2_func(self):        print(module2.module2_func)\n\n# module2.pyimport module1def module2_func():    print(module1.ModuleDemo)\n\n由于示例中只有在函数内部使用，只要 import 阶段没有执行到相应的用到 import 位置的代码就没有问题。正常使用时要避免三种使用方法：\n\nfrom … import … （如果有循环导入的，考虑把这种形式的去掉）\n直接执行的代码 （避免导入直接执行的代码）\n类的继承（避免基类的模块去 import 派生类的模块）\n\n还有其他方法：用到时再导入，而不是放在模块顶部。比如将 import 放到函数里面，可以解决问题，但治标不治本，治本的还是要重新划分模块，逻辑理顺了就不会出现循环 import 。\n错误示范，出现 ImportError：\n# module1.pyfrom module2 import module2_funcclass ModuleDemo():    def module2_func(self):        print(module2_func)\n\n# module2.pyfrom module1 import ModuleDemodef module2_func():    print(ModuleDemo)\n\n\n3. 如何拥有导入的模块假设有以下模块：\nfoo.py：\nfrom bar import bar_varfoo_var = 1\n\nbar.py：\nfrom foo import foo_varbar_var = 2\n\n问题在于解释器将执行以下步骤：\n\npython 的 main 主函数 import 导入 foo（执行 foo 模块）\n为 foo 创建空的全局变量\nfoo 被编译并开始执行\nfoo 导入 bar （即 from bar import bar_var）\n创建 bar 的空全局变量\nbar 被编译并开始执行\n在 bar 模块中，导入foo（因为前面已经有一个名为foo的模块，所以它是空操作）\nbar.foo_var &#x3D; foo.foo_var\n\n最后一步失败了，因为 Python 尚未完成解释foo，并且的全局符号字典foo仍然为空。\n同样的事情会发生：使用 import foo ，然后在全局代码中访问 foo.foo_var 。\nfoo.py：\nimport barfoo_var = 1\n\nbar.py：\nimport foobar_var = 2print(foo.foo_var) \n\n执行 bar.py 会出现 AttributeError: module &#39;foo&#39; has no attribute &#39;foo_var&#39;。\n\nGuido van Rossum 建议避免使用 from &lt;module&gt; import ... 的所有用法，并将所有代码放在函数中。全局变量和类变量的初始化应仅使用常量或内置函数。这意味着来自导入模块的所有内容都被引用为&lt;module&gt;.&lt;name&gt;。\nJim Roskind建议在每个模块中按以下顺序执行步骤：\n\n导出（不需要导入基类的全局变量，函数和类）\nimport 语句\n激活代码（包括从导入值初始化的全局变量）。\n\nvan Rossum 不太喜欢这种方法，因为这种导入语句会出现在一个奇怪的地方，但是也确实可行。\nMatthias Urlichs建议重组代码，这样一开始就不需要递归导入（循环导入）。\n以上这些解决方案不是互斥的。\nReference\n","categories":["技术","Python"],"tags":["Python"]},{"title":"systemd 管理 Flask 服务实践","url":"/posts/2025/10/19/57786/","content":"背景配置一个用于启动 flask 服务的 sh 脚本方式，start.sh：\n#!/bin/bash# shellcheck disable=SC1090source ~/tools/miniforge3/etc/profile.d/conda.shconda activate vltenvLinuxwhich pythonpython --versionflask --versiongunicorn --versionexport $(grep -v &#x27;^#&#x27; .env | xargs)TIMESTAMP=$(date &#x27;+%Y_%m_%d_%H_%M_%S&#x27;)ENABLE_SCHEDULER=true gunicorn -w 4 -b 0.0.0.0:5001 app:app \\    --access-logfile &quot;logs/gunicorn_access_$&#123;TIMESTAMP&#125;.log&quot; \\    --error-logfile &quot;logs/gunicorn_error_$&#123;TIMESTAMP&#125;.log&quot; \\    --log-level info \\    --timeout 120 \\    --keep-alive 5 \\    --max-requests 1000 \\    --max-requests-jitter 100 \\    --preload\n\n启动方式：nohup ./start.sh &gt;nohup.log 2&gt;&amp;1 &amp;\n转为 systemd 管理step1，创建 systemd 服务文件\n# /home/autotest/vlt/vlt_track(vltenvLinux) [autotest@dgvxl2905 vlt_track]$ cat vlt_track_app.service[Unit]Description=VLT TRACK Flask Application with GunicornAfter=network.target[Service]Type=notifyUser=autotestWorkingDirectory=/home/autotest/vlt/vlt_trackEnvironment=&quot;PATH=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin:/usr/local/bin:/usr/bin:/bin&quot;EnvironmentFile=/home/autotest/vlt/vlt_track/.envEnvironment=&quot;ENABLE_SCHEDULER=true&quot;ExecStart=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn \\    -w 4 \\    -b 0.0.0.0:5000 \\    app:app \\    --access-logfile /home/autotest/vlt/vlt_track/logs/gunicorn_access.log \\    --error-logfile /home/autotest/vlt/vlt_track/logs/gunicorn_error.log \\    --log-level info \\    --timeout 120 \\    --keep-alive 5 \\    --max-requests 1000 \\    --max-requests-jitter 100 \\    --preload# 优雅重启（用于日志轮转）ExecReload=/bin/kill -USR1 $MAINPIDRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target\n\nmkdir -p /home/autotest/vlt/vlt_track/logssudo ln -s /home/autotest/vlt/vlt_track/vlt_track_app.service /etc/systemd/system/vlt_track_app.service\n\nstep2，创建 logrotate 配置\n(base) [root@dgvxl2905 vlt_track]# cd /etc/logrotate.d/(base) [root@dgvxl2905 logrotate.d]# cat vlt_track/home/autotest/vlt/vlt_track/logs/gunicorn_*.log &#123;    su autotest autotest    daily    rotate 30    compress    delaycompress    notifempty    missingok    dateext    dateformat _%Y%m%d    create 0644 autotest autotest    sharedscripts    postrotate    /bin/systemctl reload vlt_track_app.service &gt; /dev/null 2&gt;&amp;1 || true    endscript&#125;\n\n测试 logrotate 配置\n(base) [root@dgvxl2905 logrotate.d]# logrotate -d /etc/logrotate.d/vlt_trackreading config file /etc/logrotate.d/vlt_trackAllocating hash table for state file, size 15360 BHandling 1 logsrotating pattern: /home/autotest/vlt/vlt_track/logs/gunicorn_*.log  after 1 days (30 rotations)empty log files are not rotated, old logs are removedswitching euid to 5991 and egid to 5991considering log /home/autotest/vlt/vlt_track/logs/gunicorn_access_2025_08_06_11_21_11.log  log does not need rotating (log has been already rotated)considering log /home/autotest/vlt/vlt_track/logs/gunicorn_access_2025_08_06_11_48_12.log\n\nstep3，启动服务\nsystemctl daemon-reloadsystemctl start vlt_track_appsystemctl status vlt_track_app\n\n(base) [root@dgvxl2905 vlt_track]# systemctl status vlt_track_app● vlt_track_app.service - VLT TRACK Flask Application with Gunicorn   Loaded: loaded (/home/autotest/vlt/vlt_track/vlt_track_app.service; linked; vendor preset: disabled)   Active: active (running) since Fri 2025-10-17 10:17:41 CST; 2s ago Main PID: 6208 (gunicorn)   Status: &quot;Gunicorn arbiter booted&quot;    Tasks: 8   Memory: 54.3M   CGroup: /system.slice/vlt_track_app.service           ├─6208 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           ├─6213 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           ├─6228 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           ├─6229 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           └─6230 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...Oct 17 10:17:40 dgvxl2905 systemd[1]: Starting VLT TRACK Flask Application with Gunicorn...Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.336 | INFO     | utils.api_scanner:start_scheduler:297 - API扫描-定时任务已启动Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.336 | INFO     | utils.api_scanner:start_scheduler:298 - API扫描-定时任务时间: 1点0分Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.336 | INFO     | utils.api_scanner:init_api_scanner_scheduler:564 - API扫描-定时任务已…PID: 6208)Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.338 | INFO     | utils.statistics_collector:start_scheduler:37 - 统计数据-定时任务已启…PID: 6208)Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.338 | INFO     | utils.statistics_collector:init_statistics_collector_scheduler:70 - …(PID: 6208)Oct 17 10:17:41 dgvxl2905 systemd[1]: Started VLT TRACK Flask Application with Gunicorn.Hint: Some lines were ellipsized, use -l to show in full.\n\n\n\n注意点1. 路径相关常见错误\n# 不要使用 ~ 波浪号WorkingDirectory=~/vlt/vlt_trackEnvironment=&quot;PATH=~/tools/bin:$PATH&quot;# 不要使用相对路径ExecStart=./start.sh# 不要使用环境变量展开WorkingDirectory=$HOME/app\n\n正确做法\n# 必须使用绝对路径WorkingDirectory=/home/autotest/vlt/vlt_trackEnvironment=&quot;PATH=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin:/usr/bin:/bin&quot;ExecStart=/home/autotest/vlt/vlt_track/start.sh\n\n2. 环境变量常见错误\n# 不能在一行中使用 shell 变量引用Environment=&quot;PATH=$CONDA_HOME/bin:$PATH&quot;# 不能导出多个变量在一行Environment=&quot;VAR1=value1 VAR2=value2&quot;# 引号使用错误Environment=PATH=&quot;/usr/bin:/bin&quot;\n\n正确做法\n# 每个变量单独一行Environment=&quot;PATH=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin:/usr/bin:/bin&quot;Environment=&quot;ENABLE_SCHEDULER=true&quot;Environment=&quot;FLASK_ENV=production&quot;# 或使用 EnvironmentFile 读取 .env 文件EnvironmentFile=/home/autotest/vlt/vlt_track/.env# 引号在外面Environment=&quot;PATH=/usr/bin:/bin&quot;\n\n3. Type 类型选择# simple - 最常见，ExecStart 进程就是主进程Type=simple# forking - 进程会 fork 后台运行（如传统 daemon）Type=forkingPIDFile=/var/run/myapp.pid# notify - 进程通过 sd_notify 通知 systemd（gunicorn 支持）Type=notify# oneshot - 执行完就退出的任务Type=oneshotRemainAfterExit=yes\n\n注意：\n\ngunicorn 使用 Type=notify 需要安装 systemd 支持\n如果 gunicorn 没有 systemd 支持，用 Type=simple 代替\n\n4. 用户权限# 指定运行用户User=autotestGroup=autotest# 如果需要提权（不推荐）# User=root# 安全限制NoNewPrivileges=truePrivateTmp=true\n\n注意：\n\n确保用户对 WorkingDirectory 和日志目录有权限\n确保用户对可执行文件有执行权限\n\n5. 重启策略# 总是重启（推荐生产环境）Restart=always# 仅非正常退出时重启Restart=on-failure# 不重启Restart=no# 重启间隔（防止频繁重启）RestartSec=10# 启动失败后重试次数限制StartLimitBurst=5StartLimitIntervalSec=60\n\n6. 服务文件位置# 不推荐：使用软链接可能导致权限问题（这里我觉得，用软连接，方便维护和同步）sudo ln -s /home/autotest/vlt/vlt_track/vlt_track_app.service /etc/systemd/system/# 推荐：直接复制sudo cp vlt_track_app.service /etc/systemd/system/# 或者用户服务（不需要 sudo）mkdir -p ~/.config/systemd/user/cp vlt_track_app.service ~/.config/systemd/user/systemctl --user enable vlt_track_app\n\n注意：\n\n软链接的源文件如果权限不对，systemd 可能拒绝加载\n系统服务放在 /etc/systemd/system/\n用户服务放在 ~/.config/systemd/user/\n\n7. 文件权限# service 文件权限sudo chmod 644 /etc/systemd/system/vlt_track_app.service# 不要给执行权限# ❌ chmod 755 vlt_track_app.service# 执行脚本需要执行权限chmod +x /home/autotest/vlt/vlt_track/start.sh\n\n8. ExecStart 命令常见错误\n# 不能使用 shell 管道、重定向ExecStart=/usr/bin/app &gt; /var/log/app.log 2&gt;&amp;1# 不能使用 &amp;&amp;、||（除非用 shell 包装）ExecStart=/usr/bin/app &amp;&amp; echo &quot;started&quot;# 不能使用环境变量ExecStart=$HOME/bin/app# 反斜杠续行后不能有空格ExecStart=/usr/bin/gunicorn \\        -w 4 \\\n\n正确做法\n# 简单命令ExecStart=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn app:app# 带参数（使用反斜杠续行）ExecStart=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn \\    -w 4 \\    -b 0.0.0.0:5000 \\    app:app# 需要 shell 特性时，用脚本包装ExecStart=/bin/bash /home/autotest/vlt/vlt_track/start.sh\n\n9. 日志管理# 标准输出/错误输出到 journaldStandardOutput=journalStandardError=journal# 或输出到文件（需要配合 Type=simple）StandardOutput=append:/var/log/myapp.logStandardError=append:/var/log/myapp_error.log# 或者完全禁用StandardOutput=null\n\n10. 修改后的操作流程# 1. 修改 service 文件后，必须 reloadsudo systemctl daemon-reload# 2. 重启服务使配置生效sudo systemctl restart vlt_track_app# 3. 检查状态sudo systemctl status vlt_track_app# 4. 查看完整日志（-l 显示完整行）sudo systemctl status vlt_track_app -l# 5. 实时查看日志sudo journalctl -u vlt_track_app -f# 6. 查看启动失败原因sudo journalctl -u vlt_track_app -n 50 --no-pager\n\n11. 依赖关系[Unit]# 在网络就绪后启动After=network.target# 在数据库服务后启动After=postgresql.serviceRequires=postgresql.service# 依赖关系说明：# After - 启动顺序（但不强制依赖）# Requires - 强依赖（依赖服务停止，本服务也停止）# Wants - 弱依赖（依赖服务失败，本服务仍启动）\n\n12. 常见排错# 检查 service 文件语法systemd-analyze verify /etc/systemd/system/vlt_track_app.service# 查看服务依赖树systemctl list-dependencies vlt_track_app# 查看服务启动耗时systemd-analyze blame# 查看某个服务的启动时间systemd-analyze critical-chain vlt_track_app\n\n13. 配置文件名称规范# 推荐命名vlt_track_app.servicemy-web-app.service# 避免使用vlt_track.service (与其他配置中的引用要保持一致)vlt-track-app.service (虽然可以，但下划线更清晰)\n\n14. EnvironmentFile 注意事项# .env 文件格式# 正确DATABASE_URL=postgresql://localhost/dbENABLE_SCHEDULER=true# 错误（不要 export）export DATABASE_URL=postgresql://localhost/db# 错误（不要引号，除非值本身包含空格）DATABASE_URL=&quot;postgresql://localhost/db&quot;\n\n核心原则\n绝对路径优先 - 避免任何路径歧义\n权限最小化 - 用普通用户运行，除非必须 root\n日志要完善 - 便于排查问题\n重启策略 - 生产环境务必配置自动重启\n修改后 reload - daemon-reload 是必须的\n服务名一致性 - service 文件名和引用要匹配\n\n","categories":["技术","Linux"],"tags":["tools","Linux"]},{"title":"从 Node.js 依赖痛点到 Docker 化 CLI：一次跨环境部署的实战记录","url":"/posts/2025/11/25/26198/","content":"问题背景在 Linux 机器上，使用 node.js 开发的某 aicode 工具，需要使用 npm 安装：npm install -g @xxx/aicode-cli --registry=https://npm.xxxx.xyz/，安装过程中出现了一系列报错，包括：在 CentOS 7 等旧系统上运行 Node.js 18+ 时，会遇到 GLIBC 版本过低的问题。\nnode: /lib64/libc.so.6: version `GLIBC_2.27&#x27; not foundnode: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20&#x27; not found\n\n几乎所有在 Linux 上运行的程序（包括 Node.js 运行时）都需要调用 GLIBC 提供的功能，程序在编译时会依赖特定版本的 GLIBC。如果一个程序（例如 Node.js 18+）是针对高版本的 GLIBC 编译的，那么它就无法在安装了低版本 GLIBC 的旧系统（例如 CentOS 7）上运行。试图手动升级 GLIBC 版本非常危险，极易导致整个操作系统崩溃。\n因此，尝试使用 Docker 完全隔离系统依赖来解决问题。\n解决方案1. 创建 DockerfileFROM node:20RUN apt-get update &amp;&amp; apt-get install -y procps &amp;&amp; rm -rf /var/lib/apt/lists/*RUN npm install -g @xxx/aicode-cli --registry=https://npm.xxxx.xyz/WORKDIR /workspaceENTRYPOINT [&quot;aicode&quot;]\n\n说明：\n\n使用 node:20 标准镜像（基于 Debian）\n安装 procps 提供完整的 ps 命令\napt-get 是在容器内运行，与宿主机的 CentOS 无关\n\n2. 构建镜像docker build -t my-aicode .\n\n3. 配置 Bash 函数（支持数据持久化）cat &gt;&gt; ~/.bashrc &lt;&lt; &#x27;EOF&#x27;aicode() &#123;    mkdir -p ~/.aicode-home    docker run -it --rm \\        -v $(pwd):/workspace:z \\        -v ~/.aicode-home:/root:z \\        --network host \\        my-aicode &quot;$@&quot;&#125;EOFsource ~/.bashrc\n\n持久化说明：\n~/.aicode-home 保存工具的配置和数据，宿主机器上保存 aicode 在登录后生成的文件 .xxxinfo，避免需要反复登录。\n使用方式：在命令行中输入 aicode，使用体验与本地安装完全一致。\n\n网络认证问题处理如果工具需要浏览器登录认证，必须使用 --network host 参数，让容器共享宿主机网络栈，使 localhost 回调地址正常工作。\n注意：使用 --network host 时不需要 -p 端口映射参数。\n进阶配置多工具支持# 为不同工具创建独立持久化目录toolname() &#123;    mkdir -p ~/.data-$&#123;FUNCNAME[0]&#125;    docker run -it --rm \\        -v $(pwd):/workspace:z \\        -v ~/.$&#123;FUNCNAME[0]&#125;-data:/root/.config:z \\        --network host \\        my-$&#123;FUNCNAME[0]&#125; &quot;$@&quot;&#125;\n\n查看容器内部（调试用）docker run -it --rm --entrypoint sh my-aicode\n\n常见问题Q: 为什么 Dockerfile 里用 apt-get 而不是 yum？A: Dockerfile 中的命令在容器内执行。node:20 镜像基于 Debian 系统，所以使用 apt-get。宿主机的 CentOS 只负责运行 Docker。\nQ: 数据保存在哪里？A: 通过 -v ~/.aicode-data:/root/.aicode:z 映射到宿主机的 ~/.aicode-data 目录。\nQ: 如何更新工具版本？A: 修改 Dockerfile 中的版本号或删除版本限制，重新执行 docker build。\n优势总结\n完全隔离系统依赖，无需升级宿主机 GLIBC\n数据持久化，配置和缓存不丢失\n使用体验与本地安装一致\n易于维护和版本管理\n\n\n容器化 CLI 解释对于不懂 Node.js 也不熟悉 Docker 的人，我们可以通过“类比”来解释原理，再通过“模式抽象”来总结这种通用做法。\n“把软件连同它运行所需的所有环境，打包进一个随用随丢的盒子里，通过传送门（挂载）处理你手头的数据。”。\n它让复杂的软件安装变得像使用“绿色版&#x2F;免安装版”软件一样简单，且不污染你的系统。\n通俗解释1. 为什么不能直接安装？（“地基不匹配”的问题）想象你在装修房子。\n\n你的电脑（CentOS 7） 是一栋建于 10 年前的老房子，它的地基（操作系统底层依赖，即 GLIBC）是老款式的。\naicode 工具（基于 Node.js 18+） 是一套最新的全智能家居系统。\n冲突点： 这套新系统要求地基必须是“2023 新款抗震地基”。如果你强行在老房子里装这套系统，或者试图强行把老房子的地基挖了换新的，房子（操作系统）可能会塌（崩溃），或者根本装不上。\n\n2. 为什么 Docker 能解决？（“房车”方案）Docker 就像是一辆自给自足的房车。\n\n镜像（Image）： 这辆房车内部已经自带了“2023 新款地基”和那套“全智能家居系统”。它不依赖你老房子的地基，它自带环境。\n隔离： 房车停在你家门口，它内部怎么折腾，都不会影响你老房子的结构。\n\n3. 为什么能在宿主机用？它是怎么“穿墙”的？你可能会问：“既然是在房车里运行，为什么感觉像是在我房子里用一样？”\n这里有两个关键动作：\n\n打通管道（挂载映射 -v）：\n我们在房车和你家之间接了一根管道。\n**-v $(pwd):/workspace**：这意味着，你把当前手头的工作文件（比如一份文档），顺着管道递进房车里。\n**-v ~/.aicode-home:/root**：这是给房车接了个“外置硬盘”，专门存在你家里。这样房车关机后，你的登录信息、配置习惯还能保存在你自己家里，下次开机不用重新设置。\n\n\n遥控器（Bash 函数）：\n那个 aicode() &#123; ... &#125; 的配置，就是一个遥控器。\n当你输入 aicode 时，你并没有真的在本地运行程序。实际上，系统背地里帮你按下了遥控器，启动了门口的房车，让房车干完活，再把结果通过管道递回给你。\n体验： 对你来说，你完全感觉不到房车的存在，你只是下令，然后得到结果。\n\n\n\n场景抽象与通用实践这种模式在技术界通常被称为 “Containerized CLI Tools”（容器化命令行工具） 或 “Shim Wrapper”（垫片封装）。\n1. 核心抽象当我们遇到以下情况时，都可以使用这种模式：\n\n环境依赖冲突： 软件需要的依赖库（Lib）与主机系统版本不兼容。\n洁癖需求： 不想在自己电脑上安装一大堆乱七八糟的语言环境（Node, Python, Go, Java 等）。\n团队统一： 确保所有团队成员使用的工具版本完全一致，不受个人电脑环境影响。\n\n2. 架构图解sequenceDiagram\n    autonumber\n    participant User as 👤 用户\n    participant Host as 💻 宿主机 Shell\n    participant Docker as 🐳 Docker 容器\n    participant Disk as 💾 宿主机磁盘\n\n    User->>Host: 输入命令 `aicode`\n    Note over Host: 触发 .bashrc 中的函数\n    \n    Host->>Docker: 启动容器 (docker run -it --rm)\n    activate Docker\n    \n    Note right of Host: 关键动作：挂载本地目录\n    Docker->>Disk: 读取当前目录 /workspace\n    Docker->>Disk: 加载配置文件 /root\n    \n    Docker->>Docker: 在 Node:20 环境中运行计算\n    \n    Docker->>Disk: 写入结果文件 (持久化)\n    Docker-->>Host: 输出控制台信息\n    \n    deactivate Docker\n    Note over Docker: 任务结束，容器自动销毁\n    \n    Host-->>User: 显示最终结果\n\n3. 通用的实践方式列举除了 Node.js 工具，这种模式广泛应用于以下场景：\n\n\n\n场景分类\n具体案例\n解决的问题\n\n\n\n多版本管理\nTerraform &#x2F; Ansible\n公司的项目 A 需要 Terraform 0.12，项目 B 需要 1.0。直接安装很麻烦，用 Docker 封装两个别名 tf12 和 tf1 即可完美共存。\n\n\n开发环境隔离\nPython &#x2F; Conda\n需要运行一个 AI 模型，依赖复杂的 CUDA 版本和 Python 库。直接把整个环境打包成 Docker，别人想跑代码，不需要自己配半天环境，一行命令搞定。\n\n\n一次性工具\n数据库客户端\n比如你需要连一下 MySQL 数据库，但不想在电脑上安装几百兆的 MySQL 软件。直接 docker run -it --rm mysql mysql-client ...，用完即走，电脑干干净净。\n\n\n编译构建\nJava &#x2F; Maven &#x2F; Gradle\n你的电脑是 Java 17，但有个老项目必须用 Java 8 编译。使用 Docker 里的 Java 8 镜像挂载代码目录进行编译，生成 jar 包后扔回宿主机。\n\n\n安全性沙箱\n运行不明脚本\n网上下载了一个脚本不敢在自己电脑跑？在 Docker 里跑。就算它是病毒，也只能炸掉那个“房车”，你的“老房子”毫发无损。\n\n\n","categories":["技术","Docker"],"tags":["Docker"]},{"title":"有趣有用的小发现","url":"/posts/2025/05/25/30924/","content":"选择超链接部分文本如果想要复制网页中的超链接的部分文本，按住 Alt + 点击拖拽选择，这样不会因为误点击而跳转该网页了。\n留一个操作链接：www.baidu.com ，复制里面的 baidu 。\nchrome 浏览器截屏F12 打开开发调试模式，快捷键 Ctrl+Shift+P ，然后输入“捕获全尺寸屏幕截图” ，就可以直接下载完整网页截图。\n直接输入“截图”，也可以搜索出相关的截图功能。在“运行”-“命令” 可以找到很多功能。\nwin 历史剪切板在 windows 上，win + v 调出 历史剪切板。\n左右水平滑动在 windows 上，按住 Shift + 鼠标滚动 &#x3D; 页面水平滚动。\nJetbrain 系软件支持按住 Shift 键滚动来达到水平滚动的效果。\n双屏切换当前窗口连接了两块屏后，把当前窗口从当前屏幕移动到另一块屏幕：Shift + win + ←/→ 。\nwin + tab 预览所有窗口。\n锁住任务管理器页面众所周知，任务管理器页面的程序位置一直变化个不停，每次想选择一个时，它跳到另一个为止。\n在任务管理器页面，按一下 Ctrl，就可以阻止程序位置变了。\nF7浏览器光标模式F7，打开插入光标浏览，可以让你用键盘选择文本。\n","categories":["生产力","工具"],"tags":["tools"]},{"title":"提升效率和管理的 systemd","url":"/posts/2025/10/04/31611/","content":"背景最近工作频繁和 Linux 打交道，发现一个挺有用的配置：systemd，多次使用到 systemd 的场景：\n\njenkins 启动节点的服务，避免手动执行 nohup、手动重连\ngitlab-runner 的服务，gitlab-runner install 时会创建一个 systemd 服务\n配置 python http 服务，启动一个服务，让其他人可以访问某个目录下的 html 静态文件\n\nsystemd 功能systemd（System Daemon）是 Linux 的系统和服务管理器，用于控制系统启动和后台服务。\n\n统一管理（systemctl start|stop|enable|status）：所有服务用同样的命令\n开机自启（WantedBy=multi-user.target）\n自动重启崩溃的服务（Restart=always）\n日志集成：通过 journalctl 统一查看日志\n依赖控制（After=、Requires=）：可以定义服务启动顺序\n资源限制: 可以限制 CPU、内存等资源\n\n实践场景Jenkins Agent 服务[Unit]Description=Jenkins Agent ServiceAfter=network.target[Service]Type=simpleUser=magnoliaWorkingDirectory=/home/magnolia/jenkins_homeExecStart=/usr/bin/java -jar /home/magnolia/jenkins_home/agent.jar \\    -url http://127.0.0.1:8081/ \\    -secret @/home/magnolia/jenkins_home/secret-file \\    -name linux \\    -webSocket \\    -workDir /home/magnolia/jenkins_home/Restart=on-failureRestartSec=10StandardOutput=journalStandardError=journal[Install]WantedBy=multi-user.target\n\n在用户目录，创建一个 service 文件，软连接到 /etc/systemd/system/ (分离操作系统文件和本地配置)\nsudo ln -s  /home/magnolia/jenkins_home/jenkins-agent.service /etc/systemd/system/jenkins-agent.service\n\nsudo systemctl stop jenkins-agentsudo systemctl daemon-reloadsudo systemctl start jenkins-agentsudo systemctl status jenkins-agentsudo journalctl -u jenkins-agent -f\n\n\n\nGitLab Runner 服务[Unit]Description=GitLab RunnerConditionFileIsExecutable=/usr/local/bin/gitlab-runnerAfter=network.target[Service]StartLimitInterval=5StartLimitBurst=10ExecStart=/usr/local/bin/gitlab-runner &quot;run&quot; &quot;--config&quot; &quot;/etc/gitlab-runner/config.toml&quot; &quot;--working-directory&quot; &quot;/home/tools/gitlab-runner&quot; &quot;--service&quot; &quot;gitlab-runner&quot; &quot;--user&quot; &quot;gitlab-runner&quot;Restart=alwaysRestartSec=120EnvironmentFile=-/etc/sysconfig/gitlab-runner[Install]WantedBy=multi-user.target\n\n\n\nPython HTTP 静态文件服务[Unit]Description=Python HTTP Static File ServerAfter=network.target[Service]Type=simpleUser=autotestWorkingDirectory=/home/autotest/work/auto-doc/doc/build/ExecStart=/usr/bin/python3.6 -m http.server 8000 --bind 0.0.0.0Restart=on-failureRestartSec=5[Install]WantedBy=multi-user.target\n\n\n\nFlask 服务一个用于启动 flask 服务的 sh 脚本方式，start.sh：\n#!/bin/bash# shellcheck disable=SC1090source ~/tools/miniforge3/etc/profile.d/conda.shconda activate vltenvLinuxwhich pythonpython --versionflask --versiongunicorn --versionexport $(grep -v &#x27;^#&#x27; .env | xargs)TIMESTAMP=$(date &#x27;+%Y_%m_%d_%H_%M_%S&#x27;)ENABLE_SCHEDULER=true gunicorn -w 4 -b 0.0.0.0:5001 app:app \\    --access-logfile &quot;logs/gunicorn_access_$&#123;TIMESTAMP&#125;.log&quot; \\    --error-logfile &quot;logs/gunicorn_error_$&#123;TIMESTAMP&#125;.log&quot; \\    --log-level info \\    --timeout 120 \\    --keep-alive 5 \\    --max-requests 1000 \\    --max-requests-jitter 100 \\    --preload\n\n转为 systemd 管理\nstep1，创建 systemd 服务文件\n# /home/autotest/vlt/vlt_track(vltenvLinux) [autotest@dgvxl2905 vlt_track]$ cat vlt_track_app.service[Unit]Description=VLT TRACK Flask Application with GunicornAfter=network.target[Service]Type=notifyUser=autotestWorkingDirectory=/home/autotest/vlt/vlt_trackEnvironment=&quot;PATH=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin:/usr/local/bin:/usr/bin:/bin&quot;EnvironmentFile=/home/autotest/vlt/vlt_track/.envEnvironment=&quot;ENABLE_SCHEDULER=true&quot;ExecStart=/home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn \\    -w 4 \\    -b 0.0.0.0:5000 \\    app:app \\    --access-logfile /home/autotest/vlt/vlt_track/logs/gunicorn_access.log \\    --error-logfile /home/autotest/vlt/vlt_track/logs/gunicorn_error.log \\    --log-level info \\    --timeout 120 \\    --keep-alive 5 \\    --max-requests 1000 \\    --max-requests-jitter 100 \\    --preload# 优雅重启（用于日志轮转）ExecReload=/bin/kill -USR1 $MAINPIDRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target\n\nmkdir -p /home/autotest/vlt/vlt_track/logssudo ln -s /home/autotest/vlt/vlt_track/vlt_track_app.service /etc/systemd/system/vlt_track_app.service\n\nstep2，创建 logrotate 配置\n(base) [root@dgvxl2905 vlt_track]# cd /etc/logrotate.d/(base) [root@dgvxl2905 logrotate.d]# cat vlt_track/home/autotest/vlt/vlt_track/logs/gunicorn_*.log &#123;    su autotest autotest    daily    rotate 30    compress    delaycompress    notifempty    missingok    dateext    dateformat _%Y%m%d    create 0644 autotest autotest    sharedscripts    postrotate    /bin/systemctl reload vlt_track_app.service &gt; /dev/null 2&gt;&amp;1 || true    endscript&#125;\n\n测试 logrotate 配置\n(base) [root@dgvxl2905 logrotate.d]# logrotate -d /etc/logrotate.d/vlt_trackreading config file /etc/logrotate.d/vlt_trackAllocating hash table for state file, size 15360 BHandling 1 logsrotating pattern: /home/autotest/vlt/vlt_track/logs/gunicorn_*.log  after 1 days (30 rotations)empty log files are not rotated, old logs are removedswitching euid to 5991 and egid to 5991considering log /home/autotest/vlt/vlt_track/logs/gunicorn_access_2025_08_06_11_21_11.log  log does not need rotating (log has been already rotated)considering log /home/autotest/vlt/vlt_track/logs/gunicorn_access_2025_08_06_11_48_12.log\n\nstep3，启动服务\nsystemctl daemon-reloadsystemctl start vlt_track_appsystemctl status vlt_track_app\n\n(base) [root@dgvxl2905 vlt_track]# systemctl status vlt_track_app● vlt_track_app.service - VLT TRACK Flask Application with Gunicorn   Loaded: loaded (/home/autotest/vlt/vlt_track/vlt_track_app.service; linked; vendor preset: disabled)   Active: active (running) since Fri 2025-10-17 10:17:41 CST; 2s ago Main PID: 6208 (gunicorn)   Status: &quot;Gunicorn arbiter booted&quot;    Tasks: 8   Memory: 54.3M   CGroup: /system.slice/vlt_track_app.service           ├─6208 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           ├─6213 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           ├─6228 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           ├─6229 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...           └─6230 /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/python /home/autotest/tools/miniforge3/envs/vltenvLinux/bin/gunicorn -w 4 -b 0.0.0.0:...Oct 17 10:17:40 dgvxl2905 systemd[1]: Starting VLT TRACK Flask Application with Gunicorn...Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.336 | INFO     | utils.api_scanner:start_scheduler:297 - API扫描-定时任务已启动Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.336 | INFO     | utils.api_scanner:start_scheduler:298 - API扫描-定时任务时间: 1点0分Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.336 | INFO     | utils.api_scanner:init_api_scanner_scheduler:564 - API扫描-定时任务已…PID: 6208)Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.338 | INFO     | utils.statistics_collector:start_scheduler:37 - 统计数据-定时任务已启…PID: 6208)Oct 17 10:17:41 dgvxl2905 gunicorn[6208]: 2025-10-17 10:17:41.338 | INFO     | utils.statistics_collector:init_statistics_collector_scheduler:70 - …(PID: 6208)Oct 17 10:17:41 dgvxl2905 systemd[1]: Started VLT TRACK Flask Application with Gunicorn.Hint: Some lines were ellipsized, use -l to show in full.\n\nTimer场景：每天凌晨2点自动清理 &#x2F;tmp 目录中的旧文件。\nstep1：创建要执行的脚本\n(base) magnolia@Magnolia:~/tools/systemd_tasks$ sudo vi cleanup-tmp.sh(base) magnolia@Magnolia:~/tools/systemd_tasks$ cat cleanup-tmp.sh#!/bin/bash# 删除 /tmp 目录下 7 天前的文件echo &quot;$(date): 开始清理临时文件...&quot;find /tmp -type f -mtime +7 -deleteecho &quot;$(date): 清理完成！&quot;(base) magnolia@Magnolia:~/tools/systemd_tasks$ sudo chmod +x cleanup-tmp.sh\n\nstep2：创建 Service 文件（定义要做什么）\n(base) magnolia@Magnolia:~/tools/systemd_tasks$ sudo vi cleanup-tmp.service(base) magnolia@Magnolia:~/tools/systemd_tasks$ cat cleanup-tmp.service[Unit]Description=清理临时文件[Service]Type=oneshotExecStart=/home/magnolia/tools/systemd_tasks/cleanup-tmp.sh\n\nstep3：创建 Timer 文件（定义什么时候执行）\n(base) magnolia@Magnolia:~/tools/systemd_tasks$ sudo vi cleanup-tmp.timer(base) magnolia@Magnolia:~/tools/systemd_tasks$ cat cleanup-tmp.timer[Unit]Description=每天凌晨2点清理临时文件[Timer]OnCalendar=*-*-* 02:00:00Persistent=true  # 如果错过了执行时间（比如关机了），开机后会立即执行一次[Install]WantedBy=timers.target(base) magnolia@Magnolia:~/tools/systemd_tasks$ ls -ltotal 12-rw-r--r-- 1 root root 103 Oct  8 10:37 cleanup-tmp.service-rwxr-xr-x 1 root root 166 Oct  8 10:31 cleanup-tmp.sh-rw-r--r-- 1 root root 139 Oct  8 10:40 cleanup-tmp.timer\n\nstep4：软连接到 /etc/systemd/system/\n在用户目录集中管理自定义配置，便于维护，systemd 通过软连接获取\n(base) magnolia@Magnolia:/etc/systemd/system$ sudo ln -s /home/magnolia/tools/systemd_tasks/cleanup-tmp.service  /etc/systemd/system/cleanup-tmp.service(base) magnolia@Magnolia:/etc/systemd/system$ sudo ln -s /home/magnolia/tools/systemd_tasks/cleanup-tmp.timer  /etc/systemd/system/cleanup-tmp.timer(base) magnolia@Magnolia:/etc/systemd/system$ ls -ltotal 48lrwxrwxrwx 1 root root   54 Oct  8 10:54 cleanup-tmp.service -&gt; /home/magnolia/tools/systemd_tasks/cleanup-tmp.servicelrwxrwxrwx 1 root root   52 Oct  8 10:56 cleanup-tmp.timer -&gt; /home/magnolia/tools/systemd_tasks/cleanup-tmp.timer\n\nstep5：启用和管理 Timer\n(base) magnolia@Magnolia:/etc/systemd/system$ sudo systemctl daemon-reload(base) magnolia@Magnolia:/etc/systemd/system$ sudo systemctl enable cleanup-tmp.timerCreated symlink /etc/systemd/system/timers.target.wants/cleanup-tmp.timer → /home/magnolia/tools/systemd_tasks/cleanup-tmp.timer.(base) magnolia@Magnolia:/etc/systemd/system$ sudo systemctl start cleanup-tmp.timer(base) magnolia@Magnolia:/etc/systemd/system$ sudo systemctl status cleanup-tmp.timer● cleanup-tmp.timer - 每天凌晨2点清理临时文件     Loaded: loaded (/etc/systemd/system/cleanup-tmp.timer; enabled; preset: enabled)     Active: active (waiting) since Wed 2025-10-08 10:57:27 CST; 4s ago    Trigger: Thu 2025-10-09 02:00:00 CST; 15h left   Triggers: ● cleanup-tmp.serviceOct 08 10:57:27 Magnolia systemd[1]: Started cleanup-tmp.timer - 每天凌晨2点清理临时文件.(base) magnolia@Magnolia:/etc/systemd/system$ systemctl list-timersNEXT                            LEFT LAST                              PASSED UNIT                         ACTIVATESWed 2025-10-08 15:26:32 CST 4h 28min Wed 2025-10-08 02:40:01 CST 1h 12min ago motd-news.timer              motd-news.serviceWed 2025-10-08 16:23:34 CST 5h 25min Fri 2025-10-03 10:54:44 CST      18h ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.serviceThu 2025-10-09 00:00:00 CST      13h Wed 2025-10-08 00:00:07 CST 1h 19min ago dpkg-db-backup.timer         dpkg-db-backup.serviceThu 2025-10-09 00:00:00 CST      13h Wed 2025-10-08 00:00:07 CST 1h 19min ago logrotate.timer              logrotate.serviceThu 2025-10-09 01:59:50 CST      15h Wed 2025-10-08 08:38:33 CST 1h 11min ago apt-daily.timer              apt-daily.serviceThu 2025-10-09 02:00:00 CST      15h -                                      - cleanup-tmp.timer            cleanup-tmp.serviceThu 2025-10-09 06:47:26 CST      19h Wed 2025-10-08 07:07:45 CST 1h 11min ago apt-daily-upgrade.timer      apt-daily-upgrade.serviceThu 2025-10-09 07:51:38 CST      20h Wed 2025-10-08 02:38:48 CST 1h 13min ago man-db.timer                 man-db.serviceSun 2025-10-12 03:10:17 CST   3 days Sun 2025-10-05 03:25:10 CST      11h ago e2scrub_all.timer            e2scrub_all.service9 timers listed.Pass --all to see loaded but inactive timers, too.(base) magnolia@Magnolia:/etc/systemd/system$ sudo journalctl -u cleanup-tmp.timer -fOct 08 10:57:27 Magnolia systemd[1]: Started cleanup-tmp.timer - 每天凌晨2点清理临时文件.\n\n\n\n\n\n","categories":["技术","Linux"],"tags":["tools","Linux"]},{"title":"将第三方库转换为真正的 pytest 插件","url":"/posts/2025/03/30/25613/","content":"问题背景在使用 pytest 进行测试时，我遇到了这样的错误：\nDefining &#x27;pytest_plugins&#x27; in a non-top-level conftest is no longer supported: It affects the entire test suite instead of just below the conftest as expected.\n\n这个错误通常出现在测试工程的结构中有多层 conftest.py 文件，并且在非顶层的 conftest 中定义了 pytest_plugins。从 pytest 7.0.0 版本开始，这种用法被废弃，因为它会影响整个测试套件而不仅仅是该 conftest.py 以下的测试。\n案例中，测试工程根目录下有一个 conftest.py，其中包含：\npytest_plugins = [&quot;my_python_lib.base.testbase.conftest&quot;]\n\n这里 my_python_lib 是一个自定义的 Python 第三方库，测试工程中的用例需要调用 my_python_lib.base.testbase.conftest 中的 fixture。\n最佳解决方案：将库转换为真正的 pytest 插件将我们的库转换为一个真正的 pytest 插件是最优雅和最可维护的解决方案。这样不仅解决了当前问题，还提高了代码的可复用性和可扩展性。\n步骤 1：重构库结构首先，调整库结构，确保 fixture 代码位于合适的模块中：\nmy_python_lib/├── __init__.py├── base/│   ├── __init__.py│   ├── testbase/│   │   ├── __init__.py│   │   ├── fixture.py  # 将 conftest.py 中的 fixture 移到这里│   │   └── plugin.py   # 新建的插件入口点文件\n\n步骤 2：创建插件入口点文件创建 plugin.py 文件，导入所有 fixture 并定义任何需要的 pytest 钩子：\n# my_python_lib/base/testbase/plugin.pyfrom .fixture import *  # 导入所有的 fixture# 在这里可以定义 pytest 钩子函数def pytest_configure(config):    &quot;&quot;&quot;    pytest 配置阶段被调用的钩子    可以在这里进行全局配置    &quot;&quot;&quot;    pass\n\n步骤 3：修改库的 setup.py在库的 setup.py 中添加 pytest 插件的入口点：\nfrom setuptools import setup, find_packagessetup(    name=&quot;my_python_lib&quot;,    version=&quot;1.0.0&quot;,    packages=find_packages(),    description=&quot;我的测试工具库&quot;,    author=&quot;Your Name&quot;,    author_email=&quot;your.email@example.com&quot;,        # 添加 pytest 插件入口点，这里的 pytest11 是一个固定写法，了解到这个情况的我，感觉这简直“逆天”    entry_points=&#123;        &#x27;pytest11&#x27;: [            &#x27;my_lib = my_python_lib.base.testbase.plugin&#x27;,        ],    &#125;,    # 添加依赖    install_requires=[        &#x27;pytest&gt;=6.0.0&#x27;,        # 其他依赖...    ],)\n\n步骤 4：重新安装库pip uninstall -y my_python_lib  # 先卸载当前版本cd /path/to/my_python_libpip install -e .  # 以开发模式安装\n\n步骤 5：修改测试项目删除测试项目中 conftest.py 中的 pytest_plugins 定义，因为现在插件会自动加载：\n# 测试项目的 conftest.py# 删除这一行：# pytest_plugins = [&quot;my_python_lib.base.testbase.conftest&quot;]# 可以添加其他测试项目特定的 fixturedef pytest_configure(config):    # 测试项目特定的配置    pass\n\n步骤 6：验证插件是否正确安装运行以下命令验证插件是否被正确识别：\npython -m pytest --trace-config\n\n应该能看到类似这样的输出：\npytest11 plugin registration SETUP: my_python_lib.base.testbase.plugin\n\n代码示例fixture.py 示例# my_python_lib/base/testbase/fixture.pyimport pytestimport osimport tempfile@pytest.fixturedef temp_dir():    &quot;&quot;&quot;提供一个临时目录&quot;&quot;&quot;    with tempfile.TemporaryDirectory() as temp_dir:        yield temp_dir@pytest.fixturedef temp_file():    &quot;&quot;&quot;提供一个临时文件&quot;&quot;&quot;    with tempfile.NamedTemporaryFile(delete=False) as temp_file:        file_path = temp_file.name        yield file_path        # 测试后清理    if os.path.exists(file_path):        os.remove(file_path)@pytest.fixturedef sample_data():    &quot;&quot;&quot;提供示例数据&quot;&quot;&quot;    return &#123;        &quot;name&quot;: &quot;test&quot;,        &quot;values&quot;: [1, 2, 3, 4, 5],        &quot;metadata&quot;: &#123;            &quot;version&quot;: &quot;1.0&quot;,            &quot;type&quot;: &quot;test-data&quot;        &#125;    &#125;\n\nplugin.py 完整示例# my_python_lib/base/testbase/plugin.pyfrom .fixture import *def pytest_configure(config):    &quot;&quot;&quot;配置 pytest 环境&quot;&quot;&quot;    config.addinivalue_line(        &quot;markers&quot;, &quot;slow: 标记执行较慢的测试&quot;    )def pytest_addoption(parser):    &quot;&quot;&quot;添加命令行选项&quot;&quot;&quot;    parser.addoption(        &quot;--skip-slow&quot;,        action=&quot;store_true&quot;,        default=False,        help=&quot;跳过标记为 slow 的测试&quot;    )def pytest_collection_modifyitems(config, items):    &quot;&quot;&quot;修改收集的测试项&quot;&quot;&quot;    if config.getoption(&quot;--skip-slow&quot;):        skip_slow = pytest.mark.skip(reason=&quot;跳过慢测试 (--skip-slow 选项)&quot;)        for item in items:            if &quot;slow&quot; in item.keywords:                item.add_marker(skip_slow)\n\n测试示例# 测试文件示例 test_utils.pyimport pytestimport osimport jsondef test_temp_dir_fixture(temp_dir):    &quot;&quot;&quot;测试临时目录 fixture&quot;&quot;&quot;    # 在临时目录创建文件    file_path = os.path.join(temp_dir, &quot;test.txt&quot;)    with open(file_path, &quot;w&quot;) as f:        f.write(&quot;Hello, World!&quot;)        # 验证文件创建成功    assert os.path.exists(file_path)    with open(file_path, &quot;r&quot;) as f:        content = f.read()    assert content == &quot;Hello, World!&quot;@pytest.mark.slowdef test_sample_data_manipulation(sample_data, temp_file):    &quot;&quot;&quot;测试数据操作（标记为慢测试）&quot;&quot;&quot;    # 将示例数据写入临时文件    with open(temp_file, &quot;w&quot;) as f:        json.dump(sample_data, f)        # 读取并验证数据    with open(temp_file, &quot;r&quot;) as f:        loaded_data = json.load(f)        assert loaded_data == sample_data    assert loaded_data[&quot;metadata&quot;][&quot;version&quot;] == &quot;1.0&quot;    assert sum(loaded_data[&quot;values&quot;]) == 15\n\n使用方法安装了这个 pytest 插件后，你可以在任何测试项目中直接使用这些 fixture，无需额外导入或配置：\n\n安装你的库：\npip install my_python_lib\n\n在测试文件中直接使用 fixture：\ndef test_file_operations(temp_dir, temp_file):    # 自动获取临时目录和临时文件    with open(temp_file, &#x27;w&#x27;) as f:        f.write(&#x27;测试内容&#x27;)        assert os.path.exists(temp_file)\n\n使用示例数据 fixture：\ndef test_data_processing(sample_data):    # sample_data 自动可用    assert sample_data[&quot;name&quot;] == &quot;test&quot;    assert len(sample_data[&quot;values&quot;]) == 5\n\n跳过慢测试：\npython -m pytest --skip-slow\n\n运行测试并查看所有可用的标记：\npython -m pytest --markers\n\n这些 fixture 可以组合使用，也可以在自己的 conftest.py 中扩展它们，为它们提供自定义行为。\n优势\n符合 pytest 最佳实践 - 使用官方推荐的插件机制\n避免警告和错误 - 不再使用不推荐的 pytest_plugins 方式\n更好的可发现性 - 自动注册 fixture，无需显式导入\n可配置性 - 可以添加命令行选项和配置项\n模块化 - 更容易维护和扩展\n可重用性 - 可以在多个项目中使用同一套测试工具\n\n总结通过将测试工具库转换为真正的 pytest 插件，我们不仅解决了特定的错误问题，还提高了代码质量和可维护性。这种方法虽然前期工作量稍大，但从长远来看更加健壮，尤其是当测试库需要在多个项目中使用时。\n","categories":["技术","pytest"],"tags":["pytest"]}]